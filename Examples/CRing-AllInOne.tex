\documentclass[11pt]{book}

% ============================ other/packages.tex
%\usepackage{amsthm}
\usepackage{amsmath}
% \usepackage{hyperref}
\usepackage[amsmath, thmmarks]{ntheorem}
\usepackage[capitalize]{cleveref}
\usepackage{amscd}
\usepackage{url}
\usepackage[top=1.3in, bottom=1.3in, left=1.3in, right=1.3in]{geometry}

% header and footer
\usepackage{fancyhdr}
\fancyhead{}
\fancyhead[CO,CE]{\itshape \name, \S\thechapter.\arabic{section}.}
\fancyfoot{}
\fancyfoot[CE,CO]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\headheight = 12pt

\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{stackrel}
\usepackage{mathrsfs}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{xy}
% \input xy
\xyoption{all}
\usepackage{titlesec}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\titleformat{\chapter}[display]{ \LARGE \bfseries \centering}{Chapter \
\textbf{\arabic{chapter}}}{3pt}{}[\hrule]
\titleformat{\section}{\Large \bfseries}{\S \arabic{section}}{10pt}{}


% ============================ other/macros.tex
\newcommand{\lecture}[1]{}
\newcommand{\rad}{\operatorname{rad}}
\newcommand{\im}{\operatorname{Im}}
\newcommand{\proj}{\operatorname{Proj}}
\renewcommand{\hom}{\operatorname{Hom}}
\newcommand{\id}{\operatorname{id}}
\providecommand{\cal}[1]{\mathcal{#1}}
\renewcommand{\cal}[1]{\mathcal{#1}}
\newcommand{\et}{\mathrm{Et}}
\renewcommand{\rad}{\operatorname{Rad}}
\newcommand{\supp}{\operatorname{supp}}
\renewcommand{\k}{\kappa}
\newcommand{\ann}{\operatorname{Ann}}
\newcommand{\ass}{\operatorname{Ass}}
\newcommand{\pic}{\operatorname{Pic}}
\newcommand{\cart}{\operatorname{Cart}}
\newcommand{\weil}{\operatorname{Weil}}
\newcommand{\krdim}{\operatorname{Krdim}}
\newcommand{\emdim}{\operatorname{Emdim}}
\newcommand{\Hom}{\operatorname{Hom}}
\renewcommand{\a}{{a}}
\renewcommand{\b}{{b}}
%\renewcommand{\c}{\mathbf{c}}
\renewcommand{\d}{{d}}
\newcommand{\e}{{e}}
\newcommand{\g}{{g}}
\newcommand{\het}{\operatorname{height}}
\newcommand{\f}{{f}}
\newcommand{\add}[1]{\textbf{TO BE ADDED:} #1}
\newcommand{\spec}{\operatorname{Spec}}
\newcommand{\cont}{\operatorname{Cont}}
\DeclareMathOperator{\Emb}{\text{Emb}}
\DeclareMathOperator{\Aut}{\text{Aut}}
\DeclareMathOperator{\Char}{\text{char}}
\DeclareMathOperator{\Gal}{\text{Gal}}
\DeclareMathOperator{\Tor}{\text{Tor}}
\DeclareMathOperator{\idem}{\text{Idem}}
\newcommand{\res}{\operatorname{Res}}
\newcommand{\coker}{\operatorname{Coker}}
\newcommand{\hearts}{\heartsuit}
\newcommand{\Ext}{\operatorname{Ext}}
\newcommand{\Tr}{\operatorname{Tr}}
\newcommand{\Specm}{\operatorname{Specm}}
\newcommand{\Ann}{\operatorname{Ann}}
\newcommand{\tor}{\operatorname{Tor}}
\newcommand{\ext}{\operatorname{Ext}}
\newcommand{\End}{\operatorname{End}}
\newcommand{\ob}{\operatorname{ob}}

\newenvironment{xyxy}[1]{\vspace{10pt}\\ \centerline{\xymatrix{#1}}\vspace{12pt} }{}
\newenvironment{qu}[2]
{\begin{list}{}
	  {\setlength\leftmargin{#1}
	  \setlength\rightmargin{#2}}
	  \item[]\footnotesize}
		  {\end{list}}
\newenvironment{random}[1]{\hspace{0pt}\vspace{10pt}\\\textbf{#1}}{}
\newenvironment{liszt}[1]{ \begin{list}{\labelitemi}{\leftmargin=#1em} \itemsep=0.1in} {\end{list}}

\newcommand{\ad}{\mathrm{ad}}
\renewcommand{\log}{\mathrm{log}}
\renewcommand{\dim}{\mathrm{dim}}
\newcommand{\dd}[2]{\frac{\partial #1}{\partial #2}}
\renewcommand{\qedsymbol}{\textbf{\large $\mathscr{Q.E.D.}$}}
\newcommand{\sqxx}[4]{\begin{xyxy}{ #1 \ar[r] \ar[d] & #2 \ar[d] \\ #3 \ar[r] & #4  }\end{xyxy}}

\newcommand{\gr}{\operatorname{gr}}
\newcommand{\st}{\ss : \ss}
\newcommand{\Sym}{\mathrm{Sym}}
\newcommand{\depth}{\operatorname{depth}}

% ============================ other/theoremdef.tex
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{sublemma}[theorem]{Sublemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theorembodyfont{\normalfont}
\newtheorem{definition}[theorem]{Definition}
\newtheorem*{remark}{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}{\sc Exercise}[chapter]
\newtheorem*{solution}{Solution}
\newtheorem*{question}{Question}
\newtheorem*{problem}{Problem}
\newtheorem*{dbend}{Dangerous bend}
\newtheorem*{prediction}{Prediction}

\theoremheaderfont{\itshape}
\theoremseparator{.}
\theoremsymbol{\ensuremath{\blacktriangle}}
\newtheorem*{proof}{Proof}


% ============================ other/formatting.tex
\renewcommand{\thesection}{\arabic{section}}

% ============================ other/weirdstuff.tex
%% this file is for things that cannot go in the individual chapters, but only
%% in the main document

\newcommand{\rref}[1]{\cref{#1}}


\def\name{The CRing Project}

% ============================ other/titlepage.tex
\def\textline#1{%
  \hbox to \hsize{%
    \vbox{\centering #1}}}%

\def\maketitle{%
  \null
  \pagestyle{empty}%
  \vbox to .9\vsize{%
    \vss
    \vbox to 1\vsize{%
      \vfill
      \textline{{\LARGE \name}\\\ \\%
      A collaborative, open source textbook on commutative algebra.\\\ \\%
      \url{http://people.fas.harvard.edu/~amathew/cr.html}}
      \vfill
      \textline{%
        \begin{tabular}{l}
          The following people have contributed to this work.
        \end{tabular}}
      \vspace{5mm}
      \textline{%
        \begin{tabular}{l}
          Shishir Agrawal\\
Eva Belmont\\
Zev Chonoles\\
Rankeya Datta\\
Anton Geraschenko\\
Sherry Gong\\
Fran\c{c}ois Greer\\
Darij Grinberg\\
Aise Johan de Jong\\
Adeel Ahmad Khan\\
Holden Lee\\
Geoffrey Lee\\
Akhil Mathew\\
Ryan Reich\\
William Wright\\
Moor Xu\\
        \end{tabular}
      }
    }%
    \vss
  }
}
\makeatother

\begin{document}
\maketitle

% ============================ other/intro.tex
%% THIS IS THE INTRODUCTORY MATERIAL
\nocite{*}

\chapter*{Introduction}

This is a massively collaborative, open source textbook on commutative
algebra. The project is currently in its infancy, and needs contributions!

The latest version of this document, along with its \LaTeX\ source code, is
available at \url{http://people.fas.harvard.edu/~amathew/cr.html}.

\section*{License}

Copyright (C) 2010 CRing Project.  Permission is granted to copy, distribute
and/or modify this document under the terms of the GNU Free Documentation
License, Version 1.2 or any later version published by the Free Software
Foundation; with no Invariant Sections, no Front-Cover Texts, and no
Back-Cover Texts. A copy of the license is included in the section entitled
``GNU Free Documentation License''.

\section*{Prerequisites}

This book is intended to be accessible to undergraduates. The prerequisite is
a basic acquaintance with modern algebra. While even the notion of a ring is
introduced from scratch, it is done so rather rapidly, and the reader is
advised to consult another source. In addition, we do not hesitate to use the
language of categories, which is developed in Chapter~\ref{categorychapter}.
The book is intended to provide preparation to study textbooks on algebraic
geometry such as \cite{Ha77}.

\section*{The project}

This project was started by several undergraduates in an attempt to create
a collaborative, open source textbook on commutative algebra.  It started with
a collection of class notes ``live-\TeX ed'' by Akhil Mathew taken in a course
 taught by Jacob Lurie at Harvard in the fall of 2010. The idea for the
 present project came
from the Stacks project \cite{St10}.

The main website for this project is
\url{http://people.fas.harvard.edu/~amathew/cr.html}. In addition, there is a
git repository at \url{http://cring.adeel.ru}. The git repository provides
slightly newer versions of the source code and contains a log of revisions.

Discussion of the CRing project can happen at the  blog,
\url{http://cringproject.wordpress.com}.

\section*{Corrections}

Please email corrections to \texttt{cring.project@gmail.com}.

\section*{Contributions}

The following people have contributed to this work.

\vspace{5mm}
\textline{
  \begin{tabular}{l}
    Shishir Agrawal\\
Eva Belmont\\
Zev Chonoles\\
Rankeya Datta\\
Anton Geraschenko\\
Sherry Gong\\
Fran\c{c}ois Greer\\
Darij Grinberg\\
Aise Johan de Jong\\
Adeel Ahmad Khan\\
Holden Lee\\
Geoffrey Lee\\
Akhil Mathew\\
Ryan Reich\\
William Wright\\
Moor Xu\\
  \end{tabular}
}
\vspace{5mm}

A list of contributions submitted via email is be maintained at
\url{http://people.fas.harvard.edu/~amathew/contrib.html}.
They will also be accessible in the git logs.

\section*{How to contribute}

To contribute, email submissions to \texttt{cring.project@gmail.com}.
Contributions do not have to be polished; they can be rough sketches written
for any purpose at all---half-finished homework writeups, term papers, blog
posts, and others are all welcome.

Contributions in editing the chapters are also welcome. To do this, simply
download the source, edit the files, and email the modifications to the same
address.

\section*{Acknowledgments}

We thank Aise Johan de Jong for helpful advice and a blog link.

\section*{Version}

This file was last updated September 29, 2011.

\tableofcontents


\frontmatter

\mainmatter
\pagestyle{fancy}

\part{Fundamentals}
% ============================ chapters/categories.tex
\setcounter{chapter}{-1}
\chapter{Categories}
\label{categorychapter}


The language of categories is not strictly necessary to understand the basics
of  commutative
algebra. Nonetheless, it is extremely convenient and powerful. It will clarify
many of the constructions made in the future when we can freely use terms like
``universal property'' or ``adjoint functor.'' As a result, we begin this book
with a brief introduction to category theory. We only scratch the surface; the
interested reader can pursue further study in \cite{Ma98} or \cite{KS05}.


Nonetheless, the reader is advised not to take the present chapter too
seriously; skipping it for the moment to chapter 1 and returning here as a
reference could be quite reasonable.

\section{Introduction}

\subsection{Definitions}

Categories are supposed to be places where mathematical objects live.
Intuitively, to any given type of structure (e.g. groups, rings, etc.),
there should be a
category of objects with that structure. These are not, of course, the only
type of categories, but they will be the primary ones of concern to us in this
book.


The basic idea of a category is that there should be objects, and that one
should be able to map between objects. These mappings could be functions, and
they often are, but they don't have to be. Next, one has to be able to compose
mappings, and associativity and unit conditions are required. Nothing else is required.

\begin{definition}
A \textbf{category} $\mathcal{C}$ consists of:
\begin{enumerate}
\item  A collection of \textbf{objects},
$\ob \mathcal{C}$.
\item For each pair of objects $X, Y \in
\ob \mathcal{C}$, a set
of \textbf{morphisms} $\hom_{\mathcal{C}}(X, Y)$ (abbreviated $\hom(X,Y)$).
\item For each object $X \in \ob\mathcal{C}$, there is an \textbf{identity
morphism}
$1_X \in \hom_{\mathcal{C}}(X, X)$ (often just abbreviated to $1$).
\item There is a \textbf{composition law}
$\circ: \hom_{\mathcal{C}}(X, Y) \times \hom_{\mathcal{C}}(Y, Z) \to
\hom_{\mathcal{C}}(X, Z), (g, f) \to g
\circ f$ for every
triple $X, Y, Z$ of objects.
\item  The composition law is unital  and associative.
In other words, if $f \in \hom_{\mathcal{C}}(X, Y)$, then $1_Y \circ f = f
\circ 1_X = f$. Moreover, if $g \in \hom_{\mathcal{C}}(Y, Z)$ and $h \in
\hom_{\mathcal{\mathcal{C}}}(Z, W)$ for objects $Z, Y, W$, then
\[ h \circ (g \circ f) = (h \circ g) \circ f \in \hom_{\mathcal{C}}(X, W).   \]
\end{enumerate}
\end{definition}

We shall write $f: X \to Y$ to denote an element of $\hom_{\mathcal{C}}(X, Y)$.
In practice, $\mathcal{C}$ will often be the storehouse for mathematical objects: groups, Lie algebras,
rings, etc., in which case these ``morphisms'' will just be ordinary functions.

Here is a simple list of examples.
\begin{example}[Categories of structured sets]
\begin{enumerate}
\item $\mathcal{C}  = \mathbf{Sets}$; the objects are sets, and the morphisms
are functions.
\item $\mathcal{C} = \mathbf{Grps}$; the objects are groups, and the morphisms
are maps of groups (i.e. homomorphisms).
\item $\mathcal{C} = \mathbf{LieAlg}$; the objects are Lie algebras, and the
morphisms are maps of Lie algebras (i.e. homomorphisms).\footnote{Feel free to
omit if the notion of Lie algebra is unfamiliar.}
\item  $\mathcal{C} = \mathbf{Vect}_k$; the objects are vector spaces over a
field $k$, and the morphisms are linear maps.
\item $\mathcal{C} = \mathbf{Top}$; the objects are topological spaces, and the
morphisms are continuous maps.
\item  This example is slightly more subtle. Here the category $\mathcal{C}$
has objects consisting of topological spaces, but the morphisms between two
topological spaces $X,Y$ are the \emph{homotopy classes} of maps $X \to Y$.
Since composition respects homotopy classes, this is well-defined.
\end{enumerate}
\end{example}



In general, the objects of a category do not have to form a set; they can
be too large for
that.
For instance, the collection of objects in $\mathbf{Sets}$ does not form a set.


\begin{definition}
A category is \textbf{small} if the collection of objects is a set.
\end{definition}

The standard examples of categories are the ones above: structured sets
together with structure-preserving maps. Nonetheless, one can easily give
other examples that are not of this form.

\begin{example}[Groups as categories] \label{BG}
Let $G$ be a finite group. Then we can make a category $B_G$ where the objects
just consist of one element $\ast$ and the maps $\ast \to \ast$ are the elements
 $g \in G$. The identity is the identity of $G$ and composition is multiplication
in the group.

In this case, the category does not represent much of  a class of objects, but
instead we think of the composition law as the key thing. So a group is a
special kind of (small) category.
\end{example}

\begin{example}[Monoids as categories]
A monoid is precisely a category with one object. Recall that a \textbf{monoid}
is a set together with  an associative and unital multiplication (but which
need not have inverses).
\end{example}


\begin{example}[Posets as categories] \label{posetcategory} Let $(P, \leq)$ be a partially ordered
 (or even preordered) set (i.e. poset). Then $P$ can be regarded as a (small) category, where the objects are the elements
$p \in P$, and $$\hom_P(p, q) = \begin{cases}
\ast & \text{if } p \leq q \\
\emptyset & \text{otherwise}
 \end{cases} $$
\end{example}

There is, however, a major difference between category theory and set theory.
There is \textbf{nothing} in the language of categories that lets one look
\emph{inside} an object. We think of vector spaces having elements, spaces
having points, etc.
By contrast, categories treat these kinds of things as invisible. There
is nothing ``inside'' of an object $X \in \mathcal{C}$; the only way to
understand $X$ is
to understand the ways one can map into and out of $X$.
Even if one is working with  a category of ``structured sets,'' the underlying
set of an object in this category is not part of the categorical data.
However, there are instances in which the ``underlying set'' can be recovered
as a $\hom$-set.

\begin{example}
In the category $\mathbf{Top}$ of topological spaces, one can in fact recover the
``underlying set'' of a topological space via the hom-sets. Namely, for each
topological space, the points of $X$ are the same thing as the mappings from a
one-point space into $X$.
That is, we have
\[ |X| = \hom_{\mathbf{Top}}(\ast, X),  \]
where $\ast$ is the one-point space.

Later we will say that the functor assigning to each
space its underlying set is \emph{corepresentable.}
\end{example}

\begin{example}
Let $\mathbf{Ab}$ be the category of abelian groups and group-homomorphisms. Again, the claim is that
using only this category, one can recover the underlying set of a given abelian
group $A$. This is because the elements of $A$ can be canonically identified
with \emph{morphisms} $\mathbb{Z} \to A$ (based on where $1 \in \mathbb{Z}$
maps).
\end{example}


\begin{definition}
We say that $\mathcal{C}$ is a \textbf{subcategory} of the category
$\mathcal{D}$ if the collection of objects of $\mathcal{C}$ is a subclass of
the collection of objects of $\mathcal{D}$, and if whenever
$X, Y \in \mathcal{C}$, we have
\[ \hom_{\mathcal{C}}(X, Y) \subset \hom_{\mathcal{D}}(X, Y)  \]
with the laws of composition in $\mathcal{C}$ induced by that in $\mathcal{D}$.

$\mathcal{C}$ is called a \textbf{full subcategory} if $\hom_{\mathcal{C}}(X,
Y) = \hom_{\mathcal{D}}(X, Y)$ whenever $X, Y \in \mathcal{C}$.
\end{definition}


\begin{example}
The category of abelian groups is a full subcategory of the category of groups.
\end{example}


\subsection{The language of commutative diagrams}

While the language of categories is, of course, purely algebraic, it will be
convenient for psychological reasons to visualize categorical arguments
through diagrams.
We shall introduce this notation here.

Let $\mathcal{C}$ be a category, and let $X, Y$ be objects in $\mathcal{C}$.
If $f \in \hom(X, Y)$, we shall sometimes write $f$ as an arrow
\[ f: X \to Y  \]
or
\[ X \stackrel{f}{\to} Y \]
as if $f$ were an actual function.
If $X \stackrel{f}{\to} Y$ and $Y \stackrel{g}{\to} Z$ are morphisms,
composition $g \circ f: X \to Z$ can be visualized by the picture
\[ X \stackrel{f}{\to} Y \stackrel{g}{\to} Z.\]

Finally, when we work with several objects, we shall often draw collections of
morphisms into diagrams, where arrows indicate morphisms between two objects.
\begin{definition}
A diagram will be said to \textbf{commute} if whenever one goes from one
object in the diagram to another by following the arrows in the right order,
one obtains the same morphism.
For instance, the commutativity of the diagram
\[ \xymatrix{
X \ar[d]^f \ar[r]^{f'} &  W \ar[d]^g \\
Y \ar[r]^{g'} &  Z
}\]
is equivalent to the assertion that
\[ g \circ f' = g' \circ f \in \hom(X, Z).  \]
\end{definition}


As an example, the assertion that the associative law holds in a category
$\mathcal{C}$ can be stated as follows. For every quadruple $X, Y, Z, W \in
\mathcal{C}$, the following diagram (of \emph{sets}) commutes:
\[ \xymatrix{
\hom(X, Y) \times \hom(Y, Z) \times \hom(Z, W) \ar[r] \ar[d]  & \hom(X, Z)
\times \hom(Z, W) \ar[d]  \\
\hom(X,Y) \times \hom(Y, W) \ar[r] &  \hom(X, W).
}\]
Here the maps are all given by the composition laws in $\mathcal{C}$.
For instance, the downward map to the left is the product of the identity on
$\hom(X, Y)$ with the composition law $\hom(Y, Z) \times \hom(Z, W) \to \hom(Y,
W)$.
\subsection{Isomorphisms}

Classically, one can define an isomorphism of groups as a bijection that
preserves the group structure. This does not generalize well to categories, as
we do not have a notion of ``bijection,'' as there is no way (in general) to
talk about the ``underlying set'' of an object.
Moreover, this definition does not generalize well to topological spaces:
there, an isomorphism should not just be a bijection, but something which
preserves the topology (in a strong sense), i.e. a homeomorphism.


Thus we make:

\begin{definition}
An \textbf{isomorphism} between objects $X, Y$ in a category $\mathcal{C}$ is a
map $f: X \to Y$ such that there exists $g: Y \to X$ with
\[ g \circ f = 1_X, \quad f \circ g = 1_Y.  \]

Such a $g$ is called an \textbf{inverse} to $f$. \end{definition}

\begin{remark}
It is easy to check that the inverse $g$ is
unique. Indeed, suppose $g, g'$ both were inverses to $f$. Then
\[ g' = g' \circ 1_Y = g' \circ (f \circ g) = (g' \circ f) \circ g = 1_X
\circ g = g.  \]
\end{remark}

This notion is isomorphism is more correct than the idea of being one-to-one and onto. A bijection of
topological spaces is not necessarily a homeomorphism.


\begin{example}
It is easy to check that an isomorphism in the category $\mathbf{Grp}$ is an
isomorphism of groups, that an isomorphism in the category $\mathbf{Set}$ is a
bijection, and so on.
\end{example}

We are supposed to be able to identify isomorphic objects. In the categorical
sense, this means mapping into $X$ should be the same as mapping into $Y$, if
$X, Y$ are isomorphic, via an isomorphism $f: X \to Y$.
Indeed, let
$Z$ be another object of $\mathcal{C}$.
Then we can define a map
\[ \hom_{\mathcal{C}}(Z, X) \to \hom_{\mathcal{C}}(Z, Y)  \]
given by post-composition with $f$. This is a \emph{bijection} if $f$ is an
isomorphism (the inverse is given by postcomposition with the inverse to $f$).
Similarly, one can easily see that mapping \emph{out of} $X$ is essentially the
same as mapping out of $Y$.
Anything in general category theory that is true for $X$ should be true for $Y$
(as general category theory can only try to understand $X$ in terms of maps
into or out of it!).

\begin{exercise}
The relation ``$X, Y$ are isomorphic'' is an equivalence relation on the class
of objects of a category $\mathcal{C}$.
\end{exercise}

\begin{exercise}
Let $P$ be a preordered set, and make $P$ into a category as in
\cref{posetcategory}. Then $P$ is a poset if and only if two isomorphic objects
are equal.
\end{exercise}

For the next exercise, we need:
\begin{definition}
A \textbf{groupoid} is a category where every morphism is an isomorphism.
\end{definition}
\begin{exercise}
 The
sets $\hom_{\mathcal{C}}(A, A)$ are \emph{groups} if $\mathcal{C}$ is a
groupoid and $A \in \mathcal{C}$. A group is essentially the same as a groupoid
with one object.
\end{exercise}

\begin{exercise}

Show that the following is a groupoid. Let $X$ be a topological space, and let
$\Pi_1(X)$ be the category defined as follows: the objects are elements of $X$,
and morphisms $x \to y$ (for $x,y \in X$) are homotopy classes of maps $[0,1]
\to X$ (i.e. paths) that send $0 \mapsto x, 1 \mapsto y$. Composition of maps
is given by concatenation of paths.
(Check that, because one is working with \emph{homotopy classes} of paths,
composition is associative.)

$\Pi_1(X)$ is called the \textbf{fundamental groupoid} of $X$. Note that
$\hom_{\Pi_1(X)}(x, x)$ is the \textbf{fundamental group} $\pi_1(X, x)$.
\end{exercise}

\section{Functors}

A functor is a way of mapping from one category to another: each object is sent
to another object, and each morphism is sent to another morphism. We shall
study many functors in the sequel: localization, the tensor product, $\hom$,
and fancier ones like $\tor, \ext$, and local cohomology functors.
The main benefit of a functor is that it doesn't simply send objects to
other objects, but also morphisms to morphisms: this allows one to get new commutative
diagrams from old ones.
This will turn out to be a powerful tool.


\subsection{Covariant functors}
Let $\mathcal{C}, \mathcal{D}$ be categories. If $\mathcal{C}, \mathcal{D}$
are categories of structured sets (of possibly different types), there may be a
way to associate objects in $\mathcal{D}$ to objects in $\mathcal{C}$. For
instance, to every group $G$ we can associate its \emph{group ring}
$\mathbb{Z}[G]$
 (which we do not define here); to each topological space we can associate its
 \emph{singular chain complex}, and so on.
In many cases, given a map between objects in $\mathcal{C}$ preserving the
relevant structure, there will be an induced map on the corresponding objects
in $\mathcal{D}$. It is from here that we define a \emph{functor.}

\begin{definition} \label{covfunc}
A \textbf{functor} $F: \mathcal{C} \to \mathcal{D}$ consists of a function $F:
\mathcal{C} \to  \mathcal{D}$ (that is, a rule that assigns to each object
in $\mathcal{C}$ an object of $\mathcal{D}$) and, for each pair $X, Y \in
\mathcal{C}$,
a map
$F: \hom_{\mathcal{C}}(X, Y) \to \hom_{\mathcal{D}}(FX, FY)$, which preserves
the identity
maps and composition.

In detail, the last two conditions state the following.
\begin{enumerate}
\item  If $X \in
\mathcal{C}$, then $F(1_X)$ is the identity morphism $1_{F(X)}: F(X) \to
F(X)$.
\item  If $A \stackrel{f}{\to} B \stackrel{g}{\to} C$ are
morphisms in $\mathcal{C}$,
then $F(g \circ f) = F(g) \circ F(f)$ as morphisms $F(A) \to F(C)$.
Alternatively, we can say that $F$ \emph{preserves commutative diagrams.}
\end{enumerate}
\end{definition}

In the last statement of the definition, note that if
\[ \xymatrix{
X \ar[rd]^h \ar[r]^f &  Y \ar[d]^g \\
 & Z
}\]
is a commutative diagram in $\mathcal{C}$, then the diagram obtained by
applying the functor $F$, namely
\[ \xymatrix{
F(X) \ar[rd]^{F(h)} \ar[r]^{F(f)} &  F(Y) \ar[d]^{F(g)} \\
 & F(Z)
}\]
also commutes. It follows that applying $F$ to more complicated commutative
diagrams also yields new commutative diagrams.


Let us give a few examples of functors.

\begin{example}
There is a functor from $\mathbf{Sets} \to \mathbf{AbelianGrp}$ sending a set
$S$ to the free abelian group on the set. (For the definition of a free abelian
group, or more generally a free $R$-module over a ring $R$, see
\cref{freemoduledef}.)
\end{example}

\begin{example} \label{pi0}
Let $X$ be a topological space. Then to it we can associate the set $\pi_0(X)$
of \emph{connected components} of $X$.

Recall that the continuous image of a
connected set is connected, so if $f: X \to Y$ is a continuous map and $X'
\subset X$ connected, $f(X')$ is contained in a connected component of $Y$. It
follows that $\pi_0$ is a functor $\mathbf{Top} \to \mathbf{Sets}$.
In fact, it is a functor on the \emph{homotopy category} as well, because
homotopic maps induce the same maps on $\pi_0$.
\end{example}


\begin{example}
Fix $n$.
There is a functor from $\mathbf{Top} \to \mathbf{AbGrp}$
(categories of topological spaces and abelian groups) sending a
space $X$ to its  $n$th homology group $H_n(X)$. We know that given a map of spaces
$f: X \to Y$,
we get a map of abelian groups $f_*: H_n(X) \to H_n(Y)$. See \cite{Ha02}, for
instance.
\end{example}

We shall often need to compose functors. For instance, we will want to see, for
instance, that the \emph{tensor product} (to be defined later, see
\cref{sec:tensorprod}) is
associative, which is really a statement about composing functors. The
following (mostly self-explanatory) definition elucidates this.

\begin{definition}\label{composefunctors}
If $\mathcal{C}, \mathcal{D}, \mathcal{E}$ are categories, $F: \mathcal{C} \to
\mathcal{D}, G: \mathcal{D} \to \mathcal{E}$ are covariant functors, then one
can define a \textbf{composite functor}
\[ F \circ G: \mathcal{C}  \to \mathcal{E}  \]
This sends an object $X \in \mathcal{C}$ to $G(F(X))$.
Similarly, a morphism $f :X \to Y$ is sent to $G(F(f)): G(F(X)) \to G(F(Y))$.
We leave the reader to check that this is well-defined.
\end{definition}




\begin{example}\label{categoryofcats}
In fact, because we can compose functors, there is a \emph{category of
categories.} Let $\mathbf{Cat}$ have objects as the small categories, and
morphisms as functors. Composition is defined as in \cref{composefunctors}.
\end{example}


\begin{example}[Group actions] \label{groupact} Fix a group $G$.
Let us understand what  a functor $B_G \stackrel{}{\to} \mathbf{Sets}$ is. Here $B_G$ is the
category  of \cref{BG}.

The unique object $\ast$ of $B_G$ goes to some set $X$. For each element $g \in G$, we
get a map $g: \ast \to \ast$ and thus a map $X \to X$. This is supposed to
preserve the composition law (which in $G$ is just multiplication), as well as
identities.

In particular, we get maps $i_g: X \to X$ corresponding to each $g \in G$, such
that the following diagram commutes for each $g_1, g_2 \in G$:
\[ \xymatrix{
X \ar[r]^{i_{g_1}} \ar[rd]_{i_{g_1g_2}} & X \ar[d]^{i_{g_2}} \\ & X.
}\]
Moreover, if $e \in G$ is the identity, then $i_e = 1_X$.
So a functor $B_G \to \mathbf{Sets}$ is just a left $G$-action on a set $X$.
\end{example}



An important example of functors is given by the following. Let $\mathcal{C}$
be a category of ``structured sets.'' Then, there is a functor $F: \mathcal{C}
\to \textbf{Sets}$ that sends  a structured set to the underlying set. For
instance, there is a functor from groups to sets that forgets the group
structure.
More generally, suppose given two categories $\mathcal{C}, \mathcal{D}$, such
that $\mathcal{C}$ can be regarded as ``structured objects in $\mathcal{D}$.''
Then there is a functor $\mathcal{C} \to \mathcal{D}$ that forgets the
structure.
Such examples are called \emph{forgetful functors.}

\subsection{Contravariant functors}
Sometimes what we have described above are called \textit{covariant functors}.
Indeed, we shall also be interested in similar objects that reverse the
arrows, such as duality functors:

\begin{definition}
A \textbf{contravariant functor}  $\mathcal{C}
\stackrel{F}{\to}\mathcal{D}$ (between categories $\mathcal{C}, \mathcal{D}$)
is similar
data as in \cref{covfunc} except that now a map $X \stackrel{f}{\to} Y$ now
goes to a map $F(Y)
\stackrel{F(f)}{\to} F(X)$. Composites
are required to be preserved, albeit in the other direction.
In other words, if $X \stackrel{f}{\to} Y, Y \stackrel{g}{\to} Z$ are
morphisms, then we require
\[ F ( g \circ f) = F(f) \circ F(g): F(Z) \to F(X).  \]
\end{definition}

We shall sometimes  say just ``functor'' for \emph{covariant functor}. When we are
dealing with a contravariant functor, we will always say the word
``contravariant.''


A contravariant functor also preserves commutative diagrams, except that the
arrows have to be reversed. For instance, if $F: \mathcal{C} \to \mathcal{D}$
is contravariant and the diagram
\[ \xymatrix{
A \ar[d] \ar[r] &  C\\
B \ar[ru]
}\]
is commutative in $\mathcal{C}$, then the diagram
\[ \xymatrix{
F(A)   & \ar[l] \ar[ld] F(C)\\
F(B) \ar[u]
}\]
commutes in $\mathcal{D}$.

One can, of course, compose contravariant functors as in \cref{composefunctors}. But the composition of two
contravariant functors will be \emph{covariant.} So there is no ``category of
categories'' where the morphisms between categories are contravariant functors.

Similarly as in \cref{groupact}, we have:

\begin{example}
A \textbf{contravariant} functor from $B_G$ (defined as in \cref{BG}) to $\mathbf{Sets}$ corresponds to a
set with a \emph{right} $G$-action.
\end{example}

\begin{example}[Singular cohomology]
In algebraic topology, one encounters contravariant functors on the homotopy
category of topological spaces via the \emph{singular cohomology} functors $X
\mapsto H^n(X; \mathbb{Z})$. Given a continuous map $f: X \to Y$, there is a
homomorphism of groups
\[ f^* : H^n(Y; \mathbb{Z}) \to H^n(X; \mathbb{Z}).  \]
\end{example}

\begin{example}[Duality for vector spaces] \label{dualspace}
On the category $\mathbf{Vect}$ of vector spaces over a field $k$, we
have
the contravariant functor
\[ V \mapsto V^{\vee}.  \]
sending a vector space to its dual $V^{\vee} = \hom(V,k)$.
Given a map $V \to W$ of vector spaces, there is an induced map
\[ W^{\vee} \to V^{\vee}  \]
given by the transpose.
\end{example}

\begin{example}
If we map $B_G \to B_G$ sending $\ast \mapsto \ast$ and $g \mapsto g^{-1}$, we
get a
contravariant functor.
\end{example}

We now give a useful (linguistic) device for translating between covariance and
contravariance.

\begin{definition}[The opposite category] \label{oppositecategory}
Let $\mathcal{C}$ be a category. Define the \textbf{opposite category}
$\mathcal{C}^{op}$ of $\mathcal{C}$ to have the same objects as
$\mathcal{C}$  but such that the morphisms between $X,Y$ in
$\mathcal{C}^{op}$
are those between $Y$ and $X$ in $\mathcal{C}$.
\end{definition}

There is a contravariant functor $\mathcal{C} \to
\mathcal{C}^{op}$.
In fact, contravariant functors out of $\mathcal{C}$ are the \emph{same} as
covariant functors out of $\mathcal{C}^{op}$.

As a result, when results are often stated for both covariant and contravariant
functors, for instance, we can often reduce to the covariant case by using the
opposite category.

\begin{exercise}
A map that is an isomorphism in $\mathcal{C}$ corresponds to an isomorphism in
$\mathcal{C}^{op}$.
\end{exercise}
\subsection{Functors and isomorphisms}
Now we want to prove a simple and intuitive fact: if isomorphisms allow one to
say that one object in a category is ``essentially the same'' as another,
functors should be expected to preserve this.
\begin{proposition}
If $f: X \to Y$ is a map in $\mathcal{C}$, and $F: \mathcal{C} \to \mathcal{D}$
is a functor, then $F(f): FX \to FY$ is an isomorphism.
\end{proposition}

The proof is quite straightforward, though there is an important point here.
Note that the analogous result holds for \emph{contravariant} functors too.

\begin{proof}
If we have maps $f: X \to Y$ and $g : Y \to X$ such that the composites both
ways are identities, then we can apply the functor $F$ to this, and we find
that since
\[ f \circ g = 1_Y, \quad g \circ f = 1_X,   \]
it must hold that
\[ F(f) \circ F(g) = 1_{F(Y)}, \quad F(g) \circ F(f) = 1_{F(X)}.  \]
We have used the fact that functors preserve composition and identities. This
implies that $F(f)$ is an isomorphism, with inverse $F(g)$.
\end{proof}

Categories have a way of making things so general that are trivial. Hence,
this material is called general abstract nonsense.
Moreover, there is another philosophical point about category theory to
be made here: often, it is the definitions, and not the proofs, that matter.
For instance, what matters here is not the theorem, but the \emph{definition of
an
isomorphism.} It is a categorical one, and much more general than the usual
notion via injectivity and surjectivity.


\begin{example}
As a simple example, $\left\{0,1\right\}$ and $[0,1]$ are not isomorphic in the
homotopy category of topological spaces (i.e. are not homotopy equivalent)
because $\pi_0([0,1]) = \ast$ while $\pi_0(\left\{0,1\right\}) $ has two
elements.
\end{example}

\begin{example}
More generally, the higher homotopy group functors  $\pi_n$ (see \cite{Ha02}) can be used to show
that the $n$-sphere $S^n$ is not homotopy equivalent to a point. For then
$\pi_n(S^n, \ast)$ would be trivial, and it is not.
\end{example}


There is room, nevertheless, for something else. Instead of having
something that sends objects to other objects, one could have something that
sends an object to a map.



\subsection{Natural transformations}



Suppose $F, G: \mathcal{C} \to \mathcal{D}$ are functors.

\begin{definition}
A \textbf{natural transformation} $T: F \to G$ consists of the following data.
For each $X \in C$, there is a morphism $TX: FX \to GX$ satisfying the
following
condition. Whenever $f: X \to Y$ is a morphism, the following diagram must
commute:
\[ \xymatrix{
FX \ar[d]^{TX }\ar[r]^{F(f)} &  FY \ar[d]^{TY}  \\
GX \ar[r]^{G(f)} &  GY
}.\]

If $TX$ is an isomorphism for each $X$, then we shall say that $T$ is a
\textbf{natural isomorphism.}
\end{definition}

It is similarly possible to define the notion of a natural transformation
between \emph{contravariant} functors.

When we say that things are ``natural'' in the future, we will mean that the
transformation between functors is natural in this sense.
We shall use this language to state theorems conveniently.

\begin{example}[The double dual]
Here is the canonical example of ``naturality.''
Let $\mathcal{C}$ be the category of finite-dimensional vector spaces over a
given field $k$. Let us further restrict the category such that the only
morphisms are the \emph{isomorphisms} of vector spaces.
For each $V \in \mathcal{C}$, we know that there is an isomorphism
\[ V \simeq V^{\vee} = \hom_k(V, k),  \]
because both have the same dimension.

Moreover, the maps $V \mapsto V, V \mapsto V^{\vee}$ are both covariant functors on
$\mathcal{C}$.\footnote{Note that the dual $\vee$ was defined as a
\emph{contravariant} functor in \cref{dualspace}.} The first is the identity functor; for the second, if $f: V \to
W$ is an isomorphism, then there is induced a transpose map $f^t: W^{\vee} \to V^{\vee}$
(defined by sending a map $W \to k$ to the precomposition $V \stackrel{f}{\to}
W \to k$), which is an isomorphism; we can take its inverse.
So we have two functors from $\mathcal{C}$ to itself, the identity and the
dual, and we know that $V \simeq V^{\vee}$ for each $V$ (though we have not
chosen any particular set of isomorphisms).


However, the isomorphism $V \simeq
V^{\vee}$ \emph{cannot} be made natural. That is, there is no way of choosing
isomorphisms
\[ T_V: V \simeq V^{\vee}  \]
such that,
whenever $f: V \to W$ is an isomorphism of vector spaces, the following diagram
commutes:
\[ \xymatrix{
V \ar[r]^{f} \ar[d]^{T_V}  &  W \ar[d]^{T_W} \\
V^{\vee} \ar[r]^{(f^t)^{-1}} &  W^{\vee}.
}\]
Indeed, fix $d>1$, and choose $V = k^d$.
Identify $V^{\vee}$ with $k^d$, and so the map $T_V$ is a $d$-by-$d$ matrix $M$
with coefficients in $k$. The requirement is that for each \emph{invertible}
$d$-by-$d$ matrix $N$, we have
\[ (N^t)^{-1}M = MN,  \]
by considering the above diagram with $V = W = k^d$, and $f$ corresponding to
the matrix $N$.
This is impossible unless $M = 0$, by elementary linear algebra.

Nonetheless, it \emph{is} possible to choose a natural isomorphism
\[ V \simeq V^{\vee \vee}.  \]
To do this, given $V$, recall that $V^{\vee \vee}$ is the collection of maps
$V^{\vee} \to k$. To give a map $V \to V^{\vee \vee}$ is thus the same as
giving linear functions $l_v, v \in V$ such that $l_v: V \to k$ is linear in
$v$. We can do this by letting $l_v$ be ``evaluation at $v$.''
That is, $l_v$ sends a linear functional $\ell: V \to k$ to $\ell(v) \in k$. We
leave it to the reader to check (easily) that this defines a homomorphism $V
\to V^{\vee \vee}$, and that everything is natural.
\end{example}





\begin{exercise}
 Suppose there are  two functors $B_G \to
\mathbf{Sets}$, i.e. $G$-sets. What is a natural transformation between them?
\end{exercise}


Natural transformations can be \emph{composed}. Suppose given functors $F, G,
H: \mathcal{C} \to \mathcal{D}$ a natural
transformation $T: F \to G$ and a natural transformation $U: G \to H$.
Then, for each $X \in \mathcal{C}$, we have maps $TX: FX \to GX, UX: GX \to
HY$. We can compose $U$ with $T$ to get a natural transformation $U \circ T: F
\to H$.

In fact, we can thus define a \emph{category} of functors
$\mathrm{Fun}(\mathcal{C}, \mathcal{D})$ (at least if $\mathcal{C},
\mathcal{D}$ are small). The objects of this category are the functors $F:
\mathcal{C} \to \mathcal{D}$. The morphisms are natural transformations between
functors. Composition of morphisms is as above.

\subsection{Equivalences of categories}

Often we want to say that two categories $\mathcal{C}, \mathcal{D}$ are ``essentially the same.'' One way
of formulating this precisely is to say that $\mathcal{C}, \mathcal{D}$ are
\emph{isomorphic} in the category of categories. Unwinding the definitions,
this means that there exist functors
\[ F: \mathcal{C} \to \mathcal{D}, \quad G: \mathcal{D} \to \mathcal{C} \]
such that $F \circ G = 1_{\mathcal{D}}, G \circ F = 1_{\mathcal{C}}$.
This notion, of \emph{isomorphism} of categories, is generally far too
restrictive.

For instance, we could consider the category of all finite-dimensional vector
spaces over a given field $k$, and we could consider the full subcategory
of vector spaces of the form $k^n$. Clearly both categories encode essentially
the same mathematics, in some sense, but they are not isomorphic: one has a
countable set of objects, while the other has an uncountable set of objects.
Thus, we need  a more refined way of saying that two categories are
``essentially the same.''

\begin{definition}
Two categories $\mathcal{C}, \mathcal{D}$ are called \textbf{equivalent} if
there are functors
\[ F: \mathcal{C} \to \mathcal{D}, \quad G: \mathcal{D} \to \mathcal{C}  \]
and natural isomorphisms
\[ F G \simeq 1_{\mathcal{D}}, \quad GF \simeq 1_{\mathcal{C}}.  \]
\end{definition}

For instance, the category of all vector spaces of the form $k^n$ is equivalent
to the category of all finite-dimensional vector spaces.
One functor is the inclusion from vector spaces of the form $k^n$; the other
functor maps a finite-dimensional vector space $V$ to $k^{\dim V}$. Defining
the second functor properly is, however, a little more subtle.
The next criterion will be useful.

\begin{definition}
A functor $F: \mathcal{C} \to \mathcal{D}$ is \textbf{fully faithful} if $F:
\hom_{\mathcal{C}}(X, Y) \to \hom_{\mathcal{D}}(FX, FY)$ is a bijection for each pair of objects $X, Y \in
\mathcal{C}$.
$F$ is called \textbf{essentially surjective} if every element of $\mathcal{D}$
is isomorphic to an object in the image of $F$.
\end{definition}

So, for instance, the inclusion of a full subcategory is fully faithful (by
definition). The forgetful functor from groups to sets is not fully faithful,
because not all functions between groups are automatically homomorphisms.


\begin{proposition}
A functor $F: \mathcal{C} \to \mathcal{D}$ induces an equivalence of categories
if and only if it is fully faithful and essentially surjective.
\end{proposition}
\begin{proof}
\add{this proof, and the definitions in the statement.}
\end{proof}

\section{Various universal constructions}

Now that we have introduced the idea of a category and showed that a functor
takes isomorphisms to isomorphisms, we shall take various steps to characterize objects in terms of
maps (the most complete of which is the Yoneda lemma, \cref{yonedalemma}). In
general category
theory, this is generally all we \emph{can} do, since this is all the data we
are given.
We shall describe objects satisfying certain ``universal properties'' here.


As motivation, we first discuss the concept of the ``product'' in terms of a
universal property.

\subsection{Products}
Recall that if we have two sets $X$ and $Y$, the product $X\times Y$ is the set
of all elements of the form $(x,y)$ where $x\in X$ and $y\in Y$. The product is
also equipped with natural projections $p_1: X \times Y \to X$ and $p_2: X
\times Y \to Y$ that take $(x,y)$ to $x$
and $y$ respectively. Thus any element of $X\times Y$ is uniquely determined by
where they project to on $X$ and $Y$. In fact, this is the case more generally; if
we have an index set $I$ and a product $X=\prod_{i\in I} X_i$, then an element
$x\in X$ determined uniquely by where where the projections $p_i(x)$ land in
$X_i$.

To get into the categorical spirit, we should speak not of elements but of maps
to $X$. Here is the general observation: if we have any other set $S$ with maps
$f_i:S\rightarrow X_i$ then there is a unique map $S\rightarrow X=\prod_{i\in
I}X_i$ given by sending $s\in S$ to the element $\{ f_i(s)\}_{i\in I}$. This
leads to the following characterization of a product using only ``mapping
properties.''

\begin{definition} Let $\{X_i\}_{i\in I}$ be a collection of objects in some
category $\mathcal{C}$. Then an object $P \in \mathcal{C}$ with projections $p_i: P\rightarrow X_i$
is said to be the \textbf{product} $\prod_{i\in I} X_i$ if the following ``universal
property'' holds:
let $S$ be any other object in $\mathcal{C}$ with maps $f_i:S\rightarrow X_i$.
Then there is a unique morphism $f:S\rightarrow P$ such that $p_i f = f_i$.
\end{definition}

In other words, to map into $X$ is the same as mapping into all the
$\left\{X_i\right\}$ at once. We have thus given a precise description of how
to map into $X$.
Note that, however, the product need not exist!
If it does, however, we can express the above formalism by the following
natural isomorphism
of contravariant functors
\[ \hom(\cdot, \prod_I X_i) \simeq \prod_I \hom(\cdot, X_i).  \]
This is precisely the meaning of the last part of the definition. Note that
this observation shows that products in the category of \emph{sets} are really
fundamental to the idea of products in any category.

\begin{example} One of the benefits of this construction is that an actual
category is not specified; thus when we take $\mathcal{C}$ to be
$\mathbf{Sets}$, we
recover the cartesian product notion of sets, but if we take $\mathcal{C}$ to
be $\mathbf{Grp}$, we achieve the regular notion of the product of groups (the reader is
invited to check these statements). \end{example}

The categorical product is not unique, but it is as close to being so as
possible.

\begin{proposition}[Uniqueness of products]\label{produnique}
Any two products of the collection $\left\{X_i\right\}$ in $\mathcal{C}$ are
isomorphic by a unique isomorphism commuting with the projections.
\end{proposition}

This is a special case of a general ``abstract nonsense'' type result that we
shall see many more of in the sequel.
The precise statement is the following: let $X$ be a product of the
$\left\{X_i\right\}$ with projections $p_i : X \to X_i$, and let $Y$ be a
product of them too, with projections $q_i: Y \to X_i$.
Then the claim is that there is a \emph{unique} isomorphism
\[ f: X \to Y  \]
such that the diagrams below commute for each $i \in I$:
\begin{equation} \label{prodcommutative} \xymatrix{
X \ar[rd]^{p_i}  \ar[rr]^f &  & Y \ar[ld]_{q_i} \\
& X_i.
}\end{equation}
\begin{proof}
This is a ``trivial'' result, and is part of a general fact that objects
with the same universal property are always canonically isomorphic. Indeed, note that the projections $p_i: X \to
X_i$ and the fact that mapping into $Y$ is the same as mapping into all the
$X_i$ gives a unique map $f: X \to Y$ making the diagrams
\eqref{prodcommutative} commute. The same reasoning (applied to the $q_i: Y \to
X_i$) gives a map $g:  Y \to X$ making the diagrams
\begin{equation} \label{prodcommutative2} \xymatrix{
Y \ar[rd]^{q_i}  \ar[rr]^g &  & X \ar[ld]_{p_i} \\
& X_i
}\end{equation}
commute. By piecing the two diagrams together, it follows that the composite $g \circ f$ makes the diagram
\begin{equation} \label{prodcommutative3} \xymatrix{
X \ar[rd]^{p_i}  \ar[rr]^{g \circ f} &  & X \ar[ld]_{p_i} \\
& X_i
}\end{equation}
commute.
But the identity $1_X: X \to X$ also would make \eqref{prodcommutative3}
commute, and the \emph{uniqueness} assertion in the definition of the product
shows that $g \circ f = 1_X$. Similarly, $f \circ g = 1_Y$. We are done.
\end{proof}
\begin{remark}
 If we reverse the arrows in the above construction,
the universal property obtained (known as the ``coproduct'') characterizes
disjoint unions in the category of sets and free products in the category of
groups.
That is, to map \emph{out} of a  coproduct of objects $\left\{X_i\right\}$ is the same as
mapping out of each of these. We shall later study this construction more
generally.
\end{remark}


\begin{exercise}
Let $P$ be a poset, and make $P$ into a category as in \cref{posetcategory}.
Fix $x, y \in P$. Show that the \emph{product} of $x,y$ is the greatest lower
bound of $\left\{x,y\right\}$ (if it exists). This claim holds more generally
for arbitrary subsets of $P$.

In particular, consider the poset of subsets of a given set $S$. Then the
``product'' in this category corresponds to the intersection of subsets.
\end{exercise}

We shall, in this section, investigate this notion of ``universality''
more thoroughly.


\subsection{Initial and terminal objects}

We now introduce another example of universality, which is simpler but more
abstract than the products introduced in the previous section.

\begin{definition}
Let $\mathcal{C}$ be a category. An \textbf{initial object} in $\mathcal{C}$ is an
object $X \in \mathcal{C}$ with the property that $\hom_{\mathcal{C}}(X, Y)$ has one
element for all $Y \in \mathcal{C}$.

\end{definition}

So there is a unique map out of $X$ into each $Y \in \mathcal{C}$.
Note that this idea is faithful to the categorical spirit of describing objects
in terms of their mapping properties. Initial objects are very easy to map
\emph{out} of.


\begin{example}
If $\mathcal{C}$ is $\mathbf{Sets}$, then the empty set $\emptyset$ is an
initial object. There is a unique map from the empty set into any other set;
one has to make no decisions about where elements are to map when
constructing a map $\emptyset \to X$.
\end{example}

\begin{example}
In the category $\mathbf{Grp}$ of groups, the group consisting of one element
is an initial object.
\end{example}

Note that the initial object in $\mathbf{Grp}$ is \emph{not} that in
$\mathbf{Sets}$. This should not be too surprising, because $\emptyset$ cannot
be a group.

\begin{example}
Let $P$ be a poset, and make it into a category as in \cref{posetcategory}.
Then it is easy to see that an initial object of $P$ is the smallest object in
$P$ (if it exists). Note that this is equivalently the product of all the
objects in $P$. In general, the initial object of a category is not the product
of all objects in $\mathcal{C}$ (this does not even make sense for a large
category).
\end{example}

There is a dual notion, called a \textit{terminal object}, where every object
can map into it in precisely one way.
\begin{definition}
A \textbf{terminal object} in a category $\mathcal{C}$ is an object $Y \in
\mathcal{C}$ such that $\hom_{\mathcal{C}}(X, Y) = \ast$ for each $X \in \mathcal{C}$.
\end{definition}

Note that an initial object in $\mathcal{C}$ is the same as a terminal object
in $\mathcal{C}^{op}$, and vice versa. As a result, it suffices to prove
results about initial objects, and the corresponding results for terminal
objects will follow formally.
But there is a fundamental difference between initial and terminal objects.
Initial objects are characterized by how one maps \emph{out of} them, while
terminal objects are characterized by how one maps \emph{into} them.
\begin{example}
The one point set is a terminal object in $\mathbf{Sets}$.
\end{example}



The important thing about the next ``theorems'' is the conceptual framework.
\begin{proposition}[Uniqueness of the initial (or terminal) object]
\label{initialunique}
Any two initial (resp. terminal) objects in $\mathcal{C}$ are isomorphic by a
unique isomorphism.
\end{proposition}
\begin{proof}
The proof is easy. We do it for terminal objects. Say $Y, Y'$ are
terminal objects. Then $\hom(Y, Y')$ and $\hom(Y', Y)$ are one
point sets. So there are unique maps $f: Y \to Y', g: Y' \to Y$, whose composites
must be the identities: we know that $\hom(Y, Y) , \hom(Y', Y')$
are one-point sets, so the composites have no other choice to be the
identities. This means that the maps $f: Y \to Y', g: Y' \to Y$ are
isomorphisms.
\end{proof}

There is a philosophical point to be made here. We have characterized an object
uniquely in terms of mapping properties. We have characterized it
\emph{uniquely up to unique isomorphism,} which is really the best one can do
in mathematics. Two sets are not generally the ``same,'' but they may be
isomorphic up to unique isomorphism. They are different,
but the sets are isomorphic up
to unique isomorphism.
Note also that the argument was essentially similar to that of \cref{produnique}.

In fact, we could interpret  \cref{produnique} as a special case of
\cref{initialunique}.
If $\mathcal{C}$ is a category and $\left\{X_i\right\}_{i \in I}$ is a family
of objects in $\mathcal{C}$, then we can define a category $\mathcal{D}$ as
follows. An object of $\mathcal{D}$ is the data of an object $Y \in
\mathcal{C}$ and morphisms $f_i: Y \to X_i$ for all $i \in I$.
A morphism between objects $(Y, \left\{f_i: Y \to X_i\right\})$ and $(Z,
\left\{g_i: Z \to X_i\right\})$ is
a map $Y \to Z$ making the obvious diagrams commute. Then a product $\prod X_i$
in $\mathcal{C}$ is the same thing as a terminal object in $\mathcal{D}$, as
one easily checks from the definitions.

\subsection{Push-outs and pull-backs}

Let $\mathcal{C}$ be a category.

Now we are going to talk about more  examples of universal constructions, which can all be
phrased via initial or terminal objects in some category. This,
therefore, is the proof for the uniqueness up to unique
isomorphism of \emph{everything} we will do in this
section. Later we will present these in more generality.


Suppose we have objects $A, B, C, X \in \mathcal{C}$.

\begin{definition}
A commutative square
\[
\xymatrix{
A \ar[d] \ar[r] &  B \ar[d] \\
C \ar[r] &  X}.
\]
is a \textbf{pushout square} (and $X$ is called the \textbf{push-out}) if,
given a commutative diagram
\[ \xymatrix{
A \ar[r] \ar[d]  &  B \ar[d] \\
C \ar[r] & Y  \\
}\]
there is a unique map $X \to Y$ making the following diagram commute:
\[
\xymatrix{
A \ar[d] \ar[r] &  B \ar[d] \ar[rdd] \\
C \ar[r] \ar[rrd] &  X \ar[rd] \\
& & Y'}
\]
Sometimes push-outs are also called \textbf{fibered coproducts}.
We shall also write $X = C \sqcup_A B$.
\end{definition}

In other words, to map out of $X = C \sqcup_A B$ into some object $Y$ is to
give maps $B \to Y, C \to Y$ whose restrictions to $A$ are the same.


The next few examples will rely on notions to be introduced later.
\begin{example}
The following is a pushout square in the category of abelian groups:
\[ \xymatrix{
\mathbb{Z}/2 \ar[r] \ar[d]  &  \mathbb{Z}/4 \ar[d]  \\
\mathbb{Z}/6 \ar[r] &  \mathbb{Z}/12
}\]
In the category of groups, the push-out is actually
$\mathrm{SL}_2(\mathbb{Z})$, though we do not prove it. The point is that
the property of a square's being a
push-out is actually dependent on the category.

In general, to construct a push-out of groups $C \sqcup_A B$, one constructs
the direct sum $C \oplus B$ and quotients by the subgroup generated by
$(a, a)$ (where $a \in A$ is identified with its image in $C \oplus B$).
We shall discuss this later, more thoroughly, for modules over a ring.
\end{example}

\begin{example}
Let $R$ be a commutative ring and let $S$ and $Q$ be two commutative
$R$-algebras. In other words, suppose
we have two maps of rings $s:R\rightarrow S$ and $q:R\rightarrow Q$. Then we
can fit this information together
into a pushout square:

\[ \xymatrix{
R \ar[r] \ar[d]  &  S \ar[d]   \\
Q \ar[r] &X
}\]
It turns out that the pushout in this case is the tensor product of algebras
$S\otimes_R Q$ (see \cref{tensprodalg} for the construction). This is particularly important
in algebraic geometry as the dual construction will give the correct notion of
``products'' in the category of ``schemes'' over
a field.\end{example}

\begin{proposition}
Let $\mathcal{C}$ be any category.
If the push-out of
the diagram
\[ \xymatrix{
A \ar[d] \ar[r] & B \\
C
}\]
exists, it is unique up to unique isomorphism.
\end{proposition}
\begin{proof}
We can prove this in two ways. One is to suppose that there were two pushout
squares:
\[
\xymatrix{
A \ar[d] \ar[r] &  B \ar[d]  \\
C \ar[r]  &  X \\
}
\quad \quad
\xymatrix{
A \ar[d] \ar[r] &  B \ar[d]  \\
C \ar[r]  &  X' \\
}
\]
Then there are unique maps $f:X \to X', g: X' \to X$ from the universal property.
In detail, these maps fit into commutative diagrams
\[
\xymatrix{
A \ar[d] \ar[r] &  B \ar[d] \ar[rdd] \\
C \ar[r] \ar[rrd]  &  X  \ar[rd]^f\\
 & & X'
}
\quad \quad
\xymatrix{
A \ar[d] \ar[r] &  B \ar[d] \ar[rdd] \\
C \ar[r] \ar[rrd]  &  X' \ar[rd]^g\\
 & & X
}
\]
Then $g \circ f$ and $f \circ g$ are the identities of $X, X'$ again by
\emph{uniqueness} of the map in the definition of the push-out.

Alternatively, we can phrase push-outs in terms of initial objects. We could
consider the category of all diagrams as above,
\[ \xymatrix{
A \ar[d] \ar[r] &  B \ar[d]  \\
C \ar[r] &  D
},\]
where $A \to B, A \to C$ are fixed and $D$ varies.
The morphisms in this category of diagrams consist of commutative
diagrams. Then the initial
object in this category is the push-out, as one easily checks.
\end{proof}

Often when studying categorical constructions, one can create a kind of
``dual''construction by reversing the direction of the arrows. This is exactly
the
relationship between the push-out construction and the pull-back
construction to be described below.
So suppose we have two morphisms $A \to C$ and $B\to C$, forming a diagram
\[ \xymatrix{
& B \ar[d] \\
A \ar[r] &  C.
}\]
\begin{definition}
The \textbf{pull-back} or \textbf{fibered product} of the above
diagram is an object $P$ with two morphisms $P\to B$ and $P\to
C$ such that the following diagram commutes:
\[ \xymatrix {
P \ar[d] \ar[r] & B \ar[d]\\
A\ar[r] & C }\]
Moreover, the object $P$ is required  to be universal in the following sense: given any $P'$
and maps $P'\to A$ and $P'\to B$ making the square commute, there is a
unique map
$P'\to P$ making the following diagram commute:
\[
\xymatrix{
 P' \ar[rd] \ar[rrd] \ar[ddr] \\
& P \ar[d] \ar[r] &  B \ar[d] \\
& A \ar[r] &  C }\]
We shall also write $P = B \times_C A$.
\end{definition}


\begin{example}
In the category $\mathbf{Set}$ of sets, if we have sets $A, B, C$ with maps $f:
A \to C, g: B \to C$, then the fibered product $A \times_C B$ consists of
pairs $(a,b) \in A \times B$ such that $f(a) = g(b)$.
\end{example}

\begin{example}[Requires prerequisites not developed yet] The next example may
be omitted without loss of continuity.

As said above, the fact that the tensor product of algebras is
a push-out in the category of
commutative $R$-algebras allows for the correct notion of the ``product'' of
schemes. We now elaborate on this example: naively one would think that we
could pick the underlying space of the product scheme to just be the topological
product of two Zariski topologies. However, it is an easy exercise to check
that the product of two Zariski topologies in general is not Zariski! This
motivates
the need for a different concept.

Suppose we have a field $k$ and two $k$-algebras $A$ and $B$ and let
$X=\spec(A)$and $Y=\spec(B)$ be the affine $k$-schemes corresponding to $A$ and
$B$. Consider the following pull-back diagram:
\[
\xymatrix{
X\times_{\spec(k)} Y \ar[d] \ar[r] &X \ar[d]\\
Y \ar[r] &\spec(k) }\]

Now, since $\spec$ is a contravariant functor, the arrows in this pull-back
diagram have been flipped; so in fact, $X\times_{\spec(k)} Y$ is actually
$\spec(A\otimes _k B)$. This construction is motivated by the following example:
let $A=k[x]$ and $B=k[y]$. Then $\spec(A)$ and $\spec(B)$ are both affine lines
$\mathbb{A}^1_k$ so we want a suitable notion of product that makes the product
of $\spec(A)$ and $\spec(B)$ the affine plane. The pull-back construction is the
correct one since $\spec(A)\times_{\spec(k)} \spec(B)=\spec(A\otimes_k
B)=\spec(k[x,y])=\mathbb{A}^2_k$.
\end{example}


\subsection{Colimits}


We now want to generalize the push-out.
Instead of a shape with $A,B,C$, we do something more general.
Start with a small category $I$: recall that \emph{smallness} means that the objects of $I$
form a set. $I$ is to be called  the  \textbf{indexing
category}. One is supposed to picture
is that $I$ is something like the category
\[
\xymatrix{
\ast \ar[d] \ar[r] &  \ast \\
\ast
}
\]
or the category
\[ \ast \rightrightarrows \ast.  \]
We will formulate the notion of a \textbf{colimit} which will specialize to the
push-out when $I$ is the first case.


So we will look at functors
\[ F: I \to \mathcal{C},  \]
which in the case of the three-element category, will just
 correspond to
diagrams
\[ \xymatrix{A \ar[d]  \ar[r] &  B \\ C}.  \]

We will call a \textbf{cone} on $F$ (this is an ambiguous term) an object $X
\in \mathcal{C}$ equipped with maps $F_i \to X, \forall i \in I$ such that for
all maps $i \to
i' \in I$, the diagram below commutes:
\[ \xymatrix{
F_i \ar[d] \ar[r] &  X \\
F_{i'} \ar[ru]
}.\]

An example would be a cone on the three-element category above: then
this is just a commutative diagram
\[ \xymatrix{
A \ar[r]\ar[d]  &  B \ar[d]  \\
C \ar[r] &  D
}.\]

\newcommand{\colim}{\mathrm{colim}}

\begin{definition}
The \textbf{colimit} of the diagram $F: I \to \mathcal{C}$, written as $\colim
F$ or $\colim_I F $ or $\varinjlim_I F$, if it exists, is a cone $F \to X$ with
the property that if $F \to Y$ is any other cone, then there is a unique map $X
\to Y$ making the diagram
\[ \xymatrix{
F  \ar[rd] \ar[r] &  X \ar[d]  \\
& Y
}\]
commute. (This means that the corresponding diagram with $F_i$ replacing $F$
commutes for each $i \in I$.)
\end{definition}

We could form a category $\mathcal{D}$ where the objects are the cones $F \to
X$, and the morphisms from $F \to X$ and $F \to Y$ are the maps $X \to Y$ that
make all the obvious diagrams commute. In this case, it is easy to see that a
\emph{colimit} of the diagram is just an initial object in $\mathcal{D}$.

 In any case, we see:

\begin{proposition}
$\colim F$, if it exists, is unique up to unique isomorphism.
\end{proposition}

Let us go through some examples. We already looked at push-outs.

\begin{example}
Consider the category $I$ visualized as
\[ \ast, \ast, \ast, \ast.  \]
So $I$ consists of four objects with no non-identity morphisms.
A functor $F: I \to \mathbf{Sets}$ is just a list of four sets $A, B, C, D$.
The colimit is just the disjoint union $A \sqcup B \sqcup C \sqcup D$. This is
the universal property of the disjoint union. To map out of the disjoint union
is the same thing as mapping out of each piece.
\end{example}


\begin{example}
Suppose we had the same category $I$ but the functor $F$ took values in the
category of abelian groups. Then $F$
corresponds, again, to a list of four abelian groups. The colimit is the direct
sum. Again, the direct sum is characterized by the same universal property.
\end{example}

\begin{example}
Suppose we had the same $I$ ($\ast, \ast, \ast, \ast$) the functor took its
value in the category of groups. Then the colimit is the
free product of the four groups.
\end{example}

\begin{example}
Suppose we had the same $I$ and the category $\mathcal{C}$ was of commutative
rings with unit. Then the colimit is the tensor product.
\end{example}

So the idea of a colimit unifies a whole bunch of constructions.
Now let us take a different example.

\begin{example}
Take
\[ I = \ast \rightrightarrows \ast.  \]
So a functor $I \to \mathbf{Sets}$ is a diagram
\[ A \rightrightarrows B.  \]
Call the two maps $f,g: A \to B$. To get the colimit, we take $B$ and mod out
by the equivalence relation generated by $f(a) \sim g(a)$.
To hom out of this is the same thing as homming  out of $B$ such that the
pullbacks to $A$ are the same.

This is the relation \textbf{generated} as above, not just as above. It can get
tricky.
\end{example}

\begin{definition}
When $I$ is just a bunch of points  $\ast, \ast, \ast, \dots$ with no
non-identity morphisms, then the
colimit over $I$ is called the \textbf{coproduct}.
\end{definition}

We use the coproduct to mean things like direct sums, disjoint unions, and
tensor products.
If $\left\{A_i, i \in I\right\}$ is a collection of objects in some category,
then we find the universal property of the coproduct can be stated succinctly:
\[ \hom_{\mathcal{C}}(\bigsqcup_I A_i, B) = \prod \hom_{\mathcal{C}}(A_i, B).  \]

\begin{definition}
When $I$ is $\ast \rightrightarrows \ast$, the colimit is called the
\textbf{coequalizer}.
\end{definition}

\begin{theorem} \label{coprodcoequalsufficeforcocomplete}
If $\mathcal{C}$ has all coproducts and coequalizers, then it has all colimits.
\end{theorem}

\begin{proof}
Let $F: I \to \mathcal{C}$ be a functor, where $I$ is a small category. We
need to obtain an object $X$ with morphisms
\[ Fi \to X, \quad i \in I  \]
such that for each $f: i \to i'$, the diagram below commutes:
\[
\xymatrix{
Fi \ar[d] \ar[r] &  Fi' \ar[ld] \\
X
}
\]
and such that $X$ is universal among such diagrams.

To give such a diagram, however, is equivalent to giving a collection of maps
\[ Fi \to X  \]
that satisfy some conditions. So $X$ should be thought of as a quotient of the
coproduct $\sqcup_i Fi$.
Let us consider the coproduct $\sqcup_{i \in I, f} Fi$, where $f$ ranges over
all
morphisms in the category $I$ that start from $i$.
We construct two maps
\[ \sqcup_f Fi \rightrightarrows \sqcup_f Fi,  \]
whose coequalizer will be that of $F$. The first map is the identity. The
second map sends a factor
\end{proof}

\subsection{Limits}
As in the example with pull-backs and push-outs and products and coproducts,
one can define a limit by using the exact same universal property above
just with
all the arrows reversed.

\begin{example} The product is an example of a limit where the indexing
category is a small category $I$ with no morphisms other than the identity. This
example
shows the power of universal constructions; by looking at colimits and limits,
a whole variety of seemingly unrelated mathematical constructions are shown
to be
in the same spirit.
\end{example}

\subsection{Filtered colimits}


\emph{Filtered colimits} are colimits
over special indexing categories $I$ which look like totally ordered sets.
These have several convenient properties as compared to general colimits.
For instance, in the category of \emph{modules} over a ring (to be studied in
\rref{foundations}), we shall see that filtered colimits actually
preserve injections and surjections. In fact, they are \emph{exact.} This is
not true in more general categories which are similarly structured.



\begin{definition}
An indexing category is \textbf{filtered} if the following hold:
\begin{enumerate}
\item Given $i_0, i_1 \in I$, there is a third object $i \in I$ such that both
$i_0, i_1$ map into $i$.
So there is a diagram
\[ \xymatrix{
i_0 \ar[rd] \\
& i \\
i_1 \ar[ru]
}.\]
\item Given any two maps $i_0 \rightrightarrows i_1$, there exists $i$ and $i_1
\to i$ such that the two maps $i_0 \rightrightarrows i$ are equal:
intuitively, any two ways
of pushing an object into another can be made into the same eventually.
\end{enumerate}
\end{definition}

\begin{example}
If $I$ is the category
\[ \ast \to \ast \to \ast \to \dots,  \]
i.e. the category generated by the poset $\mathbb{Z}_{\geq 0}$, then that is
filtered.
\end{example}


\begin{example}
If $G$ is a torsion-free abelian group, the category $I$ of finitely generated
subgroups of $G$ and inclusion maps is filtered. We don't actually need the
lack of torsion.
\end{example}

\begin{definition}
Colimits over a filtered category are called \textbf{filtered colimits}.
\end{definition}

\begin{example}
Any torsion-free abelian group is the filtered colimit of its finitely
generated subgroups, which are free abelian groups.
\end{example}
This gives a simple approach for showing that a torsion-free abelian group is
flat.

\begin{proposition}
If $I$ is filtered\footnote{Some people say filtering.} and $\mathcal{C} =
\mathbf{Sets}, \mathbf{Abgrp}, \mathbf{Grps}$, etc., and $F: I \to \mathcal{C}$
is a functor, then $\colim_I F$ exists and is given by the disjoint union of
$F_i, i \in I$ modulo the relation $x \in F_i$ is equivalent to $x' \in F_{i'}$
if $x$ maps to $x'$ under $F_i \to F_{i'}$. This is already an equivalence
relation.
\end{proposition}

The fact that the relation given above is transitive uses the filtering of the
indexing set. Otherwise, we would need to use the relation generated by it.

\begin{example}
Take $\mathbb{Q}$. This is the filtered colimit of the free submodules
$\mathbb{Z}(1/n)$.

Alternatively, choose a sequence of numbers $m_1 , m_2, \dots, $ such that for
all $p, n$, we have $p^n \mid m_i$ for $i \gg 0$. Then we have a sequence of
maps
\[ \mathbb{Z} \stackrel{m_1}{\to} \mathbb{Z} \stackrel{m_2}{\to}\mathbb{Z}
\to \dots.   \]
The colimit of this is $\mathbb{Q}$. There is a quick way of seeing this, which
is left to the reader.
\end{example}

When we have a functor $F: I \to \mathbf{Sets}, \mathbf{Grps},
\mathbf{Modules}$ taking values in a ``nice'' category (e.g. the category of
sets, modules, etc.), one can construct the colimit by taking the union of the
$F_i, i \in I$ and quotienting by the equivalence relation $x \in F_i \sim x'
\in F_{i'}$ if $f: i \to i'$ sends $x$ into $x'$. This is already an
equivalence relation, as one can check.

Another way of saying this is that we have the disjoint union of the $F_i$
modulo the relation that $a \in F_i$ and $b \in F_{i'}$ are equivalent if and
only if there is a later $i''$ with maps $i \to i'', i' \to i''$ such that
$a,b$ both map to the same thing in $F_{i''}$.


One of the key properties of filtered colimits is that, in ``nice'' categories they commute with
finite limits.

\begin{proposition}
In the category of sets, filtered colimits and finite limits commute with each
other.
\end{proposition}

The reason this result is so important is that, as we shall see, it will imply
that in categories such as the category of $R$-modules, filtered colimits
preserve \emph{exactness}.
\begin{proof}
Let us show that filtered colimits commute with (finite) products in the
category of sets. The case of an equalizer is similar, and finite limits can be
generated from products and equalizers.

So let $I$ be a filtered category, and $\left\{A_i\right\}_{i \in I},
\left\{B_i\right\}_{i \in I}$
be functors from $I \to \mathbf{Sets}$.
We want to show that
\[ \varinjlim_I (A_i \times B_i) = \varinjlim_I A_i \times \varinjlim_I B_i . \]
To do this, note first that there is a map in the direction $\to$ because of
the natural maps $\varinjlim_I (A_i \times B_i) \to \varinjlim_I A_i$ and
$\varinjlim_I (A_i \times B_i) \to \varinjlim_I B_i$.
We want to show that this is an isomorphism.

Now we can write the left side as the disjoint union $\bigsqcup_I (A_i \times
B_i)$ modulo the equivalence relation that $(a_i, b_i)$ is related to $(a_j,
b_j)$ if there exist morphisms $i \to k, j \to k$ sending $(a_i, b_i), (a_j,
b_j)$ to the same object in $A_k \times B_k$.
For the left side, we have to work with pairs: that is, an element of
 $\varinjlim_I A_i \times \varinjlim_I B_i$ consists of a pair $(a_{i_1},
 b_{i_2})$
 with two pairs $(a_{i_1}, b_{i_2}), (a_{j_1}, b_{j_2})$ equivalent if there exist
 morphisms $i_1,j_1 \to k_1 $ and $i_2,  j_2 \to k_2$ such that both have the
 same image in $A_{k_1} \times A_{k_2}$. It is easy to see that these amount to
 the same thing, because of the filtering condition: we can always modify an
 element of $A_{i} \times B_{j}$ to some $A_{k} \times B_k$ for $k$ receiving
 maps from $i, j$.
\end{proof}

\begin{exercise}
Let $A$ be an abelian group, $e: A \to A$ an \emph{idempotent} operator, i.e.
one such that $e^2 = e$. Show that $eA$ can be obtained as the filtered colimit
of
\[ A \stackrel{e}{\to} A \stackrel{e}{\to} A \dots.  \]
\end{exercise}

\subsection{The initial object theorem}

We now prove a fairly nontrivial result, due to Freyd. This gives a sufficient
condition for the existence of initial objects.
We shall use it in proving the adjoint functor theorem below.

Let $\mathcal{C}$ be a category. Then we recall that $A \in \mathcal{C}$ if
for each $X \in \mathcal{C}$, there is a \emph{unique} $A \to X$.
Let us consider the weaker condition that for each $ X \in \mathcal{C}$, there
exists \emph{a} map $A \to X$.

\begin{definition} Suppose $\mathcal{C}$ has equalizers.
If $A \in \mathcal{C}$ is such that $\hom_{\mathcal{C}}(A, X) \neq \emptyset$
for each $X \in \mathcal{C}$, then $X$ is called \textbf{weakly initial.}
\end{definition}

We now want to get an initial object from a weakly initial object.
To do this, note first that if $A$ is weakly initial and $B$ is any object
with a morphism $B \to A$, then $B$ is weakly initial too. So we are going to
take
our initial object to be a very small subobject of $A$.
It is going to be so small as to guarantee the uniqueness condition of an
initial object. To make it small, we equalize all endomorphisms.

\begin{proposition} \label{weakinitial}
If  $A$ is a weakly initial object in $\mathcal{C}$,
then the equalizer of all endomorphisms $A \to A$ is initial for $\mathcal{C}$.
\end{proposition}
\begin{proof}
Let $A'$ be this equalizer; it is endowed with a morphism $A'\to A$. Then let
us recall what this means. For any two
endomorphisms $A \rightrightarrows A$, the two pull-backs $A'
\rightrightarrows A$ are equal. Moreover, if $B \to A$ is a morphism that has
this property, then $B$ factors uniquely through $A'$.

Now $A' \to A$ is a morphism, so by the remarks above, $A'$ is weakly initial:
to each $X \in \mathcal{C}$, there exists a morphism $A' \to X$.
However, we need to show that it is unique.

So suppose given two maps $f,g: A' \rightrightarrows X$. We are going to show
that they are equal. If not, consider their equalizer $O$.
Then we have a morphism $O \to A'$ such that the post-compositions with $f,g$
are equal. But by weak initialness, there is a map $A \to O$; thus we get a
composite
\[ A \to O \to A'.  \]
We claim that this is a \emph{section} of the embedding $A'\to A$.
This will prove the result. Indeed, we will have constructed a section $A \to
A'$, and since it factors through $O$, the two maps
\[ A \to O \to A' \rightrightarrows X  \]
are equal. Thus, composing each of these with the inclusion $A' \to A$ shows
that $f,g$ were equal in the first place.

Thus we are reduced to proving:
\begin{lemma}
Let $A$ be an object of a category $\mathcal{C}$. Let $A'$ be the equalizer of
all endomorphisms of $A$. Then any morphism $A \to A'$ is a section of the
inclusion $A' \to A$.
\end{lemma}
\begin{proof}
Consider the canonical inclusion $i: A' \to A$. We are given some map $s: A
\to A'$; we must show that $si = 1_{A'}$.
Indeed, consider the composition
\[ A' \stackrel{i}{\to} A \stackrel{s}{\to} A' \stackrel{i}{\to} A .\]
Now $i$ equalizes endomorphisms of $A$; in particular, this composition is the
same as
\[ A' \stackrel{i}{\to} A \stackrel{\mathrm{id}}{\to} A; \]
that is, it equals $i$. So the map $si: A' \to A$ has the property that $isi =
i$ as maps $A' \to A$. But $i$ being a monomorphism, it follows that $si  =
1_{A'}$.
\end{proof}
\end{proof}

\begin{theorem}[Freyd] \label{initialobjectthm}
Let $\mathcal{C}$ be a category admitting all small limits.\footnote{We shall
later call such a category \textbf{complete}.} Then $\mathcal{C}$ has an initial
object if and only if the following \textbf{solution set condition holds:}
there is a set $\left\{X_i, i \in I\right\}$ of objects in $\mathcal{C}$ such
that any $X \in \mathcal{C}$ can be mapped into by one of these.
\end{theorem}

The idea is that the family $\left\{X_i\right\}$ is somehow weakly universal
\emph{together.}
\begin{proof}
If $\mathcal{C}$ has an initial object, we may just consider that as the
family $\left\{X_i\right\}$: we can hom out (uniquely!) from a universal
object into anything, or in other words a universal object is weakly universal.

Suppose we have a ``weakly universal family'' $\left\{X_i\right\}$. Then the
product $\prod X_i$ is weakly universal. Indeed, if $X \in \mathcal{C}$,
choose some $i'$ and a morphism $X_{i'} \to X$ by the hypothesis. Then this map
composed with the projection from the product gives a map  $\prod X_i \to
X_{i'} \to X$.
\cref{weakinitial} now implies that $\mathcal{C}$ has an initial object.
\end{proof}

\subsection{Completeness and cocompleteness}
\begin{definition}\label{completecat} A category $\mathcal{C}$ is said to be \textbf{complete} if for every
functor $F:I\rightarrow \mathcal{C}$ where $I$ is a small category, the limit
$\lim F$ exists (i.e. $\mathcal{C}$ has all small limits). If all colimits exist, then $\mathcal{C}$ is said to be
\textbf{cocomplete}.
\end{definition}

If a category is complete, various nice properties hold.
\begin{proposition} If $\mathcal{C}$ is a complete category, the following
conditions are true:
\begin{enumerate}
\item{all (finite) products exist}
\item{all pull-backs exist}
\item{there is a terminal object}
\end{enumerate}
\end{proposition}
\begin{proof} The proof of the first two properties is trivial since they can
all be expressed as limits; for the proof of the existence of a terminal
object, consider the empty diagram $F:\emptyset \rightarrow \mathcal{C}$. Then
the
terminal object is just $\lim F$.
\end{proof}

Of course, if one dualizes everything we get a theorem about cocomplete
categories which is proved in essentially the same manner. More is true
however; it turns out that finite (co)completeness are equivalent to the
properties above if one requires the finiteness condition for the existence of
(co)products.

\subsection{Continuous and cocontinuous functors}
\subsection{Monomorphisms and epimorphisms}
We now wish to characterize monomorphisms and epimorphisms in a purely
categorical setting. In categories where there is an underlying set the notions
of injectivity and surjectivity makes sense but in category theory, one
does not
in a sense have ``access'' to the internal structure of objects. In this light,
we make the following definition.

\begin{definition}
A morphism $f:X \to Y$ is a \textbf{monomorphism} if for any two morphisms
$g_1:X'\rightarrow X$ and $g_2:X'\rightarrow X$, we have that $f g_1 = f g_2$
implies $g_1=g_2$. A morphism $f:X\rightarrow Y$ is an \textbf{epimorphism} if for any two
maps $g_1:Y\rightarrow Y'$ and $g_2:Y\rightarrow Y'$, we have that $g_1 f = g_2
f$ implies $g_1 = g_2$.
\end{definition}

So $f: X \to Y$ is a monomorphism if whenever $X'$ is another object in
$\mathcal{C}$, the map
\[ \hom_{\mathcal{C}}(X', X) \to \hom_{\mathcal{C}}(X', Y)  \]
is an injection (of sets). Epimorphisms in a category are defined similarly;
note that neither definition makes any reference to \emph{surjections} of sets.


The reader can easily check:

\begin{proposition}  \label{compositeofmono}
The composite of two monomorphisms is a monomorphism, as is the composite of
two epimorphisms.
\end{proposition}

\begin{exercise}
Prove \cref{compositeofmono}.
\end{exercise}


\begin{exercise}
The notion of ``monomorphism'' can be detected using only the notions of
fibered product and isomorphism. To see this, suppose $i: X \to Y$ is a
monomorphism. Show that the diagonal
\[ X \to X \times_Y X  \]
is an isomorphism. (The diagonal map is such that the two
projections to $X$ both give the identity.) Conversely, show that if $i: X \to Y$ is any morphism such
that the above diagonal map is an isomorphism, then $i$ is a monomorphism.

Deduce the following consequence: if $F: \mathcal{C} \to \mathcal{D}$ is a
functor that commutes with fibered products, then $F $ takes monomorphisms to
monomorphisms.
\end{exercise}


\section{Yoneda's lemma}

\add{this section is barely fleshed out}

Let $\mathcal{C}$ be a category.
In general, we have said that there is no way to study an object in  a
category other than by considering maps into and out of it.
We will see that essentially everything about $X \in \mathcal{C}$ can be
recovered from these hom-sets.
We will thus get an embedding of $\mathcal{C}$ into a category of functors.

\subsection{The functors $h_X$}

We now use the structure of a category to construct hom functors.
\begin{definition}
Let $X \in \mathcal{C}$. We define the contravariant functor $h_X: \mathcal{C}
\to \mathbf{Sets}$ via
\[ h_X(Y) = \hom_{\mathcal{C}}(Y, X).  \]
\end{definition}

This is, indeed, a functor. If $g: Y \to Y'$, then precomposition gives a map
of sets
\[ h_X(Y') \to h_X(Y),  \quad f \mapsto f \circ g \]
which satisfies all the usual identities.

As a functor, $h_X$ encodes \emph{all} the information about
how one can map into $X$.
It turns out that one can basically recover $X$ from $h_X$, though.

\subsection{The Yoneda lemma}

Let $X \stackrel{f}{\to} X'$ be a morphism in $\mathcal{C}$.
Then for each $Y \in \mathcal{C}$, composition gives a map
\[ \hom_{\mathcal{C}}(Y, X) \to \hom_{\mathcal{C}}(Y, X').  \]
It is easy to see that this induces a \emph{natural} transformation
\[ h_{X} \to h_{X'}.  \]
Thus we get a map of sets
\[ \hom_{\mathcal{C}}(X, X') \to \hom(h_X, h_{X'}),  \]
where $h_X, h_{X'}$ lie in the category of contravariant functors $\mathcal{C}
\to \mathbf{Sets}$.
In other words, we have defined a \emph{covariant functor}
\[ \mathcal{C} \to \mathbf{Fun}(\mathcal{C}^{op}, \mathbf{Sets}).  \]
This is called the \emph{Yoneda embedding.} The next result states that the
embedding is fully faithful.

\begin{theorem}[Yoneda's lemma]
\label{yonedalemma}
If $X, X' \in \mathcal{C}$, then the map
$\hom_{\mathcal{C}}(X, X') \to \hom(h_X, h_{X'})$ is a bijection. That is,
every natural transformation $h_X \to h_{X'}$ arises in one and only one way
from a morphism $X \to X'$.
\end{theorem}


\begin{theorem}[Strong Yoneda lemma]
\end{theorem}

\subsection{Representable functors}

We use  the same notation of the preceding section: for a category
$\mathcal{C}$ and $X \in \mathcal{C}$, we let $h_X$ be the contravariant
functor $\mathcal{C} \to \mathbf{Sets}$ given by $Y \mapsto
\hom_{\mathcal{C}}(Y, X)$.
\begin{definition}
A contravariant functor $F: \mathcal{C} \to \mathbf{Sets}$ is
\textbf{representable} if it is naturally isomorphic to some $h_X$.
\end{definition}

The point of a representable functor is that it can be realized as maps into a
specific object.
In fact, let us look at a specific feature of the functor $h_X$.
Consider the object $\alpha \in h_X(X)$ that corresponds to the identity.
Then any morphism
\[ Y \to X  \]
factors \emph{uniquely}
as \[ Y \to X \stackrel{\alpha}{\to } X  \]
(this is completely trivial!) so that
any element of $h_X(Y)$ is a $f^*(\alpha)$ for precisely one $f:  Y \to X$.

\begin{definition}
Let $F: \mathcal{C} \to \mathbf{Sets}$ be a contravariant functor. A
\textbf{universal object} for $\mathcal{C}$ is a pair $(X, \alpha)$ where $X
\in \mathcal{C}, \alpha \in F(X)$ such that the following condition holds:
if $Y$ is any object and $\beta \in F(Y)$, then there is a unique $f: Y \to X$
such that $\alpha$ pulls back to $\beta$ under $f$.

In other words, $\beta = f^*(\alpha)$.
\end{definition}

So a functor has a universal object if and only if it is representable.
Indeed, we just say that the identity $X \to X$ is universal for $h_X$, and
conversely if $F$ has a universal object $(X, \alpha)$, then $F$ is naturally
isomorphic to $h_X$ (the isomorphism $h_X \simeq F$ being given by pulling
back $\alpha$ appropriately).


The article \cite{Vi08} by Vistoli contains a good introduction to and several
examples of this theory.
Here is one of them:

\begin{example}
Consider the contravariant functor $F: \mathbf{Sets} \to \mathbf{Sets}$ that
sends any set $S$ to its power set $2^S$ (i.e. the collection of subsets).
This is a contravariant functor: if $f: S \to T$, there is a morphism
\[ 2^T \to 2^S, \quad T' \mapsto f^{-1}(T').  \]

This is a representable functor. Indeed, the universal object can be taken as
the pair
\[ ( \left\{0,1\right\}, \left\{1\right\}).  \]

To understand this, note that a subset $S;$ of $S$ determines its
\emph{characteristic function} $\chi_{S'}: S \to \left\{0,1\right\}$ that
takes the value $1$ on $S$ and $0$ elsewhere.
If we consider $\chi_{S'}$ as a morphism $ S \to \left\{0,1\right\}$, we see
that
\[ S' = \chi_{S'}^{-1}(\{1\}).  \]
Moreover, the set of subsets is in natural bijection with the set of
characteristic functions, which in turn are precisely \emph{all} the maps $S
\to \left\{0,1\right\}$. From this the assertion is clear.
\end{example}

We shall meet some elementary criteria for the representability of
contravariant functors in the next subsection. For now, we note\footnote{The
reader unfamiliar with algebraic topology may omit these remarks.} that in
algebraic topology, one often works with the \emph{homotopy category} of
pointed CW complexes (where morphisms are pointed continuous maps modulo
homotopy), any contravariant functor that satisfies two relatively mild
conditions (a
Mayer-Vietoris condition and a condition on coproducts), is automatically
representable by a theorem of Brown. In particular, this implies that the
singular cohomology functors $H^n(-, G)$ (with coefficients in some group $G$)
are representable; the representing objects are the so-called
Eilenberg-MacLane spaces  $K(G,n)$.  See \cite{Ha02}.


\subsection{Limits as representable functors}

\add{}

\subsection{Criteria for representability}

Let $\mathcal{C}$ be a category.
We saw in the previous subsection that a representable functor must send
colimits to limits.
We shall now see that there is a converse under certain set-theoretic
conditions.
For simplicity, we start by stating the result for corepresentable functors.

\begin{theorem}[(Co)representability theorem]
Let $\mathcal{C}$ be a complete category, and let $F: \mathcal{C} \to
\mathbf{Sets}$ be a covariant functor. Suppose $F$ preserves limits and satisfies the solution set condition:
there is a set of objects $\left\{Y_\alpha\right\}$ such that, for any $X \in
\mathcal{C}$ and $x \in F(X)$, there is a morphism
\[ Y_\alpha \to X  \]
carrying some element of $F(Y_\alpha)$ onto $x$.

Then $F$ is corepresentable.
\end{theorem}
\begin{proof}
To $F$, we associate the following \emph{category} $\mathcal{D}$. An object of
$\mathcal{D}$ is a pair $(x, X)$ where $x \in F(X)$ and $X \in \mathcal{C}$.
A morphism between $(x, X)$ and $(y, Y)$ is a map
\[ f:X \to Y  \]
that sends $x$ into $y$ (via $F(f): F(X) \to F(Y)$).
It is easy to see that $F$ is corepresentable if and only if there is an initla
object in this category; this initial object is the ``universal object.''

We shall apply the initial object theorem, \cref{initialobjectthm}. Let us first verify that
$\mathcal{D}$ is complete; this follows because $\mathcal{C}$ is and $F$
preserves limits. So, for instance, the product of $(x, X)$ and $(y, Y)$ is
$((x,y), X \times Y)$; here $(x,y)$ is the element of $F(X) \times F(Y) = F(X
\times Y)$.
The solution set condition states that there is a weakly
initial family of objects, and the initial object theorem now implies that
there is an initial object.
\end{proof}
\section{Adjoint functors}

According to MacLane, ``Adjoint functors arise everywhere.'' We shall see
several examples of adjoint functors in this book (such as $\hom$ and the
tensor product). The fact that a functor has an adjoint often immediately
implies useful properties about it (for instance, that it commutes with either
limits or colimits); this will lead, for instance, to conceptual arguments
behind the right-exactness of the tensor product later on.


\subsection{Definition}

Suppose $\mathcal{C}, \mathcal{D}$ are categories, and let $F: \mathcal{C} \to
\mathcal{D}, G: \mathcal{D} \to \mathcal{C}$ be (covariant) functors.

\begin{definition}
$F, G$ are \textbf{adjoint functors} if there is a natural isomorphism
\[ \hom_{\mathcal{D}}(Fc, d) \simeq \hom_{\mathcal{C}}(c, Gd)  \]
whenever $c \in \mathcal{C}, d \in \mathcal{D}$. $F$ is said to be the
\textbf{right adjoint,} and $G$ is the \textbf{left adjoint.}
\end{definition}

Here ``natural'' means that the two quantities are supposed to be considered
as functors $\mathcal{C}^{op} \times \mathcal{D} \to \mathbf{Set}$.

\begin{example}
There is a simple pair of adjoint functors between $\mathbf{Set}$ and $\mathbf{AbGrp}$. Here
$F$ sends  a set $A$ to the free abelian group (see \cref{} for a discussion
of free modules over arbitrary rings) $\mathbb{Z}[A]$, while $G$ is
the ``forgetful'' functor that sends an abelian group to its underlying set.
Then $F$ and $G$ are adjoints. That is, to give a group-homomorphism
\[ \mathbb{Z}[A] \to G  \]
for some abelian group $G$
is the same as giving a map of \emph{sets}
\[ A \to G.  \]
This is precisely the defining property of the free abelian group.
\end{example}

\begin{example}
In fact, most ``free'' constructions are just left adjoints.
For instance, recall the universal property of the free group $F(S)$ on a set $S$ (see
\cite{La02}): to give a group-homomorphism $F(S) \to G$ for $G$ any group is
the same as choosing an image in $G$ of each $s \in S$.
That is,
\[ \hom_{\mathbf{Grp}}(F(S), G) = \hom_{\mathbf{Sets}}(S, G).  \]
This states that the free functor $S \mapsto F(S)$ is left adjoint to the
forgetful functor from $\mathbf{Grp}$ to $\mathbf{Sets}$.
\end{example}

\begin{example}
The abelianization functor $G \mapsto G^{ab} = G/[G, G]$ from $\mathbf{Grp}
\to \mathbf{AbGrp}$ is left adjoint to the
inclusion $\mathbf{AbGrp} \to \mathbf{Grp}$.
That is, if $G$ is a group and $A$ an abelian group, there is  a natural
correspondence between homomorphisms $G \to A$ and $G^{ab} \to A$.
Note that $\mathbf{AbGrp}$ is a subcategory of $\mathbf{Grp}$ such that the
inclusion admits a left adjoint; in this situation, the subcategory is called
\textbf{reflective.}
\end{example}



\subsection{Adjunctions}

The fact that two functors are adjoint is encoded by a simple set of algebraic
data between them.
To see this, suppose $F: \mathcal{C} \to \mathcal{D}, G: \mathcal{D} \to \mathcal{C}$ are
adjoint functors.
For any object $c \in \mathcal{C}$, we know that
\[ \hom_{\mathcal{D}}(Fc, Fc) \simeq \hom_{\mathcal{C}}(c, GF c),  \]
so that the identity morphism $Fc \to Fc$ (which is natural in $c$!) corresponds to a map $c \to GFc$
that is natural in $c$, or equivalently a natural
transformation
\[ \eta: 1_{\mathcal{C}} \to GF. \]
Similarly, we get a natural transformation
\[ \epsilon:  FG \to 1_{\mathcal{D}}  \]
where the map $FGd \to d$ corresponds to the identity $Gd \to Gd$ under the
adjoint correspondence.
Here $\eta$ is called the \textbf{unit}, and $\epsilon$ the \textbf{counit.}

These natural transformations $\eta, \epsilon$ are not simply arbitrary.
We are, in fact, going to show that they determine the isomorphism
determine the isomorphism $\hom_{\mathcal{D}}(Fc, d) \simeq
\hom_{\mathcal{C}}(c, Gd)$. This will be a little bit of diagram-chasing.

We know that the isomorphism $\hom_{\mathcal{D}}(Fc, d) \simeq
\hom_{\mathcal{C}}(c, Gd)$ is \emph{natural}. In fact, this is the key point.
Let $\phi: Fc \to d$ be any map.
Then there is a morphism $(c, Fc) \to (c, d) $ in the product category
$\mathcal{C}^{op} \times \mathcal{D}$; by naturality of the adjoint
isomorphism, we get a commutative square of sets
\[ \xymatrix{
\hom_{\mathcal{D}}(Fc, Fc) \ar[r]^{\mathrm{adj}}  \ar[d]^{\phi_*} & \hom_{\mathcal{C}}(c, GF c)
\ar[d]^{G(\phi)_*} \\
\hom_{\mathcal{D}}(Fc, d) \ar[r]^{\mathrm{adj}} &  \hom_{\mathcal{C}}(c, Gd)
}\]
Here the mark $\mathrm{adj}$ indicates that the adjoint isomorphism is used.
If we start with the identity $1_{Fc}$ and go down and right, we get the map
\( c \to Gd  \)
that corresponds under the adjoint correspondence to $Fc \to d$. However, if we
go right and down, we get the natural unit map $\eta(c): c \to GF c$ followed by $G(\phi)$.

Thus, we have a \emph{recipe} for constructing a map $c \to Gd$ given $\phi: Fc \to
d$:
\begin{proposition}[The unit and counit determines everything]
Let $(F, G)$ be a pair of adjoint functors with unit and counit transformations
$\eta, \epsilon$.

Then given $\phi: Fc \to d$, the adjoint map $\psi:c \to Gd$ can be constructed simply as
follows.
Namely, we start with the unit $\eta(c): c \to GF c$ and take
\begin{equation} \label{adj1} \psi =  G(\phi) \circ \eta(c): c \to Gd
\end{equation} (here $G(\phi): GFc \to Fd$).
\end{proposition}

In the same way, if we are given $\psi: c \to Gd$ and want to construct a map
$\phi: Fc \to d$, we construct
\begin{equation} \label{adj2} \epsilon(d) \circ  F(\psi): Fc \to FGd \to   d.
\end{equation}
In particular, we have seen that the \emph{unit and counit morphisms determine
the adjoint isomorphisms.}


Since the adjoint isomorphisms $\hom_{\mathcal{D}}(Fc, d) \to
\hom_{\mathcal{C}}(c, Gd)$ and
$\hom_{\mathcal{C}}(c, Gd) \to \hom_{\mathcal{D}}(Fc, d)
$
are (by definition) inverse to each other, we can determine
conditions on the units and counits.

For
instance, the natural transformation $F \circ \eta$ gives a natural
transformation $F \circ \eta: F \to FGF$, while the natural transformation
$\epsilon \circ F$ gives a natural transformation $FGF \to F$.
(These are slightly different forms of composition!)

\begin{lemma}  The composite natural transformation $F \to F$ given by
$(\epsilon \circ F) \circ (F \circ \eta)$ is the identity.
Similarly, the composite natural transformation
$G \to GFG \to G$ given by $(G \circ \epsilon) \circ (\eta \circ G)$ is the
identity.
\end{lemma}


\begin{proof} We prove the first assertion; the second is similar.
Given $\phi: Fc \to d$, we know that we must get back to $\phi$ applying the
two constructions above. The first step (going to a map $\psi: c \to Gd$) is by
\eqref{adj1}
\( \psi = G(\phi) \circ \eta(c);  \) the second step sends $\psi$ to
$\epsilon(d) \circ F(\psi)$, by \eqref{adj2}.
It follows that
\[ \phi = \epsilon(d) \circ F( G(\phi) \circ \eta(c)) = \epsilon(d) \circ
F(G(\phi)) \circ F(\eta(c)). \]
Now suppose we take $d = Fc$ and $\phi: Fc \to Fc $ to be the identity.
We find that $F(G(\phi))$ is the identity $FGFc \to FGFc$, and consequently we
find
\[ \id_{F(c)} = \epsilon(Fc) \circ F(\eta(c)). \]
This proves the claim.
\end{proof}



\begin{definition}
Let $F: \mathcal{C} \to \mathcal{D}, G: \mathcal{D} \to \mathcal{C}$ be
covariant functors. An \textbf{adjunction} is the data of two natural
transformations
\[ \eta: 1 \to GF, \quad \epsilon: FG \to 1,  \]
called the \textbf{unit} and \textbf{counit}, respectively, such that the
composites $(\epsilon \circ F) \circ (F \circ \epsilon): F \to F$
and $(G \circ \epsilon) \circ (\eta \circ G)$ are the identity (that is, the
identity natural transformations of $F, G$).
\end{definition}

We have seen that a pair of adjoint functors gives rise to an adjunction.
Conversely, an adjunction between $F, G$ ensures that $F, G$ are adjoint, as
one may check: one uses the same formulas \eqref{adj1} and \eqref{adj2} to
define the natural isomorphism.


For any set $S$, let $F(S)$ be the free group on $S$.
So, for instance, the fact that there is a natural map of sets
$S \to F(S)$, for any set $S$, and a natural map of
groups $F(G) \to G$ for any group $G$, determines the adjunction between the
free group functor from $\mathbf{Sets}$ to $\mathbf{Grp}$, and the forgetful
functor $\mathbf{Grp} \to \mathbf{Sets}$.



As another example, we give a criterion for a functor in an adjunction to be
fully faithful.

\begin{proposition} \label{adjfullfaithful}
Let $F, G$ be a pair of adjoint functors between categories $\mathcal{C}, \mathcal{D}$.
Then $G$ is fully faithful if and only if the unit maps $\eta: 1 \to GF$ are
isomorphisms.
\end{proposition}
\begin{proof}
We use the recipe \eqref{adj1}.
Namely, we have a map $\hom_{\mathcal{D}}(Fc, d) \to
\hom_{\mathcal{C}}(c, Gd)$ given by
$\phi \mapsto G(\phi) \circ \eta(c)$. This is an isomorphism, since we have an
adjunction.
As a result, composition with $\eta$ is an isomorphism of hom-sets if and only if $\phi
\mapsto G(\phi)$ is an isomorphism. From this the result is easy to deduce.
\end{proof}

\begin{example}
For instance, recall that the inclusion functor from $\mathbf{AbGrp}$ to
$\mathbf{Grp}$ is fully faithful (clear).
This is a right adjoint to the abelianization functor $G \mapsto G^{ab}$.
As a result, we would expect the unit map of the adjunction to be an
isomorphism, by \cref{adjfullfaithful}.

The unit map sends an abelian group to its abelianization: this is obviously an
isomorphism, as abelianizing an abelian group does nothing.
\end{example}

\subsection{Adjoints and (co)limits}
One very pleasant property of functors that are left (resp. right) adjoints is
that they preserve all colimits (resp. limits).

\begin{proposition} \label{adjlimits}
A left adjoint $F: \mathcal{C} \to \mathcal{D}$ preserves colimits. A right
adjoint $G: \mathcal{D} \to \mathcal{C}$ preserves limits.
\end{proposition}

As an example, the free functor from $\mathbf{Sets}$ to $\mathbf{AbGrp}$ is a
left adjoint, so it preserves colimits. For instance, it preserves coproducts.
This corresponds to the fact that if $A_1, A_2$ are sets, then $\mathbb{Z}[A_1
\sqcup A_2]$ is naturally isomorphic to $\mathbb{Z}[A_1] \oplus
\mathbb{Z}[A_2]$.

\begin{proof}
Indeed, this is mostly formal.
Let $F: \mathcal{C}\to \mathcal{D}$ be a left adjoint functor, with right
adjoint $G$.
Let $f: I \to \mathcal{C}$ be a ``diagram'' where $I$ is a small category.
Suppose $\colim_I f$ exists as an object of $\mathcal{C}$. The result states
that $\colim_I F \circ f$ exists as an object of $\mathcal{D}$ and can be
computed as
$F(\colim_I f)$.
To see this, we need to show that mapping out of $F(\colim_I f)$ is what we
want---that is, mapping out of $F(\colim_I f)$ into some $d \in \mathcal{D}$---amounts to
giving compatible $F(f(i)) \to d$ for each $i \in I$.
In other words, we need to show that $\hom_{\mathcal{D}}( F(\colim_I f), d) =
\lim_I \hom_{\mathcal{D}}(
F(f(i)), d)$; this is precisely the defining property of the colimit.

But we have
\[ \hom_{\mathcal{D}}( F(\colim_I f  ), d) = \hom_{\mathcal{C}}(\colim_I f, Gd)
= \lim_I \hom_{\mathcal{C}}(fi, Gd) = \lim_I \hom_{\mathcal{D}}(F(fi), d),
\]
by using adjointness twice.
This verifies the claim we wanted.
\end{proof}

The idea is that one can easily map \emph{out} of the value of a left adjoint
functor, just as one can map out of a colimit.



% ============================ chapters/foundations.tex

\chapter{Foundations}
\label{foundations}


The present foundational chapter will introduce the notion of a ring and,
next, that of  a module over a ring. These notions will be the focus of the
present book. Most of the chapter will be definitions.

We begin with a few historical remarks.  Fermat's last theorem states that the
equation
  \[ \label{ft} x^n  + y^n = z^n \]
has no nontrivial solutions in the integers, for $n \ge 3$.  We could try to
prove this by factoring the expression on the left hand side. We can write
  \[ (x+y)(x+ \zeta y) (x+ \zeta^2y) \dots (x+ \zeta^{n-1}y) = z^n, \]
where $\zeta$ is a primitive $n$th root of unity.  Unfortunately, the factors
lie in $\mathbb{Z}[\zeta]$, not the integers $\mathbb{Z}$.  Though
$\mathbb{Z}[\zeta]$ is still a \emph{ring} where we have notions of primes and
factorization, just as in $\mathbb{Z}$, we will see that prime factorization
is not always unique in $\mathbb{Z}[\zeta]$. (If it were always unique, then we
could at least one important case of Fermat's last theorem rather easily; see
the introductory chapter of \cite{Wa97} for an argument.)

For instance, consider the ring
$\mathbb{Z}[\sqrt{-5}]$ of complex numbers of the form $a + b\sqrt{-5}$, where
$a, b \in \mathbb{Z}$.  Then we have the two factorizations
  \[ 6 = 2 \cdot 3 = (1 + \sqrt{-5})(1 - \sqrt{-5}). \]
Both of these are factorizations of 6 into irreducible factors, but they
are fundamentally different.

In part, commutative algebra grew out of the need to understand this failure
of unique factorization more generally. We shall have more to say on
factorization in the future, but here we just focus on the formalism.
The basic definition for studying this problem is that of a \emph{ring}, which we now
introduce.

\section{Commutative rings and their ideals}

\subsection{Rings}

We shall mostly just work with commutative rings in this book, and consequently
will just say ``ring'' for one such.
\begin{definition}
A \textbf{commutative ring} is a set $R$ with an addition map
$+ : R \times R \to R$ and a multiplication map $\times : R \times R \to R$
that satisfy the following conditions.

\begin{enumerate}
  \item $R$ is a group under addition.
  \item The multiplication map is commutative and distributes over addition.
  This means that $x \times (y+z) = x \times y + x\times z$ and $x \times y = y
  \times x$.
  \item There is a \textbf{unit} (or \textbf{identity element}), denoted by
        $1$, such that $1 \times x = x$ for all $x \in R$.
\end{enumerate}
We shall typically write $xy$ for $x \times y$.

Given a ring, a \textbf{subring} is a subset that contains the identity
element and is closed under addition and multiplication.
\end{definition}

A \emph{noncommutative} (i.e. not necessarily commutative) ring is one
satisfying the above conditions, except possibly for the commutativity
requirement $xy = yx$. For instance, there is a noncommutative ring of
$2$-by-$2$ matrices over $\mathbb{C}$. We shall not work too much with noncommutative rings in
the sequel, though many of the basic results (e.g. on modules) do generalize.


\begin{example}
$\mathbb{Z}$ is the simplest example of a ring.
\end{example}

\begin{exercise}\label{polynomial} Let $R$ be a commutative ring.
Show that the set of polynomials in one variable over $R$ is a commutative
ring $R[x]$. Give a rigorous definition of this.
\end{exercise}

\begin{example}
For any ring $R$, we can consider the polynomial ring $R[x_1, \ldots, x_n]$
which consists of the polynomials in $n$ variables with coefficients in $R$.
This can be defined inductively as $(R[x_1, \dots, x_{n-1}])[x_n]$, where the
procedure of adjoining a single variable comes from the previous
\cref{polynomial}.
\end{example}

We shall see a more general form of this procedure in \cref{groupring}.


\begin{exercise}
If $R$ is a commutative ring, recall that an \textbf{invertible element} (or, somewhat
confusingly, a \textbf{unit}) $u \in R$ is an element such
that there exists $v \in R$ with $uv = 1$. Prove that $v$ is necessarily
unique.
\end{exercise}

\begin{exercise} \label{ringoffns}
Let $X$ be a set and $R$ a ring. The set $R^X$ of functions $f:X \to R$ is a
ring. \end{exercise}

\subsection{The category of rings}
The class of rings forms a category. Its morphisms are called ring homomorphisms.


\begin{definition}
A \textbf{ring homomorphism} between two rings $R$ and $S$ as a map
$f : R \to S$ that respects addition and multiplication. That is,

\begin{enumerate}
  \item $f(1_R) = 1_S$, where $1_R$ and $1_S$ are the respective identity
        elements.
  \item $f(a + b) = f(a) + f(b)$ for $a, b \in R$.
  \item $f(ab) = f(a)f(b)$ for $a, b \in R$.
\end{enumerate}
There is thus a \emph{category} $\mathbf{Ring}$ whose objects are commutative
rings and whose morphisms are ring-homomorphisms.
\end{definition}

The philosophy of Grothendieck, as expounded in his EGA \cite{EGA}, is that one should
always do things in a relative context. This means that instead of working
with objects, one should work with \emph{morphisms} of objects. Motivated by
this, we introduce:

\begin{definition}
Given a ring $A$, an \textbf{$A$-algebra} is a ring $R$ together with a
morphism of rings (a \textbf{structure morphism}) $A \to R$. There is a category of $A$-algebras, where a
morphism between $A$-algebras is a ring-homomorphism that is required to commute with the structure
morphisms.
\end{definition}

So if $R$ is an $A$-algebra, then $R$ is not only a ring, but there is a way
to multiply elements of $R$ by elements of $A$ (namely, to multiply $a \in A$
with $r \in R$, take the image of $a $ in $R$, and multiply that by $r$).
For instance, any ring is an algebra over any subring.

We can think of an $A$-algebra as an arrow $A \to R$, and a morphism from $A
\to R$ to $A \to S$ as a commutative diagram
\[ \xymatrix{
R \ar[rr] & & S \\
& \ar[lu] A \ar[ru]
}\]
This is a special case of the \emph{undercategory} construction.

If $B$ is an $A$-algebra and $C$ a $B$-algebra, then $C$ is an $A$-algebra in a
natural way. Namely, by assumption we are given morphisms of rings $A \to B$
and $B \to C$, so composing them gives the structure morphism $A \to C$ of $C$
as an $A$-algebra.


\begin{example}
Every ring is a $\mathbb{Z}$-algebra in a natural and unique way. There is a
unique map (of rings) $\mathbb{Z} \to R$ for any ring $R$ because a
ring-homomorphism is required to preserve the identity.
In fact, $\mathbb{Z}$ is the \emph{initial object} in the category of rings:
this is a restatement of the preceding discussion.
\end{example}

\begin{example}
If $R$ is a ring, the polynomial ring $R[x]$ is an $R$-algebra in a natural
manner. Each element of $R$ is naturally viewed as a ``constant polynomial.''
\end{example}

\begin{example}
$\mathbb{C}$ is an $\mathbb{R}$-algebra.
\end{example}

Here is an example that generalizes the case of the polynomial ring.
\begin{example}
\label{groupring}
If $R$ is a ring and $G$ a commutative monoid,\footnote{That is, there is a
commutative multiplication on $G$ with an identity element, but not
necessarily with inverses.} then the set
$R[G]$ of formal finite sums $\sum r_i g_i$ with $r_i \in R, g_i \in G$ is a
commutative ring, called the \textbf{moniod ring} or \textbf{group ring} when
$G$ is a group.
Alternatively, we can think of elements of $R[G]$ as infinite sums $\sum_{g \in
G} r_g g$ with $R$-coefficients, such that almost all the $r_g$ are zero.
We can define the multiplication law such that
\[ \left(\sum r_g g\right)\left( \sum s_g g\right) =
\sum_h \left( \sum_{g g' = h} r_g s_{g'}  \right) h.
\]
This process is called \emph{convolution.} We can think of the multiplication
law as extended the group multiplication law (because the product of the
ring-elements corresponding to $g, g'$ is the ring element corresponding to
$gg' \in G$).

The case of $G =
\mathbb{Z}_{\geq 0}$ is the polynomial ring.
In some cases, we can extend this notion to formal infinite sums, as in the
case of the formal power series ring; see \cref{powerseriesring} below.
\end{example}

\begin{exercise}
\label{integersinitial}
The ring $\mathbb{Z}$ is an \emph{initial object} in the category of rings.
That is, for any ring $R$, there is a \emph{unique} morphism of rings
$\mathbb{Z} \to R$. We discussed this briefly earlier; show more generally that
$A$ is the initial object in the category of $A$-algebras for any ring $A$.
\end{exercise}

\begin{exercise}
The ring where $0=1$ (the \textbf{zero ring}) is a \emph{final object} in the category of rings. That
is, every ring admits a unique map to the zero ring.	
\end{exercise}

\begin{exercise}
\label{corepresentable}
Let $\mathcal{C}$ be a category and $F: \mathcal{C} \to \mathbf{Sets}$  a
covariant functor. Recall that $F$ is said to be \textbf{corepresentable} if
$F$ is naturally isomorphic to $X \to \hom_{\mathcal{C}}(U, X)$ for some
object $U \in \mathcal{C}$. For instance, the functor sending everything to a
one-point set is corepresentable if and only if $\mathcal{C}$ admits an
initial object.

Prove that the functor  $\mathbf{Rings} \to \mathbf{Sets}$ assigning to each ring its underlying set is
representable. (Hint: use a suitable polynomial ring.)
\end{exercise}


The category of rings is both complete and cocomplete. To show this in full
will take more work, but we can here describe what
certain cases (including all limits) look like.
As we saw in \cref{corepresentable}, the forgetful functor $\mathbf{Rings} \to
\mathbf{Sets}$ is corepresentable. Thus, if we want to look for limits in the
category of rings, here is the approach we should follow: we should take the
limit first of the underlying sets, and then place a ring structure on it in
some natural way.

\begin{example}[Products]
The \textbf{product} of two rings $R_1, R_2$ is the set-theoretic product $R_1
\times R_2$ with the multiplication law $(r_1, r_2)(s_1, s_2) = (r_1 s_1, r_2
s_2)$. It is easy to see that this is a product in the category of rings. More
generally, we can easily define the product of any collection of rings.
\end{example}

To describe the coproduct is more difficult: this will be given by the
\emph{tensor product} to be developed in the sequel.

\begin{example}[Equalizers]
Let $f, g: R \rightrightarrows S$ be two ring-homomorphisms. Then we can
construct the \textbf{equalizer} of $f,g$ as the subring of $R$ consisting of
elements $x \in R$ such that $f(x) = g(x)$. This is clearly a subring, and one
sees quickly that it is the equalizer in the category of rings.
\end{example}

As a result, we find:
\begin{proposition}
$\mathbf{Rings}$ is complete.
\end{proposition}

As we said, we will not yet show that $\mathbf{Rings}$ is cocomplete. But we
can describe filtered colimits.  In fact, filtered colimits will be constructed
just as in the set-theoretic fashion. That is, the forgetful functor
$\mathbf{Rings} \to \mathbf{Sets}$ commutes with \emph{filtered} colimits
(though not with general colimits).
\begin{example}[Filtered colimits]
Let $I$ be a filtering category, $F: I \to \mathbf{Rings}$ a functor. We can
construct $\varinjlim_I F$ as follows. An object is an element $(x,i)$ for $i
\in I$ and $x \in F(i)$, modulo equivalence; we say that $(x, i)$ and $(y, j)$
are equivalent if there is a $k \in I$ with maps $i \to k, j \to k$ sending
$x,y$ to the same thing in the ring $F(k)$.

To multiply $(x, i)$ and $(y,j)$, we find
some $k \in I$ receiving maps from $i, j$, and replace $x,y$ with elements of
$F(k)$. Then we multiply those two in $F(k)$. One easily sees that this is a
well-defined multiplication law that induces a ring structure, and that what we
have described is in fact the filtered colimit.

\end{example}
\subsection{Ideals}

An \emph{ideal} in a ring is  analogous to a normal subgroup of a
group. As we shall see, one may quotient by ideals just as one quotients by
normal subgroups.
The idea is that one wishes to have a suitable \emph{equivalence relation} on a
ring $R$ such that the relevant maps (addition and multiplication) factor
through this equivalence relation. It is easy to check that any such relation
arises via an ideal.

\begin{definition}
Let $R$ be a ring.  An \textbf{ideal} in $R$ is a subset $I \subset R$ that
satisfies the following.

\begin{enumerate}
  \item $0 \in I$.
  \item If $x, y \in I$, then $x + y \in I$.
  \item If $x \in I$ and $y \in R$, then $xy \in I$.
\end{enumerate}
\end{definition}

There is a simple way of obtaining ideals, which we now describe.
Given elements $x_1, \ldots, x_n \in R$, we denote by $(x_1, \ldots, x_n) \subset
R$ the subset of linear combinations $\sum r_i x_i$, where $r_i \in R$.  This
is clearly an ideal, and in fact the smallest one containing all $x_i$.  It is
called the ideal \textbf{generated} by $x_1, \ldots, x_n$.  A
\textbf{principal ideal} $(x)$ is one generated by a single $x \in R$.

\begin{example}
Ideals generalize the notion of divisibility.  Note that
in $\mathbb{Z}$, the set of elements divisible by $n \in \mathbb{Z}$ forms the
ideal $I = n\mathbb{Z} = (n)$. We shall see that every ideal in $\mathbb{Z}$ is
of this form: $\mathbb{Z}$ is a \emph{principal ideal domain.}
\end{example}

Indeed, one can think of an ideal as axiomatizing the notions that
``divisibility'' ought to satisfy. Clearly, if two elements are divisible by
something, then their sum and product should also be divisible by it. More
generally, if an element is divisible by something, then the product of that
element with anything else should also be divisible. In general, we will extend
(in the chapter on Dedekind domains) much of the ordinary arithmetic with
$\mathbb{Z}$ to arithmetic with \emph{ideals} (e.g. unique factorization).

\begin{example}
We saw in \cref{ringoffns}
that if $X$ is a set and $R$ a ring, then the set $R^X$ of functions $X \to R$
is naturally a ring. If $Y \subset X$ is a subset, then the subset of functions
vanishing on $Y$ is an ideal.
\end{example}
\begin{exercise}
Show that the ideal $(2, 1 + \sqrt{-5}) \subset \mathbb{Z}[\sqrt{-5}]$ is not
principal.
\end{exercise}

\subsection{Operations on ideals}

There are a number of simple operations that one may do with ideals, which we
now describe.

\begin{definition}
The sum $I + J$ of two ideals $I, J \subset R$ is defined as the set of sums
  \[ \left\{ x + y : x \in I, y \in J \right\}. \]
\end{definition}

\begin{definition}
The product $IJ$ of two ideals $I, J \subset R$ is defined as the smallest
ideal containing the products $xy$ for all $x \in I, y \in J$. This is just
the set
  \[ \left\{ \sum x_i y_i : x_i \in I, y_i \in J \right\}. \]
\end{definition}

We leave the basic verification of properties as an exercise:
\begin{exercise}
Given ideals $I, J \subset R$, verify the following.

\begin{enumerate}
  \item $I + J$ is the smallest ideal containing $I$ and $J$.
  \item  $IJ$ is contained in $I$ and $J$.
  \item $I \cap J$ is an ideal.
\end{enumerate}
\end{exercise}

\begin{example}
In $\mathbb{Z}$, we have the following for any $m, n$.

\begin{enumerate}
  \item $(m) + (n) = (\gcd\{ m, n \})$,
  \item $(m)(n) = (mn)$,
  \item $(m) \cap (n) = (\mathrm{lcm}\{ m, n \})$.
\end{enumerate}
\end{example}

\begin{proposition}
For ideals $I, J, K \subset R$, we have the following.

\begin{enumerate}
  \item Distributivity: $I(J + K) = IJ + IK$.
  \item $I \cap (J + K) = I \cap J + I \cap K$ if $I \supset J$ or $I \supset K$.
  \item If $I + J = R$, $I \cap J = IJ$.
\end{enumerate}

\begin{proof}
1 and 2 are clear.  For 3, note that $(I + J)(I \cap J) = I(I \cap J)
+ J(I \cap J) \subset IJ$.  Since $IJ \subset I \cap J$, the result
follows.
\end{proof}
\end{proposition}

\begin{exercise}
There is a \emph{contravariant} functor $\mathbf{Rings} \to \mathbf{Sets}$ that
sends each ring to its set of ideals. Given a map $f: R \to S$ and an ideal $I
\subset S$, we define an ideal $f^{-1}(I) \subset R$; this defines the
functoriality.
This functor is not representable, as it does not send the initial object
in $\mathbf{Rings} $ to the
one-element set. We will later use a \emph{subfunctor} of this functor, the
$\spec$ construction, when we replace ideals with ``prime'' ideals.
\end{exercise}


\subsection{Quotient rings}

We next describe a procedure for producing new rings from old ones.
If $R$ is a ring and $I \subset R$ an ideal, then the quotient group $R/I$
is a ring in its own right. If $a+I, b+I$ are two cosets, then the
multiplication is $(a+I)(b+I) = ab + I$.  It is easy to check that this does
not depend on the coset representatives $a,b$. In other words, as mentioned
earlier, the arithmetic operations on $R$ \emph{factor} through the equivalence
relation defined by $I$.

As one easily checks, this becomes to a multiplication
\[ R/I \times R/I \to R/I  \]
which is commutative and associative, and
whose identity element is $1+I$.
In particular, $R/I$ is a ring, under multiplication $(a+I)(b+I) = ab+I$.
\begin{definition}
$R/I$ is called the \textbf{quotient ring} by the ideal $I$.
\end{definition}

The process is analogous to quotienting a group by a normal subgroup: again,
the point is that the equivalence relation induced on the algebraic
structure---either the group or the ring---by the subgroup (or ideal)---is
compatible with the algebraic structure, which thus descends to the quotient.

The
reduction map $\phi \colon R \to R/I$ is a ring-homomorphism with a
\emph{universal
property}.
Namely, for any ring $B$, there is a map
 \[ \hom(R/I, B) \to \hom(R, B)  \]
 on the hom-sets
 by composing with the ring-homomorphism $\phi$; this map is injective and the
 image consists of all homomorphisms $R \to B$ which vanish on $I$.
Stated alternatively, to map out of $R/I$ (into some ring $B$) is the same thing as mapping out of
$R$ while killing the ideal $I \subset R$.

This is best thought out for oneself, but here is the detailed justification.
The reason is that any map $R/I \to B$ pulls back to a map $R \to R/I \to B$
which annihilates $I$ since $R \to R/I$ annihilates $I$. Conversely, if we have
a map
\[ f: R \to B  \]
killing $I$, then we can define $R/I \to B$ by sending $a+I$ to $f(a)$; this is
uniquely defined since $f$ annihilates $I$.

\begin{exercise}
 If $R$ is a commutative
ring, an element $e \in R$ is said to be \textbf{idempotent} if $e^2 =
e$. Define a covariant functor $\mathbf{Rings} \to \mathbf{Sets}$ sending a
ring to its idempotents. Prove that it is corepresentable. (Answer: the
corepresenting object is $\mathbb{Z}[X]/(X - X^2)$.)
\end{exercise}

\begin{exercise}
Show that the functor assigning to each ring the set of elements annihilated
by 2 is corepresentable.
\end{exercise}

\begin{exercise}
If $I \subset J \subset R$, then $J/I$ is an ideal of $R/I$, and there is a
canonical isomorphism
\[ (R/I)/(J/I) \simeq R/J.  \]
\end{exercise}






\subsection{Zerodivisors}


Let $R$ be a commutative ring.
\begin{definition}
If $r \in R$, then $r$ is called  a \textbf{zerodivisor} if there is $s \in R, s
\neq 0$ with $sr = 0$. Otherwise $r$ is called a \textbf{nonzerodivisor.}
\end{definition}

As an example, we prove a basic result on the zerodivisors in a polynomial ring.

\begin{proposition}
Let $A=R[x]$. Let $f=a_nx^n+\cdots +a_0\in A$. If there is a non-zero polynomial $g\in
A$ such that $fg=0$, then there exists $r\in R\smallsetminus\{0\}$ such that $f\cdot
 r=0$.
\end{proposition}
So all the coefficients are zerodivisors.
\begin{proof}
 Choose $g$ to be of minimal degree, with leading coefficient $bx^d$. We may assume
 that  $d>0$. Then $f\cdot b\neq 0$, lest we contradict minimality of $g$. We must have
$a_i g\neq 0$ for some $i$. To see this, assume that $a_i\cdot g=0$, then $a_ib=0$ for
all $i$ and then $fb=0$. Now pick $j$ to be the largest integer such that $a_jg\neq
   0$. Then $0=fg=(a_0 + a_1x + \cdots a_jx^j)g$, and looking at the leading coefficient,
   we get $a_jb=0$. So $\deg (a_jg)<d$. But then $f\cdot (a_jg)=0$, contradicting
   minimality of $g$.
 \end{proof}

\begin{exercise}
The product of two nonzerodivisors is a nonzerodivisor, and the product of two
zerodivisors is a zerodivisor. It is, however, not necessarily true that the
\emph{sum} of two zerodivisors is a zerodivisor.
\end{exercise}

\section{Further examples}

We now illustrate a few important examples of
commutative rings. The section is in large measure an advertisement for why
one might care about commutative algebra; nonetheless, the reader is
encouraged at least to skim this section.

\subsection{Rings of holomorphic functions}

The following subsection may be omitted without impairing understanding.

There is a fruitful analogy in number theory between the rings $\mathbb{Z}$ and
$\mathbb{C}[t]$, the latter being the polynomial ring over $\mathbb{C}$ in one
variable (\rref{polynomial}).  Why are they analogous? Both of these rings have a theory of unique
factorization:  that is, factorization into primes or irreducible polynomials. (In the
latter, the irreducible polynomials have degree one.)
Indeed we know:
\begin{enumerate}
\item Any nonzero integer factors as a product of primes (possibly times $-1$).
\item Any  nonzero polynomial factors as a product of an element of
$\mathbb{C}^* =\mathbb{C} - \left\{0\right\}$ and polynomials of the form $t -
a, a \in \mathbb{C}$.
\end{enumerate}


There is another way of thinking of $\mathbb{C}[t]$ in terms of complex
analysis.  This is equal to the ring of holomorphic functions on $\mathbb{C}$
which are meromorphic at infinity.
Alternatively, consider the Riemann sphere $\mathbb{C} \cup \{ \infty\}$; then the ring $\mathbb{C}[t]$
consists of meromorphic functions on the sphere whose poles (if any) are at
$\infty$.

This description admits generalizations.
Let $X$ be a
Riemann surface.  (Example: take the complex numbers modulo a lattice, i.e. an
elliptic curve.)
Suppose that $x \in X$. Define $R_x$ to be the ring of meromorphic functions on $X$
which are allowed poles only at $x$ (so are everywhere else holomorphic).

\begin{example} Fix the notations of the previous discussion.
Fix $y \neq x \in X$. Let $R_x$ be the ring of meromorphic functions on the
Riemann surface $X$ which are holomorphic on $X - \left\{x\right\}$, as before.
Then the collection of functions that vanish at $y$ forms an
\emph{ideal} in $R_x$.

There are lots of other ideals. For instance, fix two
points $y_0, y_1 \neq x$; we look at the ideal of $R_x$ that vanish at both $y_0, y_1$.

\end{example}


\textbf{For any Riemann surface $X$, the conclusion of Dedekind's theorem
(\rref{ded1}) applies.  } In other
words, the ring  $R_x$ as defined in the example admits  unique factorization of
ideals. We shall call such rings \textbf{Dedekind domains} in the future.

\begin{example} Keep the preceding notation.

Let $f \in R_x$, nonzero. By definition, $f$ may have a pole at $x$, but no poles elsewhere. $f$ vanishes
at finitely many points $y_1, \dots, y_m$. When $X$ was the Riemann sphere,
knowing the zeros of $f$ told us something about $f$. Indeed, in this case
$f$ is just a
polynomial, and we have a nice factorization of $f$ into functions in $R_x$ that vanish only
at one point. In general Riemann surfaces, this
is not generally possible.  This failure turns out to be very interesting.

Let $X = \mathbb{C}/\Lambda$ be an elliptic curve (for $\Lambda \subset
\mathbb{C}^2$ a lattice), and suppose $x = 0$. Suppose we
are given $y_1, y_2, \dots, y_m \in X$ that are nonzero; we ask whether there
exists a function $f \in R_x$ having simple zeros at $y_1, \dots, y_m$ and nowhere else.
The answer is interesting, and turns out to recover the group structure on the
lattice.

\begin{proposition}
A function $f \in R_x$ with simple zeros only at the $\left\{y_i\right\}$ exists if and only if $y_1 + y_2 + \dots + y_n = 0$ (modulo $\Lambda$).

\end{proposition}
So this problem of finding a function with specified zeros is equivalent to
checking that the specific zeros add up to zero with the group structure.

In any case, there might not be such a nice function, but we have at least an
ideal $I$ of functions that have zeros (not necessarily simple) at $y_1, \dots,
y_n$.  This ideal has unique factorization into the ideals of functions
vanishing at $y_1$, functions vanishing at $y_2$, so on.
\end{example}

\subsection{Ideals and varieties}

We saw in the previous subsection that ideals can be thought of as the
vanishing of functions. This, like divisibility, is another interpretation,
which is particularly interesting in algebraic geometry.


Recall the  ring $\mathbb{C}[t]$ of complex polynomials discussed in the
last subsection. More generally, if $R$ is a ring,  we saw in
\rref{polynomial} that the set $R[t]$ of polynomials with coefficients
in $R$
is a ring.  This is a construction that
can be iterated to get a polynomial ring in several variables over $R$.

\begin{example}
Consider the polynomial ring $\mathbb{C}[x_1, \dots, x_n]$. Recall that before
we thought of the ring $\mathbb{C}[t]$ as a ring of meromorphic functions.
Similarly each element of the polynomial ring $\mathbb{C}[x_1, \dots, x_n]$
gives a function $\mathbb{C}^n \to \mathbb{C}$; we can think of the polynomial
ring as sitting inside the ring of all functions $\mathbb{C}^n \to \mathbb{C}$.

A question you might ask: What are the ideals in this ring?  One way to get an
ideal is to pick a point $x=(x_1, \dots, x_n) \in \mathbb{C}^n$; consider the
collection of all functions $f \in \mathbb{C}[x_1, \dots, x_n]$ which vanish on
$x$; by the usual argument, this is an ideal.

There are, of course, other ideals. More generally, if $Y \subset
\mathbb{C}^n$, consider the collection of polynomial functions $f:
\mathbb{C}^n \to \mathbb{C}$ such that $f \equiv 0$ on
$Y$.  This is easily seen to be an ideal in the polynomial ring. We thus have a
way of taking a subset of $\mathbb{C}^n$ and producing an ideal.
Let $I_Y$ be the ideal corresponding to $Y$.

This construction is not injective. One can have $Y \neq Y'$ but $I_Y = I_{Y'}$. For instance, if $Y$ is dense in
$\mathbb{C}^n$, then $I_Y = (0)$, because the only way a continuous function on
$\mathbb{C}^n$ can vanish on $Y$ is for it to be zero.

There is a much closer connection in the other direction. You might ask whether
all ideals can arise in this way. The quick answer is no---not even when $n=1$. The ideal $(x^2) \subset \mathbb{C}[x]$ cannot be obtained
in this way.  It is easy to see that the only way we could get this as $I_Y$ is
for $Y=\left\{0\right\}$, but $I_Y$ in this case is just $(x)$, not $(x^2)$.
What's going wrong in this example is that $(x^2)$ is not a \emph{radical}
ideal.
\end{example}

\begin{definition}\label{def-radical-ideal}
An ideal $I \subset R$ is \textbf{radical} if whenever $x^2 \in I$, then $x \in
I$.
\end{definition}

The ideals $I_Y$ in the polynomial ring are all radical.  This is obvious.
You might now ask whether this is the only obstruction. We now state a theorem
that we will prove later.

\begin{theorem}[Hilbert's Nullstellensatz] If $I \subset \mathbb{C}[x_1, \dots,
x_n]$ is a radical ideal, then $I = I_Y$ for some $Y \subset \mathbb{C}^n$. In
fact, the canonical choice of $Y$ is the set of points where all the functions
in $Y$ vanish.\footnote{Such a subset is called an algebraic variety.}
\end{theorem}


This will be one of the highlights of the present course. But before we can
get to it, there is much to do.

\begin{exercise}
Assuming the Nullstellensatz, show that any \emph{maximal} ideal in the
polynomial ring $\mathbb{C}[x_1, \dots, x_n]$ is of the form
$(x_1-a_1, \dots, x_n-a_n)$ for $a_1, \dots, a_n \in \mathbb{C}$. An ideal of a
ring is called \textbf{maximal} if the only ideal that contains it is the
whole ring (and it itself is not the whole ring).

As a corollary, deduce that if $I \subset \mathbb{C}[x_1, \dots, x_n]$ is a
proper ideal (an ideal is called \textbf{proper} if it is not equal to the
entire ring), then there exists $(x_1, \dots, x_n) \in \mathbb{C}^n$ such that
every polynomial in $I$ vanishes on the point $(x_1, \dots, x_n)$. This is
called the \textbf{weak Nullstellensatz.}
\end{exercise}

\section{Modules over a commutative ring}



We will now establish some basic terminology about modules.

\subsection{Definitions}
Suppose $R$ is a commutative ring.

\begin{definition}
An \textbf{$R$-module $M$} is an abelian group $M$ with a map $R \times M \to
M$ (written $(a,m) \to am$) such that
\begin{enumerate}[\textbf{M} 1]
\item  $(ab) m = a(bm)$ for $a,b \in R, m \in M$, i.e. there is an associative law.
\item $1m
= m$; the unit acts as the identity.
\item There are distributive laws
on both sides:
$(a+b)m = am + bm$ and $a(m+n) = am + an$ for $a,b \in R, \ m,n \in M$.

\end{enumerate} \end{definition}

Another definition can be given  as follows.
\begin{definition}
If $M$ is an abelian group, $End(M)$ is the set of homomorphisms $f: M \to M$.
This can be made into a (noncommutative) \emph{ring}.\footnote{A
noncommutative ring is one satisfying all the usual axioms of a ring except
that multiplication is not required to be commutative.} Addition is defined pointwise, and
multiplication is by composition. The identity element is the identity
function $1_M$.
\end{definition}

We made the following definition earlier for commutative rings, but for
clarity we re-state it:
\begin{definition}
If $R, R'$ are rings (possibly noncommutative) then a function $f: R \to R'$ is a
\textbf{ring-homomorphism}  or \textbf{morphism} if it is compatible with the
ring structures, i.e
\begin{enumerate}
\item  $f(x+y) = f(x) + f(y)$
\item $f(xy) = f(x)f(y)$
\item  $f(1) = 1$.
\end{enumerate}
\end{definition}

The last condition is not redundant because otherwise the zero map would
automatically be a homomorphism.
The alternative definition of a module is left to the reader in the following
exercise.
\begin{exercise}
If $R$ is a ring and $R \to End(M)$ a homomorphism, then $M$ is made into an
$R$-module, and vice versa.
\end{exercise}


\begin{example}
If $R$ is a ring, then $R$ is an $R$-module by multiplication on the left.
\end{example}
\begin{example}
A $\mathbb{Z}$-module is the same thing as an abelian group.
\end{example}

\begin{definition}
If $M$ is an $R$-module, a subset $M_0 \subset M$ is a \textbf{submodule} if it
is a subgroup (closed under addition and inversion) and is closed under
multiplication by elements of $R$, i.e. $aM_0 \subset M_0$ for $a \in R$. A
submodule is a module in its own right. If $M_0 \subset M$ is a submodule,
there is a commutative diagram:
\[ \xymatrix{
R \times M_0 \ar[d] \ar[r] &  M_0 \ar[d] \\ R \times M \ar[r] &  M
}.\]
Here the horizontal maps are multiplication.
\end{definition}

\begin{example}
Let $R$ be a (\textbf{commutative}) ring; then an ideal in $R$ is the same thing as a
submodule of $R$.
\end{example}

\begin{example}
If $A$ is a ring, an $A$-algebra is an $A$-module in an obvious way. More
generally, if $A$ is a ring and $R$ is an $A$-algebra, any $R$-module becomes
an $A$-module by pulling back the multiplication map via $A \to R$.
\end{example}



Dual to submodules  is the notion of a \emph{quotient module}, which we define
next:
\begin{definition} Suppose $M$ is an $R$-module and $M_0$  a
submodule.  Then the abelian group $M/M_0$ (of cosets)  is an $R$-module,
called the \textbf{quotient module} by $M_0$.

Multiplication is as follows. If
one has a coset $x  + M_0 \in M/M_0$, one  multiplies this by $a \in R$ to
get the coset $ax
+ M_0$. This does not depend on the coset representative.
\end{definition}


\subsection{The categorical structure on modules}
So far, we have talked about modules, but we have not discussed morphisms
between modules, and have yet to make the class of modules over a given ring
into a category. This we do next.

Let us thus  introduce a  few more basic notions.

\begin{definition}
Let $R$ be a ring.  Suppose $M,N$ are $R$-modules.  A map $f: M \to N$
is a \textbf{module-homomorphism} if it preserves all the relevant structures.
Namely, it must be a homomorphism of abelian groups, $f(x+y) = f(x) + f(y)$,
and second it must
preserve multiplication:
$$f(ax)  = af(x)$$ for $a \in R, x \in M$.
\end{definition}

A simple way of getting plenty of module-homomorphisms is simply to consider
multiplication by a fixed element of the ring.
\begin{example}
If $a \in R$, then multiplication by $a$ is a module-homomorphism $M
\stackrel{a}{\to} M$ for any $R$-module $M$.\footnote{When one considers
modules over noncommutative rings, this is no longer true.} Such homomorphisms
are called \textbf{homotheties.}
\end{example}


If $M \stackrel{f}{\to} N$ and $N \stackrel{g}{\to} P$ are
module-homomorphisms, their composite $M \stackrel{g \circ f}{\to} P$ clearly
is too.
Thus, for any commutative ring $R$, the class of $R$-modules and
module-homomorphisms forms a \textbf{category}.

\begin{exercise}
The initial object in this category is the zero module, and this is also the
final object.

In general, a category where the initial object and final object are the same
(that is, isomorphic) is called a \emph{pointed category.} The common object
is called the \emph{zero object.} In a pointed category $\mathcal{C}$, there is a morphism
$X \to Y$ for any two objects $X, Y \in \mathcal{C}$: if $\ast$ is the zero
object, then we can take $X \to \ast \to Y$. This is well-defined and is
called the \emph{zero morphism.}
One can easily show that the composition (on the left or the right) of a
zero morphism is a zero morphism (between a possibly different set of objects).

In the case of the category of modules, the zero object is clearly the zero
module, and the zero morphism $M \to N$ sends $m \mapsto 0$ for each $m \in M$.
\end{exercise}
\begin{definition} Let $f: M \to N$ be a module homomorphism.
In this case, the \textbf{kernel} $\ker f$ of $f$ is  the set of elements $m
\in M$ with $f(m)=0$. This is
a submodule of $M$, as is easy to see.

The \textbf{image} $\im f$ of $f$ (the set-theoretic
image, i.e. the collection of all $f(x), x \in M$) is also a submodule of $N$.

The
\textbf{cokernel} of $f$ is defined by
\(  N/\im(f).  \)
\end{definition}

\begin{exercise} \label{univpropertykernel}
The universal property of the kernel is as follows. Let $M \stackrel{f}{\to }
N$ be a morphism with kernel $K \subset M$. Let $T \to M$ be a map. Then $T \to M$ factors through the
kernel $K \to M$ if and only if its composition with $f$ (a morphism $T \to N$) is zero.
That is, an arrow $T \to K$ exists in the diagram (where the dotted arrow
indicates we are looking for a map that need not exist)
\[ \xymatrix{
& T \ar@{-->}[ld] \ar[d]  \\
K \ar[r] &  M \ar[r]^f &  N
}\]
if and only if the composite $T \to N$ is zero.
In particular, if we think of the hom-sets as abelian groups (i.e.
$\mathbb{Z}$-modules)
\[ \hom_R( T,K) = \ker\left( \hom_R(T, M) \to \hom_R(T, N) \right). \]
\end{exercise}

In other words, one may think of the kernel as follows. If $X
\stackrel{f}{\to} Y$ is a morphism, then the kernel $\ker(f)$ is the equalizer
of $f$ and the zero morphism $X \stackrel{0}{\to} Y$.

\begin{exercise}
What is the universal property of the cokernel?
\end{exercise}

\begin{exercise} \label{moduleunderlyingsetrepresentable}
On the category of modules, the functor assigning to each module $M$ its
underlying set is corepresentable (cf. \rref{corepresentable}). What
is the corepresenting object?
\end{exercise}

We shall now introduce the notions of \emph{direct sum} and \emph{direct
product}. Let $I$ be a set, and suppose that for each $i \in I$, we are given
an $R$-module $M_i$.

\begin{definition}
The \textbf{direct product} $\prod M_i$ is set-theoretically the cartesian product. It is given
the structure of an $R$-module by addition and multiplication pointwise on
each factor.
\end{definition}
\begin{definition}
The \textbf{direct sum} $\bigoplus_I M_i$ is the set of elements in the direct
product such that all but finitely many entries are zero. The direct sum is a
submodule of the direct product.
\end{definition}


\begin{example} \label{productcoproduct}
The direct product is a product in the category of modules, and the direct sum
is a coproduct. This is easy to verify: given maps $f_i: M \to M_i$, then we
get get a unique map $f: M \to \prod M_i$ by taking the product in the category
of sets. The case of a coproduct is dual: given maps $g_i: M_i \to N$, then we
get a map $\bigoplus M_i \to N$ by taking the \emph{sum} $g$ of the $g_i$: on a
family $(m_i) \in \bigoplus M_i$, we take $g(m_i) = \sum_I g_i(m_i)$; this is
well-defined as almost all the $m_i$ are zero.
\end{example}

\cref{productcoproduct} shows that the category of modules over a fixed
commutative ring has products and coproducts. In fact, the category of modules
is both complete and cocomplete (see \cref{completecat} for the definition).
To see this, it suffices to show that (by
\cref{coprodcoequalsufficeforcocomplete} and its dual) that this category
admits equalizers and coequalizers.

The equalizer of two maps
\[ M \stackrel{f,g}{\rightrightarrows} N  \]
is easily checked to be the submodule of $M$ consisting of $m \in M$ such that
$f(m) = g(m)$, or, in other words, the kernel of $f-g$. The coequalizer of these two maps is the quotient module of $N$
by the submodule $\left\{f(m) - g(m), m \in M\right\}$, or, in other words,
the cokernel of $f-g$.

Thus:

\begin{proposition}
If $R$ is a ring, the category of $R$-modules is complete and cocomplete.
\end{proposition}

\begin{example}
Note that limits in the category of $R$-modules are calculated in the same way
as they are for sets, but colimits are not. That is, the functor from
$R$-modules to $\mathbf{Sets}$, the forgetful functor, preserves limits but not
colimits. Indeed, we will see that the forgetful functor is a right adjoint
(\cref{freeadj}), which implies it preserves limits (by \cref{adjlimits}).
\end{example}

\subsection{Exactness}
Finally, we introduce the notion of \emph{exactness}.
\begin{definition} \label{exactness}
Let $f: M \to N$ be a morphism of $R$-modules.  Suppose $g: N \to P$ is another morphism of
$R$-modules.

The pair of maps is a \textbf{complex} if $g \circ f = 0: M \to N \to P$.
This is equivalent to the condition that $\im(f) \subset \ker(g)$.

This complex is \textbf{exact} (or exact at $N$) if $\im(f) = \ker(g)$.
In other words, anything that is killed when mapped to $P$ actually comes from something in
$M$.

\end{definition}


We shall often write pairs of maps as sequences
\[ A \stackrel{f}{\to} B \stackrel{g}{\to} C  \]
and say that the sequence is exact if the pair of maps is, as in
\rref{exactness}. A longer (possibly infinite) sequence of modules
\[ A_0 \to A_1 \to A_2 \to \dots  \]
will be called a \textbf{complex} if each set of three
consecutive terms is a complex, and \textbf{exact} if it is exact at each step.

\begin{example}
The sequence $0 \to A \stackrel{f}{\to} B$ is exact if and only if the map $f$
is injective. Similarly, $A \stackrel{f}{\to} B \to 0$ is exact if and only if
$f$ is surjective. Thus, $0 \to A \stackrel{f}{\to}  B \to 0$ is exact if and
only if $f$ is an isomorphism.
\end{example}

One typically sees this definition applied to sequences of the form
\[ 0 \to M'\stackrel{f}{ \to} M \stackrel{g}{\to} M'' \to 0,  \]
which, if exact, is called a \textbf{short exact sequence}.
Exactness here means that $f$ is injective, $g$ is surjective, and $f$ maps
onto the kernel of $g$.  So $M''$ can be thought of as the quotient $M/M'$.

\begin{example}
Conversely, if $M$ is a module and $M' \subset M$ a submodule, then there is a
short exact sequence
\[ 0 \to M' \to M \to M/M' \to 0.  \]
So every short exact sequence is of this form.
\end{example}


Suppose   $F$ is a functor from the category of $R$-modules to the
category of  $S$-modules, where $R, S$ are rings.  Then:

\begin{definition}
\begin{enumerate}
\item  $F$ is called \textbf{additive} if $F$ preserves direct sums.
\item  $F$ is called \textbf{exact} if $F$ is additive and preserves exact sequences.
\item  $F$ is called \textbf{left exact} if $F$ is additive and preserves exact sequences of the form
$0 \to M' \to M \to M''$.  Equivalently, $F$ preserves kernels.
\item  $F$ is \textbf{right exact} if $F$ is additive and $F$ preserves exact
sequences of the form $M' \to M \to M'' \to 0$, i.e. $F$ preserves cokernels.
\end{enumerate}
\end{definition}

The reader should note that much of homological algebra can be developed using the more
general setting of an \emph{abelian category,}  which axiomatizes much of the
standard properties of the category of modules over a ring. Such a
generalization turns out to be necessary when many natural categories, such as
the category of chain complexes or the category of sheaves on a topological
space, are not naturally categories of modules.
We do not go into this here, cf. \cite{Ma98}.



A functor  $F$	is exact if and only if it is both left and right exact.
This actually requires proof, though it is not hard. Namely, right-exactness implies that $F$
preserves cokernels. Left-exactness implies that $F$ preserves kernels. $F$
thus preserves images, as the image of a morphism is the kernel of its cokernel.
So if
\[ A \to B \to C  \]
is a short exact sequence, then the kernel of the second map is equal to the
image of the first; we have just seen that this is preserved under $F$.


From this, one can check that left-exactness is equivalent to requiring that $F$ preserve
finite limits (as an additive functor, $F$ automatically preserves products,
and we have just seen that $F$ is left-exact iff it preserves kernels).
Similarly, right-exactness is equivalent to requiring that $F$ preserve
finite colimits.
So, in \emph{any}  category with finite limits and colimits, we can talk about
right or left exactness of a functor, but the notion is used most often for
categories with an additive structure (e.g. categories of modules over a ring).



\begin{exercise}
Suppose whenever $0 \to A' \to A \to A'' \to 0$ is short exact, then $FA' \to
FA \to FA'' \to 0$ is exact. Prove that $F$ is right-exact. So we get a
slightly weaker criterion for right-exactness.

Do the same for left-exact functors.
\end{exercise}




\subsection{Split exact sequences}

Let $f: A \to B$ be a map of sets which is injective. Then there is a map $g: A
\to B$ such that the composite $g \circ f: A \stackrel{f}{\to} B
\stackrel{g}{\to} A$ is the identity. Namely, we define $g$ to be the inverse
of $f$ on $f(A)$ and arbitrarily on $B-f(A)$.
Conversely, if $f: A \to B$ admits an element $g: B \to A$ such that $g \circ f
= 1_A$, then $f$ is injective. This is easy to see, as any $a \in A$ can be
``recovered'' from $f(a)$ (by applying $g$).

In general, however, this observation does not generalize to arbitrary
categories.

\begin{definition}
Let $\mathcal{C}$ be a category. A morphism $A \stackrel{f}{\to} B$ is called a
\textbf{split injection} if there is $g: B \to A$ with $g \circ f = 1_A$.
\end{definition}

\begin{exercise}[General nonsense]
Suppose $f: A \to B$ is a split injection. Show that $f$ is a categorical monomorphism.
(Idea: the map $\hom(C,A) \to \hom(C,B)$ becomes a split injection of sets
thanks to $g$.)
\end{exercise}

\add{what is a categorical monomorphism? Maybe omit the exercise}

In the category of sets, we have seen above that \emph{any} monomorphism is a
split injection. This is not true in other categories, in general.

\begin{exercise}
Consider the morphism $\mathbb{Z} \to \mathbb{Z}$ given by multiplication by
2. Show that this is not a split injection: no left inverse $g$ can exist.
\end{exercise}

We are most interested in the case of modules over a ring.

\begin{proposition}
A morphism $f: A \to B$ in the category of $R$-modules is a split injection if
and only if:
\begin{enumerate}
\item $f$ is injective.
\item $f(A)$ is a direct summand in $B$.
\end{enumerate}
\end{proposition}
The second condition means that there is a submodule $B' \subset B$ such that
$B = B' \oplus f(A)$ (internal direct sum). In other words, $B = B'  + f(A)$
and $B' \cap f(A) = \left\{0\right\}$.
\begin{proof}
Suppose the two conditions hold, and we have a module $B'$ which is a
complement to $f(A)$.
Then we define a left inverse
\[ B \stackrel{g}{\to} A  \]
by letting $g|_{f(A)} = f^{-1}$ (note that $f$ becomes an \emph{isomorphism}
$A \to f(A)$) and $g|_{B'}=0$. It is easy to see that this is indeed a left
inverse, though in general not a right inverse, as $g$ is likely to be
non-injective.

Conversely, suppose $f: A \to B$ admits a left inverse $g: B \to A$. The usual
argument (as for sets) shows that $f$ is injective. The essentially new
observation is that $f(A) $ is a direct summand in $B$. To define the
complement, we take $\ker(g) \subset B$.
It is easy to see (as $g \circ f = 1_A$) that $\ker(g) \cap f(A) =
\left\{0\right\}$. Moreover, $\ker(g) +f(A)$ fills $B$: given $b \in B$, it is
easy to check that
\[ b - f(g(b)) \in \ker(g).  \]
Thus we find that the two conditions are satisfied.
\end{proof}




\add{further explanation, exactness of filtered colimits}


\subsection{The five lemma}

The five lemma will be a useful tool for us in proving that maps are
isomorphisms. Often this argument is used in inductive proofs. Namely, we will
see that often ``long exact sequences'' (extending infinitely in one or both
directions) arise from short exact sequences in a natural way. In such
events, the five lemma
will allow us to prove that certain morphisms are isomorphisms by induction on
the dimension.
\begin{theorem}
Suppose given a commutative diagram
\[ \xymatrix{
A \ar[d] \ar[r] &  B \ar[d] \ar[r] &  C \ar[d]  \ar[r] &  D \ar[d] \ar[r] & E \ar[d]  \\
A' \ar[r] &  B' \ar[r] &  C' \ar[r] &  D' \ar[r] &  E'
}\]
such that the rows are exact and the four vertical maps $A \to A', B \to B', D
\to D', E \to E'$ are isomorphisms. Then $C \to C'$ is an isomorphism.
\end{theorem}

This is the type of proof that goes by the name of ``diagram-chasing,'' and
is best thought out visually for oneself, even though we give a complete proof.

\begin{proof}
We have the diagram
\[
\xymatrix{
A \ar[r]^k \ar[d]^\a & B \ar[r]^l \ar[d]^\b
	& C \ar[r]^m \ar[d]^g & D \ar[r]^n \ar[d]^\d & E \ar[d]^\e  \\
F \ar[r]_p & G \ar[r]_q & H \ar[r]_r & I \ar[r]_s & J
}
\]
where the rows are exact at $B, C, D, G, H, I$ and the squares commute. In
addition, suppose that $\a, \b, \d, \e$ are isomorphisms. We will show that
$\g$ is an isomorphism.

\emph{We show that $\g$ is surjective:}

Suppose that $h \in H$. Since $\d$ is surjective, there exists an element
$d \in D$ such that $r(h) = \d(d) \in I$.
By the commutativity of the rightmost square, $s(r(h)) = \e(n(d))$.
The exactness at $I$ means that $\im r = \ker s$, so hence
$\e(n(d)) = s(r(h)) = 0$. Because $\e$ is injective, $n(d) = 0$.
Then $d \in \ker(n) = \im(m)$ by exactness at $D$.
Therefore, there is some $c \in C$ such that $m(c) = d$.
Now, $\d(m(c)) = \d(d) = r(h)$ and by the commutativity of squares,
$\d(m(c)) = r(\g(c))$, so therefore $r(\g(c)) = r(h)$. Since $r$ is a
homomorphism, $r(\g(c) - h) = 0$. Hence $\g(c) - h \in \ker r = \im q$ by
exactness at $H$.

Therefore, there exists $g \in G$ such that $q(g) = \g(c) - h$.
$\b$ is surjective, so there is some $b \in B$ such that $\b(b) = g$ and hence
$q(\b(b)) = \g(c) - h$. By the commutativity of squares,
$q(\b(b)) = \g(l(b)) = \g(c) - h$. Hence
$h = \g(c) - \g(l(b)) = \g(c - l(b))$, and therefore $\g$ is surjective.

So far, we've used that $\b$ and $\g$ are surjective, $\e$ is injective, and
exactness at $D$, $H$, $I$.

\emph{We show that $\g$ is injective:}

Suppose that $c \in C$ and $\g(c) = 0$.
Then $r(\g(c)) = 0$, and by the commutativity of squares,
$\d(m(c)) = 0$. Since $\d$ is injective, $m(c) = 0$, so
$c \in \ker m = \im l$ by exactness at $C$.
Therefore, there is $b \in B$ such that $l(b) = c$.
Then $\g(l(b)) = \g(c) = 0$, and by the commutativity of squares,
$q(\b(b)) = 0$. Therefore, $\b(b) \in \ker q$, and by exactness at $G$,
$\b(b) \in \ker q = \im p$.

There is now $f \in F$ such that $p(f) = \b(b)$. Since $\a$ is surjective, this
means that there is $a \in A$ such that $f = \a(a)$, so then
$\b(b) = p(\a(a))$. By commutativity of squares,
$\b(b) = p(\a(a)) = \b(k(a))$, and hence $\b(k(a) - b) = 0$.
Since $\b$ is injective, we have $k(a) -b = 0$, so $k(a) = b$.
Hence $b \in \im k = \ker l$ by commutativity of squares, so $l(b) = 0$.
However, we defined $b$ to satisfy $l(b) = c$, so therefore $c = 0$ and hence
$\g$ is injective.

Here, we used that $\a$ is surjective, $\b, \d$ are injective, and exactness at
$B, C, G$.

Putting the two statements together, we see that $\g$ is both surjective and
injective, so $\g$ is an isomorphism. We only used that $\b, \d$ are
isomorphisms and that $\a$ is surjective, $\e$ is injective, so we can slightly
weaken the hypotheses; injectivity of $\a$ and surjectivity of $\e$ were
unnecessary.

\end{proof}


\section{Ideals}

The notion of an \emph{ideal} has already been defined. Now we will introduce additional terminology related to the theory of ideals.

\subsection{Prime and maximal ideals}

Recall that the notion of an ideal generalizes that of divisibility. In
elementary number theory, though, one finds that questions of divisibility
basically reduce to questions about primes.
The notion of a ``prime ideal'' is intended to generalize the familiar idea of a prime
number.

\begin{definition}
An ideal $I \subset R$ is said to be \textbf{prime} if
\begin{enumerate}[\textbf{P} 1]
\item  $1 \notin I$ (by convention, 1 is not a prime number)
\item If $xy \in I$, either $x \in I$ or $y \in I$.
\end{enumerate}
\end{definition}

\begin{example}
\label{integerprimes}
If $R = \mathbb{Z}$ and $p \in R$, then $(p) \subset \mathbb{Z}$ is a prime ideal iff $p$ or $-p$ is a
prime number in $\mathbb{N}$ or if $p$ is zero.
\end{example}



If $R$ is any commutative ring, there are two obvious ideals. These obvious
ones are the zero ideal $(0)$
consisting only of the zero element, and the unit element $(1)$ consisting of all of
$R$.


\begin{definition} \label{maximalideal}
An ideal $I \subset R$ is called \textbf{maximal}\footnote{Maximal with
respect to not being the unit ideal.} if
\begin{enumerate}[\textbf{M} 1]
\item  $1 \notin I$
\item Any larger ideal contains $1$ (i.e., is all of $R$).
\end{enumerate}
\end{definition}

So a maximal ideal is a maximal element in the partially ordered set of proper
ideals (an ideal is \textbf{proper} if it does not contain 1).

\begin{exercise}
Find the maximal ideals in $\mathbb{C}[t]$.
\end{exercise}


\begin{proposition}
A maximal ideal is prime.
\end{proposition}
\begin{proof}
First, a maximal ideal does not contain 1.

Let $I \subset R$ be a maximal ideal.
We need to show that if $xy \in I$,
then one of $x,y \in I$.  If $x \notin I$, then $(I,x) = I + (x)$ (the ideal
generated by $I$ and $x$) strictly contains $I$, so by maximality contains
$1$.  In particular, $1 \in I+(x)$, so we can write
\[ 1 = a + xb  \]
where $a \in I, b \in R$. Multiply both sides by $y$:
\[ y = ay  + bxy.  \]
Both terms on the right here are in $I$ ($a \in I$ and $xy \in I$), so we find
that $y \in I$.

\end{proof}

Given a ring $R$, what can we say about the collection of ideals in $R$?
There
are two obvious ideals in $R$, namely $(0)$ and $ (1)$.  These are the same if and
only if $0=1$, i.e. $R$ is the zero ring.
So for any nonzero commutative ring, we have at least two distinct ideals.

Next, we show that maximal ideals always \emph{do} exist, except in the case
of the zero ring.
\begin{proposition} \label{anycontainedinmaximal}
Let $R$ be a commutative ring. Let $I \subset R$ be a proper ideal.  Then $I$
is contained in a maximal ideal.
\end{proposition}

\begin{proof}
This requires the axiom of choice in the form of Zorn's lemma.  Let
$P$ be the collection of all ideals $J \subset R$ such that $I
\subset J$ and $J \neq R$.  Then $P$ is a poset with respect to  inclusion.  $P$ is
nonempty because it contains $I$.  Note that given a (nonempty) linearly ordered
collection of ideals $J_{\alpha} \in P$, the union $\bigcup J_{\alpha} \subset
R$ is an ideal: this is easily seen in view of the linear ordering (if $x,y
\in \bigcup J_{\alpha}$, then both $x,y$ belong to some $J_{\gamma}$, so $x+y
\in J_{\gamma}$; multiplicative closure is even easier). The union is not all
of $R$ because it does not contain $1$.

This implies that $P$ has a maximal element by Zorn's lemma.  This maximal element may
be called $\mathfrak{M}$; it's a proper element containing $I$. I claim that
$\mathfrak{M}$ is a maximal ideal, because if it were contained in a larger
 ideal, that would  be in $P$ (which cannot happen by maximality) unless it were all of $R$.
\end{proof}

\begin{corollary}
Let $R $ be a nonzero commutative ring.  Then $R$ has a maximal ideal.
\end{corollary}
\begin{proof}
Apply the lemma to the zero ideal.
\end{proof}

\begin{corollary}
Let $R$ be a nonzero commutative ring. Then $x \in R$ is invertible if and
only if it belongs to no maximal ideal $\mathfrak{m} \subset R$.
\end{corollary}
\begin{proof}
Indeed, $x$ is invertible if and only if $(x) = 1$. That is, if and only if
$(x)$ is not a proper ideal; now \rref{anycontainedinmaximal}
finishes the argument.
\end{proof}

\subsection{Fields and integral domains}

Recall:

\begin{definition}
A commutative ring $R$ is called a  \textbf{field} if $1 \neq 0$ and for every $x \in R -
\left\{0\right\}$ there exists an \textbf{inverse} $x^{-1} \in R$ such that $xx^{-1} =
1$.


\end{definition}


This condition has an obvious interpretation in terms of ideals.
\begin{proposition}
A commutative ring with $1 \neq 0$ is a field iff it has only the two ideals $(1),
(0)$.
\end{proposition}

Alternatively, a ring is a field if and only if $(0)$ is a maximal ideal.

\begin{proof}
Assume $R$ is a field.  Suppose $I \subset R$.  If $I \neq (0)$, then there is
a nonzero $x \in I$. Then there is an inverse $x^{-1}$. We have $x^{-1} x =1
\in I$, so $I = (1)$.
In a field, there is thus 	no room for ideals other than $(0)$ and $(1)$.

To prove the converse, assume every ideal of $R$ is $(0)$ or $(1)$. Then for
each $x \in R$, $(x) = (0)$ or $(1)$. If $x \neq 0$, the first cannot happen, so
that means that the ideal generated by $x$ is the unit ideal. So $1$ is a
multiple of $x$, implying that $x$ has a multiplicative inverse.
\end{proof}

So fields also have an uninteresting ideal structure.

\begin{corollary} \label{maximalfield}
If $R$ is a ring and $I \subset R$ is an ideal, then $I$ is maximal if and only
if $R/I$ is a field.
\end{corollary}

\begin{proof}
The basic point here is that there is a bijection between the ideals of $R/I$
and ideals of $R$ containing $I$.

Denote  by $\phi: R \to R/I$ the reduction map. There is a
construction mapping ideals of $R/I$ to ideals of $R$. This sends an ideal in
$R/I$ to
its inverse image.  This is easily seen to map to ideals of $R$ containing $I$.
The map from ideals of $R/I$ to ideals of $R$ containing $I$ is a bijection,
as one checks easily.

It follows that $R/I$ is a field precisely if
$R/I$ has precisely two ideals, i.e. precisely if there are precisely two
ideals in $R$ containing $I$. These ideals must be $(1)$ and $I$, so this
holds if and only if $I$ is maximal.
\end{proof}

There is a similar characterization of prime ideals.

\begin{definition}
A commutative ring $R$ is an \textbf{integral domain} if for all $ x,y \in R$,
$x \neq 0 $ and $y \neq 0$ imply $xy \neq 0$.
\end{definition}

\begin{proposition} \label{primeifdomain}
An ideal $I \subset R$ is prime iff $R/I$ is a domain.
\end{proposition}

\begin{exercise}
Prove \rref{primeifdomain}.
\end{exercise}

Any field is an integral domain. This is because in a field, nonzero elements
are invertible, and the product of two invertible elements is invertible. This
statement translates in ring theory to the statement that a maximal ideal is
prime.


Finally, we include an example that describes what \emph{some} of the prime
ideals in a polynomial ring look like.
\begin{example}
Let $R$ be a ring and $P$ a prime ideal. We claim that $PR[x] \subset R[x]$ is a
prime ideal.

Consider the map $\tilde{\phi}:R[x]\rightarrow(R/P)[x]$ with
$\tilde{\phi}(a_0+\cdots+a_nx^n)=(a_0+P)+\cdots+(a_n+P)x^n$. This is clearly
a homomorphism because $\phi:R\rightarrow R/P$ is, and its kernel consists
of those polynomials $a_0+\cdots+a_nx^n$ with $a_0,\ldots,a_n\in P$, which is
precisely $P[x]$. Thus $R[x]/P[x]\simeq (R/P)[x]$, which is an integral domain
because $R/P$ is an integral domain. Thus $P[x]$ is a prime ideal.

However, if
$P$ is a maximal ideal, then $P[x]$ is never a maximal ideal because the ideal
$P[x]+(x)$ (the polynomials with constant term in $P$) always strictly contains
$P[x]$ (because if $x\in P[x]$ then $1\in P$, which is impossible). Note
that $P[x]+(x)$ is the kernel of the composition of $\tilde{\phi}$ with
evaluation at 0, i.e $(\text{ev}_0\circ\tilde{\phi}):R[x]\rightarrow R/P$,
and this map is a surjection and $R/P$ is a field, so that $P[x]+(x)$ is
the maximal ideal in $R[x]$ containing $P[x]$.
\end{example}


\begin{exercise} \label{quotfld1}
Let $R$ be a domain. Consider the set of formal quotients $a/b, a, b \in R$
with $b \neq 0$. Define addition and multiplication using usual rules. Show
that the resulting object $K(R)$ is a ring, and in fact a \emph{field}. The
natural map $R \to K(R)$, $r \to r/1$, has a universal property. If $R
\hookrightarrow L$ is an injection of $R$ into a field $L$, then there is a
unique morphism $K(R) \to L$ of fields extending $R \to L$. This construction
will be generalized when we consider \emph{localization.}
This construction is called the \textbf{quotient field.}

Note that a non-injective map $R\to L$ will \emph{not} factor through the
quotient field!
\end{exercise}


\begin{exercise}\label{Jacobson}
Let $R$ be a commutative ring. Then the \textbf{Jacobson radical} of $R$ is
the intersection $\bigcap \mathfrak{m}$ of all maximal ideals $\mathfrak{m}
\subset R$. Prove that an element $x$ is in the Jacobson radical if and only
if $1 - yx$ is invertible for all $y \in R$.
\end{exercise}

\subsection{Prime avoidance}

The following fact will come in handy occasionally. We will, for instance, use
it much later to show that an ideal consisting of zerodivisors on a module $M$ is
contained in associated prime.

\begin{theorem}[Prime avoidance] \label{primeavoidance}
   Let $I_1,\dots, I_n \subset R$ be ideals. Let $A\subset R$ be a subset which is closed
   under addition and multiplication. Assume that at least $n-2$ of the ideals are
   prime. If $A\subset I_1\cup \cdots \cup I_n$, then $A\subset I_j$ for some $j$.
 \end{theorem}

The result is frequently used in the following specific case: if an ideal $I$
is contained in a finite union $\bigcup \mathfrak{p}_i$ of primes, then $I
\subset \mathfrak{p}_i$ for some $i$.

 \begin{proof}
   Induct on $n$. If $n=1$, the result is trivial. The case $n=2$ is an easy argument: if
   $a_1\in A\smallsetminus I_1$ and $a_2\in A\smallsetminus I_2$, then $a_1+a_2\in
   A\smallsetminus (I_1\cup I_2)$.

Now assume $n\ge 3$. We may assume that for each $j$, $A\not\subset I_1\cup \cdots
   \cup \hat I_j\cup \cdots I_n$.\footnote{The hat means omit $I_j$.} Fix an element
   $a_j\in A\smallsetminus (I_1\cup \cdots \cup \hat I_j\cup \cdots I_n)$. Then this
   $a_j$ must be contained in $I_j$ since $A\subset \bigcup I_j$. Since $n\ge 3$, one
   of the $I_j$ must be prime. We may assume that $I_1$ is prime. Define
   $x=a_1+a_2a_3\cdots a_n$, which is an element of $A$. Let's show that $x$ avoids
   \emph{all} of the $I_j$. If $x\in I_1$, then $a_2a_3\cdots a_n\in I_1$, which
   contradicts the fact that $a_i\not\in I_j$ for $i\neq j$ and that $I_1$ is prime. If
   $x\in I_j$ for $j\ge 2$. Then $a_1\in I_j$, which contradicts $a_i\not\in I_j$ for
   $i\neq j$.
 \end{proof}
\subsection{The Chinese remainder theorem}

Let $m,n$ be relatively prime integers. Suppose $a, b \in \mathbb{Z}$; then
one can show that the two congruences $x \equiv a \mod m$
and $x \equiv b \mod n$ can be solved simultaneously in $x \in \mathbb{Z}$.
The solution is unique, moreover, modulo $mn$.
The Chinese remainder theorem generalizes this fact:


\begin{theorem}[Chinese remainder theorem] Let $I_1, \dots I_n$ be ideals in a
ring $R$ which satisfy $I_i + I_j = R$ for $i \neq j$. Then we have $I_1 \cap
\dots \cap I_n = I_1 \dots I_n$ and the morphism of rings
\[ R \to \bigoplus R/I_i \]
is an epimorphism with kernel $I_1 \cap \dots \cap I_n$.
\end{theorem}

\begin{proof}
First, note that for any two ideals $I_1$ and $I_2$, we
have $I_1I_2\subset I_1\cap I_2$ and $(I_1+I_2)(I_1\cap I_2)\subset
I_1I_2$ (because any element of $I_1+I_2$ multiplied by any element of
$I_1\cap I_2$ will clearly be a sum of products of elements from both $I_1$
and $I_2$). Thus, if $I_1$ and $I_2$ are coprime, i.e. $I_1+I_2=(1)=R$,
then $(1)(I_1\cap I_2)=(I_1\cap I_2)\subset I_1I_2\subset I_1\cap I_2$,
so that $I_1\cap I_2=I_1I_2$. This establishes the result for $n=2$.

If the
ideals $I_1,\ldots,I_n$ are pairwise coprime and the result holds for $n-1$,
then $$\bigcap_{i=1}^{n-1} I_i=\prod_{i=1}^{n-1}I_i.$$  Because $I_n+I_i=(1)$
for each $1\leq i\leq n-1$, there must be $x_i\in I_n$ and $y_i\in I_i$ such
that $x_i+y_i=1$. Thus, $z_n=\prod_{i=1}^{n-1}y_i=\prod_{i=1}^{n-1}(1-x_i)\in
\prod_{i=1}^{n-1} I_i$, and clearly $z_n+I_n=1+I_n$ since each $x_i\in
I_n$. Thus $I_n+\prod_{i=1}^{n-1}I_i=I_n+\bigcap_{i=1}^{n-1}I_i=(1)$,
and we can now apply the $n=2$ case to conclude that $\bigcap_{i=1}^n
I_i=\prod_{i=1}^n I_i$.

Note that for any $i$, we can construct a $z_i$
with $z_i\in I_j$ for $j\neq i$ and $z_i+I_i=1+I_i$ via the same procedure.

 Define $\phi:R\rightarrow\bigoplus R/I_i$
by $\phi(a)=(a+I_1,\ldots,a+I_n)$. The kernel of $\phi$ is
$\bigcap_{i=1}^n I_i$, because $a+I_i=0+I_i$ iff $a\in I_i$, so that
$\phi(a)=(0+I_1,\ldots,0+I_n)$ iff $a\in I_i$ for all $i$, that is,
$a\in\bigcap_{i=1}^n I_i$. Combined with our previous result, the kernel
of $\phi$ is $\prod_{i=1}^n I_i$.

Finally, recall that we constructed
$z_i\in R$ such that $z_i+I_i=1+I_i$, and $z+I_j=0+I_j$ for all $j\neq
i$, so that $\phi(z_i)=(0+I_1,\ldots,1+I_{i},\ldots,0+I_n)$. Thus,
$\phi(a_1z_1+\cdots+a_nz_n)=(a_1+I_1,\ldots,a_n+I_n)$ for all $a_i\in R$,
so that $\phi$ is onto. By the first isomorphism theorem, we have that
$R/I_1\cdots I_n\simeq \bigoplus_{i=1}^nR/I_i$.   \\

\end{proof}

\section{Some special classes of domains}

\subsection{Principal ideal domains}

\begin{definition}
A ring $R$ is a \textbf{principal ideal domain} or \textbf{PID} if $R \neq 0$, $R$ is not a
field, $R$ is a domain, and every ideal of $R$ is principal.
\end{definition}

These have the next simplest theory of ideals.
Each ideal is very simple---it's principal---though there might be a lot of ideals.

\begin{example}
$\mathbb{Z}$ is a PID. The only nontrivial fact to check here is that:
\begin{proposition}
Any nonzero ideal $I \subset \mathbb{Z}$ is principal.
\end{proposition}
\begin{proof}
If $I = (0)$, then this is obvious.  Else there is $n \in I -
\left\{0\right\}$; we can assume $n>0$.  Choose $n \in I$ as small as possible and
positive. Then  I claim that the ideal $I$ is generated by $(n)$. Indeed, we have $(n)
\subset I$ obviously. If $m \in I$ is another integer, then divide $m$ by $n$,
to find $m = nb + r$ for $r \in [0, n)$. We find that $r \in I$ and $0 \leq r <
n$, so $r=0$, and $m$ is divisible by $n$. And $I \subset (n)$.

So $I = (n)$.
\end{proof}
\end{example}

A module $M$ is said to be \emph{finitely generated} if there exist elements
$x_1, \dots, x_n \in M$ such that any element of $M$ is a linear combination
(with coefficients in $R$) of the $x_i$. (We shall define this more formally
below.)
One reason that PIDs are so convenient is:

\begin{theorem}[Structure theorem] \label{structurePID}
If $M$ is a finitely generated module over a principal ideal domain $R$, then
$M$ is isomorphic to a direct sum
\[ M \simeq \bigoplus_{i=1}^n R/a_i,  \]
for various $a_i \in R$ (possibly zero).
\end{theorem}

\add{at some point, the proof should be added. This is important!}

\subsection{Unique factorization domains}

The integers $\mathbb{Z}$ are especially nice because of the fundamental
theorem of arithmetic, which states that every integer has a unique
factorization into primes. This is not true for every integral domain.

\begin{definition}
An element of a domain $R$ is \textbf{irreducible} if it cannot be written
as the product of two non-unit elements of $R$.
\end{definition}

\begin{example}
Consider the integral domain $\mathbb{Z}[\sqrt{-5}]$. We saw earlier that
\[
6 = 2 \cdot 3 = (1 + \sqrt{-5})(1 - \sqrt{-5}),
\]
which means that $6$ was written as the product of two non-unit elements in
different ways. $\mathbb{Z}[\sqrt{-5}]$ does not have unique factorization.
\end{example}

\begin{definition} \label{earlyUFD}
A domain $R$ is a \textbf{unique factorization domain} or \textbf{UFD} if every
non-unit $x \in R$ satisfies
\begin{enumerate}
\item $x$ can be written as a product $x = p_1 p_2 \cdots p_n$ of
irreducible elements $p_i \in R$
\item if $x = q_1 q_2 \cdots q_m$ where $q_i \in R$ are irreducible
then the $p_i$ and $q_i$ are the same up to order and multiplication by units.
\end{enumerate}
\end{definition}

\begin{example}
$\mathbb{Z}$ is a UFD, while $\mathbb{Z}[\sqrt{-5}]$ is not. In fact, many of
our favorite domains have unique factorization. We will prove that all PIDs
are UFDs. In particular, in  \rref{gaussianintegersareprincipal} and
\rref{polyringisprincipal}, we saw that $\mathbb{Z}[i]$ and $F[t]$ are PIDs,
so they also have unique factorization.
\end{example}

\begin{theorem} \label{PIDUFD}
Every principal ideal domain is a unique factorization domain.
\end{theorem}

\begin{proof}
Suppose that $R$ is a principal ideal domain and $x$ is an element of $R$. We
first demonstrate that $x$ can be factored into irreducibles.
If $x$ is a unit or an irreducible, then we are done. Therefore, we can assume
that $x$ is reducible, which means that $x = x_1 x_2$ for non-units
$x_1, x_2 \in R$. If there are irreducible, then we are again done, so we
assume that they are reducible and repeat this process. We need to show that
this process terminates.

Suppose that this process continued infinitely. Then we have an infinite
ascending chain of ideals, where all of the inclusions are proper:
$(x) \subset (x_1) \subset (x_{11}) \subset \cdots \subset R$.
We will show that this is impossible because any infinite ascending chain of
ideals $I_1 \subset I_2 \subset \cdots \subset R$ of a principal ideal domain
eventually becomes stationary, i.e. for some $n$, $I_k = I_n$ for $k \geq n$.
Indeed, let $I = \bigcup_{i=1}^\infty I_i$. This is an ideal, so it is
principally generated as $I = (a)$ for some $a$. Since $a \in I$, we must have
$a \in I_N$ for some $N$, which means that the chain stabilizes after $I_N$.

It remains to prove that this factorization of $x$ is unique. We induct on
the number of irreducible factors $n$ of $x$. If $n = 0$, then $x$ is a unit,
which has unique factorization up to units. Now, suppose that
$x = p_1 \cdots p_n = q_1 \cdots q_m$ for some $m \ge n$. Since $p_1$ divides
$x$, it must divide the product $q_1 \cdots q_m$ and by irreducibility, one of
the factors $q_i$. Reorder the $q_i$ so that $p_1$ divides $q_1$. However,
$q_1$ is irreducible, so this means that $p_1$ and $q_1$ are the same up to
multiplication by a unit $u$. Canceling $p_1$ from each of the two
factorizations, we see that $p_2 \cdots p_n = u q_2 \cdots q_m = q_2' \cdots
q_m$. By induction, this shows that the factorization of $x$ is unique up to
order and multiplication by units.
\end{proof}


\subsection{Euclidean domains}

A euclidean domain is a special type of principal ideal domain. In practice,
it will often happen that one has an explicit proof that a given domain is
euclidean, while it might not be so trivial to prove that it is a UFD without
the general implication below.

\begin{definition}
An integral domain $R$ is a \textbf{euclidean domain} if there is a function
$|\cdot |:R\to \mathbb \mathbb{Z}_{\geq 0}$ (called the norm) such that the following hold.
\begin{enumerate}
\item $|a|=0$ iff $a=0$.
\item For any nonzero $a,b\in R$ there exist $q,r\in R$ such that $b=aq+r$ and $|r|<|a|$.
\end{enumerate}
In other words, the norm is compatible with division with remainder.
\end{definition}
\begin{theorem}\label{EDPID}
A euclidean domain is a principal ideal domain.
\end{theorem}
\begin{proof}
Let $R$ be an euclidean domain, $I\subset R$ and ideal, and $b$ be the nonzero element of smallest norm in $I$.
Suppose $ a\in I$. Then we can write $ a = qb + r$ with $ 0\leq r < |b|$, but since $ b$ has minimal nonzero absolute value, $ r = 0$ and $ b|a$. Thus $ I=(b)$ is principal.
\end{proof}


As we will see, this implies that any euclidean domain admits \emph{unique
factorization.}

\begin{proposition} \label{polyringED}
Let $F$ be a field. Then the polynomial ring $F[t]$ is a euclidean domain.
In particular, it is a PID.
\end{proposition}
\begin{proof}
We define \add{}
\end{proof}


\begin{exercise} \label{gaussianintegersareprincipal}
Prove that $\mathbb{Z}[i]$ is principal.
(Define the norm as $N(a+ib) = a^2 + b^2$.)
\end{exercise}

\begin{exercise} \label{polyringisprincipal}
Prove that the polynomial ring $F[t]$ for $F$ a field is principal.
\end{exercise}


It is \emph{not} true that a PID is necessarily euclidean. Nevertheless, it
was shown in \cite{Gre97} that the converse is ``almost'' true. Namely,
\cite{Gre97} defines the notion of an \textbf{almost euclidean domain.}
A domain $R$ is almost euclidean if there is a function $d: R \to
\mathbb{Z}_{\geq 0}$ such that
\begin{enumerate}
\item $d(a) = 0$ iff $a = 0$.
\item $d(ab) \geq d(a)$ if $b \neq 0$.
\item  If $a,b \in R - \left\{0\right\}$, then either $b \mid a$ or there is
$r \in (a,b)$ with $d(r)<d(b)$.
\end{enumerate}

It is easy to see by the same argument that an almost euclidean domain is a PID.
(Indeed, let $R$ be an almost euclidean domain, and $I \subset R$ a nonzero
ideal. Then choose $x \in I - \left\{0\right\}$ such that $d(x)$ is minimal among elements in
$I$. Then if $y \in I - \left\{0\right\}$, either $x \mid y$ or $(x,y) \subset I$ contains an
element with smaller $d$. The latter cannot happen, so the former does.)
However, in fact:
\begin{proposition}[\cite{Gre97}] \label{almosteuclidean}
A domain is a PID if and only if it is almost euclidean.
\end{proposition}
\begin{proof}
Indeed, let $R$ be a PID. Then $R$ is a UFD (\rref{PIDUFD}), so for any $x \in R$,
there is a factorization into prime elements, unique up to units. If $x$
factors into $n$ elements, we define $d(x)=n$; we set $d(0)=0$.
The first two conditions for an almost euclidean domain are then evident.

Let $x = p_1 \dots p_m$ and $y = q_1 \dots q_n$ be two elements of $R$,
factored into irreducibles. Suppose $x \nmid y$. Choose a generator $b$ of the (principal) ideal $(x,y)$; then obviously $y
\mid b$ so $d(y) \leq d(b)$. But if $d(y) = d(b)$, then the
number of factors of $y$ and $b$ is the same, so  $y \mid b$ would imply
that $y$ and $b$ are associates. This is a contradiction, and implies that
$d(y)<d(b)$.

\end{proof}


\begin{remark}
We have thus seen that a euclidean domain is a PID, and a PID is a UFD. Both
converses, however, fail. By Gauss's lemma (\rref{}), the
polynomial ring $\mathbb{Z}[X]$ has unique factorization, though the ideal
$(2, X)$ is not principal.

In \cite{Ca88}, it is shown that the ring $\mathbb{Z}[\frac{1+
\sqrt{-19}}{2}]$ is a PID but not euclidean (i.e. there is \emph{no} euclidean
norm on it).
\end{remark}

According to \cite{Cl11}, sec. 8.3, \cref{almosteuclidean} actually goes back to Hasse
(and these norms are sometimes called ``Dedekind-Hasse norms'').

\section{Basic properties of modules}

\subsection{Free modules}

We now describe a simple way of constructing modules over a ring, and an
important class of modules.

\begin{definition}
\label{freemoduledef}
A module $M$ is \textbf{free} if it is isomorphic to $\bigoplus_I R$ for some
index set $I$. The cardinality of $I$ is called the \textbf{rank}.
\end{definition}

\begin{example}
$R$ is the simplest example of a free module.
\end{example}

Free modules have a \emph{universal property}.
Namely, recall that if $M$ is an $R$-module, then to give a homomorphism
\[ R \to M  \]
is equivalent to giving an element $m \in M$ (the image of $1$).
By the universal product of the direct sum (which is the coproduct in the
category of modules), it follows that to give a map
\[ \bigoplus_I \to M  \]
is the same as giving a map of \emph{sets} $I \to M$.
In particular:
\begin{proposition} \label{freeadj}
The functor $I \mapsto \bigoplus_I R$ from $\mathbf{Sets}$ to
$R$-modules is the \emph{left adjoint} to the forgetful functor from
$R$-modules to $\mathbf{Sets}$.
\end{proposition}

The claim now is that the notion of ``rank'' is well-defined for a free
module. To see this, we will have to use the notion
of a \emph{maximal ideal} (\rref{maximalideal}) and
\rref{maximalfield}.
Indeed, suppose
$\bigoplus_I R$ and $\bigoplus_J R$ are isomorphic; we must show that $I$ and
$J$ have the same cardinality. Choose a maximal ideal $\mathfrak{m}
\subset R$. Then, by applying the functor $M \to
M/\mathfrak{m}M$, we find that the $R/\mathfrak{m}$-\emph{vector spaces}
\[ \bigoplus_I R/\mathfrak{m}, \quad \bigoplus_J R/\mathfrak{m}  \]
are isomorphic. By linear algebra, $I$ and $J$ have the same cardinality.


Free modules have a bunch of nice properties. The first is that it is very
easy to map out of a free module.
\begin{example}
Let $I$ be an indexing set, and $M$ an $R$-module. Then to give a morphism
\[ \bigoplus_I R \to M  \]
is equivalent to picking an element of $M$ for each $i \in I$. Indeed, given
such a collection of elements $\left\{m_i\right\}$, we send the generator of $\bigoplus_I R$ with a 1
in the $i$th spot and zero elsewhere to $m_i$.
\end{example}

\begin{example}
In a domain, every principal ideal (other than zero) is a free module of rank
one.
\end{example}

Another way of saying this is that the free module $\bigoplus_I R$ represents
the functor on modules sending $M$ to the \emph{set} $ M^I$. We have already seen a special case of this for $I$ a
one-element set (\rref{moduleunderlyingsetrepresentable}).

The next claim is that free modules form a reasonably large class of the
category of $R$-modules.

\begin{proposition} \label{freesurjection}
Given an $R$-module $M$, there is a free module $F$ and a surjection
\[ F \twoheadrightarrow M.  \]
\end{proposition}
\begin{proof}
We let $F$ to be the free $R$-module on the elements $e_m$, one for each $m
\in M$. We define the map
\[ F \to M  \]
by describing the image of each of the generators $e_m$: we just send each
$e_m$ to $m \in M$. It is clear that this map is surjective.
\end{proof}


We close by making a few remarks on matrices.
Let $M$ be a free module of rank $n$, and fix an isomorphism $M \simeq R^n$.
Then we can do linear algebra with $M$, even though we are working over a
ring and not necessarily a field, at least to some extent.
For instance, we can talk about $n$-by-$n$ matrices over the ring $R$, and
then each of them induces a transformation, i.e. a module-homomorphism, $M \to
M$; it is easy to see that every module-homomorphism between free modules is
of this form. Moreover, multiplication of matrices corresponds to composition
of homomorphisms, as usual.

\begin{example} Let us consider the question of when the transformation
induced by an $n$-by-$n$ matrix is invertible. The answer is similar to the
familiar one from linear algebra in the case of a field. Namely, the condition
is that the determinant be invertible.

Suppose that an $n \times n$ matrix $A$ over a ring $R$ is invertible. This
means that there exists $A^{-1}$ so that $A A^{-1} = I$, so hence
$1 = \det I = \det(A A^{-1}) = (\det A) (\det A^{-1})$, and therefore,
$\det A$ must be a unit in $R$.

Suppose instead that an $n \times n$ matrix $A$ over a ring $R$ has an
invertible determinant. Then, using Cramer's rule, we can actually construct
the inverse of $A$.
\end{example}


We next show that if $R$ is a commutative ring, the category of modules over
$R$ contains enough information to reconstruct $R$. This is a small part of the
story of \emph{Morita equivalence,} which we shall not enter into here.
\begin{example}
Suppose $R$ is a commutative ring, and let $\mathcal{C}$ be the category of
$R$-modules. The claim is that $\mathcal{C}$, as an \emph{abstract} category,
determines $R$. Indeed, the claim is that $R$ is canonically the ring of
endomorphisms of the identity functor $1_{\mathcal{C}}$.

Such an \emph{endomorphism} is given by a natural transformation
$\phi: 1_{\mathcal{C}} \to 1_{\mathcal{C}}$. In other words, one requires for
each $R$-module $M$, a homomorphism of $R$-modules $\phi_M : M \to M$ such that
if $f: M \to N$ is any homomorphism of modules, then there is a commutative
square
\[ \xymatrix{
M \ar[d]^f \ar[r]^{\phi_M} &  M \ar[d] \\
N \ar[r]^{\phi_N} & N.
}\]

Here is a simple way of obtaining such endomorphisms. Given $r \in R$, we
consider the map $r: M \to m$ which just multiplies each element by $r$. This
is a homomorphism, and it is clear that it is natural in the above sense. There
is thus a map $R \to \mathrm{End}(1_\mathcal{C})$ (note that multiplication
corresponds to composition of natural transformations).
This map is clearly injective; different $r, s \in R$ lead to different natural
transformations (e.g. on the $R$-module $R$).

The claim is that \emph{any} natural transformation of $1_{\mathcal{C}}$ is
obtained in this way.
Namely, let $\phi: 1_{\mathcal{C}} \to 1_{\mathcal{C}}$ be such a natural
transformation. On the $R$-module $R$, $\phi$ must be multiplication by some
element $r \in R$
(because $\hom_R(R, R)$ is given by such homotheties).
Consequently, one sees by drawing commutative diagrams that $\phi: R^{\oplus S}
\to R^{\oplus S}$ is of this form for any set $S$. So $\phi$ is multiplication
by $r$ on any free $R$-module.
Since any module $M$ is a quotient of a free module $F$, we can draw a diagram
\[ \xymatrix{
F\ar[d] \ar[r]^{\phi_F} & F \ar[d] \\
M \ar[r]^{\phi_M} &  M.
}\]
Since the vertical arrows are surjective, we find that $\phi_F$ must be given
by multiplication by $r$ too.
\end{example}


\subsection{Finitely generated modules}

The notion of a ``finitely generated'' module is analogous to that of a
finite-dimensional vector space.

\begin{definition}
An $R$-module $M$ is \textbf{finitely generated} if there exists a surjection
$R^n \to M$ for some $n$. In other words, it has a finite number of elements
whose ``span'' contains $M$.
\end{definition}

The basic properties of finitely generated modules follow from the fact that
they are stable under extensions and quotients.

\begin{proposition} \label{exact-fingen}
Let $0 \to M' \to M \to M'' \to 0$ be an exact sequence. If $M', M''$ are
finitely generated, so is $M$.
\end{proposition}
\begin{proof}
Suppose $0\rightarrow
M'\stackrel{f}{\rightarrow}M\stackrel{g}{\rightarrow}M''\rightarrow0$
is exact. Then $g$ is surjective, $f$ is injective, and
$\text{ker}(g)=\text{im}(f)$. Now suppose $M'$ is finitely generated,
say by $\{a_1,\ldots,a_s\}$, and $M''$ is finitely generated, say by
$\{b_1,\ldots,b_t\}$. Because $g$ is surjective, each $g^{-1}(b_i)$ is
non-empty. Thus, we can fix some $c_i\in g^{-1}(b_i)$ for each $i$.

For any
$m\in M$, we have $g(m)=r_1b_1+\cdots+r_tb_t$ for some $r_i\in R$ because
$g(m)\in M''$ and $M''$ is generated by the $b_i$. Thus $g(m)=r_1g(c_i)+\cdots
r_tg(c_t)=g(r_1c_1+\cdots+r_tc_t)$, and because $g$ is a homomorphism
we have $m-(r_1c_1+\cdots+r_tc_t)\in\text{ker}(g)=\text{im}(f)$. But
$M'$ is generated by the $a_i$, so the submodule $\text{im}(f)\subset
M$ is finitely generated by the $d_i=f(a_i)$.

Thus, any $m\in
M$ has $m-(r_1c_1+\cdots+r_tc_t)=r_{t+1}d_1+\cdots+r_{t+s}d_s$
for some $r_1,\ldots,r_{t+s}$, thus $M$ is finitely generated by
$c_1,\ldots,c_t,d_1,\ldots,d_s$.  \\

\end{proof}

The converse is false. It is possible for finitely generated modules to have
submodules which are \emph{not} finitely generated. As we shall see in
\rref{noetherian}, this does not happen over \emph{noetherian} rings.



\begin{example}
Consider the ring $R=\mathbb{C}[X_1, X_2, \dots,]$ and the ideal $(X_1, X_2,
\dots)$. This ideal is a submodule of the finitely generated $R$-module $R$,
but it is not finitely generated.
\end{example}

\begin{exercise}
Show that a quotient of a finitely generated module is finitely generated.
\end{exercise}

\begin{exercise}
Consider a \emph{split} exact sequence $0 \to M' \to M \to M'' \to 0$. In this
case, show that if $M$ is finitely generated, so is $M'$.
\end{exercise}


\subsection{Finitely presented modules}

Over messy rings, the notion of a finitely presented module is often a good
substitute for that of a finitely generated one. In fact, we are going to see
(\rref{}), that there is a general method of reducing questions about finitely
presented modules over arbitrary rings to finitely generated modules over
finitely generated $\mathbb{Z}$-algebras.

Throughout, fix a ring $R$.

\begin{definition}
An $R$-module $M$ is \textbf{finitely presented} if there is an exact sequence
\[ R^m \to R^n \to M \to 0.  \]
\end{definition}

The point of this definition is that $M$ is the quotient of a free module
$R^n$ by the ``relations'' given by the images of the vectors in $R^m$.
Since $R^m$ is finitely generated, $M$ can be represented via finitely many
generators \emph{and} finitely many relations.

The reader should compare this with the definition of a \textbf{finitely
generated} module; there we only require an exact sequence
\[ R^n \to M \to 0.  \]

As usual, we establish the usual properties of finitely presented modules.

We start by showing that if a finitely presented module $M$ is generated by
finitely many elements, the ``module of relations'' among these generators is
finitely generated itself. The condition of finite presentation only states that
there is \emph{one} such set of generators such that the module of generators
is finitely generated.
\begin{proposition}
Suppose $M$ is finitely presented. Then if $R^m \twoheadrightarrow M$ is a
surjection, the kernel is finitely generated.
\end{proposition}
\begin{proof} Let $K$ be the kernel of $R^m \twoheadrightarrow M$.
Consider an exact sequence
\[ F' \to F \to M \to 0 \]
where $F', F$ are finitely generated and free, which we can do as $M$ is
finitely presented.
Draw a commutative and exact diagram
\[
\xymatrix{
& F' \ar[r] &  F \ar[r] \ar@{-->}[d]  &  M \ar[r] \ar[d]  &  0 \\
0 \ar[r] &  K \ar[r] &  R^m \ar[r] &  M \ar[r] &  0
}
\]
The dotted arrow $F \to R^m$ exists as $F$ is projective. There is induced a
map $F' \to K$.
We get a commutative and exact diagram
\[
\xymatrix{
& F' \ar[r]\ar[d]^f  &  F \ar[r] \ar[d]^g  &  M \ar[r] \ar[d]  &  0 \\
0 \ar[r] &  K \ar[r] &  R^m \ar[r] &  M \ar[r] &  0
},
\]
to which we can apply the snake lemma. There is an exact sequence
\[ 0 \to \coker(f) \to \coker(g) \to 0,  \]
which gives an isomorphism $\coker(f) \simeq \coker(g)$.
However, $\coker(g)$ is finitely generated, as a quotient of $R^m$.
Thus $\coker(f)$ is too.
Since we have an exact sequence
\[ 0 \to \im(f) \to K \to \coker(f) \to 0,  \]
and $\im(f)$ is finitely generated (as the image of a finitely generated
object, $F'$), we find by \rref{exact-fingen} that $\coker(f)$ is finitely generated.
\end{proof}

\begin{proposition} \label{exact-finpres}
Given an exact sequence
\[ 0 \to M' \to M \to M'' \to 0,  \]
if $M', M''$ are finitely presented, so is $M$.
\end{proposition}

In general, it is not true that if $M$ is finitely presented, then $M'$ and
$M''$ are. For instance, it is possible that a submodule of the free, finitely
generated module $R$ (i.e. an ideal), might fail to be finitely generated. We
shall see in \rref{noetherian} that this does not happen over a
\emph{noetherian} ring.

\begin{proof}
Indeed, suppose we have  exact sequences
\[ F_1' \to F_0' \to M' \to 0   \]
and
\[ F_1'' \to F_0'' \to M'' \to 0  \]
where the $F$'s are finitely generated and free.
We need to get a similar sequence for $M$.
Let us stack these into a diagram
\[ \xymatrix{
& F_1' \ar[d] & & F_1'' \ar[d]  \\
& F_0' \ar[d]  & & F_0'' \ar[d] \\
0 \ar[r] &  M' \ar[r] &  M \ar[r] &  M'' \ar[r] &  0
}\]
However, now, using general facts about projective modules (\rref{}), we can
splice these presentations into a resolution
\[ F_1' \oplus F_1'' \to F_0' \oplus F_0'' \to M \to 0,  \]
which proves the assertion.
\end{proof}


\begin{corollary}
The (finite) direct sum of finitely presented modules is finitely presented.
\end{corollary}
\begin{proof}
Immediate from \rref{exact-finpres}
\end{proof}

\subsection{Modules of finite length}

A much stronger condition on modules that of finite generation is that of \emph{finite
length}. Here, basically any operation one does will eventually terminate.

Let $R$ be a commutative ring, $M$ an $R$-module.

\begin{definition}
$M$ is \textbf{simple} if $M \neq 0$ and $M$ has no nontrivial submodules.
\end{definition}


\begin{exercise}
A torsion-free abelian group is never a simple $\mathbb{Z}$-module.
\end{exercise}

\begin{proposition}
$M$ is simple if and only if it is isomorphic to $R/\mathfrak{m}$ for $\mathfrak{m} \subset
R$ a maximal ideal.
\end{proposition}

\begin{proof} Let $M$ be simple. Then
$M$ must contain a cyclic submodule $Rx$ generated by some $x \in
M - \left\{0\right\}$. So it must contain a submodule isomorphic to $R/I$
for some ideal $I$, and
simplicity implies that $M \simeq R/I$ for some $I$. If $I$ is not maximal,
say properly contained in $J$,
then we will get a nontrivial submodule $J/I$ of $R/I \simeq M$. Conversely,
it is easy to see
that $R/\mathfrak{m}$ is simple for $\mathfrak{m}$ maximal.
\end{proof}


\begin{exercise}[Schur's lemma] Let $f: M \to N$ be a module-homomorphism,
where $M, N$ are both simple. Then either $f =0$ or $f$ is an isomorphism.
\end{exercise}

\begin{definition}
$M$ is of \textbf{finite length} if there is a finite filtration $0 \subset M^0
\subset \dots \subset M^n = M$ where each $M^i/M^{i-1}$ is simple.
\end{definition}

\begin{exercise}
Modules of finite length are closed under extensions (that is, if $0 \to M'
\to M \to M'' \to 0$ is an exact sequence, then if $M', M''$ are of finite
length, so is $M$).
\end{exercise}

In the next result (which will not be used in this chapter), we shall use the
notions of a \emph{noetherian} and an \emph{artinian} module. These notions
will be developed at length in \cref{chnoetherian}, and we refer the reader
there for more explanation.
A module is \emph{noetherian} if every ascending chain $M_1 \subset M_2 \subset
\dots$ of submodules stabilizes, and it is \emph{artinian} if every descending chain
stabilizes.
\begin{proposition}
$M$ is finite length iff $M$ is both noetherian and artinian.
\end{proposition}
\begin{proof}
Any simple module is obviously both noetherian and artinian: there are two
submodules. So if $M$ is finite length, then the finite filtration with simple
quotients implies that $M$ is noetherian and artinian, since these two
properties are stable under extensions (\rref{exactnoetherian}
and \rref{exactartinian} of \rref{noetherian}).

Suppose $M \neq 0$ is noetherian and artinian. Let $M_1 \subset M$ be a minimal
nonzero submodule, which exists as $M$ is artinian. This is necessarily simple. Then we have a filtration
\[ 0 = M_0 \subset M_1.  \]
If $M_1 = M$, then the filtration goes up to $M$, and we have that $M$ is of
finite length. If not, find a submodule $M_2$ that contains $M_1$ and is
minimal among submodules containing $M_1$; then the quotient
$M_2/M_1$ is simple. We have the filtration
\[ 0 = M_0 \subset M_1 \subset M_2,  \]
which we can keep continuing until at some point we reach $M$. Note that since
$M$ is noetherian, we cannot continue this strictly ascending chain forever.
\end{proof}

\begin{exercise}
In particular, any submodule or quotient module of a finite length module is
of finite length. Note that the analog is not true for finitely generated
modules unless the ring in question is noetherian.
\end{exercise}

Our next goal is to show that the length of a filtration of a module with
simple quotients is well-defined.
For this, we need:
\begin{lemma}  \label{simplefiltrationint}
Let $0 = M_0 \subset M_1 \subset \dots \subset M_n = M$ be  a filtration of
$M$ with simple quotients. Let $N \subset M$. Then the filtration
$0 = M_0 \cap N \subset M_1 \cap N \subset \dots \subset N$ has simple or zero
quotients.
\end{lemma}
\begin{proof}
Indeed, for each $i$, $(N \cap M_i)/(N \cap M_{i-1})$ is a submodule of
$M_i / M_{i-1}$, so is either zero or simple.
\end{proof}


\begin{theorem}[Jordan-H\"older]\label{lengthexists} Let $M$ be a module of
finite length.
In this case, any two filtrations
on $M$ with simple quotients have the same length.
\end{theorem}
\begin{definition}
This number is called the \textbf{length} of $M$ and is denoted $\ell(M)$.
\end{definition}
\begin{proof}[Proof of \rref{lengthexists}]
Let us introduce a temporary definition: $l(M)$ is the length of the
\emph{minimal} filtration on $M$. We will show that any filtration of $M$ (with
simple quotients) is of length
$l(M)$. This is the proposition in another form.

The proof of this claim is by induction on $l(M)$. Suppose we have a filtration
\[ 0 = M_0 \subset M_1 \subset \dots \subset M_n = M  \]
with simple quotients. We would like to show that $n  = l(M)$. By definition of
$l(M)$, there is another filtration
\[ 0 = N_0 \subset \dots \subset N_{l(M)} = M.  \]
If $l(M) = 0,1$, then $M$ is zero or simple, which will necessarily imply that $n=0,1$
respectively. So we can assume $l(M)  \geq 2$. We can also assume that the
result is known for strictly smaller submodules of $M$.

There are two cases:
\begin{enumerate}
\item $M_{n-1} = N_{l(M) -1 } $. Then $M_{n-1} = N_{l(M)-1}$ has $l$ at most
$l(M)-1$. Thus by the inductive hypothesis any two filtrations on $M_{n-1}$
have the same length, so $n-1 = l(M) -1$, implying what we want.
\item We have $M_{n-1} \cap N_{l(M) - 1} \subsetneq M_{n-1}, N_{l(M)-1}$.
Call this intersection $K$.

Now we have two  filtrations of these modules $M_{n-1}, N_{l(M)-1}$ whose
quotients are simple. We can replace them such that the next
term before them is $K$.
To do this, consider the filtrations
\[ 0 = M_0 \cap K \subset M_1 \subset K \subset \dots M_{n-1} \cap K = K
\subset M_{n-1}  \]
and
\[ 0 = N_0 \cap K \subset M_1 \subset K \subset \dots N_{l(M)-1} \cap K = K
\subset N_{l(M)-1} . \]
These filtrations have simple or zero quotients by
\rref{simplefiltrationint}, and since $ M_{n-1}/K =
M_{n-1}/M_{n-1} \cap N_{l(M)-1} = M/M_{n-1}$ is simple, and similarly for
$N_{l(M)-1}/K$. We can throw out redundancies to eliminate
the zero terms.
So we get two new filtrations of $M_{n-1}$ and $N_{l(M)-1}$ whose second-to-last
term is $K$.

By the
inductive hypothesis any two filtrations on either of these proper submodules $M_{n-1},
N_{l(M)-1} $
have the same length.
Thus the lengths of the two new filtrations are $n-1$ and $l(M)-1$,
respectively.
So we find that $n-1 = l(K) +1$ and $l(M)-1 = l(K)+1$ by
the inductive hypothesis. This implies what we want.
\end{enumerate}
\end{proof}

\begin{exercise}
Prove that the successive quotients $M_i/M_{i-1}$ are also determined (up to
permutation).
\end{exercise}



% ============================ chapters/fields.tex
\chapter{Fields and Extensions}

In this chapter, we shall discuss the theory of fields.
Recall that a \textbf{field} is an integral domain for which all non-zero elements are
invertible; equivalently, the only two ideals of a field are $(0)$ and $(1)$
since any nonzero element is a unit. Consequently fields will be the
simplest cases of much of the theory developed later.

The theory of field extensions has a different feel from standard commutative
algebra since, for instance, any morphism of fields is injective. Nonetheless,
it turns out that questions involving rings can often be reduced to questions
about fields. For instance, any integral domain can be embedded in a field
(its quotient field), and any \emph{local ring} (that is, a ring with a unique
maximal ideal; we have not defined this term yet) has associated to it its
residue field (that is, its quotient by the maximal ideal). A knowledge of field extensions will thus be useful. And here we have a fine example of a document that can serve as a  performance benchmark.


\section{Introduction}


Recall once again that:
\begin{definition}
A \textbf{field} is an integral domain where every non-zero element is
invertible. Alternatively, it is a set $k$, endowed with binary operations of
addition and multiplication, which satisfy the usual axioms of commutativity,
associativity, distributivity, $1$ and $0$ (and $1 \neq 0$!), and additive and
multiplicative inverses.
\end{definition}

A \textbf{subfield} is a subset closed under these operations: equivalently, it
is a subring that is itself a field.

For a field $k$, we write $k^*$ for the subset $k  \setminus \left\{0\right\}$.
(This generalizes the usual notation \cref{} $R^*$ that refers to the group of
invertible elements in a ring $R$.)

\subsection{Examples}
To get started, let us begin by providing several examples of fields. The reader should
recall (\cref{maximalfield}) that if $R$ is a ring and $I \subset R$ an
ideal, then $R/I$ is a field precisely when $I$ is maximal.

\begin{example}
One of the most familiar examples of a field is the rational
numbers $\mathbb{Q}$.
\end{example}

\begin{example}
If $p$ is a prime number, then $\mathbb{Z}/(p)$ is a field, denoted
$\mathbb{F}_p$. Indeed, $(p)$ is a
maximal ideal in $\mathbb{Z}$. Thus, fields may be finite: $\mathbb{F}_p$
contains $p$ elements.
\end{example}


\begin{example}[Quotients of the polynomial ring]
In a principal ideal domain, every prime ideal is principal. Now, by
\rref{polyringED}, if $k$ is a field, then the polynomial ring $k[x]$ is a PID.
It follows that if $P \in k[x]$ is an irreducible polynomial (that is, a
nonconstant polynomial
that does not admit a factorization into terms of smaller degrees), then
$k[x]/(P)$ is a field. It contains a copy of $k$ in a natural way.

This is a very general way of constructing fields. For instance, the
complex numbers $\mathbb{C}$
can be constructed as $\mathbb{R}[x]/(x^2 + 1)$.
\end{example}



\begin{exercise}
What is $\mathbb{C}[x]/(x^2 + 1)$?
\end{exercise}

\begin{example}[Quotient fields]
Recall from \cref{quotfld1} that, given an integral domain $A$, there is an
imbedding $A \hookrightarrow K(A)$ into a field $K(A)$ formally constructed as
quotients $a/b, a, b \in A$ (and $b \neq 0$) modulo an evident equivalence
relation.
This is called the \textbf{quotient field.}
The quotient field has the following universal property: given an injection
$\phi: A
\hookrightarrow K$ for a field $K$, there is a unique map $\psi: K(A) \to K$ making
the diagram commutative (i.e. a map of $A$-algebras).
Indeed, it is clear how to define such a map: we set
\[ \psi(a/b) = \phi(a)/\phi(b),  \]
where injectivity of $\phi$ assures that $\phi(b) \neq 0$ if $ b \neq 0$.

If the map is not injective, then such a factorization may not exist. Consider
the imbedding $\mathbb{Z} \to \mathbb{Q}$ into its quotient field, and consider
the map $\mathbb{Z} \to \mathbb{F}_p$: this last map goes from $\mathbb{Z} $
into a field, but it does not factor through $\mathbb{Q}$ (as $p$ is invertible
in $\mathbb{Q}$ and zero in $\mathbb{F}_p$!).
\end{example}


\begin{example}[Rational function field] \label{monofldext}
\label{rationalfnfld}
If $k$ is a field, then we can consider the field $k(x)$ of \textbf{rational functions}
over $k$. This is the quotient field of the polynomial ring $k[x]$; in other
words, it is the set of quotients $F/G$ for $F, G \in k[x]$ with the obvious
equivalence relation.
\end{example}


Here is a fancier example of a field.
\begin{example}
\label{meromorphicfn}
Let $X$ be a Riemann surface.\footnote{Readers not familiar with Riemann
surfaces may ignore this example.} Let $\mathbb{C}(X)$ denote the
set of meromorphic functions on $X$; clearly $\mathbb{C}(X)$ is a ring under
multiplication and addition of functions. It turns out that in fact
$\mathbb{C}(X)$ is a
field; this is because if a nonzero function $f(z)$ is meromorphic, so is $1/f(z)$. For example,
let $S^2$ be the Riemann sphere; then we know from complex
analysis that the ring of meromorphic functions $\mathbb{C}(S^2)$ is the
field of rational functions $\mathbb{C}(z)$.
\end{example}



One reason fields are so nice from the point of view of most other chapters
in this book is that the theory of $k$-modules (i.e. vector spaces), for $k$ a field, is very simple.
Namely:

\begin{proposition}  \label{vectorspacefree}
If $k$ is a field, then every $k$-module is free.
\end{proposition}
\begin{proof}
Indeed, by linear algebra we know that a $k$-module (i.e. vector space) $V$ has a
\emph{basis} $\mathcal{B} \subset V$, which defines an isomorphism from the
free vector space on $\mathcal{B}$ to $V$.
\end{proof}

\begin{corollary} \label{fieldsemisimple}
Every exact sequence of modules over a field splits.
\end{corollary}
\begin{proof}
This follows from \cref{} and \cref{vectorspacefree}, as every vector space is
projective.
\end{proof}

This is another reason why much of the theory in future chapters will not say
very much about fields, since modules behave in such a simple manner.
Note that \cref{fieldsemisimple} is a statement about the \emph{category} of
$k$-modules (for $k$ a field), because the notion of exactness is inherently
arrow-theoretic (i.e. makes use of purely categorical notions, and can in fact
be phrased within a so-called \emph{abelian category}).

Henceforth, since the study of modules over a field is linear algebra, and
since the ideal theory of fields is not very interesting, we shall study what
this chapter is really about: \emph{extensions} of fields.

\subsection{The characteristic of a field}
\label{more-fields}

In the category of rings, there is an \emph{initial object} $\mathbb{Z}$: any
ring $R$ has a map from $\mathbb{Z}$ into it in precisely one way. For fields,
there is no such initial object.
Nonetheless, there is a family of objects such that every field can be mapped
into in exactly one way by exactly one of them, and in no way by the others.

Let $F$ be a field. As $\mathbb{Z}$ is the initial object of the category of
rings, there is a ring map $f : \mathbb{Z} \to F$, see
\rref{integersinitial}.
The image of this ring map is an integral domain (as a subring of a field)
hence the kernel of $f$ is a prime ideal in $\mathbb{Z}$, see
\rref{primeifdomain}.
Hence the kernel of $f$ is either $(0)$ or $(p)$ for some prime number $p$, see
\rref{integerprimes}.

In the first case we see that $f$ is injective, and in this case
we think of $\mathbb{Z}$ as a subring of $F$. Moreover, since every
nonzero element of $F$ is invertible we see that it makes sense to
talk about $p/q \in F$ for $p, q \in \mathbb{Z}$ with $q \not = 0$.
Hence in this case we may and we do think of $\mathbb{Q}$ as a subring of $F$.
One can easily see that this is the smallest subfield of $F$ in this case.

In the second case, i.e., when $\text{Ker}(f) = (p)$ we see that
$\mathbb{Z}/(p) = \mathbb{F}_p$ is a subring of $F$.  Clearly it is the smallest subfield of $F$.

Arguing in this way we see that every field contains a smallest subfield
which is either $\mathbb{Q}$ or finite equal to $\mathbb{F}_p$ for some
prime number $p$.

\begin{definition}
The \textbf{characteristic} of a field $F$ is $0$ if
$\mathbb{Z} \subset F$, or is a prime $p$ if $p = 0$ in $F$.
The \textbf{prime subfield of $F$} is the smallest subfield of $F$
which is either $\mathbb{Q} \subset F$ if the characteristic is zero, or
$\mathbb{F}_p \subset F$ if the characteristic is $p > 0$.
\end{definition}


It is easy to see that if $E$ is a field containing $k$, then the characteristic of
$E$ is the same as the characteristic of $k$.

\begin{example}
The characteristic of $\mathbb{Z}/p$ is $p$, and that of $\mathbb{Q}$ is $0$.
This is obvious from the definitions.
\end{example}


\section{Field extensions}

\subsection{Preliminaries}

In general, though, we are interested not so much in fields by themselves but
in field \emph{extensions.} This is perhaps analogous to studying not rings
but \emph{algebras} over a fixed ring.
The nice thing for fields is that the notion of a ``field over another field''
just recovers the notion of a field extension, by the next result.

\begin{proposition} \label{fieldinj} If $F$ is a field and $R$ is any ring, then any ring homomorphism $f:F\rightarrow
R$ is either injective or the zero map (in which case $R=0$).
\end{proposition}

\begin{proof} Indeed, $\ker(f)$ is an ideal in
$F$. But there are only two ideals in $F$, namely $(0)$ and $(1)$. If $f$ is identically
zero, then $1=f(1)=0$ in $R$, so $R=0$ too.
\end{proof}

\begin{definition} If $F$ is a field contained in a field $G$, then $G$ is said
to be a \textbf{field extension} of $F$. We shall write $G/F$ to indicate
that  $G$ is an extension of $F$.
\end{definition}

So if $F, F'$ are fields, and $F \to F'$ is any ring-homomorphism, we see by
\cref{fieldinj} that it is injective,\footnote{The zero ring is not a field!} and $F'$ can be regarded as an extension
of $F$, by a slight abuse of notation. Alternatively, a field extension of $F$
is just an $F$-algebra that happens to be a field.
This is completely different than the situation for general rings, since a
ring homomorphism is not necessarily injective.

Let $k$ be a field. There is a \emph{category} of field extensions of $k$.
An object of this category is an extension $E/k$, that is a
(necessarily injective) morphism of fields
\[ k \to E,  \]
while a morphism between extensions $E/k, E'/k$ is a $k$-algebra morphism $E \to E'$;
alternatively, it is a commutative diagram
\[ \xymatrix{
E \ar[rr] & & E' \\
& k \ar[ru] \ar[lu] &
}.\]


\begin{definition}
A \textbf{tower} of field extensions $E'/E/k$ consists of an extension $E/k$
and an extension $E'/E$.
\end{definition}

It is easy to see that any morphism $E \to E'$ in the category of
$k$-extensions gives a tower.


Let us give a few examples of field extensions.

\begin{example}
Let $k$ be a field, and $P \in k[x]$ an irreducible polynomial. We have seen
that $k[x]/(P)$ is a field (\rref{monofldext}). Since it is also a $k$-algebra
in the obvious way, it is an extension of $k$.
\end{example}

\begin{example}
If $X$ is a Riemann surface, then the field of meromorphic functions
$\mathbb{C}(X)$ (see \cref{meromorphicfn}) is an extension field of
$\mathbb{C}$, because any element of $\mathbb{C}$ induces a
meromorphic---indeed, holomorphic---constant function on $X$.
\end{example}

Let $F/k$ be a field extension. Let $S \subset F$ be any subset.
Then there is a  \emph{smallest} subextension of $F$ (that is, a subfield of $F$ containing $k$)
that contains $S$.
To see this, consider the family of subfields of $F $ containing $S$ and
$k$, and take their intersection; one easily checks that this is a field.
It is easy to see, in fact, that this is the set of elements of $F$ that can
be obtained via  a finite number of elementary algebraic operations
(addition, multiplication, subtraction, and division) involving elements of
$k$ and $S$.

\begin{definition}
If $F/k$ is an extension and $S \subset F$, we write $k(S)$ for the smallest
subextension of $F$ containing $S$.
We will say that $S$ \textbf{generates} the extension $k(S)/k$.
\end{definition}

For instance, $\mathbb{C}$ is generated by $i$ over $\mathbb{R}$.

\begin{exercise}
Show that $\mathbb{C}$ does not have a countable set of generators over
$\mathbb{Q}$.
\end{exercise}


Let us now classify extensions generated by one element.
\begin{proposition}[Simple extensions of a field] \label{fldmono}
If an extension $F/k$ is generated by one element, then it is $F$ is $k$-isomorphic
either to the rational function field $k(t)/k$ or to one of the extensions
$k[t]/(P)$ for $P \in k[t]$ irreducible.
\end{proposition}

We will see that many of the most important cases of field extensions are generated
by one element, so this is actually useful.

\begin{proof}
Let $\alpha \in F$ be such that $F = k(\alpha)$; by assumption, such an
$\alpha$ exists.
There is a morphism of rings
\[ k[t] \to F  \]
sending the indeterminate $t$ to $\alpha$. The image is a domain, so the
kernel is a prime ideal. Thus, it is either $(0)$ or $(P)$ for $P \in k[t]$
irreducible.

If the kernel is $(P)$ for $P \in k[t]$ irreducible, then the map factors
through $k[t]/(P)$, and induces a morphism of fields $k[t]/(P) \to F$. Since
the image contains $\alpha$, we see easily that the map is surjective, hence
an isomorphism. In this case, $k[t]/(P) \simeq F$.

If the kernel is trivial, then we have an injection
$k[t] \to F$.
One may thus define a morphism of the quotient field $k(t)$ into $F$; given a
quotient $R(t)/Q(t)$ with $R(t), Q(t) \in k[t]$, we map this to
$R(\alpha)/Q(\alpha)$. The hypothesis that $k[t] \to F$ is injective implies
that $Q(\alpha) \neq 0$ unless $Q$ is the zero polynomial.
The quotient field of $k[t]$ is the rational function field $k(t)$, so we get a  morphism $k(t) \to F$
whose image contains $\alpha$. It is thus surjective, hence an isomorphism.
\end{proof}




\subsection{Finite extensions}
If
$F/E$ is a field extension,  then evidently  $F$ is also a vector space over $E$
(the scalar action is just multiplication in $F$).

\begin{definition}
The dimension of $F$
considered as an $E$-vector space is called the \textbf{degree} of the extension and is
denoted $[F:E]$. If $[F:E]<\infty$ then $F$ is said to be a
\textbf{finite} extension.
\end{definition}

\begin{example}
$\mathbb{C}$ is obviously a finite extension of $\mathbb{R}$ (of degree 2).
\end{example}

Let us now consider the degree in the most important special example, that
given by \cref{fldmono}, in the next two examples.

\begin{example}[Degree of a simple transcendental extension]
\label{monodeg1}
If $k$ is any field, then the rational function field $k(t)$ is \emph{not} a
finite extension. The elements $\left\{t^n, n \in \mathbb{Z}\right\}$
are linearly independent over $k$.

In fact, if $k$ is uncountable, then $k(t)$ is \emph{uncountably} dimensional
as a $k$-vector space. To show this, we claim that the family of elements
$\left\{1/(t- \alpha), \alpha \in k\right\} \subset k(t)$ is linearly independent over $k$. A
nontrivial relation between them would lead to a contradiction: for instance,
if one works over $\mathbb{C}$, then this follows because
$\frac{1}{t-\alpha}$, when considered as a meromorphic function on
$\mathbb{C}$, has a pole at $\alpha$ and nowhere else.
Consequently any sum $\sum c_i \frac{1}{t - \alpha_i}$ for the $c_i \in k^*$,
and $\alpha_i \in k$ distinct, would have poles at each of the $\alpha_i$.
In particular, it could not be zero.

(Amusingly, this leads
to a quick if suboptimal proof of the Hilbert Nullstellensatz; see \cref{}.)
\end{example}

\begin{example}[Degree of a simple algebraic extension]
\label{monodeg2}
Consider a monogenic  field extension $E/k$ of the form in
\rref{monofldext}, say $E = k[t]/(P)$ for $P \in k[t]$ an irreducible
polynomial.
Then the degree $[E:k]$ is just the degree $\deg P$.
Indeed, without loss of generality, we can assume $P$ monic, say
\begin{equation} \label{P} P = t^n + a_1 t^{n-1} + \dots + a_0.\end{equation}
It is then easy to see that the images of $1, t, \dots, t^{n-1}$ in
$k[t]/(P)$ are linearly
independent over $k$, because any relation involving them would have
degree strictly smaller than that of $P$, and $P$ is the element of smallest
degree in the ideal $(P)$.

Conversely, the set $S=\left\{1, t, \dots, t^{n-1}\right\}$ (or more
properly their images) spans $k[t]/(P)$ as a vector space.
Indeed, we have by \eqref{P} that $t^n$ lies in the span of $S$.
Similarly, the relation $tP(t)=0$ shows that the image of  $t^{n+1}$ lies in the span of
$\left\{1, t, \dots, t^n\right\}$---by what was just shown, thus in the span of
$S$. Working upward inductively, we find
that the image of $t^M$ for $M  \geq n$ lies in the span of $S$.
\end{example}

This confirms the observation that $[\mathbb{C}: \mathbb{R}] = 2$, for instance.
More generally, if $k$ is a field, and $\alpha \in k$ is not a square, then the
irreducible polynomial $x^2 - \alpha \in k[x]$ allows one to construct an
extension $k[x]/(x^2 - \alpha)$ of degree two.
We shall write this as $k(\sqrt{\alpha})$. Such extensions will be called
\textbf{quadratic,} for obvious reasons.


The basic fact about the degree is that it is \emph{multiplicative in
towers.}

\begin{proposition}[Multiplicativity]
Suppose given a tower $F/E/k$. Then
\[ [F:k] = [F:E][E:k].  \]
\end{proposition}
\begin{proof}
Let $\alpha_1, \dots, \alpha_n \in F$ be an $E$-basis for $F$. Let $\beta_1,
\dots, \beta_m \in E$ be a $k$-basis for $E$. Then the claim is that
the set of products $\{\alpha_i \beta_j, 1 \leq i \leq n, 1 \leq j \leq m\}$ is a $k$-basis for $F$.
Indeed, let us check first that they span $F$ over $k$.

By assumption, the $\left\{\alpha_i\right\}$ span $F$ over $E$. So if $f \in
F$, there are $a_i \in E$ with
\[ f = \sum a_i\alpha_i,  \]
and, for each $i$, we can write $a_i = \sum b_{ij} \beta_j$ for some $b_{ij} \in k$. Putting
these together, we find
\[ f = \sum_{i,j} b_{ij}\alpha_i \beta_j,  \]
proving that the $\left\{\alpha_i \beta_j\right\}$ span $F$ over $k$.

Suppose now that there existed a nontrivial relation
\[ \sum_{i,j} c_{ij} \alpha_i \beta_j =0 \]
for the $c_{ij} \in k$. In that case, we would have
\[ \sum_i \alpha_i \left( \sum_j c_{ij} \beta_j \right) =0, \]
and the inner terms lie in $E$ as the $\beta_j$ do. Now $E$-linear independence of
the $\left\{\alpha_i\right\}$ shows that the inner sums are all zero. Then
$k$-linear independence of the $\left\{\beta_j\right\}$ shows that the
$c_{ij}$ all vanish.
\end{proof}

We sidetrack to a slightly tangential definition:
\begin{definition}
 A field extensions $K$ of $\mathbb{Q}$ is said to be a \textbf{number field}
if it is a finite extension of $\mathbb{Q}$.
\end{definition}
Number fields are the basic objects in algebraic number theory. We shall see
later that,
for the analog of the integers $\mathbb{Z}$ in a number field, something kind
of like unique factorization still holds (though strict unique factorization
generally does not!).

\subsection{Algebraic extensions}

Consider a field extension $F/E$.

\begin{definition}
An element $\alpha\in F$ is said to be \textbf{algebraic} over $E$ if
$\alpha$ is the root of some polynomial with coefficients in $E$. If all
elements of $F$ are \textbf{algebraic} then $F$ is said to be an algebraic extension.
\end{definition}

By \cref{fldmono}, the subextension $E(\alpha)$ is isomorphic either to
the rational function field $E(t)$ or to a quotient ring $E[t]/(P)$ for $P
\in E[t]$ an irreducible polynomial.
In the latter case, $\alpha$ is algebraic over $E$ (in fact, it
satisfies the polynomial $P$!); in the former case, it is not.

\begin{example}
$\mathbb{C}$ is algebraic over $\mathbb{R}$.
\end{example}

\begin{example}
Let $X$ be a compact Riemann surface, and $f \in \mathbb{C}(X) - \mathbb{C}$ any
nonconstant meromorphic function on $X$ (see \cref{meromorphicfn}). Then it is known that
$\mathbb{C}(X)$ is algebraic over the subextension $\mathbb{C}(f)$ generated by
$f$. We shall not prove this.
\end{example}

We now show that there is a deep connection between finiteness and being
algebraic.
\begin{proposition} \label{finalgebraic}
A finite extension is algebraic.
In fact, an extension $E/k$ is algebraic if and only if every subextension
$k(\alpha)/k$ generated by some $\alpha \in E$ is finite.
\end{proposition}
In general, it is very false that an algebraic extension is finite.
\begin{proof}
Let $E/k$ be finite, say of degree $n$. Choose $\alpha \in E$.
Then the elements
$\left\{1, \alpha, \dots, \alpha^n\right\}$ are linearly
dependent over $E$, or we would necessarily have $[E:k] > n$. A relation of
linear dependence now gives the desired polynomial that $\alpha$ must satisfy.

For the last assertion, note that a monogenic extension  $k(\alpha)/k$ is
finite if and only $\alpha$ is algebraic over $k$, by \cref{monodeg1} and
\cref{monodeg2}.
So if $E/k$ is algebraic, then each $k(\alpha)/k, \alpha \in E$, is a finite
extension, and conversely.
\end{proof}



We can extract a corollary of the last proof (really of \cref{monodeg1} and
\cref{monodeg2}): a monogenic extension is finite
if and only if it is algebraic.
We shall use this observation in the next result.

\begin{corollary} \label{fingenalg}
Let $k$ be a field, and let $\alpha_1, \alpha_2, \dots, \alpha_n$ be elements
of some extension field such that each $\alpha_i$ is finite over $k$. Then the
extension $k(\alpha_1, \dots, \alpha_n)/k$ is finite.
That is, a finitely generated algebraic extension is finite.
\end{corollary}
\begin{proof}
Indeed, each $k(\alpha_{1}, \dots, \alpha_{i+1})/k(\alpha_1, \dots,
\alpha_{i})$ is monogenic and algebraic, hence finite.
\end{proof}

The set of complex numbers that are algebraic over $\mathbb{Q}$ are simply
called the \textbf{algebraic numbers.} For instance, $\sqrt{2}$ is algebraic,
$i$ is algebraic, but $\pi$ is not.
It is a basic fact that the algebraic numbers form a field, although it is not
obvious how to prove this from the definition that a number is algebraic
precisely when it satisfies a nonzero polynomial equation with rational
coefficients (e.g. by polynomial equations).




\begin{corollary}
Let $E/k$ be a field extension. Then the elements of $E$ algebraic over $k$
form a field.
\end{corollary}
\begin{proof}
Let $\alpha, \beta \in E$ be algebraic over
$k$. Then $k(\alpha, \beta)/k$ is a finite extension by \cref{fingenalg}. It follows that $k(\alpha
+ \beta) \subset k(\alpha, \beta)$ is a finite extension, which implies that
$\alpha + \beta$ is algebraic by \cref{finalgebraic}.
\end{proof}


Many nice properties of field extensions, like those of rings, will have the property
that they will be preserved by towers and composita.


\begin{proposition}[Towers]
Let $E/k$ and $F/E$ be algebraic. Then $F/k$ is algebraic.
\end{proposition}
\begin{proof}
Choose $\alpha \in F$. Then $\alpha$ is algebraic over $E$.
The key observation is that $\alpha$ is algebraic over a \emph{finitely
generated} subextension of $k$.
That is, there is a finite set $S \subset E$ such that $\alpha $ is algebraic
over $k(S)$: this is clear because being algebraic means that a certain
polynomial in $E[x]$ that $\alpha$ satisfies exists, and as $S$ we can take the
coefficients of this polynomial.

It follows that $\alpha$ is algebraic over $k(S)$. In particular, $k(S,
\alpha)/ k(S)$ is finite. Since $S$ is a finite set, and $k(S)/k$ is algebraic,
\cref{fingenalg} shows that $k(S)/k$ is finite. Together we find that
$k(S,\alpha)/k$ is finite, so $\alpha$ is algebraic over $k$.
\end{proof}

The method of proof in the previous argument---that being algebraic over $E$ was a
property that \emph{descended} to a finitely generated subextension of $E$---is
an idea that recurs throughout algebra, and will be put to use more generality
in \cref{}.

\subsection{Minimal polynomials}

Let $E/k$ be a field extension, and let $\alpha \in E$ be algebraic over $k$.
Then $\alpha$ satisfies a (nontrivial) polynomial equation in $k[x]$.
Consider the set of polynomials $P(x) \in k[x]$ such that $P(\alpha) = 0$; by
hypothesis, this set does not just contain the zero polynomial.
It is easy to see that this set is an \emph{ideal.} Indeed, it is the kernel
of the map
\[ k[x] \to E, \quad x \mapsto \alpha.  \]
Since $k[x]$ is a PID,
there is a \emph{generator} $m(x) \in k[x]$ of this ideal. If we assume $m$
monic, without loss of generality, then $m$ is uniquely determined.

\begin{definition}
$m(x)$ as above is called the \textbf{minimal polynomial} of $\alpha$ over $k$.
\end{definition}

The minimal polynomial has the following characterization: it is the monic
polynomial, of smallest degree, that annihilates $\alpha$. (Any nonconstant
multiple of $m(x)$ will have larger degree, and only multiples of $m(x)$ can
annihilate $\alpha$.)
This explains the name \emph{minimal.}

Clearly the minimal polynomial is \emph{irreducible.} This is equivalent to the
assertion that the ideal in $k[x]$ consisting of polynomials annihilating
$\alpha$ is prime. But this follows from the fact that the map $k[x] \to E, x
\mapsto \alpha$ is
a map into a domain (even a field), so the kernel is a prime ideal.

\begin{proposition}
The degree of the minimal polynomial is $[k(\alpha):k]$.
\end{proposition}
\begin{proof}
This is just a restatement of the argument in \cref{monofld}: the observation is that if $m(x)$
is the minimal polynomial of $\alpha$, then the map
\[ k[x]/(m(x)) \to k(\alpha), \quad x \mapsto \alpha  \]
is an isomorphism as in the aforementioned proof, and we have counted the degree
of such an extension  (see \cref{monodeg2}).
\end{proof}

So the observation of the above proof is that if $\alpha \in E$ is algebraic,
then $k(\alpha) \subset E$ is isomorphic to $k[x]/(m(x))$.


\subsection{Algebraic closure}

Now we want to define a ``universal'' algebraic extension of a field. Actually,
we should be careful: the algebraic closure is \emph{not} a universal object.
That is, the algebraic closure is not unique up to \emph{unique} isomorphism:
it is only unique up to isomorphism. But still, it will be very handy, if not
functorial.


\begin{definition}
Let $F$ be a field. An \textbf{algebraic closure} of $F$ is a field
$\overline{F}$ containing $F$ such that:
\begin{enumerate}[\textbf{AC} 1]
\item $\overline{F} $ is algebraic over $F$.
\item $\overline{F}$ is \textbf{algebraically closed} (that is, every
non-constant polynomial in $\overline{F}[X]$ has a root in $\overline{F}$).
\end{enumerate}
\end{definition}

The ``fundamental theorem of algebra'' states that $\mathbb{C}$ is
algebraically closed. While the easiest proof of this result uses Liouville's
theorem in complex analysis, we shall give a mostly algebraic proof below
(\cref{}).

We now prove the basic existence result.


\begin{theorem}
Every field has an algebraic closure.
\end{theorem}

The proof will mostly be a red herring to the rest of the chapter. However, we
will want to know that it is \emph{possible} to embed a field inside an
algebraically closed field, and we will often assume it done.
\begin{proof}
Let $ K$ be a field and $ \Sigma$ be the set of all monic irreducibles in $ K[x]$. Let $ A = K[\{x_f : f \in \Sigma\}]$ be the polynomial ring generated by indeterminates $ x_f$, one for each $ f \in \Sigma$. Then let $ \mathfrak{a}$ be the ideal of $ A$ generated by polynomials of the form $ f(x_f)$ for each $ f \in \Sigma$.

\emph{Claim 1}. $ \mathfrak{a}$ is a proper ideal.

\emph{Proof of claim 1}. Suppose $ \mathfrak{a} = (1)$, so there exist finitely many polynomials $ f_i \in \Sigma$ and $ g_i \in A$ such that $ 1 = f_1(x_{f_1}) g_1 + \dotsb + f_k(x_{f_k}) g_k$. Each $ g_i$ uses some finite collection of indeterminates $ V_i \{x_{f_{i_1}}, \dotsc, x_{f_{i_{k_i}}}\}$. This notation is ridiculous, so we simplify it.

We can take the union of all the $ V_i$, together with the indeterminates $ x_{f_1}, \dotsc, x_{f_k}$ to get a larger but still finite set of indeterminates $ V = \{x_{f_1}, \dotsc, x_{f_n}\}$ for some $ n \geq k$ (ordered so that the original $ x_{f_1}, \dotsc, x_{f_k}$ agree the first $ k$ elements of $ V$). Now we can regard each $ g_i$ as a polynomial in this new set of indeterminates $ V$.
Then, we can write $ 1 = f_1(x_{f_1}) g_1 + \dotsb + f_n(x_{f_n}) g_n$ where for each $ i > k$, we let $ g_i = 0$ (so that we've adjoined a few zeroes to the right hand side of the equality).
Finally, we define $ x_i = x_{f_i}$, so that we have
$ 1 = f_1(x_1)g_1(x_1, \dotsc, x_n) + \dotsb + f_n(x_n) g_n(x_1, \dotsc, x_n)$.

Suppose $ n$ is the minimal integer such that there exists an expression of this form, so that
\[ \mathfrak{b} = (f_1(x_1), \dotsc, f_{n-1}(x_{n-1})) \]
is a proper ideal of $ B = K[x_1, \dotsc, x_{n-1}]$, but
\[ (f_1(x_1), \dotsc, f_n(x_n)) \]
is the unit ideal in $ B[x_n]$. Let $ \hat{B} = B/\mathfrak{b}$ (observe that this ring is nonzero). We have a composition of maps
\[ B[x_n] \to \hat{B}[x_n] \to \hat{B}[x_n]/(\widehat{f_n(x_n)}) \]
where the first map is reduction of coefficients modulo $ \mathfrak{b}$, and the second map is the quotient by the principal ideal generated by the image $ \widehat{f_n(x_n)}$ of $ f_n(x_n)$ in $ \hat{B}[x_n]$. We know $ \hat{B}$ is a nonzero ring, so since $ f_n$ is monic, the top coefficient of $ \widehat{f_n(x_n)}$ is still $ 1 \in \hat{B}$. In particular, the top coefficient cannot be nilpotent. Furthermore, since $ f_n$ was irreducible, it is not a constant polynomial, so by the characterization of units in polynomial rings, $ \widehat{f_n(x_n)}$ is not a unit, so it does not generate the unit ideal. Thus the quotient $ \hat{B}[x_n]/(\widehat{f_n(x_n)})$ should not be the zero ring.

On the other hand, observe that each $ f_i(x_i)$ is in the kernel of this composition, so in fact the entire ideal $ (f_1(x_1), \dotsc, f_n(x_n))$ is contained in the kernel. But this ideal is the unit ideal, so all of $ B[x_n]$ is in the kernel of this composition. In particular, $ 1 \in B[x_n]$ is in the kernel, and since ring maps preserve identity, this forces $ 1 = 0$ in $ \hat{B}[x_n]/(\widehat{f_n(x_n)})$, which makes this the the zero ring. This contradicts our previous observation, and proves the claim that $ \mathfrak{a}$ is a proper ideal.

Now, given claim 1, there exists a maximal ideal $ \mathfrak{m}$ of $ A$ containing $ \mathfrak{a}$. Let $ K_1 = A/\mathfrak{m}$. This is an extension field of $ K$ via the inclusion given by
\[ K \to A \to A/\mathfrak{m} \]
(this map is automatically injective as it is a map between fields). Furthermore every $ f \in \Sigma$ has a root in $ K_1$. Specifically, the coset $ x_f + \mathfrak{m}$ in $ A/\mathfrak{m} = K_1$ is a root of $ f$ since
\[ f(x_f + \mathfrak{m}) = f(x_f) + \mathfrak{m} = 0. \]

Inductively, given $ K_n$ for some $ n \geq 1$, repeat the construction with $ K_n$ in place of $ K$ to get an extension field $ K_{n+1}$ of $ K_n$ in which every irreducible $ f \in K_n[x]$ has a root. Let $ L = \bigcup_{n = 1}^{\infty} K_n$.

\emph{Claim 2}. Every $ f \in L[x]$ splits completely into linear factors in $ L$.

\emph{Proof of claim 2}. We induct on the degree of $ f$. In the base case, when $ f$ itself is linear, there is nothing to prove. Inductively, suppose every polynomial in $ L[x]$ of degree less than $ n$ splits completely into linear factors, and suppose
\[ f = a_0 + a_1x + \dotsb + a_nx^n \in L[x] \]
has degree $ n$. Then each $ a_i \in K_{n_i}$ for some $ n_i$, so let $ n = \max n_i$ and regard $ f$ as a polynomial in $ K_n[x]$. If $ f$ is reducible in $ K_n[x]$, then we have a factorization $ f = gh$ with the degree of $ g, h$ strictly less than $ n$. Therefore, inductively, they both split into linear factors in $ L[x]$, so $ f$ must also. On the other hand, if $ f$ is irreducible, then by our construction, it has a root $ a\in K_{n+1}$, so we have $ f = (x - a) g$ for some $ g \in K_{n+1}[x]$ of degree $ n - 1$. Again inductively, we can split $ g$ into linear factors in $ L$, so clearly we can do the same with $ f$ also. This completes the proof of claim 2.

Let $ \bar{K}$ be the set of algebraic elements in $ L$. Clearly $ \bar{K}$ is an algebraic extension of $ K$. If $ f \in \bar{K}[x]$, then we have a factorization of $ f$ in $ L[x]$ into linear factors
\[ f = b(x - a_1)(x - a_2) \dotsb (x - a_n). \]
for $ b \in \bar{K}$ and, a priori, $ a_i \in L$. But each $ a_i$ is a root of $ f$, which means it is algebraic over $ \bar{K}$, which is an algebraic extension of $ K$; so by transitivity of "being algebraic," each $ a_i$ is algebraic over $ K$. So in fact we conclude that $ a_i \in \bar{K}$ already, since $ \bar{K}$ consisted of all elements algebraic over $ K$. Therefore, since $ \bar{K}$ is an algebraic extension of $ K$ such that every $ f \in \bar{K}[x]$ splits into linear factors in $ \bar{K}$, $ \bar{K}$ is the algebraic closure of $ K$.

\end{proof}

\add{two algebraic closures are isomorphic}

Let $K$ be an algebraically closed field. Then the ring $K[x]$ has a very
simple ideal structure.
Since every polynomial $P \in K[x]$ has a root, it follows that there is always
a decomposition (by dividing repeatedly)
\[ P =c (x-\alpha_1)\dots(x-\alpha_n)  ,\]
where $c$ is the constant term and the $\left\{\alpha_i\right\} \subset k$ are the roots
of $P$.
In particular:
\begin{proposition}
For $K$ algebraically closed, the only irreducible polynomials in $K[x]$ are
the linear polynomials $c(x-\alpha), \ c, \alpha \in K$ (and $c \neq 0$).
\end{proposition}

In particular, two polynomials in $K[x]$ are \textbf{relatively prime}
(i.e., generate the unit ideal) if and only if they have no common roots. This
follows because the maximal ideals of $K[x]$ are of the form $(x-\alpha),
\alpha \in K$.
So if $F, G \in K[x]$ have no common root, then $(F, G)$ cannot be contained
in any $(x-\alpha)$ (as then they would have a common root at $\alpha$).


If $k$ is \emph{not} algebraically closed, then this still gives
information about when two polynomials in $k[x]$ generate the unit ideal.

\begin{definition}
If $k$ is any field, we say that two polynomials in $k[x]$ are
\textbf{relatively prime} if they generate the unit ideal in $k[x]$.
\end{definition}

\begin{proposition} \label{primepoly}
Two polynomials in $k[x]$ are relatively prime precisely when they
have no common roots in an algebraic closure $\overline{k}$ of $k$.
\end{proposition}
\begin{proof}
The claim is that any two polynomials $P, Q$ generate $(1)$ in $k[x]$ if and
only if they generate $(1)$ in $\overline{k}[x]$. This is a piece of
linear algebra: a system of linear equations with coefficients in $k$ has
a solution if and only if it has a solution in any extension of $k$.
Consequently, we can reduce to the case of an algebraically closed field, in
which case the result is clear from what we have already proved.
\end{proof}



\section{Separability and normality}


\subsection{Separable extensions}

Throughout, $F \subset K$ is a finite field extension.  We fix once and for
all an algebraic closure $\overline{F}$ for $F$ and an embedding of $F$ in $M$.


\begin{definition}
For an element $\alpha \in K$ with minimal polynomial $q \in F[x]$, we say
$q$ and $\alpha$ are \textbf{separable} if $q$ has distinct roots (in some
algebraic closure $\overline{F}$!), and we say $K$ is
separable if this holds for all $\alpha \in K$.
\end{definition}



By \cref{primepoly}, separability of a polynomial $P \in F[x]$ is equivalent
to $(P, P') = 1$ in $F[x]$.
Indeed, this follows from the fact that $P$ has no multiple roots if and only if $P, P'$ have no
common roots.

\begin{lemma} $q(x) \in F[x]$ is separable if and only if $\gcd(q, q') = 1$,
where $q'$ is the formal derivative of $q$.
\label{der_poly}
\end{lemma}




\subsection{Purely inseparable extensions}

\begin{definition}
For an element $\alpha \in K$ with minimal polynomial $q$, we say $\alpha$ is \textbf{purely
inseparable} if $q$ has only one root.  We say $K$ is splitting if each $q$
splits in $K$.
\label{def:sepsplit}
\end{definition}


\begin{definition} If $K = F(\alpha)$ for some $\alpha$ with minimal polynomial
$q(x) \in F[x]$, then by \rref{sep_poly}, $q(x) = r(x^{p^d})$, where $p =
\Char{F}$ (or $1$ if $\Char{F} = 0$) and $r$ is separable; in this case we
also denote $\deg_s(K/F) = \deg(r), \deg_i(K/F) = p^d$.  \label{def:prim_sep}
\end{definition}


\section{Galois theory}
\subsection{Definitions}

Throughout, $F \subset K$ is a finite field extension.  We fix once and for
all an algebraic closure $M$ for both and an embedding of $F$ in $M$.  When
necessary, we write $K = F(\alpha_1, \dots, \alpha_n)$, and $K_0 = F, K_i =
F(\alpha_1, \dots, \alpha_i)$, $q_i$ the minimal polynomial of $\alpha_i$ over
$F_{i - 1}$, $Q_i$ that over $F$.

\begin{definition} $\Aut(K/F)$ denotes the group of automorphisms of $K$ which fix
$F$ (pointwise!).  $\Emb(K/F)$ denotes the set of embeddings of $K$ into $M$
respecting the chosen embedding of $F$.
\label{def:gal}
\end{definition}

\begin{definition} By $\deg(K/F)$ we mean the dimension of $K$ as an $F$-vector
space.  We denote $K_s/F$ the set of elements of $K$ whose minimal polynomials
over $F$ have distinct roots; by \rref{sep_subfield} this is a subfield, and
$\deg(K_s/F) = \deg_s(K/F)$ and $\deg(K/K_s) = \deg_i(K/F)$ by definition.
\label{def:sep}
\end{definition}
\subsection{Theorems}
\begin{lemma} If $\Char{F} = 0$ then $K_s = K$.  If $\Char{F} = p > 0$, then for
any irreducible $q(x) \in K[x]$, there is some $d \geq 0$ and polynomial $r(x)
\in K[x]$ such that $q(x) = r(x^{p^d})$, and $r$ is separable and irreducible.
\label{sep_poly}
\end{lemma}

\begin{proof} By formal differentiation, $q'(x)$ has positive degree unless
each exponent is a multiple of $p$; in characteristic zero this never occurs.
If this is not the case, since $q$ is irreducible, it can have no factor in
common with $q'$ and therefore has distinct roots by \rref{der_poly}.

If $p > 0$, let $d$ be the largest integer such that each exponent of $q$ is a
multiple of $p^d$, and define $r$ by the above equation.  Then by
construction, $r$ has at least one exponent which is not a multiple of $p$,
and therefore has distinct roots. \end{proof}

\begin{corollary} In the statement of \rref{sep_poly}, $q$ and $r$ have the same
number of roots.
\label{sep_roots}
\end{corollary}

\begin{proof} $\alpha$ is a root of $q$ if and only if $\alpha^{p^d}$ is a
root of $r$; i.e. the roots of $q$ are the roots of $x^{p^d} - \beta$, where
$\beta$ is a root of $r$.  But if $\alpha$ is one such root, then $(x -
\alpha)^{p^d} = x^{p^d} - \alpha^{p^d} = x^{p^d} - \beta$ since $\Char{K} =
p$, and therefore $\alpha$ is the only root of $x^{p^d} - \beta$. \end{proof}

\begin{lemma} The correspondence which to each $g \in \Emb(K/F)$ assigns the
$n$-tuple $(g(\alpha_1), \dots, g(\alpha_n))$ of elements of $M$ is a
bijection from $\Emb(K/F)$ to the set of tuples of $\beta_i \in M$, such that
$\beta_i$ is a root of $q_i$ over $K(\beta_1, \dots, \beta_{i - 1})$.
\label{emb_roots}
\end{lemma}

\begin{proof} First take $K = F(\alpha) = F[x]/(q)$, in which case the maps $g
\colon K \to M$ over $F$ are identified with the elements $\beta \in M$ such
that $q(\beta) = 0$ (where $g(\alpha) = \beta$).

Now, considering the tower $K = K_n / K_{n - 1} / \dots / K_0 = F$, each
extension of which is primitive, and a given embedding $g$, we define
recursively $g_1 \in \Emb(K_1/F)$ by restriction and subsequent $g_i$ by
identifying $K_{i - 1}$ with its image and restricting $g$ to $K_i$.  By the
above paragraph each $g_i$ corresponds to the image $\beta_i = g_i(\alpha_i)$,
each of which is a root of $q_i$.  Conversely, given such a set of roots of
the $q_i$, we define $g$ recursively by this formula. \end{proof}

\begin{corollary} $|\Emb(K/F)| = \prod_{i = 1}^n \deg_s(q_i)$.
\label{emb_size}
\end{corollary}

\begin{proof} This follows immediately by induction from \rref{emb_roots} by
\rref{sep_roots}. \end{proof}

\begin{lemma} For any $f \in \Emb(K/F)$, the map $\Aut(K/F) \to \Emb(K/F)$ given
by $\sigma \mapsto f \circ \sigma$ is injective.
\label{aut_inj}
\end{lemma}

\begin{proof} This is immediate from the injectivity of $f$. \end{proof}

\begin{corollary} $\Aut(K/F)$ is finite.
\label{aut_fin}
\end{corollary}

\begin{proof} By \rref{aut_inj}, $\Aut(K/F)$ injects into $\Emb(K/F)$, which by
\rref{emb_size} is finite. \end{proof}

\begin{proposition} The inequality
\begin{equation*}
|\Aut(K/F)| \leq |\Emb(K/F)|
\end{equation*}
is an equality if and only if the $q_i$ all split in $K$.
\label{aut_ineq}
\end{proposition}

\begin{proof} The inequality follows from \rref{aut_inj} and from \rref{aut_fin}.
Since both sets are finite, equality holds if and only if the injection of
\rref{aut_inj} is surjective (for fixed $f \in \Emb(K/F)$).

If surjectivity holds, let $\beta_1, \dots, \beta_n$ be arbitrary roots of
$q_1, \dots, q_n$ in the sense of \rref{emb_roots}, and extract an embedding $g
\colon K \to M$ with $g(\alpha_i) = \beta_i$.  Since the correspondence $f
\mapsto f \circ \sigma$ ($\sigma \in \Aut(K/F)$) is a bijection, there is some
$\sigma$ such that $g = f \circ \sigma$, and therefore $f$ and $g$ have the
same image.  Therefore the image of $K$ in $M$ is canonical, and contains
$\beta_1, \dots, \beta_n$ for any choice thereof.

If the $q_i$ all split, let $g \in \Emb(K/F)$ be arbitrary, so the
$g(\alpha_i)$ are roots of $q_i$ in $M$ as in \rref{emb_roots}.  But the $q_i$
have all their roots in $K$, hence in the image $f(K)$, so $f$ and $g$ again
have the same image, and $f^{-1} \circ g \in \Aut(K/F)$.  Thus $g = f \circ
(f^{-1} \circ g)$ shows that the map of \rref{aut_inj} is surjective.
\end{proof}

\begin{corollary} Define
\begin{equation*}
D(K/F) = \prod_{i = 1}^n \deg_s(K_i/K_{i - 1}).
\end{equation*}
Then the chain of equalities and inequalities
\begin{equation*}
|\Aut(K/F)| \leq |\Emb(K/F)| = D(K/F) \leq \deg(K/F)
\end{equation*}
holds; the first inequality is an equality if and only if each $q_i$ splits in
$K$, and the second if and only if each $q_i$ is separable.
\label{large_aut_ineq}
\end{corollary}

\begin{proof} The statements concerning the first inequality are just
\rref{aut_ineq}; the interior equality is just \rref{emb_size}; the latter
inequality is obvious from the multiplicativity of the degrees of field
extensions; and the deduction for equality follows from the definition of
$\deg_s$. \end{proof}

\begin{corollary} The $q_i$ respectively split and are separable in $K$ if and only
if the $Q_i$ do and are.
\label{absolute_sepsplit}
\end{corollary}

\begin{proof} The ordering of the $\alpha_i$ is irrelevant, so we may take
each $i = 1$ in turn.  Then $Q_1 = q_1$ and if either of the equalities in
\rref{large_aut_ineq} holds then so does the corresponding statement here.
Conversely, clearly each $q_i$ divides $Q_i$, so splitting or separability
for the latter implies that for the former. \end{proof}

\begin{corollary} Let $\alpha \in K$ have minimal polynomial $q$; if the $Q_i$ are
respectively split, separable, and purely inseparable over $F$ then $q$ is as
well.
\label{global_sepsplit}
\end{corollary}

\begin{proof} We may take $\alpha$ as the first element of an alternative
generating set for $K/F$.  The numerical statement of \rref{large_aut_ineq}
does not depend on the particular generating set, hence the conditions given
hold of the set containing $\alpha$ if and only if they hold of the canonical
set ${\alpha_1, \dots, \alpha_n}$.

For purely inseparable, if the $Q_i$ all have only one root then $|\Emb(K/F)|
= 1$ by \rref{large_aut_ineq}, and taking $\alpha$ as the first element of a
generating set as above shows that $q$ must have only one root as well for
this to hold. \end{proof}

\begin{corollary} $K_s$ is a field and $\deg(K_s/F) = D(K/F)$.
\label{sep_subfield}
\end{corollary}

\begin{proof} Assume $\Char{F} = p > 0$, for otherwise $K_s = K$.  Using
\rref{sep_poly}, write each $Q_i = R_i(x^{p^{d_i}})$, and let $\beta_i =
\alpha_i^{p^{d_i}}$.  Then the $\beta_i$ have $R_i$ as minimal polynomials and
the $\alpha_i$ satisfy $s_i = x^{p^{d_i}} - \beta_i$ over $K' = F(\beta_1,
\dots, \beta_n)$.  Therefore the $\alpha_i$ have minimal polynomials over $K'$
dividing the $s_i$ and hence those polynomials have but one distinct root.

By \rref{global_sepsplit}, the elements of $K'$ are separable, and those of
$K'$ purely inseparable over $K'$.  In particular, since these minimal
polynomials divide those over $F$, none of these elements is separable, so $K'
= K_s$.

The numerical statement follows by computation:
\begin{equation*}
\deg(K/K') = \prod_{i = 1}^n p^{d_i}
	= \prod_{i = 1}^n \frac{\deg(K_i/K_{i - 1})}{\deg_s(K_i/K_{i - 1})}
	= \frac{\deg(K/F)}{D(K/F)}.
	\end{equation*}
\end{proof}

\begin{theorem} The following inequality holds:
\begin{equation*}
|\Aut(K/F)| \leq |\Emb(K/F)| = \deg_s(K/F) \leq \deg(K/F).
\end{equation*}
Equality holds on the left if and only if $K/F$ is splitting; it holds on the
right if and only if $K/F$ is separable.
\label{galois_size}
\end{theorem}

\begin{proof} The numerical statement combines \rref{large_aut_ineq} and
\rref{sep_subfield}.  The deductions combine \rref{absolute_sepsplit} and
\rref{global_sepsplit}. \end{proof}

\subsection{Definitions}

Throughout, we will denote as before $K/F$ a finite field extension, and $G =
\Aut(K/F)$, $H$ a subgroup of $G$.  $L/F$ is a subextension of $K/F$.

\begin{definition} When $K/F$ is separable and splitting, we say it is Galois and
write $G = \Gal(K/F)$, the Galois group of $K$ over $F$.
\label{defn:galois_extension}
\end{definition}

\begin{definition} The fixed field of $H$ is the field $K^H$ of elements fixed by
the action of $H$ on $K$.  Conversely, $G_L$ is the fixing subgroup of $L$,
the subgroup of $G$ whose elements fix $L$.
\label{defn:fixing}
\end{definition}

\subsection{Theorems}

\begin{lemma} A polynomial $q(x) \in K[x]$ which splits in $K$ lies in
$K^H[x]$ if and only if its roots are permuted by the action of $H$.  In this
case, the sets of roots of the irreducible factors of $q$ over $K^H$ are the orbits
of the action of $H$ on the roots of $q$ (counting multiplicity).
\label{root_action}
\end{lemma}

\begin{proof} Since $H$ acts by automorphisms, we have $\sigma q(x) = q(\sigma
x)$ as a functional equation on $K$, so $\sigma$ permutes the roots of $q$.
Conversely, since the coefficients of $\sigma$ are the elementary symmetric
polynomials in its roots, $H$ permuting the roots implies that it fixes the
coefficients.

Clearly $q$ is the product of the polynomials $q_i$ whose roots are the orbits
of the action of $H$ on the roots of $q$, counting multiplicities, so it
suffices to show that these polynomials are defined over $K^H$ and are
irreducible.  Since $H$ acts on the roots of the $q_i$ by construction, the
former is satisfied.  If some $q_i$ factored over $K^H$, its factors would
admit an action of $H$ on their roots by the previous paragraph.  The roots of
$q_i$ are distinct by construction, so its factors do not share roots; hence
the action on the roots of $q_i$ would not be transitive, a contradiction.
\end{proof}

\begin{corollary} Let $q(x) \in K[x]$; if it is irreducible, then $H$ acts
transitively on its roots; conversely, if $q$ is separable and $H$ acts
transitively on its roots, then $q(x) \in K^H[x]$ is irreducible.
\label{sep_irred}
\end{corollary}

\begin{proof} Immediate from \rref{root_action}. \end{proof}

\begin{lemma} If $K/F$ is Galois, so is $K/L$, and $\Gal(K/L) = G_L$..
\label{sub_galois}
\end{lemma}

\begin{proof} $K/F$ Galois means that the minimal polynomial over $F$ of every
element of $K$ is separable and splits in $K$; the minimal polynomials over $L
= K^H$ divide those over $F$, and therefore this is true of $K/L$ as well;
hence $K/L$ is likewise a Galois extension. $\Gal(K/L) = \Aut(K/L)$ consists
of those automorphisms $\sigma$ of $K$ which fix $L$; since $F \subset L$ we
have \emph{a fortiori} that $\sigma$ fixes $F$, hence $\Gal(K/L) \subset G$
and consists of the subgroup which fixes $L$; i.e. $G_L$. \end{proof}

\begin{corollary} If $K/F$ and $L/F$ are Galois, then the action of $G$ on elements of $L$
defines a surjection of $G$ onto $\Gal(L/F)$.  Thus $G_L$ is normal in $G$ and $\Gal(L/F) \cong G/G_L$.  Conversely, if $N \subset G$ is normal, then $K^N/F$ is Galois.
\label{normal}
\end{corollary}

\begin{proof} $L/F$ is splitting, so by \rref{root_action} the elements of $G$
act as endomorphisms (hence automorphisms) of $L/F$, and the kernel of this action is $G_L$.  By
\rref{sub_galois}, we have $G_L = \Gal(K/L)$, so $|G_L| = |\Gal(K/L)| = [K : L] = [K : F] / [L : F]$,
or rearranging and using that $K/F$ is Galois, we get $|G|/|G_L| = [L : F] =
|\Gal(L/F)|$.  Thus the map $G \to \Gal(L/F)$ is surjective and thus the induced map $G/G_L \to
\Gal(L/F)$ is an isomorphism.

Conversely, let $N$ be normal and take $\alpha \in K^N$.  For any conjugate $\beta$ of $\alpha$, we
have $\beta = g(\alpha)$ for some $g \in G$; let $n \in N$.  Then $n(\beta) = (ng)(\alpha) =
g(g^{-1} n g)(\alpha) = g(\alpha) = \beta$, since $g^{-1} n g \in N$ by normality of $N$.  Thus
$\beta \in K^N$, so $K^N$ is splitting, i.e., Galois. \end{proof}

\begin{proposition} If $K/F$ is Galois and $H = G_L$, then $K^H = L$.
\label{fixed_field}
\end{proposition}

\begin{proof} By \rref{sub_galois}, $K/L$ and $K/K^H$ are both Galois.  By
definition, $\Gal(K/L) = G_L = H$; since $H$ fixes $K^H$ we certainly have
$H < \Gal(K/K^H)$, but since $L \subset K^H$ we have \emph{a fortiori} that
$\Gal(K/K^H) < \Gal(K/L) = H$, so $\Gal(K/K^H) = H$ as well.  It follows
from \rref{galois_size} that $\deg(K/L) = |H| = \deg(K/K^H)$, so that $K^H =
L$. \end{proof}

\begin{lemma} If $K$ is a finite field, then $K^\ast$ is cyclic.
\label{fin_cyclic}
\end{lemma}

\begin{proof} $K$ is then a finite extension of $\mathbb{F}_p$ for $p =
\Char{K}$, hence has order $p^n$, $n = \deg(K/\mathbb{F}_p)$.  Thus
$\alpha^{p^n} = \alpha$ for all $\alpha \in K$, since $|K^\ast| = p^n - 1$.
It follows that every element of $K$ is a root of $q_n(x) = x^{p^n} - x$.  For
any $d < n$, the elements of order at most $p^d - 1$ satisfy $q_d(x)$, which has
$p^d$ roots.  It follows that there are at least $p^n(p - 1) > 0$ elements of
order exactly $p^n - 1$, so $K^\ast$ is cyclic. \end{proof}

\begin{corollary} If $K$ is a finite field, then $\Gal(K/F)$ is cyclic, generated by
the Frobenius automorphism.
\label{fin_gal_cyclic}
\end{corollary}

\begin{proof} First take $F = \mathbb{F}_p$.  Then the map $f_i(\alpha) =
\alpha^{p^i}$ is an endomorphism, injective since $K$ is a field, and
surjective since it is finite, hence an automorphism.  Since every $\alpha$
satisfies $\alpha^{p^n} = \alpha$, $f_n = 1$, but by \rref{fin_cyclic}, $f_{n -
1}$ is nontrivial (applied to the generator).  Since $n = \deg(K/F)$, $f =
f_1$ generates $\Gal(K/F)$.

If $F$ is now arbitrary, by \rref{fixed_field} we have $\Gal(K/F) =
\Gal(K/\mathbb{F}_p)_F$, and every subgroup of a cyclic group is cyclic.
\end{proof}

\begin{corollary} If $K$ is finite, $K/F$ is primitive.
\label{fin_prim_elt}
\end{corollary}

\begin{proof} No element of $G$ fixes the generator $\alpha$ of $K^\ast$, so
it cannot lie in any proper subfield.  Therefore $F(\alpha) = K$. \end{proof}

\begin{proposition} If $F$ is infinite and $K/F$ has only finitely many subextensions, then it is
primitive.
\label{gen_prim_elt}
\end{proposition}

\begin{proof} We proceed by induction on the number of generators of $K/F$.

If $K = F(\alpha)$ we are done.  If not, $K = F(\alpha_1, \dots, \alpha_n) =
F(\alpha_1, \dots, \alpha_{n - 1})(\alpha_n) = F(\beta, \alpha_n)$ by
induction, so we may assume $n = 2$.  There are infinitely many subfields
$F(\alpha_1 + t \alpha_2)$, with $t \in F$, hence two of them are equal, say for $t_1$ and
$t_2$.  Thus, $\alpha_1 + t_2 \alpha_2 \in F(\alpha_1 + t_1 \alpha_2)$.  Then
$(t_2 - t_1)\alpha_2 \in F(\alpha_1 + t_1 \alpha_2)$, hence $\alpha_2$ lies in
this field, hence $\alpha_1$ does.  Therefore $K = F(\alpha_1 + t_1
\alpha_2)$. \end{proof}

\begin{corollary} If $K/F$ is separable, it is primitive, and the generator may be
taken to be a linear combination of any finite set of generators of $K/F$.
\label{prim_elt}
\end{corollary}

\begin{proof} We may embed $K/F$ in a Galois extension $M/F$ by adjoining all
the conjugates of its generators.  Subextensions of $K/F$ are as well subextensions
of $K'/F$ and by \rref{fixed_field} the map $H \mapsto (K')^H$ is a surjection
from the subgroups of $G$ to the subextensions of $K'/F$, which are hence
finite in number.  By \rref{fin_prim_elt} we may assume $F$ is infinite.  The
result now follows from \rref{gen_prim_elt}. \end{proof}

\begin{corollary}
 If $K/F$ is Galois and $H \subset G$, then if $L = K^H$, we have $H = G_L$.
 \label{fixing_subgroup}
\end{corollary}

\begin{proof}
 Let $\alpha$ be a primitive element for $K/L$.  The polynomial $\prod_{h \in H} (x - h(\alpha))$ is fixed by $H$, and therefore has coefficients in $L$, so $\alpha$ has $|H|$ conjugate roots over $L$.  But since $\alpha$ is primitive, we have $K = L(\alpha)$, so the minimal polynomial of $\alpha$ has degree $\deg(K/L)$, which is the same as the number of its roots.  Thus $|H| = \deg(K/L)$.  Since $H \subset G_L$ and $|G_L| = \deg(K/L)$, we have equality.
\end{proof}


\begin{theorem} The correspondences $H \mapsto K^H$, $L \mapsto G_L$ define
inclusion-reversing inverse maps between the set of subgroups of $G$ and the
set of subextensions of $K/F$, such that normal subgroups and Galois subfields
correspond.
\label{fundamental_theorem}
\end{theorem}

\begin{proof} This combines \rref{fixed_field}, \rref{fixing_subgroup}, and \rref{normal}.
\end{proof}


\section{Transcendental Extensions}


There is a distinguished type of transcendental extension: those that are
``purely transcendental.''
\begin{definition} A field extension $E'/E$ is purely transcendental if it is
obtained by adjoining a set $B$ of algebraically independent elements. A set of
elements is algebraically independent over $E$ if there is no nonzero polynomial$P$
with coefficients in $E$ such
that $P(b_1,b_2,\cdots b_n)=0$ for any finite subset of elements $b_1, \dots,
b_n \in B$.
\end{definition}

\begin{example} The field $\mathbb{Q}(\pi)$ is purely transcendental; in
particular, $\mathbb{Q}(\pi)\cong\mathbb{Q}(x)$ with the isomorphism fixing
$\mathbb{Q}$. \end{example}
Similar to the degree of an algebraic extension, there is a way of keeping
track of the number of algebraically independent generators that are required to
generate a purely transcendental extension.
\begin{definition} Let $E'/E$ be a purely transcendental extension generated by
some set of algebraically independent elements $B$. Then the transcendence
degree $trdeg(E'/E)=\#(B)$ and $B$ is called a transcendence basis for $E'/E$
(we will see later that $trdeg(E'/E)$ is independent of choice of basis).
\end{definition}
In general, let $F/E$ be a field extension, we can always construct an
intermediate extension $F/E'/E$ such that $F/E'$ is algebraic and $E'/E$ is
purely transcendental. Then if $B$ is a transcendence basis for $E'$, it is
also called a transcendence basis for $F$. Similarly, $trdeg(F/E)$ is defined to
be
$trdeg(E'/E)$.
\begin{theorem} Let $F/E$ be a field extension, a transcendence basis exists.
\end{theorem}
\begin{proof} Let $A$ be an algebraically independent subset of $F$. Now pick a
subset $G\subset F$ that generates $F/E$, we can find a transcendence basis
$B$ such that $A\subset B\subset G$. Define a collection of algebraically
independent sets $\mathcal{B}$ whose members are subsets of $G$ that contain
$A$. The set can be partially ordered inclusion and contains at least one
element, $A$. The union of elements of $\mathcal{B}$ is algebraically
independent since any algebraic dependence relation would have occurred in one
of the elements of $\mathcal{B}$ since the polynomial is only allowed to be over
finitely many variables. The union also satisfies $A\subset
\bigcup\mathcal{B}\subset G$ so by Zorn's lemma, there is a maximal element
$B\in\mathcal{B}$. Now we claim $F$ is algebraic over $E(B)$. This is because
if it wasn't then there would be a transcendental element $f\in G$ (since
$E(G)=F$)such that $B\cup\{f\}$ wold be algebraically independent contradicting
the
maximality of $B$. Thus $B$ is our transcendence basis. \end{proof}
Now we prove that the transcendence degree of a field extension is independent
of choice of basis.
\begin{theorem} Let $F/E$ be a field extension. Any two transcendence bases for
$F/E$ have the same cardinality. This shows that the $trdeg(E/F)$ is well
defined. \end{theorem}
\begin{proof}
Let $B$ and $B'$ be two transcendence bases. Without loss of generality, we can
assume that $\#(B')\leq \#(B)$. Now we divide the proof into two cases: the
first case is that $B$ is an infinite set. Then for each $\alpha\in B'$, there
is a finite set $B_{\alpha}$ such that $\alpha$ is algebraic over
$E(B_{\alpha})$ since any algebraic dependence relation only uses finitely many
indeterminates. Then we define $B^*=\bigcup_{\alpha\in B'} B_{\alpha}$. By
construction, $B^*\subset B$, but we claim that in fact the two sets are
equal. To see this, suppose that they are not equal, say there is an element
$\beta\in B\setminus B^*$. We know $\beta$ is algebraic over $E(B')$ which is
algebraic over $E(B^*)$. Therefor $\beta$ is algebraic over $E(B^*)$, a
contradiction. So $\#(B)\leq \sum_{\alpha\in B'} \#(B_{\alpha})$. Now if $B'$ is
finite, then so is $B$ so we can assume $B'$ is infinite; this means
\begin{equation} \#(B)\leq \sum_{\alpha\in B'}\#(B_{\alpha})=\#(\coprod
B_{\alpha})\leq \#(B'\times\mathbb{Z})=\#(B')\end{equation} with the inequality $\#(\coprod
B_{\alpha}) \leq \#(B'\times \mathbb{Z})$ given by the correspondence
$b_{\alpha_i}\mapsto (\alpha,i)\in B'\times \mathbb{Z}$ with $B_\alpha =
\{b_{\alpha_1},b_{\alpha_2}\cdots b_{\alpha_{n_\alpha}}\}$ Therefore in the
infinite case, $\#(B)=\#(B')$.

Now we need to look at the case where $B$ is finite. In this case, $B'$ is also
finite, so suppose $B=\{\alpha_1,\cdots\alpha_n\}$ and
$B'=\{\beta_1,\cdots\beta_m\}$ with $m\leq n$. We perform induction on $m$: if
$m=0$ then $F/E$ is algebraic so $B=\null$ so $n=0$, otherwise there is an
irreducible polynomial $f\in E[x,y_1,\cdots y_n]$ such that
$f(\beta_1,\alpha_1,\cdots \alpha_n) = 0$. Since $\beta_1$ is not algebraic over
$E$, $f$ must involve some $y_i$ so without loss of generality, assume $f$ uses
$y_1$. Let $B^*=\{\beta_1,\alpha_2,\cdots\alpha_n\}$. We claim that $B^*$ is a
basis for $F/E$. To prove this claim, we see that we have a tower of algebraic
extensions $F/E(B^*,\alpha_1)/E(B^*)$ since $\alpha_1$ is algebraic over
$E(B^*)$. Now we claim that $B^*$ (counting multiplicity of elements) is
algebraically independent over $E$ because if it weren't, then there would be an
irreducible $g\in E[x,y_2,\cdots y_n]$ such that
$g(\beta_1,\alpha_2,\cdots\alpha_n)=0$ which must involve $x$ making $\beta_1$
algebraic over $E(\alpha_2,\cdots \alpha_n)$ which would make $\alpha_1$
algebraic over $E(\alpha_2,\cdots \alpha_n)$ which is impossible. So this means
that $\{\alpha_2,\cdots\alpha_n\}$ and $\{\beta_2,\cdots\beta_m\}$ are bases for
$F$ over $E(\beta_1)$ which means by induction, $m=n$. \end{proof}

\begin{example} Consider the field extension $\mathbb{Q}(e,\pi)$ formed by
adjoining the numbers $e$ and $\pi$. This field extension has transcendence
degree at least $1$ since both $e$ and $\pi$ are transcendental over the
rationals. However, this field extension might have transcendence degree $2$ if
$e$ and $\pi$ are algebraically independent. Whether or not this is true is
unknown and the problem of determining $trdeg(\mathbb{Q}(e,\pi))$ is an open
problem.\end{example}

\begin{example} let $E$ be a field and $F=E(t)/E$. Then $\{t\}$ is a
transcendence basis since $F=E(t)$. However, $\{t^2\}$ is also a transcendence
basis since $E(t)/E(t^2)$ is algebraic. This illustrates that while we can
always decompose an extension $F/E$ into an algebraic extension $F/E'$ and a
purely transcendental extension $E'/E$, this decomposition is not unique and
depends on choice of transcendence basis. \end{example}

\begin{exercise} If we have a tower of fields $G/F/E$, then $trdeg(G/E)=trdeg(F/E)+trdeg(G/F)$. \end{exercise}

\begin{example}
Let $X$ be a compact Riemann surface. Then the function field $\mathbb{C}(X)$
(see \cref{meromorphicfn}) has transcendence degree one over $\mathbb{C}$. In
fact, \emph{any} finitely generated extension of $\mathbb{C}$ of transcendence
degree one arises from a Riemann surface. There is even an equivalence of
categories between the category of compact Riemann surfaces and
(non-constant) holomorphic maps
and the opposite category of finitely generated extensions of $\mathbb{C}$ and
morphisms of $\mathbb{C}$-algebras. See \cite{Fo81}.

There is an algebraic version of the above statement as well. Given an
(irreducible) algebraic curve in projective space over an algebraically
closed field $k$ (e.g. the complex numbers), one can consider its ``field of rational
functions:'' basically, functions that look like quotients of polynomials,
where the denominator does not identically vanish on the curve.
There is a similar anti-equivalence of categories between smooth projective curves and
non-constant morphisms of curves and finitely generated extensions of $k$ of
transcendence degree one. See \cite{Ha77}.
\end{example}


\subsection{Linearly Disjoint Field Extensions}
Let $k$ be a field, $K$ and $L$ field extensions of $k$. Suppose also that $K$ and $L$ are embedded in some larger field $\Omega$.

\begin{definition} The compositum of $K$ and $L$ written $KL$ is $k(K\cup L)=L(K)=K(L)$.
\end{definition}



\begin{definition} $K$ and $L$ are said to be linearly disjoint over $k$ if the following map is injective:
\begin{equation} \theta: K\otimes_k L\rightarrow KL \end{equation} defined by $x\otimes y\mapsto xy$.
\end{definition}



% ============================ chapters/threeimportantfunctors.tex

\chapter{Three important functors}

There are three functors that will be integral to our study of commutative
algebra in the future: localization, the tensor product, and $\hom$.
While localization is an \emph{exact} functor, the tensor product and $\hom$
are not. The failure of exactness in those cases leads to the theory of
flatness and projectivity (and injectivity), and eventually the \emph{derived functors}
$\mathrm{Tor}$ and $\mathrm{Ext}$ that crop up in commutative algebra.

\section{Localization}

Localization is the process of making invertible a collection of elements in a
ring. It is a generalization of the process of forming a quotient field of an
integral domain.

\subsection{Geometric intuition}
We first start off with some of the geometric intuition behind the idea of
localization. Suppose we have a Riemann surface $X$ (for example, the Riemann
sphere). Let $A(U)$ be the ring of holomorphic functions over some neighborhood
$U\subset X$. Now, for holomorphicity to hold, all that is required is
that a function doesn't have a pole inside of $U$, thus when $U=X$, this
condition is the strictest and as $U$ gets smaller functions begin to show
up that may not arise from the restriction of a holomorphic function over
a larger domain. For example, if we want to study holomorphicity ``near a
point $z_0$'' all that we should require is that the function doesn't pole at
$z_0$. This means that we should consider quotients of holomorphic functions
$f/g$ where $g(z_0)\neq 0$. This process of inverting a collection of elements
is expressed through the algebraic construction known as ``localization.''


\subsection{Localization at a multiplicative subset}

Let $R$ be a commutative ring.
We start by constructing the notion of \emph{localization} in the most general
sense.

We have already implicitly used this definition, but nonetheless, we make it
formally:
\begin{definition} \label{multset}
A subset $S \subset R$ is a \textbf{multiplicative subset} if $1 \in S$ and
if $x,y \in S$ implies $xy \in S$.
\end{definition}

We now define the notion of \emph{localization}. Formally, this means
inverting things.
This will give us a functor from $R$-modules to $R$-modules.

\begin{definition}
If $M$ is an $R$-module, we define the module $S^{-1}M$ as the set of formal
fractions
\[  \left\{m/s, m \in M, s \in S\right\}  \]
modulo an equivalence relation: where $m/s \sim m'/s'$ if and only if
\[ t( s'm -   m's ) = 0  \]
for some $t \in S$.  The reason we need to include the $t$ in the definition
is that otherwise the
 relation would not be transitive (i.e. would not be an
equivalence relation).
\end{definition}
So two fractions agree if they agree when clearing denominators and
multiplication.

It is easy to check that this is indeed an equivalence relation. Moreover
$S^{-1}M$ is an abelian group with the usual addition of fractions
\[ \frac{m}{s}+\frac{m'}{s'} = \frac{s'm + sm'}{ss'}  \]
and it is easy to check that this is a legitimate abelian group.

\begin{definition}
Let $M$ be an $R$-module and $S \subset R$ a multiplicative subset.
The abelian group $S^{-1}M$ is naturally an $R$-module.  We define
\[ x(m/s) = (xm)/s, \quad x \in R.  \]
It is easy to check that this is well-defined and makes it into a module.

Finally, we note that localization is a \emph{functor} from the category of
$R$-modules to itself. Indeed, given $f: M \to N$, there is a naturally
induced map $S^{-1}M \stackrel{S^{-1}f}{\to} S^{-1}N$.

\end{definition}

We now consider the special case when the localized module is the initial ring
itself.
Let $M = R$.  Then $S^{-1}R$ is an $R$-module, and it is in fact a commutative
ring in its own right. The ring structure is quite tautological:
\[ (x/s)(y/s') = (xy/ss').  \]
There is a map $R \to S^{-1}R$ sending $x \to x/1$, which is a
ring-homomorphism.

\begin{definition}
For $S \subset R$ a multiplicative set, the localization $S^{-1}R$ is a
commutative ring as above. In fact, it is an $R$-algebra; there is a natural
map $\phi: R \to S^{-1}R$ sending $r \to r/1$.
\end{definition}

We can, in fact, describe $\phi: R \to S^{-1}R$ by a \emph{universal
property}. Note
that for each $s \in S$, $\phi(s)$ is invertible.  This is because $\phi(s) =
s/1$ which has a multiplicative inverse $1/s$.  This property characterizes
$S^{-1}R$.

For any commutative ring $B$, $\hom(S^{-1}R, B)$ is naturally isomorphic to the
subset of $\hom(R,B)$ that send $S$ to units.  The map takes $S^{-1}R \to B$ to
the pull-back $R \to S^{-1}R \to B$.  The proof of this is very simple.
Suppose that $f: R \to B$ is such that $f(s) \in B$ is invertible for each $s
\in S$.  Then we must define $S^{-1}R \to B$ by sending $r/s$ to
$f(r)f(s)^{-1}$.  It is easy to check that this is well-defined and that the
natural isomorphism as claimed is true.

Let $R$ be a ring, $M$ an $R$-module, $S \subset R$ a multiplicatively closed
subset. We defined a ring of fractions $S^{-1}R$ and an $R$-module $S^{-1}M$.
But in fact this is a module over the ring $S^{-1}R$.
We just multiply $(x/t)(m/s) = (xm/st)$.

In particular, localization at $S$ gives a \emph{functor} from $R$-modules to
$S^{-1}R$-modules.

\begin{exercise}
Let $R$ be a ring, $S$ a multiplicative subset. Let $T$ be the $R$-algebra
$R[\left\{x_s\right\}_{s \in S}]/( \left\{sx_s - 1\right\})$. This is the
polynomial ring in the variables $x_s$, one for each $s \in S$, modulo the
ideal generated by $sx_s  = 1$. Prove that this $R$-algebra is naturally
isomorphic to $S^{-1}R$, using the universal property.
\end{exercise}

\begin{exercise} Define a functor $\mathbf{Rings} \to \mathbf{Sets}$ sending
a ring to
its set of units, and show that it is corepresentable (use $\mathbb{Z}[X,
X^{-1}]$).
\end{exercise}
\subsection{Local rings}

A special case of great importance in the future is when the multiplicative
subset is the complement of a prime ideal, and we study this in the present
subsection. Such localizations will be ``local rings'' and geometrically
correspond to the process of zooming at a point.

\begin{example}
Let $R$ be an integral domain and let $S = R - \left\{0\right\}$. This is a
multiplicative subset because $R$ is a domain.  In this case, $S^{-1}R$ is just
the ring of fractions by allowing arbitrary nonzero denominators; it is a
field, and is called the \textbf{quotient field}. The most familiar example is
the construction of $\mathbb{Q}$ as the quotient field of $\mathbb{Z}$.
\end{example}

We'd like to generalize this example.

\begin{example}
Let $R$ be arbitrary and $\mathfrak{p}$ is a prime ideal.  This means that $1
\notin \mathfrak{p}$ and $x,y \in R - \mathfrak{p}$ implies that $xy \in R -
\mathfrak{p}$. Hence, the complement $S = R- \mathfrak{p}$  is multiplicatively
closed.  We get a ring $S^{-1}R$.

\begin{definition}
This ring is denoted $R_{\mathfrak{p}}$ and is called the \textbf{localization
at $\mathfrak{p}$.} If $M$ is an $R$-module, we write $M_{\mathfrak{p}}$ for
the localization of $M$ at $R - \mathfrak{p}$.
\end{definition}
This generalizes the previous example (where $\mathfrak{p} = (0)$).
\end{example}

There is a nice property of the rings $R_{\mathfrak{p}}$. To elucidate this,
we start with a lemma.

\begin{lemma}
Let $R$ be a nonzero commutative ring. The following are equivalent:
\begin{enumerate}
\item  $R$ has a unique maximal ideal.
\item If $x \in R$, then either $x$ or $1-x$ is invertible.
\end{enumerate}
\end{lemma}

\begin{definition}
In this case, we call $R$ \textbf{local}.  A local ring is one with a unique
maximal ideal.
\end{definition}

\begin{proof}[Proof of the lemma]
First we prove $(2) \implies (1)$.

Assume $R$ is such that for
each $x$, either $x$ or $1-x$ is invertible.  We will find the maximal ideal.
Let $\mathfrak{M} $ be the collection of noninvertible elements of $R$. This is
a subset of $R$, not containing $1$,  and it is closed under multiplication.
Any proper ideal must be a subset of $\mathfrak{M}$, because otherwise that
proper ideal would contain an invertible element.

We just need to check that $\mathfrak{M}$ is closed under addition.
Suppose to the
contrary that $x, y \in \mathfrak{M}$ but $x+y$ is invertible.   We get (with
$a = x/(x+y)$)
\[ 1 = \frac{x}{x+y} + \frac{y}{x+y} =a+(1-a). \]
Then one of $a,1-a$ is invertible. So either $x(x+y)^{-1}$  or $y(x+y)^{-1}$ is
invertible, which implies that either $x,y$ is invertible, contradiction.

Now prove the reverse direction. Assume $R$ has a unique maximal ideal
$\mathfrak{M}$.  We claim that $\mathfrak{M}$ consists precisely of the
noninvertible elements.  To see this, first note that $\mathfrak{M}$
can't contain any invertible elements since it is proper.  Conversely, suppose
$x$ is not invertible, i.e. $(x) \subsetneq R$.  Then $(x)$ is contained in a
maximal ideal by \rref{anycontainedinmaximal},  so $(x) \subset
\mathfrak{M}$ since $\mathfrak{M}$ is unique among maximal ideals.
Thus $x \in \mathfrak{M}$.

Suppose $x \in R$; we can write $1 = x + (1-x)$. Since $1 \notin \mathfrak{M}$,
one of $x, 1-x$ must not be in $\mathfrak{M}$, so one of those must not be
invertible. So $(1) \implies (2)$.   The lemma is proved.
\end{proof}

Let us give some examples of local rings.

\begin{example}
Any field is a local ring because the unique maximal ideal is $(0)$.
\end{example}

\begin{example}
Let $R$ be any commutative ring and $\mathfrak{p}\subset R$ a prime ideal. Then
$R_{\mathfrak{p}}$ is a local ring.

We state this as a result.
\begin{proposition}
$R_{\mathfrak{p}}$ is a local ring if $\mathfrak{p}$ is prime.\end{proposition}
\begin{proof}
Let $\mathfrak{m} \subset R_{\mathfrak{p}}$ consist of elements $x/s$ for $x
\in \mathfrak{p}$ and $s \in R - \mathfrak{p}$. It is left as an exercise
(using the primality of $\mathfrak{p}$) to
the reader to see that whether the numerator belongs to $\mathfrak{p}$ is
\emph{independent} of the representation $x/s$ used for it.

Then I claim that $\mathfrak{m}$ is the
unique maximal ideal. First, note that $\mathfrak{m}$ is
an ideal; this is evident since the numerators form an ideal. If $x/s, y/s'$
belong to $\mathfrak{m}$ with appropriate expressions, then
the numerator of
\[ \frac{xs'+ys}{ss'}  \]
belongs to $\mathfrak{p}$, so this sum belongs to $\mathfrak{m}$.  Moreover,
$\mathfrak{m}$ is a proper ideal because $\frac{1}{1}$ is not of the
appropriate form.

I claim that $\mathfrak{m}$ contains all other proper ideals, which will imply
that it is the unique maximal ideal. Let $I \subset R_{\mathfrak{p}}$ be any
proper ideal. Suppose $x/s \in I$.  We want to prove $x/s \in \mathfrak{m}$.
In other words, we have to show $x \in \mathfrak{p}$. But if not $x/s$ would be
invertible, and $I = (1)$, contradiction. This proves locality.
\end{proof}
\end{example}

\begin{exercise}
Any local ring is of the form $R_{\mathfrak{p}}$ for some ring $R$ and for
some prime ideal $\mathfrak{p} \subset R$.
\end{exercise}

\begin{example}
Let $R = \mathbb{Z}$. This is not a local ring; the maximal ideals are given by
$(p)$ for $p$ prime.  We can thus construct the localizations
$\mathbb{Z}_{(p)}$ of all fractions $a/b \in \mathbb{Q}$ where $b \notin (p)$.
Here $\mathbb{Z}_{(p)}$ consists of all rational numbers that don't have
powers of $p$ in the denominator.
\end{example}

\begin{exercise}
A local ring has no idempotents other than $0$ and $1$. (Recall that $e \in R$
is \emph{idempotent} if $e^2 = e$.) In particular, the product of two rings is
never local.
\end{exercise}

It may not yet be clear why localization is such a useful process. It turns
out that many problems can be checked on the localizations at prime (or even
maximal) ideals, so certain proofs can reduce to the case of a local ring.
Let us give a small taste.

\begin{proposition}
Let $f: M \to N$ be a homomorphism of $R$-modules.  Then $f$ is injective if
and only if for every maximal ideal $\mathfrak{m} \subset R$, we have that
$f_{\mathfrak{m}}: M_{\mathfrak{m}} \to N_{\mathfrak{m}}$ is injective.
\end{proposition}
Recall that, by definition, $M_{\mathfrak{m}}$ is the localization at $R -
\mathfrak{m}$.

There are many variants on this (e.g. replace with surjectivity, bijectivity).
This is a general observation that lets you reduce lots of commutative algebra
to local rings, which are easier to work with.

\begin{proof}
Suppose first that each $f_{\mathfrak{m}}$ is injective.  I claim that $f$ is
injective.  Suppose $x \in M - \left\{0\right\}$. We must show that $f(x) \neq
0$. If $f(x)=0$, then $f_{\mathfrak{m}}(x)=0$ for every maximal ideal
$\mathfrak{m}$.  Then by
injectivity it follows that $x$ maps to zero in each $M_{\mathfrak{m}}$.
We would now like to get a contradiction.

Let $I = \left\{ a \in R: ax = 0 \in M \right\}$.  This is proper since $x \neq
0$.  So $I$ is contained in some maximal ideal $\mathfrak{m}$.  Then $x$
maps to zero in $M_{\mathfrak{m}}$ by the previous paragraph; this means that
there is $s \in R - \mathfrak{m}$ with $sx = 0 \in M$. But $s \notin I$,
contradiction.

Now let us do the other direction. Suppose $f$ is injective and $\mathfrak{m}$
a maximal ideal; we prove $f_{\mathfrak{m}}$ injective.  Suppose
$f_{\mathfrak{m}}(x/s)=0 \in N_{\mathfrak{m}}$. This means that $f(x)/s=0$ in
the localized module, so that $f(x) \in M$ is killed by some $t \in R -
\mathfrak{m}$.  We thus have $f(tx) = t(f(x)) = 0 \in M$.  This means that $tx
= 0 \in M$ since $f$ is injective. But this in turn means that $x/s = 0 \in
M_{\mathfrak{m}}$. This is what we wanted to show.
\end{proof}



\subsection{Localization is exact}
Localization is to be thought of as a very mild procedure.

The next result says how inoffensive localization is. This result is a key
tool in reducing problems to the local case.
\begin{proposition}
Suppose $f: M \to N, g: N \to P$ and  $M \to N \to P$ is exact. Let $S \subset
R$ be multiplicatively closed. Then
\[ S^{-1}M \to S^{-1}N \to S^{-1}P  \]
is exact.
\end{proposition}

Or, as one can alternatively express it, localization is an \emph{exact
functor.}

Before proving it, we note a few corollaries:
\begin{corollary}
If $f: M \to N$ is surjective, then $S^{-1}M \to S^{-1}N$ is too.
\end{corollary}
\begin{proof}
To say that $A \to B$ is surjective is the same as saying that $A \to B \to 0$
is exact. From this the corollary is evident.
\end{proof}

Similarly:
\begin{corollary}
If $f: M \to N$ is injective, then  $S^{-1}M \to S^{-1}N$ is too.
\end{corollary}
\begin{proof}
To say that $A \to B$ is injective is the same as saying that $0 \to A \to B $
is exact. From this the corollary is evident.
\end{proof}

\begin{proof}[Proof of the proposition] We adopt the notation of the
proposition.
If the composite $g\circ f$ is zero, clearly the localization $S^{-1}M \to
S^{-1}N \to S^{-1}P$ is zero too.
Call the maps $S^{-1}M \to S^{-1}N, S^{-1}N \to S^{-1}P$ as $\phi, \psi$. We
know that $\psi \circ \phi  = 0$ so $\ker(\psi) \supset \im(\phi)$. Conversely,
suppose  something belongs to $\ker(\psi).  $ This can be written as a fraction
\[ x/s \in \ker(\psi)  \]
where $x \in N, s \in S$. This is mapped to
\[ g(x)/s \in S^{-1}P,  \]
which we're assuming is zero. This means that there is $t \in S$ with $tg(x) =
0 \in P$.  This means that $g(tx)=0$ as an element of $P$.  But $tx \in N$ and
its image of $g$ vanishes, so $tx$ must come from something in $M$.  In
particular,
\[ tx = f(y) \ \text{for some} \ y \in M.  \]
In particular,
\[ \frac{x}{s}  = \frac{tx}{ts} = \frac{f(y)}{ts} = \phi( y/ts) \in \im(\phi).
\]
This proves that anything belonging to the kernel of $\psi$ lies in
$\im(\phi)$.
\end{proof}

\subsection{Nakayama's lemma}

We now state a very useful criterion for determining when a module over a
\emph{local} ring is zero.


\begin{lemma}[Nakayama's lemma] \label{nakayama} If $R$ is a local ring with
maximal ideal
$\mathfrak{m}$. Let $M$ be a finitely generated $R$-module.  If
$\mathfrak{m}M = M$, then $M = 0$.
\end{lemma}

Note that $\mathfrak{m}M$ is the submodule generated by products of
elements of $\mathfrak{m}$ and $M$.

\begin{remark}
Once one has the theory of the tensor product, this equivalently states that
if $M$ is finitely generated, then
\[ M \otimes_R R/\mathfrak{m} = M/\mathfrak{m}M \neq 0.  \]
So to prove that a finitely generated module over a local ring is zero, you
can reduce to studying the reduction to $R/\mathfrak{m}$. This is thus a very
useful criterion.
\end{remark}

Nakayama's lemma highlights why it is so useful to work over a local ring.
Thus, it is useful to reduce questions about general rings to questions about
local rings.
Before proving it, we note a corollary.

\begin{corollary}
Let $R$ be a local ring with maximal ideal $\mathfrak{m}$, and $M$ a finitely
generated module. If $N \subset M$ is a submodule such that $N +
\mathfrak{m}N =
M$, then $N=M$.
\end{corollary}
\begin{proof}
Apply Nakayama above (\cref{nakayama}) to $M/N$.
\end{proof}


We shall prove more generally:

\begin{proposition}
Suppose $M$ is a finitely generated $R$-module, $J \subset R$ an ideal.
Suppose $JM = M$. Then there is $a \in 1+J$ such that $aM = 0$.
\end{proposition}

If $J$ is the maximal ideal of a local ring, then $a$ is a unit, so that $M=0$.

\begin{proof}
Suppose $M$ is generated by $\left\{x_1, \dots, x_n\right\} \subset M$. This
means that every element of $M$ is  a linear combination of elements of
$x_i$. However, each $x_i \in JM$ by assumption. In particular, each
$x_i$ can be written as
\[ x_i = \sum a_{ij} x_j, \ \mathrm{where} \ a_{ij} \in \mathfrak{m}.  \]
If we let $A$ be the matrix $\left\{a_{ij}\right\}$, then $A$ sends the
vector  $(x_i)$ into itself. In particular, $I-A$ kills
the vector $(x_i)$.

Now $I-A$ is an $n$-by-$n$ matrix in the ring $R$. We could, of course,
reduce everything modulo $J$ to get the identity; this is
because $A$ consists of elements of $J$. It follows that the
determinant must be congruent to $1$ modulo $J$.

In particular, $a=\det (I - A)$ lies in $1+J$.
Now by familiar linear algebra, $aI$ can be represented as the product of $A$
and the matrix of cofactors; in particular, $aI$ annihilates the vector
$(x_i)$, so that $aM=0$.
\end{proof}

Before returning to the special case of local rings, we observe the following
useful fact from ideal theory:

\begin{proposition}  \label{idempotentideal}
Let $R$ be a commutative ring, $I \subset R$ a finitely generated ideal such that $I^2 = I$.
Then $I$ is generated by an idempotent element.
\end{proposition}
\begin{proof}
We know that there is $x \in 1+I$ such that $xI =0$. If $x = 1+y, y \in I$, it
follows that
\[ yt = t  \]
for all $t \in I$. In particular, $y$ is idempotent and $(y) = I$.
\end{proof}

\begin{exercise}
\rref{idempotentideal} fails if the ideal is not finitely generated.
\end{exercise}

\begin{exercise}
Let $M$ be a finitely generated module over a ring $R$. Suppose $f: M \to M$
is a surjection. Then $f$ is an isomorphism. To see this, consider $M$ as a
module over $R[t]$ with $t$ acting by $f$; since $(t)M = M$, argue that there
is a polynomial $Q(t) \in R[t]$ such that $Q(t)t$ acts as the identity on
$M$, i.e. $Q(f)f=1_M$.
\end{exercise}

\begin{exercise}
Give a counterexample to the conclusion of Nakayama's lemma when the module is
not finitely generated.
\end{exercise}
\begin{exercise}
Let $M$ be a finitely generated module over the ring $R$. Let $\mathfrak{I}$
be the Jacobson
radical of $R$ (cf. \rref{Jacobson}). If $\mathfrak{I} M = M$,
then $M =
0$.
\end{exercise}

\begin{exercise}[A converse to Nakayama's lemma]
Suppose conversely that $R$ is a ring, and $\mathfrak{a} \subset R$ an ideal
such that $\mathfrak{a} M \neq M$ for every nonzero finitely generated
$R$-module. Then $\mathfrak{a}$ is contained in every maximal ideal of $R$.
\end{exercise}


\begin{exercise}
Here is an alternative proof of Nakayama's lemma. Let $R$ be local with
maximal ideal $\mathfrak{m}$, and let $M$ be a finitely generated module with
$\mathfrak{m}M = M$. Let $n$ be the minimal number of generators for $M$. If
$n>0$, pick generators $x_1, \dots, x_n$. Then write $x_1 = a_1 x_1 + \dots +
a_n x_n$ where each $a_i \in \mathfrak{m}$. Deduce that $x_1$ is in the
submodule generated by the $x_i, i \geq 2$, so that $n$ was not actually
minimal, contradiction.
\end{exercise}

Let $M, M'$ be finitely generated modules over a local ring $(R,
\mathfrak{m})$, and let $\phi: M \to M'$ be a homomorphism of modules. Then
Nakayama's lemma gives a criterion for $\phi$ to be a surjection: namely, the
map $\overline{\phi}: M/\mathfrak{m}M \to M'/\mathfrak{m}M'$ must be a surjection.
For injections, this is false. For instance, if $\phi$ is  multiplication by any element of
$\mathfrak{m}$, then $\overline{\phi}$ is zero but $\phi$ may yet be injective.
Nonetheless, we give a criterion for a map of \emph{free} modules over a local ring to
be a \emph{split}  injection.

\begin{proposition} \label{splitcriterion1}
Let $R$ be a local ring with maximal ideal $\mathfrak{m}$. Let $F, F'$ be two
finitely generated free $R$-modules, and let $\phi: F \to F'$ be a homomorphism.
Then $\phi$ is a split injection if and only if the reduction $\overline{\phi}$
\[ F/\mathfrak{m}F \stackrel{\overline{\phi}}{\to} F'/\mathfrak{m}F'  \]
is an injection.
\end{proposition}
\begin{proof}
One direction is easy. If $\phi$ is a split injection, then it has a left
inverse
$\psi: F' \to F$ such that $\psi \circ \phi = 1_F$. The reduction of $\psi$ as a
map $F'/\mathfrak{m}F' \to F/\mathfrak{m}F$ is a left inverse to
$\overline{\phi}$, which is thus injective.

Conversely, suppose $\overline{\phi}$ injective. Let $e_1, \dots, e_r$ be a
``basis'' for $F$, and let $f_1, \dots, f_r$ be the images under $\phi$ in
$F'$. Then the reductions $\overline{f_1}, \dots, \overline{f_r}$ are linearly
independent in the $R/\mathfrak{m}$-vector space $F'/\mathfrak{m}F'$. Let us
complete this to a basis of $F'/\mathfrak{m}F'$ by adding elements
$\overline{g_1}, \dots, \overline{g_s} \in F'/\mathfrak{m}F'$, which we can
lift to elements $g_1, \dots, g_s \in F'$. It is clear that $F'$ has rank $r+s $
since its reduction $F'/\mathfrak{m}F'$ does.

We claim that the set $\left\{f_1, \dots, f_r, g_1, \dots, g_s\right\}$ is a
basis for $F'$. Indeed, we have a map
\[ R^{r+s} \to F'  \]
of free modules of rank $r+s$. It can be expressed as an $r+s$-by-$r+s$ matrix
$M$; we need to show that $M$ is invertible. But if we reduce modulo
$\mathfrak{m}$, it is invertible since the reductions of $f_1, \dots, f_r,
g_1, \dots, g_s$ form a basis of $F'/\mathfrak{m}F'$.
Thus the determinant of $M$ is not in $\mathfrak{m}$, so by locality it is
invertible.
The claim about $F'$ is thus proved.

We can now define the left inverse $F' \to F$ of $\phi$. Indeed, given $x \in F'$,
we can write it uniquely as a linear combination $\sum a_i f_i + \sum b_j g_j$
by the above. We define $\psi(\sum a_i f_i + \sum b_j g_j) = \sum a_i e_i \in
F$. It is clear that this is a left inverse
\end{proof}

We next note  a slight strenghtening of the above result, which is sometimes
useful. Namely, the first module does not have to be free.
\begin{proposition}
Let $R$ be a local ring with maximal ideal $\mathfrak{m}$. Let $M, F$ be two
finitely generated $R$-modules with $F$ free, and let $\phi: M \to F'$ be a homomorphism.
Then $\phi$ is a split injection if and only if the reduction $\overline{\phi}$
\[ M/\mathfrak{m}M \stackrel{\overline{\phi}}{\to} F/\mathfrak{m}F  \]
is an injection.
\end{proposition}
It will in fact follow that $M$ is itself free, because $M$ is projective (see
\cref{} below) as it is a direct summand of a free module.
\begin{proof}
Let $L$ be a ``free approximation'' to $M$.
That is, choose a basis $\overline{x_1}, \dots, \overline{x_n}$ for $M/\mathfrak{m}M$ (as an $R/\mathfrak{m}$-vector
space) and lift this to elements $x_1, \dots, x_n \in M$. Define a map
\[ L = R^n \to M  \]
by sending the $i$th basis vector to $x_i$.
Then $L/\mathfrak{m} L \to M/\mathfrak{m}M$ is an isomorphism.
By Nakayama's lemma,
$L \to M$ is surjective.

Then the composite map
$L \to M \to F$ is such that the $L/\mathfrak{m}L \to F/\mathfrak{m}F$ is injective, so
$L \to F$ is a split injection (by \cref{splitcriterion1}).
It follows that we can find a splitting $F \to L$, which when composed with $L
\to M$ is a splitting of $M \to F$.
\end{proof}

\begin{exercise}
Let $A$ be a local ring, and $B$ a ring which is finitely generated and free as an
$A$-module. Suppose $A \to B$ is an injection. Then $A \to B$ is a \emph{split
injection.} (Note that any nonzero morphism mapping out of a field is
injective.)
\end{exercise}

\section{The functor $\hom$}

In any category, the morphisms between two objects form a
set.\footnote{Strictly speaking, this may depend on your set-theoretic
foundations.} In many
categories, however, the hom-sets have additional structure. For instance,
the hom-sets
between abelian groups are themselves abelian groups. The same situation holds
for the category of modules over a commutative ring.


\begin{definition}
Let $R$ be a commutative ring and $M,N$ to be $R$-modules.  We write
$\hom_R(M,N)$ for
the set of all $R$-module homomorphisms $M \to N$.
 $\hom_R(M,N)$ is an $R$-module because one can add homomorphisms $f,g: M
\to N$ by adding
them pointwise: if $f,g$ are homomorphisms $M \to N$, define $f+g: M \to N$ via
\( (f+g)(m) = f(m)+g(m);  \)
similarly, one can multiply homomorphisms $f: M \to N$ by elements  $ a \in
R$: one sets
\( (af)(m) = a(f(m)).  \)
\end{definition}

Recall that in any category, the hom-sets are \emph{functorial}. For instance,
given $f: N \to N'$, post-composition with $f$ defines a map $\hom_R(M,N) \to
\hom_R(M,N')$ for any $M$.
Similarly precomposition gives  a natural map $\hom_R(N', M) \to \hom_R(N, M)$.
In particular, we get a bifunctor $\hom$, contravariant in the first variable
and covariant in the second, of $R$-modules into $R$-modules.

\subsection{Left-exactness of $\hom$}

We now discuss the exactness properties of this construction of forming
$\hom$-sets. The following result is basic and is, in fact, a reflection of
the universal property of the kernel.
\begin{proposition} \label{homcovleftexact}
If $M$ is an $R$-module, then the functor
\[ N \to \hom_R(M,N)  \]
is left exact (but \emph{not exact} in general).
\end{proposition}
This means that if
\[ 0 \to N' \to N \to N''  \]
is exact,
then
\[ 0 \to \hom_R(M, N') \to \hom_R(M, N) \to \hom_R(M, N'')  \]
is exact as well.

\begin{proof}
 First, we have to show that the map
$\hom_R(M,N') \to \hom_R(M,N)$ is injective; this is because $N' \to N$ is
injective, and composition with $N' \to N$ can't kill any nonzero $M \to N'$.
Similarly, exactness in the middle can be checked easily, and follows from
\rref{univpropertykernel}; it states simply that a map $M \to N$ has
image landing inside $N'$ (i.e. factors through $N'$) if and only if it
composes to zero in $N''$.
\end{proof}

\newcommand{\ol}[1]{\mathbf{#1}}
This functor $\hom_R(M, \cdot)$  is not exact in general.  Indeed:
\begin{example}
Suppose $R = \mathbb{Z}$, and consider the $R$-module (i.e. abelian group)
$M = \mathbb{Z}/2\mathbb{Z}$. There is a short exact
sequence
\[ 0 \to 2\mathbb{Z} \to \mathbb{Z} \to \mathbb{Z}/2\mathbb{Z} \to 0.  \]
Let us apply $\hom_R(M, \cdot)$. We get a \emph{complex}
\[ 0 \to \hom(\mathbb{Z}/2\mathbb{Z}, 2\mathbb{Z}) \to
\hom(\mathbb{Z}/2\mathbb{Z}, \mathbb{Z}) \to \hom(\mathbb{Z}/2\mathbb{Z},
\mathbb{Z}/2\mathbb{Z}) \to 0.  \]
The second-to-last term is $\mathbb{Z}/2\mathbb{Z}$; everything else is
zero. Thus the sequence is not exact, and in particular the functor
$\hom_{\mathbb{Z}}(\mathbb{Z}/2, -)$ is not an exact functor.
\end{example}


We have seen that homming out of a module is left-exact. Now, we see the same
for homming \emph{into} a module.

\begin{proposition} \label{homcontleftexact}
If $M$ is a module, then $\hom_R(-,M)$ is a left-exact contravariant functor.
\end{proposition}

We write this proof in slightly more detail than \cref{homcovleftexact},
because of the
contravariance.
\begin{proof}
We want to show that $\hom(\cdot, M)$ is a left-exact contravariant functor,
which means that
if $ A \xrightarrow u B \xrightarrow v C \to 0$ is exact, then so is
$$
0 \to \hom(C, M) \xrightarrow{\ol v} \hom(B, M) \xrightarrow{\ol u} \hom(A, M)
$$
is exact. Here, the bold notation refers to the induced maps of $u,v$ on the
hom-sets: if $f \in \hom(B,M)$ and $g \in \hom(C, M)$, we define
$\ol u$ and $\ol v$ via $\ol v(g) = g \circ v$ and
$\ol u(f) = f \circ u$.

Let us show first that $\ol v$ is injective.
Suppose that $g \in \hom(C, M)$. If $\ol v(g) = g \circ v = 0$ then
$(g \circ v)(b) = 0$ for all $b \in B$. Since $v$ is a surjection, this means
that $g(C) = 0$ and hence $g = 0$. Therefore, $\ol v$ is injective, and we
have exactness at $\hom(C, M)$.

Since $v \circ u = 0$, it is clear that $\ol u \circ \ol u = 0$.

Now, suppose that $f \in \ker(\ol u) \subset \hom(B, M)$. Then
$\ol u(f) = f \circ u = 0$.
Thus $f: B \to M$ factors through $B/\im(u)$.
However, $\im(u) = \ker(v)$, so $f$ factors through $B/\ker(v)$.
Exactness shows that there is an isomorphism $B/\ker(v) \simeq C$.
In particular, we find that $f$ factors through $C$. This is what we wanted.
\end{proof}


\begin{exercise}
Come up with an example where $\hom_R(-, M)$ is not exact.
\end{exercise}

\begin{exercise}
Over a \emph{field}, $\hom$ is always exact.
\end{exercise}

\subsection{Projective modules}

Let $M$ be an $R$-module for a fixed commutative ring $R$. We have seen that
$\hom_R(M,-)$ is generally only a left-exact functor.
Sometimes, however, we do have exactness. We axiomatize this with the
following.

\begin{definition} \label{projectives}
An $R$-module $M$ is called \textbf{projective} if the functor $\hom_R(M,
\cdot)$ is
exact.\footnote{It is possible to define a projective module over a
noncommutative ring. The definition is the same, except that the $\hom$-sets
are no longer modules, but simply abelian groups. }
\end{definition}

One may first observe that a free module is projective.
Indeed, let $F = R^I$ for an indexing set. Then the functor $N \to \hom_R(F,
N)$ is
naturally
isomorphic to $N \to N^I$. It is easy to see that this functor preserves
exact sequences (that is, if $0 \to A \to B \to C \to 0$ is exact, so is $0
\to A^I \to B^I \to C^I \to 0$).
Thus $F$ is projective.
One can also easily check that a \emph{direct summand} of a projective module
is projective.

It turns out that projective modules have a very clean characterization. They
are  \emph{precisely} the direct
summands in free modules.

\add{check this}
\begin{proposition} \label{projmod}
The following are equivalent for an $R$-module $M$:
\begin{enumerate}
\item $M$ is projective.
\item Given any map $M \to N/N'$ from $M$ into a quotient of $R$-module
$N/N'$, we can lift
it to a map $M \to N$.
\item There is a module $M'$ such that $M \oplus M'$ is free.
\end{enumerate}
\end{proposition}
\begin{proof}
The equivalence of 1 and 2 is just unwinding the definition of projectivity,
because we just need to show that $\hom_R(M, \cdot)$ preserves surjective
maps, i.e. quotients.  ($\hom_R(M, \cdot)$ is already left-exact, after all.)
To say that $\hom_R(M, N) \to \hom_R(M, N/N')$ is surjective is just the
statement that any map $M \to N/N'$
can be lifted to $M \to N$.

Let us show that 2 implies 3.  Suppose $M$ satisfies 2.  Then choose a
surjection $P \twoheadrightarrow M$ where $P$ is free, by
\cref{freesurjection}. Then we can
write $M \simeq P/P'$ for a submodule $P' \subset P$. The isomorphism map
$M \to P/P'$
leads by 2 to a lifting $M \to P$.  In particular, there is a section of $P
\to M$,
namely this lifting.  Since a section leads to a split exact sequence by
\cref{}, we find then that $P \simeq \ker(P \to M) \oplus \im(M \to P) \simeq
\ker(P \to M) \oplus M$,
verifying 3 since $P$ is free.

Now let us show that 3 implies 2.
Suppose $M \oplus M'$ is free, isomorphic to $P$. Then a map $M \to N/N'$ can
be extended to
\[ P \to N/N'  \]
by declaring it to be trivial on $M'$.  But now $P \to N/N'$ can be lifted to
$N$ because $P$ is free, and we have observed that a free module is
projective above; alternatively, we just lift the image of a basis. This
defines $P
\to N$.  We may then compose this with the inclusion $M \to P$ to  get the
desired map $M \to P \to N$,
which is a lifting of $M \to N/N'$.
\end{proof}

Of course, the lifting $P \to N$ of a given map $P \to N/N'$ is generally not
unique, and in fact is unique precisely when $\hom_R(P,N') = 0$.

So projective modules are precisely those with the following lifting property.
Consider a diagram
\[ \xymatrix{
& P \ar[d] \\
M \ar[r] & M'' \ar[r] &  0
}\]
where the bottom row is exact. Then, if $P$ is projective, there is a lifting
$P \to M$ making commutative the diagram
\[ \xymatrix{
& P \ar[d]\ar@{-->}[ld] \\
M \ar[r] & M'' \ar[r] &  0
}\]

\begin{corollary}
Let $M$ be a module. Then there is a surjection $P \twoheadrightarrow M$,
where $P$ is projective.
\end{corollary}
\begin{proof}
Indeed, we know (\rref{freesurjection}) that we can always get a surjection
from a free
module. Since free modules are projective by \rref{projmod}, we are
done.
\end{proof}

\begin{exercise}
Let $R$ be a principal ideal domain, $F'$ a submodule of a free module
$F$. Show that
$F'$ is free. (Hint: well-order the set of generators of $F$, and climb up by
transfinite induction.)
In particular, any projective modules is free.
\end{exercise}

\subsection{Example: the Serre-Swan theorem}

We now briefly digress to describe an important correspondence between
projective modules and vector bundles. The material in this section will not
be used in the sequel.

Let $X$ be a compact space. We shall not recall the topological notion of a
\emph{vector bundle} here.

We note, however, that if $E$ is a (complex) vector bundle,
then the set $\Gamma(X, E)$ of global sections is naturally a module over the
ring $C(X)$ of complex-valued continuous functions on $X$.

\begin{proposition}
If $E$ is a vector bundle on a compact Hausdorff space $X$, then there is a
surjection $\mathcal{O}^N \twoheadrightarrow E$ for some $N$.
\end{proposition}
Here $\mathcal{O}^N$ denotes the trivial bundle.

It is known that in the category of vector bundles, every epimorphism splits.
In particular, it follows that $E$ can be viewed as a \emph{direct summand} of
the bundle $\mathcal{O}^N$. Since $\Gamma(X, E)$ is then a direct summand of
$\Gamma(X, \mathcal{O}^N) = C(X)^N$, we find that $\Gamma(X, E)$ is a direct
summand of a projective $C(X)$-module. Thus:

\begin{proposition}
$\Gamma(X, E)$ is a finitely generated projective $C(X)$-module.
\end{proposition}

\begin{theorem}[Serre-Swan]
The functor $E \mapsto \Gamma(X, E)$ induces an equivalence of categories
between vector bundles on $X$ and finitely generated projective modules over
$C(X)$.
\end{theorem}



\subsection{Injective modules}
\label{ssecinj}

We have given a complete answer to the question of when the functor
$\hom_R(M,-)$ is exact. We have shown that there are a lot of such
\emph{projective} modules in the category of $R$-modules, enough that any
module admits a surjection from one such.
However, we now have to answer the dual question: when is the functor
$\hom_R(-, Q)$ exact?

Let us make the dual definition:

\begin{definition}
An $R$-module $Q$ is \textbf{injective} if the functor $\hom_R(-,Q)$ is exact.
\end{definition}


Thus, a module $Q$ over a ring $R$ is injective if
whenever $M \to N$ is an injection, and one has a map $M \to Q$, it can be
extended to $N \to Q$: in other words, $\hom_R(N,Q ) \to \hom_R(M,Q)$ is
surjective.
We can visualize this by a diagram
\[ \xymatrix{
0 \ar[r] &  M \ar[r] \ar[d]  &  N \ar@{-->}[ld] \\
& Q
}\]
where the dotted arrow always exists if $Q$ is injective.

The notion is dual to projectivity, in some sense, so just as every module $M$
admits an epimorphic map $P \to M$ for $P$ projective, we expect by duality
that every module admits a monomorphic map $M \to Q$ for $Q$ injective.
This is in fact true, but will require some work.
We start, first, with a fact about injective abelian groups.

\begin{theorem}\label{divisibleimpliesinj}
A divisible abelian group (i.e. one where the map $x
\to nx$ for any $n \in \mathbb{N}$ is surjective) is injective as  a
$\mathbb{Z}$-module (i.e. abelian group).
\end{theorem}

\begin{proof}
The actual idea of the proof is rather simple, and similar to the proof
of the Hahn-Banach theorem.
Namely, we extend bit by bit, and then use Zorn's lemma.

The first step is that we have a subgroup $M $ of a larger abelian
group $N$.
We have a map of $f:M \to Q$ for $Q$ some divisible abelian group, and we
want to extend it to $N$.

Now we can consider the poset of pairs $(\tilde{f}, M')$ where $M' \supset
  M$, and $\tilde{f}: M' \to N$ is a map extending $f$.
  Naturally, we make this into a poset by defining the order as ``$(\tilde{f},
  M') \leq (\tilde{f}', M'')$ if $M'' $ contains $M'$ and $\tilde{f}'$
 is an extension of $\tilde{f}$.
  It is clear that every chain has an upper bound, so Zorn's lemma implies
  that we have a submodule $M' \subset N$ containing $M$, and a map $\tilde{f}: M'
  \to N$ extending $f$, such that there is no proper extension of $\tilde{f}$.
  From this we will derive a contradiction unless $M' = N$.

So suppose we have $M' \neq N$, for $M'$ the maximal submodule to which $f$
can be extended, as in the above paragraph.  Pick $m \in N - M'$, and consider the
submodule $M' + \mathbb{Z} m \subset N$.  We are going to show how to extend $\tilde{f}$
to this bigger submodule.  First, suppose $\mathbb{Z}m \cap M' = \{0\}$,
i.e. the sum is direct.  Then we can extend $\tilde{f}$ because $M' +
\mathbb{Z}m$ is a
direct sum: just define it to be zero on $\mathbb{Z}m$.

The slightly harder part is what happens if $\mathbb{Z} m \cap M' \neq \{ 0\}$.
In this case, there is an ideal $I \subset \mathbb{Z}$ such that $n \in I$
if and only if $nm \in M'$.
This ideal, however, is principal; let $g \in \mathbb{Z} - \left\{0\right\}$ be a generator.  Then $gm = p
\in M'$.  In particular, $\tilde{f}(gm)$ is defined.
We can ``divide'' this
by $g$, i.e. find $u \in Q$ such that $gu = \tilde{f}(gm)$.

Now we may extend to a
map $\tilde{f}'$ from $\mathbb{Z} m + M'$ into $Q$ as follows.  Choose $m'
\in M', k \in \mathbb{Z}$.  Define $\tilde{f}'( m' + km) = \tilde{f}(m')
+ k u$.  It is easy to see that this is well-defined by the choice of $u$,
and gives a proper extension of $\tilde{f}$. This contradicts maximality of
$M'$ and completes the proof.
\end{proof}

\begin{exercise}
\cref{divisibleimpliesinj} works over any principal ideal domain.
\end{exercise}
\begin{exercise}[Baer] \label{baercriterion}
Let $N$ be an $R$-module such that for any ideal $I \subset R$, any morphism
$I \to N$ can be extended to $R \to N$. Then $N$ is injective. (Imitate the
above argument.)
\end{exercise}

From this, we may prove:
\begin{theorem}
Any $R$-module $M$ can be imbedded in an injective $R$-module $Q$.
\end{theorem}
\begin{proof}
First of all, we know that any $R$-module $M$ is a quotient of a free
$R$-module.  We are going to show that the {dual} (to be defined shortly) of a free module is injective.  And so since
every module admits a surjection from a free module, we will use a  dualization
argument to prove the present theorem.

First, for any abelian group $G$, define the \textbf{dual group} as $G^\vee
= \hom_{\mathbb{Z}}(G, \mathbb{Q}/\mathbb{Z})$.
Dualization is clearly a contravariant functor from abelian groups to abelian
groups.
By \cref{homcontleftexact}
and \cref{divisibleimpliesinj}, an exact
sequence of groups
\[ 0 \to A \to B \to C \to 0 \]
induces an exact sequence
\[ 0 \to C^\vee \to B^\vee \to A^\vee \to 0 .\]
In particular, dualization is an exact functor:

\begin{proposition} Dualization preserves exact sequences (but reverses
the order).
\end{proposition}

Now, we are going to apply this to $R$-modules.  The dual of  a left $R$-module
is acted upon by $R$.
The action, which is natural enough, is as follows.  Let $M$ be an
$R$-module, and  $f: M \to
\mathbb{Q}/\mathbb{Z}$ be a homomorphism of abelian groups (since
$\mathbb{Q}/\mathbb{Z}$ has in general no $R$-module structure), and $r \in
R$; then we define $rf$ to be the map $M \to \mathbb{Q}/\mathbb{Z}$ defined via
\[ (rf)(m) = f(rm).\]
It is easy to check that $M^{\vee}$ is thus made into an
$R$-module.\footnote{If $R$ is noncommutative, this would not work: instead
$M^{\vee}$ would be an \emph{right} $R$-module. For commutative rings, we have
no such distinction between left and right modules.}
In particular, dualization into $\mathbb{Q}/\mathbb{Z}$ gives a contravariant
exact functor from $R$-\emph{modules} to $R$-\emph{modules}.


  Let $M$ be as before,
and now consider the  $R$-module $M^{\vee}$.  By \cref{freesurjection}, we can
find a free
 module $F$ and a surjection
\[ F \to M^{\vee} \to 0.\]
Now dualizing gives an exact sequence of $R$-modules
\[ 0 \to M^{\vee \vee} \to F^{\vee}. \]
However, there is a natural map (of $R$-modules) $M \to M^{\vee \vee}$: given $m \in M$, we can
define a functional $\hom(M, \mathbb{Q}/\mathbb{Z}) \to \mathbb{Q}/\mathbb{Z}$
by evaluation at $m$. One can check that this is a homomorphism. Moreover, this morphism $M \to M^{\vee \vee}$ is actually injective: if $m \in M$ were
in the kernel, then by definition every functional $M \to
\mathbb{Q}/\mathbb{Z}$ must vanish on $m$. It is easy to see (using
$\mathbb{Z}$-injectivity of $\mathbb{Q}/\mathbb{Z}$) that this cannot happen
if $m \neq 0$: we could just pick a nontrivial functional on the monogenic
\emph{subgroup} $\mathbb{Z} m$ and extend to $M$.



We claim now that $F^{\vee}$ is injective.  This will prove the theorem, as
we have the composite of monomorphisms $M \hookrightarrow M^{\vee \vee} \hookrightarrow F^{\vee}$ that
embeds $M$ inside an injective module.

\begin{lemma} The dual of a  free $R$-module $F$ is an injective
$R$-module.
\end{lemma}
\begin{proof}
Let $0 \to A \to B $ be exact; we have to show that
\[ \hom_R( B, F^\vee) \to \hom_R(A, F^\vee)  \to 0 .\]
is exact.
Now we can reduce to the case where $F$ is the $R$-module $R$ itself.
Indeed, $F$ is a direct sum of $R$'s by assumption, and taking hom's turns
them into direct products; moreover the direct product of
exact sequences is exact.

So we are reduced to showing that $R^{\vee}$ is injective.
Now we claim that
\begin{equation} \label{weirddualityexpr} \hom_R(B, R^{\vee}) =
\hom_{\mathbb{Z}}(B, \mathbb{Q}/\mathbb{Z}). \end{equation}
In particular, $\hom_R( -, R^\vee)$ is an exact functor because
$\mathbb{Q}/\mathbb{Z}$ is an injective abelian group.
The proof of \cref{weirddualityexpr} is actually ``trivial.''   For instance,
a $R$-homomorphism $f: B \to R^\vee$ induces $\tilde{f}: B \to
\mathbb{Q}/\mathbb{Z}$ by sending $b \to (f(b))(1)$.  One checks that this
is bijective.

\end{proof}

\end{proof}

\subsection{The small object argument}

There is another, more set-theoretic approach to showing that any $R$-module
$M$ can be imbedded in an injective module.
This approach, which constructs the injective module by  a transfinite
colimit of push-outs, is essentially analogous to the ``small object
argument'' that one uses in homotopy theory to show that certain categories
(e.g. the category of CW complexes) are model categories in the sense of
Quillen; see \cite{Ho07}.
While this method is somewhat abstract and more complicated than the one of
\cref{ssecinj}, it is also more general. Apparently this method originates with Baer,
and was revisited by Cartan and Eilenberg in
\cite{Cartan-Eilenberg} and by Grothendieck in \cite{Gr57}.
There Grothendieck uses it to show that
many other abelian categories have enough injectives.

We first begin with a few remarks on smallness.
Let $\{B_{\alpha}\}, \alpha \in \mathcal{A}$ be an inductive system of objects in some
category $\mathcal{C}$, indexed by
an ordinal $\mathcal{A}$. Let us assume that $\mathcal{C}$ has (small)
colimits. If $A$ is an object of $\mathcal{C}$, then there is a
natural map
\begin{equation} \label{naturalmapcolim} \varinjlim \hom(A, B_\alpha) \to
\hom(A, \varinjlim B_\alpha)  \end{equation}
because if one is given a map $A \to B_\beta$ for some $\beta$, one
naturally gets a map from $A$  into the colimit by composing with $B_\beta
\to \varinjlim B_\alpha$. (Note that the left colimit is one of sets!)


In general, the map \cref{naturalmapcolim} is neither injective or surjective.

\begin{example}
Consider the category of sets. Let $A = \mathbb{N}$ and $B_n = \left\{1,
\dots, n\right\}$ be the inductive system indexed by the natural numbers
(where $B_n \to B_{m}, n \leq m$ is the obvious map). Then $\varinjlim B_n =
\mathbb{N}$, so there is a map
\[ A \to \varinjlim B_n,  \]
which does not factor as
\[ A \to B_m  \]
for any $m$. Consequently, $\varinjlim \hom(A, B_n) \to \hom(A, \varinjlim
B_n)$ is not surjective.
\end{example}

\begin{example}
Next we give an example where the map fails to be injective. Let $B_n =
\mathbb{N}/\left\{1,  2, \dots, n\right\}$, that is, the quotient set of
$\mathbb{N}$ with the first $n$ elements collapsed to one element.
There are natural maps $B_n \to B_m$ for $n \leq m$, so the
$\left\{B_n\right\}$ form an inductive system. It is easy to see that the
colimit $\varinjlim B_n = \left\{\ast \right\}$: it is the one-point set.
So it follows that $\hom(A, \varinjlim B_n)$ is a one-element set.

However, $\varinjlim \hom(A , B_n)$ is \emph{not} a one-element set.
Consider the family of maps $A \to B_n$ which are just the natural projections
$\mathbb{N} \to \mathbb{N}/\left\{1, 2, \dots, n\right\}$ and the family of
maps $A \to B_n$ which map the whole of $A$ to the class of $1$.
These two families of maps are distinct at each step and thus are distinct in
$\varinjlim \hom(A, B_n)$, but they induce the same map $A \to \varinjlim B_n$.
\end{example}


Nonetheless, if $A$ is a \emph{finite set}, it is easy to see that for any
sequence of sets $B_1 \to B_2 \to \dots$, we have
\[ \varinjlim \hom(A, B_n) = \hom(A, \varinjlim B_n).  \]
\begin{proof}
Let $f: A \to \varinjlim B_n$. The range of $A$ is finite, containing say
elements $c_1, \dots, c_r \in \varinjlim B_n$. These all come from some
elements in $B_N$ for $N$ large by definition of the colimit. Thus we can
define $\widetilde{f}: A \to B_N$ lifting $f$ at a finite stage.

Next, suppose two  maps $f_n: A \to B_m,
g_n : A \to B_m$  define the same map $A \to \varinjlim B_n$.
Then each of the finitely many elements of $A$ gets sent to the same point in
the colimit. By definition of the colimit for sets, there is $N \geq m$ such
that the finitely many elements of $A$ get sent to the same points in $B_N$
under $f$ and $g$. This shows that $\varinjlim \hom(A, B_n) \to \hom(A,
\varinjlim B_n)$ is injective.
\end{proof}


The essential idea is that $A$ is ``small'' relative to the long chain of
compositions $B_1 \to B_2 \to \dots$, so that it has to factor through a
finite step.

Let us generalize this.

\begin{definition}  \label{smallness}
Let $\mathcal{C}$ be a category, $I $ a class of maps, and $\omega$ an ordinal.
An object $A \in \mathcal{C}$ is said to be $\omega$-\textbf{small} (with
respect to $I$) if
whenever $\{B_\alpha\}$ is an inductive system parametrized by $\omega$ with
maps in $I$, then
the map
\[ \varinjlim \hom(A, B_\alpha) \to \hom(A, \varinjlim B_\alpha)  \]
is an isomorphism.
\end{definition}

Our definition varies slightly from that of \cite{Ho07}, where only ``nice''
transfinite sequences $\left\{B_\alpha\right\}$ are considered.

In our applications, we shall begin by restricting ourselves to the category
of $R$-modules for a fixed commutative ring $R$.
We shall also take $I$ to be the set of \emph{monomorphisms,} or
injections.\footnote{There are, incidentally, categories, such as the category
of rings, where a categorical epimorphism may not be a surjection of sets.}
Then each of the maps
\[ B_\beta \to \varinjlim B_\alpha  \]
is an injection, so it follows that
$\hom(A, B_\beta )\to \hom (A, \varinjlim  B_\alpha)$ is one, and in
particular the canonical map
\begin{equation} \label{homcolimmap} \varinjlim \hom(A, B_\alpha) \to \hom (A,
\varinjlim  B_\alpha)  \end{equation}
is an \emph{injection.}
We can in fact interpret the $B_\alpha$'s as subobjects of the big module
$\varinjlim B_\alpha$, and think of their union as $\varinjlim B_\alpha$.
(This is not an abuse of notation if we identify $B_\alpha$ with the image in
the colimit.)

We now want to show that modules are always small for ``large'' ordinals
$\omega$.
For this, we have to digress to do some set theory:

\begin{definition}
Let $\omega$ be a \emph{limit} ordinal, and $\kappa$ a cardinal. Then $\omega$ is
\textbf{$\kappa$-filtered} if every collection $C$ of ordinals strictly less
than $\omega$ and of cardinality at most $\kappa$ has an upper bound strictly
less than $\omega$.
\end{definition}

\begin{example} \label{limitordfinfiltered}
A limit ordinal (e.g. the natural numbers $\omega_0$) is $\kappa$-filtered for any finite cardinal $\kappa$.
\end{example}


\begin{proposition}
Let $\kappa$ be a cardinal. Then there exists a $\kappa$-filtered ordinal
$\omega$.
\end{proposition}
\begin{proof}
If $\kappa$ is finite, \cref{limitordfinfiltered} shows that any limit ordinal
will do.  Let us thus assume that $\kappa$ is infinite.

Consider the smallest ordinal $\omega$ whose cardinality is strictly greater
than that of $\kappa$. Then we claim that $\omega$ is $\kappa$-filtered.
Indeed, if $C$ is a collection of at most $\kappa$ ordinals strictly smaller
than $\omega$, then each of these ordinals is of size at most $\kappa$. Thus
the union of all the ordinals in $C$ (which is an ordinal) is of size at most
$\kappa$, so is strictly smaller than $\omega$, and it provides an upper bound as in the definition.
\end{proof}


\begin{proposition} \label{modulesaresmall}
Let $M$ be a module, $\kappa$ the cardinality of the set of its submodules.
Then if $\omega$ is $\kappa$-filtered, then $M$ is $\omega$-small (with
respect to injections).
\end{proposition}

The proof is straightforward, but let us first think about a special case. If
$M$ is finite, then the claim is that for any inductive system
$\left\{B_\alpha\right\}$ with injections between them, parametrized by a
limit ordinal, any map $M \to
\varinjlim B_\alpha$ factors through one of the $B_\alpha$. But this is clear.
$M$ is finite, so since each element in the image must land inside one of the
$B_\alpha$, so all of $M$ lands inside some finite stage.
\begin{proof}
We need only show that the map \cref{homcolimmap} is a surjection when
$\omega$ is $\kappa$-filtered.
Let $f: A \to \varinjlim B_\alpha$ be a map.
Consider the subobjects $\{f^{-1}(B_\alpha)\}$ of $A$, where $B_\alpha$ is considered as a
subobject of the colimit. If one of these, say $f^{-1}(B_\beta)$, fills $A$,
then the map factors through $B_\beta$.

So suppose to the contrary that all of the $f^{-1}(B_\alpha)$ were proper
subobjects of $A$.
However, we know that
\[ \bigcup f^{-1}(B_\alpha) = f^{-1}\left(\bigcup B_\alpha\right) = A.  \]
Now there are at most $\kappa$ different subobjects of $A$ that occur among
the $f^{-1}(B_\alpha)$, by hypothesis.
Thus we can find a set $A$ of cardinality at most $\kappa$ such that as
$\alpha'$ ranges over $A$, the
$f^{-1}(B_{\alpha'})$ range over \emph{all} the $f^{-1}(B_\alpha)$.

However, $A$ has an upper bound $\widetilde{\omega} < \omega$ as $\omega$ is
$\kappa$-filtered. In particular,
all the $f^{-1}(B_{\alpha'})$ are contained in
$f^{-1}(B_{\widetilde{\omega}})$. It follows that
$f^{-1}(B_{\widetilde{\omega}}) = A$.
In particular, the map $f$ factors through $B_{\widetilde{\omega}}$.
\end{proof}

From this, we will be able to deduce the existence of lots of injectives.
Let us recall the criterion of Baer (\cref{baercriterion}): a module $Q$ is
injective if and only if in every commutative diagram
\[ \xymatrix{
\mathfrak{a} \ar[d]  \ar[r] &  Q \\
R \ar@{-->}[ru]
}\]
for $\mathfrak{a} \subset R$ an ideal, the dotted arrow exists. In other
words, we are trying to solve an \emph{extension problem} with respect to the
inclusion $\mathfrak{a} \hookrightarrow R$ into the module $M$.

If $M$ is an $R$-module, then in general we may have a semi-complete diagram as above. In
it, we can form the \emph{push-out}
\[ \xymatrix{
\mathfrak{a} \ar[d]  \ar[r] &  Q \ar[d] \\
R \ar[r] &  R \oplus_{\mathfrak{a}} Q
}.\]
Here the vertical map is injective, and the diagram commutes.  The point is
that we can extend $\mathfrak{a} \to Q$ to $R$ \emph{if} we extend $Q$ to the
larger module $R \oplus_{\mathfrak{a}} Q$.


The point of the small object argument is to repeat this procedure
transfinitely many times.

\begin{theorem}
Let $M$ be an $R$-module. Then there is an embedding $M \hookrightarrow Q$ for
$Q$ injective.
\end{theorem}
\begin{proof}
We start by defining a functor $\mathbf{M}$ on the category of $R$-modules.
Given $N$, we consider the set of all maps $\mathfrak{a} \to N$ for
$\mathfrak{a} \subset R$ an ideal, and consider the  push-out
\begin{equation} \label{hugediag}
\xymatrix{
\bigoplus \mathfrak{a}\ar[r] \ar[d]  & N \ar[d] \\
\bigoplus R \ar[r] &  N \oplus_{\bigoplus \mathfrak{a}} \bigoplus R
}
\end{equation}
where the direct sum of copies of $R$ is taken such that every copy of an
ideal $\mathfrak{a}$ corresponds to one copy of $R$.
We define $\mathbf{M}(N)$ to be this push-out. Given a map $N \to N'$, there
is a natural morphism of diagrams \cref{hugediag}, so $\mathbf{M}$ is a
functor.
Note furthermore that there is a natural transformation
\[ N \to \mathbf{M}(N),  \]
which is \emph{always an injection.}

The key property of $\mathbf{M}$ is that if $\mathfrak{a} \to N$ is any
morphism, it can be extended to $R \to \mathbf{M}(N)$, by the very
construction of $\mathbf{M}(N)$. The idea will now be to
apply $\mathbf{M}$ a transfinite number of times and to use the small object
property.


We define for each ordinal $\omega$ a functor $\mathbf{M}_{\omega}$ on the
category of $R$-modules, together with a natural injection $N \to
\mathbf{M}_{\omega}(N)$. We do this by transfinite induction.
First, $\mathbf{M}_1 = \mathbf{M}$ is the functor defined above.
Now, suppose given an ordinal $\omega$, and suppose $\mathbf{M}_{\omega'}$ is
defined for $\omega' < \omega$. If $\omega$ has an immediate predecessor
$\widetilde{\omega}$, we let
$$\mathbf{M}_{\omega} = \mathbf{M} \circ \mathbf{M}_{\widetilde{\omega}}.$$
If not, we let $\mathbf{M}_{\omega}(N) = \varinjlim_{\omega' < \omega}
\mathbf{M}_{\omega'}(N)$.
It is clear (e.g. inductively) that the $\mathbf{M}_{\omega}(N)$ form an inductive system over
ordinals $\omega$, so this is reasonable.

Let $\kappa$ be the cardinality of the set of ideals in $R$, and let $\Omega$
be a $\kappa$-filtered ordinal.
The claim is as follows.

\begin{lemma}
For any $N$, $\mathbf{M}_{\Omega}(N)$ is injective.
\end{lemma}

If we prove this, we will be done. In fact, we will have shown that there is a
\emph{functorial} embedding of a module into an injective.
Thus, we have only to prove this lemma.

\begin{proof}
By Baer's criterion (\cref{baercriterion}), it suffices to show that if
$\mathfrak{a} \subset R$ is an ideal, then any map $f: \mathfrak{a} \to
\mathbf{M}_{\Omega}(N)$ extends to $R \to \mathbf{M}_{\Omega}(N)$. However, we
know since $\Omega$ is a limit ordinal that
\[ \mathbf{M}_{\Omega}(N) = \varinjlim_{\omega < \Omega}
\mathbf{M}_{\omega}(N),  \]
so by \cref{modulesaresmall}, we find that
\[ \hom_R(\mathfrak{a}, \mathbf{M}_{\Omega}(N)) = \varinjlim_{\omega < \Omega}
\hom_R(\mathfrak{a}, \mathbf{M}_{\omega}(N)).   \]
This means in particular that there is some $\omega' < \Omega$ such that $f$
factors through the submodule $\mathbf{M}_{\omega'}(N)$, as
\[ f: \mathfrak{a} \to \mathbf{M}_{\omega'}(N) \to \mathbf{M}_{\Omega}(N).  \]
However, by the fundamental property of the functor $\mathbf{M}$, we know that
the map $\mathfrak{a} \to \mathbf{M}_{\omega'}(N)$ can be extended to
\[ R \to \mathbf{M}( \mathbf{M}_{\omega'}(N)) = \mathbf{M}_{\omega' + 1}(N),  \]
and the last object imbeds in $\mathbf{M}_{\Omega}(N)$.
In particular, $f$ can be extended to $\mathbf{M}_{\Omega}(N)$.
\end{proof}


\end{proof}

\subsection{Split exact sequences}

\add{additive functors preserve split exact seq}
Suppose that
$\xymatrix@1{0 \ar[r] & L \ar[r]^\psi & M \ar[r]^f & N \ar[r] & 0}$
is a split short exact sequence.
Since $\Hom_R (D, \cdot)$ is a left-exact functor, we see that
$$\xymatrix@1{0 \ar[r]
	& \Hom_R(D, L) \ar[r]^{\psi'}
	& \Hom_R(D, M) \ar[r]^{\f'}
	& \Hom_R(D, N)}$$
is exact. In addition,
$\Hom_R (D, L \oplus N) \cong \Hom_R(D, L) \oplus \Hom_R (D, N)$. Therefore, in
the case that we start with a split short exact sequence $M \cong L \oplus N$,
applying $\Hom_R (D, \cdot)$ does yield a split short exact sequence
$$\xymatrix@1{0 \ar[r]
	& \Hom_R(D, L) \ar[r]^{\psi'}
	& \Hom_R(D, M) \ar[r]^{\f'}
	& \Hom_R(D, N) \ar[r] & 0}.$$

Now, assume that
$$\xymatrix@1{0 \ar[r]
	& \Hom_R(D, L) \ar[r]^{\psi'}
	& \Hom_R(D, M) \ar[r]^{\f'}
	& \Hom_R(D, N) \ar[r] & 0}$$
is a short exact sequence of abelian groups for all $R$-modules $D$.
Set $D = R$ and using $\Hom_R (R, N) \cong N$ yields that
$\xymatrix@1{0 \ar[r] & L \ar[r]^\psi & M \ar[r]^f & N \ar[r] & 0}$
is a short exact sequence.

Set $D = N$, so we have
$$\xymatrix@1{0 \ar[r]
	& \Hom_R(N, L) \ar[r]^{\psi'}
	& \Hom_R(N, M) \ar[r]^{\f'}
	& \Hom_R(N, N) \ar[r] & 0}$$
Here, $\f'$ is surjective, so the identity map of $\Hom_R (N, N)$ lifts to a
map $g \in \Hom_R (N, M)$ so that $f \circ g = \f'(g) = id$.
This means that $g$ is a splitting homomorphism for the sequence
$\xymatrix@1{0 \ar[r] & L \ar[r]^\psi & M \ar[r]^f & N \ar[r] & 0}$,
and therefore the sequence is a split short exact sequence.


\section{The tensor product}
\label{sec:tensorprod}
We shall now introduce the third functor of this chapter: the tensor product.
The tensor product's key property is that it allows one to ``linearize''
bilinear maps. When taking the tensor product of rings, it provides a
categorical coproduct as well.

\subsection{Bilinear maps and the tensor product}

Let $R$ be a commutative ring, as usual.
We have seen that the $\hom$-sets $\hom_R(M,N)$ of $R$-modules $M,N$ are themselves
$R$-modules.
Consequently, if we have three $R$-modules $M,N,P$, we can think about
module-homomorphisms
\[ M \stackrel{\lambda}{\to}\hom_R(N,P).  \]
Suppose $x \in M, y \in N$.  Then we can consider
\( \lambda(x) \in \hom_R(N,P)  \)
and thus we can consider the element
\( \lambda(x)(y) \in P.  \)
We denote this element $\lambda(x)(y)$, which depends on the variables $x \in
M, y \in N$, by $\lambda(x,y)$ for convenience; it
is a function of two variables $M \times N \to P$.

There are
certain properties of $\lambda(\cdot, \cdot)$ that we list below.
Fix $x , x' \in M$; $y, y' \in N; \ a \in R$. Then:
\begin{enumerate}
\item  $\lambda(x,y+y') = \lambda(x,y) + \lambda(x, y')$ because $\lambda(x)$
is
 additive.
\item  $\lambda(x, ay) = a \lambda(x,y)$ because $\lambda(x)$ is an
$R$-module homomorphism.
\item  $\lambda(x+x', y) = \lambda(x,y) + \lambda(x', y)$ because
$\lambda$ is additive.
\item   $\lambda(ax, y) = a\lambda(x,y)$ because $\lambda$ is an $R$-module
homomorphism.
\end{enumerate}

Conversely, given a function $\lambda: M \times N \to P$ of two variables satisfying the above properties,
it is easy to see that we can get a morphism of $R$-modules $M \to
\hom_R(N,P)$.



\begin{definition}
An \textbf{$R$-bilinear map $\lambda: M \times N \to P$} is a map satisfying
the above listed conditions. In other words, it is required to be $R$-linear
in each variable separately.
\end{definition}

The previous discussion shows that there is a \emph{bijection} between $R$-bilinear
maps $M \times N \to P$ with $R$-module maps $M \to \hom_R(N,P)$.
Note that the first interpretation is symmetric in $M,N$; the second, by
contrast, can be interpreted in terms of the old concepts of an $R$-module map.
So both are useful.

\begin{exercise}
Prove that a $\mathbb{Z}$-bilinear map out of $\mathbb{Z}/2 \times
\mathbb{Z}/3$ is identically zero, whatever the target module.
\end{exercise}


Let us keep the notation of the previous discussion: in particular, $M,N, P$ will
be modules over a commutative ring $R$.

Given a bilinear map $M \times N \to P$ and a homomorphism $P \to P'$, we can
clearly get a bilinear map $M \times N \to P'$ by composition.
In particular, given $M,N$, there is a \emph{covariant functor} from
$R$-modules to
$\mathbf{Sets}$ sending  any $R$-module $P$ to the collection of $R$-bilinear
maps $M \times N
\to P$. As usual, we are interested in when this functor is
\emph{corepresentable.}
As  a result,
we are interested in \emph{universal} bilinear maps out of $M \times N$.


\begin{definition}
An $R$-bilinear map $\lambda: M \times N \to P$ is called \textbf{universal} if
for all $R$-modules $Q$, the composition of $P \to Q$ with $M \times N
\stackrel{\lambda}{\to} P$
gives a \textbf{bijection}
\[ \hom_R(P,Q) \simeq \left\{\mathrm{bilinear \ maps} \ M \times N \to
Q\right\}  \]
So, given a bilinear map $M \times N \to Q$, there is a \textit{unique} map $P
\to Q$ making the diagram
\[
\xymatrix{
& P \ar[dd] \\
M \times N \ar[ru]^{\lambda} \ar[rd] & \\
& Q
}
\]

Alternatively, $P$ \emph{corepresents} the functor $Q \to
\left\{\mathrm{bilinear \ maps \ } M \times N \to Q\right\}$.
\end{definition}

General nonsense says that given $M,N$, an universal $R$-bilinear map $M
\times N \to P$ is
\textbf{unique} up to isomorphism (if it exists). This  follows from \emph{Yoneda's lemma}.
For convenience, we give a direct proof.

Suppose $M \times N \stackrel{\lambda}{\to} P$ was universal and $M \times N
\stackrel{\lambda'}{\to} P'$ is also
universal. Then by the universal property, there are unique maps $P \to P'$
and $P' \to P$ making the
following diagram commutative:
\[
\xymatrix{
& P \ar[dd] \\
M \times N \ar[ru]^{\lambda} \ar[rd]^{\lambda'} & \\
& P' \ar[uu]
}
\]
These compositions $P \to P' \to P, P' \to P \to P'$ have to be the identity
because of the uniqueness part of the universal property.
As a result, $P \to P'$ is an isomorphism.

We shall now show that this universal object does indeed exist.

\begin{proposition} \label{tensorexists}
Given $M,N$, a universal bilinear map out of $M \times N$ exists.
\end{proposition}

Before proving it we make:
\begin{definition}
We denote the codomain of the universal map out of $M \times N $ by $M
\otimes_R N$. This is called the \textbf{tensor product} of $M,N$, so there
is a universal bilinear map out of $M \times N$ into $M \otimes_R N$.
\end{definition}

\begin{proof}[Proof of \rref{tensorexists}] We will simply give
a presentation of the tensor product by
``generators and relations.''
Take the free $R$-module $M \otimes_R N$ generated by the symbols $\left\{x
\otimes
y\right\}_{x \in M, y \in N}$ and quotient out by the relations forced upon us
by the definition of a bilinear map (for $x, x' \in M, \  y, y' \in N, \   a
\in R$)
\begin{enumerate}
\item  $(x+x') \otimes y = x \otimes y + x' \otimes y$.
\item $(ax) \otimes y = a(x \otimes y) = x \otimes (ay)$.
\item  $x \otimes (y+y') = x \otimes y + x \otimes y'$.
\end{enumerate}

We will abuse notation and denote $x \otimes y$ for its image in $M \otimes_R
N$ (as opposed to the symbol generating the free module).

There is a bilinear map $M \times N \to M \otimes_R N$ sending $(x,y) \to x
\otimes y$; the relations imposed imply  that this map is a bilinear map. We
have to check
that it is universal, but this is actually quite direct.

Suppose we had a bilinear map $\lambda: M \times N \to P$.  We must construct
a linear map $M
\otimes_R N \to P$.
To do this, we can just give a map on generators, and show that it is zero on
each of the relations.
It is easy to see that to make the appropriate diagrams commute, the linear
map $M \otimes N \to P$ has to send $x \otimes y \to \lambda(x,y)$.
This factors
through the relations on $x \otimes y$ by bilinearity and leads to an
$R$-linear map $M \otimes_{R} N \to P$ such that the following diagram
commutes:
\[
\xymatrix{
M \times N \ar[r] \ar[rd]^{\lambda} &  M \otimes_R N \ar[d] \\
& P
}.\]
It is easy to see that $M \otimes_R N \to P$ is unique because the $x \otimes
y$ generate it.
\end{proof}


The theory of the tensor product allows one to do away with bilinear maps and
just think of linear maps.

Given $M, N$, we have constructed an object $M \otimes_R N$. We now wish to  see
the functoriality of the tensor product. In fact, $(M,N) \to M \otimes_R N$ is a \emph{covariant
functor} in two variables from $R$-modules to $R$-modules.
In particular, if $M \to M', N \to N'$ are morphisms, there is a canonical map
\begin{equation} \label{tensorisfunctor} M \otimes_R N \to M' \otimes_R N'.
\end{equation}
To obtain \cref{tensorisfunctor}, we take the natural bilinear map $M \times N \to M' \times N'
\to M' \otimes_R N'$ and use the universal property of $M \otimes_R N$ to get
a map out of it.

\subsection{Basic properties of the tensor product}
We make some observations and prove a few basic properties. As the proofs will
show, one powerful way to prove things about an object is to reason about its
universal property. If two objects have the same universal property, they are
isomorphic.

\begin{proposition}
The tensor product is symmetric: for $R$-modules $M,N$, we have $M \otimes_R
N \simeq N \otimes_R M$
canonically.
\end{proposition}
\begin{proof}
This is clear from the universal properties: giving a bilinear map
out of  $M \times N$ is the same as a bilinear map out $N \times M$.
Thus $M \otimes_R N$ and $N \otimes_R N$ have the same universal property.
It is also
clear from the explicit construction.
\end{proof}

\begin{proposition}
For an $R$-module $M$, there is a canonical isomorphism $M \to M \otimes_R R$.
\end{proposition}
\begin{proof}
  If we think in terms of
bilinear maps, this statement is equivalent to the statement that a bilinear
map $\lambda: M \times R \to P$ is the same as a linear map $M \to N$. Indeed,
to do
this, restrict $\lambda$ to $\lambda(\cdot, 1)$.  Given $f: M \to N$,
similarly, we take for $\lambda$ as $\lambda(x,a) = af(x)$. This gives a
bijection as claimed.
\end{proof}

\begin{proposition}
The tensor product is associative.  There are canonical isomorphisms $M
\otimes_R (N \otimes_R P) \simeq (M
\otimes_R N) \otimes_R P$.
\end{proposition}
\begin{proof}
 There are a few ways to see this: one is to build
it explicitly from the construction given, sending $x \otimes (y \otimes z) \to
(x \otimes y) \otimes z$.

More conceptually, both have the same universal
property: by general categorical nonsense (Yoneda's lemma), we need to show
that for all $Q$, there is  a canonical bijection
\[ \hom_R(M \otimes (N \otimes P)), Q) \simeq \hom_R( (M \otimes N)
\otimes P, Q)  \]
where the $R$'s are dropped for simplicity.  But both of these sets can be
identified with the set of trilinear maps\footnote{Easy to define.} $M \times N
\times P \to Q$. Indeed
\begin{align*}
\hom_R(M \otimes (N \otimes P), Q) & \simeq \mathrm{bilinear} \ M \times (N
\otimes P) \to Q \\
& \simeq \hom(N \otimes P, \hom(M,Q)) \\
& \simeq \mathrm{bilinear} \ N \times P \to \hom(M,Q) \\
& \simeq \hom(N, \hom(P, \hom(M,Q)) \\
& \simeq \mathrm{trilinear\  maps}.
\end{align*}

\end{proof}

\subsection{The adjoint property}
Finally, while we defined the tensor product in terms of a ``universal
bilinear map,'' we saw earlier that bilinear maps could be interpreted as maps
into a suitable $\hom$-set.
In particular, fix $R$-modules $M,N,P$. We know that the set of bilinear maps
$M \times N \to P$ is naturally in bijection with
\[ \hom_R(M, \hom_R(N,P))  \]
as well as with
\[ \hom_R(M \otimes_R, N, P).  \]

As a result, we find:
\begin{proposition} For $R$-modules $M,N,P$, there is a natural bijection
\[ \hom_R(M,\hom_R(N,P)) \simeq \hom_R(M \otimes_R N, P).   \]
\end{proposition}

There is a more evocative way of phrasing the above natural bijection. Given
$N$, let us define the functors $F_N, G_N$ via
\[ F_N(M) = M \otimes_R N, \quad G_N(P) = \hom_R(N,P).  \]
Then the above proposition states that there is a natural isomorphism
\[ \hom_R( F_N(M), P) \simeq \hom_R( M, G_N(P)).  \]
In particular, $F_N$ and $G_N$ are \emph{adjoint functors}. So, in a sense,
the operations of $\hom$ and $\otimes$ are dual to each other.

\begin{proposition} \label{tensorcolimit}
Tensoring commutes with colimits.
\end{proposition}

In particular, it follows that if $\left\{N_\alpha\right\}$ is a family of
modules, and $M$ is a module, then
\[ M \otimes_R \bigoplus N_\alpha = \bigoplus M \otimes_R N_\alpha.  \]
\begin{exercise}
Give an explicit proof of the above relation.
\end{exercise}

\begin{proof}
This is a formal consequence of the fact that the tensor product is a left
adjoint and consequently commutes with all colimits.
\add{proof}
\end{proof}

In particular,  by \cref{tensorcolimit}, the tensor product commutes with \emph{cokernels.}
That is, if $A \to B \to C \to 0$ is an exact sequence of $R$-modules and $M$
is an $R$-module, $A \otimes_R M \to B \otimes_R M \to C \otimes_R M \to 0$ is
also exact, because exactness of such a sequence is precisely a condition on
the cokernel.
That is, the tensor product is \emph{right exact.}

We can thus prove a simple result on finite generation:
\begin{proposition} \label{fingentensor}
If $M, N$ are finitely generated, then $M \otimes_R N$ is finitely generated.
\end{proposition}
\begin{proof}
Indeed, if we have surjections $R^m \to M, R^n \to N$, we can tensor them; we
get a surjection since the tensor product is right-exact.
So have a surjection
$R^{m n} = R^m \otimes_R R^n \to M \otimes_R N$.
\end{proof}


\subsection{The tensor product as base-change}

Before this, we have considered the tensor product as a functor within a
fixed category. Now, we shall see that when one takes the tensor product with a
\emph{ring}, one gets additional structure. As a result, we will be able to
get natural functors between  \emph{different} module categories.

Suppose we have a
ring-homomorphism $\phi:R \to R'$.  In this case, any $R'$-module can be
regarded as
an $R$-module.
In particular, there is a canonical functor of \emph{restriction}
\[ R'\mbox{-}\mathrm{modules} \to R\mbox{-}\mathrm{modules}.  \]

We shall see that the tensor product provides an \emph{adjoint} to this
functor.
Namely, if $M$ has an $R$-module
structure, then $M \otimes_R R'$ has an $R'$ module structure where $R'$ acts
on the right. Since the tensor product is functorial, this gives a functor
in the opposite direction:
\[ R\mbox{-}\mathrm{modules} \to R'\mbox{-}\mathrm{modules}.  \]


Let $M'$ be an $R'$-module and $M$ an $R$-module. In view of the above,
we can talk about
\[ \hom_R(M, M')  \]
by thinking of $M'$ as an $R$-module.

\begin{proposition}
There is a canonical isomorphism between
\[ \hom_R(M, M') \simeq \hom_{R'}(M \otimes_R R', M').  \]
In particular, the restriction functor and the functor $M \to M \otimes_R R'$
are adjoints to each other.
\end{proposition}


\begin{proof}
We can describe the bijection explicitly. Given an $R'$-homomorphism $f:M
\otimes_R R' \to M'$, we get a map
\[ f_0:M \to M'  \]
sending
\[ m \to m \otimes 1 \to f(m \otimes 1).  \]
This is easily seen to be an $R$-module-homomorphism. Indeed,
\[ f_0(ax) = f(ax \otimes 1) = f(\phi(a)(x \otimes 1)) = a f(x \otimes 1)  =
a f_0(x)  \]
since $f$ is an $R'$-module homomorphism.

Conversely, if we are given a homomorphism of $R$-modules
\[ f_0: M \to M'  \]
then we can define
\[ f: M \otimes_R R' \to M'  \]
by sending $m \otimes r' \to r' f_0(m)$, which is a homomorphism of $R'$
modules.
This is well-defined because $f_0$ is  a homomorphism of $R$-modules. We leave
some details to the reader.
\end{proof}

\begin{example}
In the representation theory of finite groups, the operation of tensor product
corresponds to the procedure of \emph{inducing} a representation. Namely, if
$H \subset G$ is a subgroup of a group $G$, then there is an obvious
restriction functor from $G$-representations to $H$-representations.
The adjoint to this is the induction operator. Since a $H$-representation
(resp. a $G$-representation) is just a module over the group ring, the
operation of induction is really a special case of the tensor product. Note
that the group rings are generally not commutative, so this should be
interpreted with some care.
\end{example}

\subsection{Some concrete examples}

We now present several concrete computations of tensor products in explicit
cases to illuminate what is happening.

\begin{example} Let us compute $\mathbb{Z}/10 \otimes_{\mathbb{Z}}
\mathbb{Z}/12$.
Since $1$ spans $\mathbb{Z} / (10)$ and $1$ spans $\mathbb{Z} / (12)$,
we see that $1 \otimes 1$ spans $\mathbb{Z} / (10) \otimes \mathbb{Z} /
(12)$ and this tensor
product is a cyclic group.

Note that
$1 \otimes 0 = 1 \otimes (10 \cdot 0) = 10 \otimes 0 = 0 \otimes 0 = 0$
and
$0 \otimes 1 = (12 \cdot 0) \otimes 1 = 0 \otimes 12 = 0 \otimes 0 = 0$.
Now,
$10 (1 \otimes 1) = 10 \otimes 1 = 0 \otimes 1 = 0$
and
$12 (1 \otimes 1) = 1 \otimes 12 = 1 \otimes 0 = 0$,
so the cyclic group $\mathbb{Z} / (10) \otimes \mathbb{Z} / (12)$ has order
dividing both
$10$ and $12$. This means that the cyclic group has order dividing
$\gcd(10, 12) = 2$.

To show that the order of $\mathbb{Z} / (10) \otimes \mathbb{Z} / (12)$,
define a bilinear map
$g: \mathbb{Z} / (10) \times \mathbb{Z} / (12) \to \mathbb{Z} / (2)$ via
$g : (x, y) \mapsto xy$. The universal property of tensor products then
says that there is a unique linear map
$f: \mathbb{Z} / (10) \otimes \mathbb{Z} / (12) \to \mathbb{Z} / (2)$ making
the diagram
\[
\xymatrix{
\mathbb{Z} / (10) \times \mathbb{Z} / (12) \ar[r]^\otimes \ar[rd]_g
	& \mathbb{Z} / (10) \otimes \mathbb{Z} / (12) \ar[d]^f \\
& \mathbb{Z} / (2).
}
\]
commute. In particular, this means that $f (x \otimes y) = g(x, y) = xy$.
Hence, $f(1 \otimes 1) = 1$, so $f$ is surjective, and therefore,
$\mathbb{Z} / (10) \otimes \mathbb{Z} / (12)$ has size at least two. This
allows us to
conclude that $\mathbb{Z} / (10) \otimes \mathbb{Z} / (12) = \mathbb{Z} / (2)$.
\end{example}

We now generalize the above example to tensor products of cyclic groups.
\begin{example}
Let $d=\gcd(m,n)$. We will show that
$(\mathbb{Z}/m\mathbb{Z})\otimes(\mathbb{Z}/n\mathbb{Z})\simeq(\mathbb{Z}/d\mathbb{Z})$,
and thus in particular if $m$ and $n$
are relatively prime, then
$(\mathbb{Z}/m\mathbb{Z})\otimes(\mathbb{Z}/n\mathbb{Z})\simeq(0)$. First,
note that
any $a\otimes b\in(\mathbb{Z}/m\mathbb{Z})\otimes(\mathbb{Z}/n\mathbb{Z})$
can be written as $ab(1\otimes 1)$,
so that $(\mathbb{Z}/m\mathbb{Z})\otimes(\mathbb{Z}/n\mathbb{Z})$ is generated
by $1\otimes 1$ and hence
is a cyclic group. We know from elementary number theory that $d=xm+yn$
for some $x,y\in\mathbb{Z}$. We have $m(1\otimes 1)=m\otimes 1=0\otimes
1=0$ and
$n(1\otimes 1)=1\otimes n=1\otimes0=0$. Thus $d(1\otimes 1)=(xm+yn)(1\otimes
1)=0$, so that $1\otimes1$ has order dividing $d$.

Conversely, consider the map
$f:(\mathbb{Z}/m\mathbb{Z})\times(\mathbb{Z}/n\mathbb{Z})\rightarrow(\mathbb{Z}/d\mathbb{Z})$
defined by
$f(a+m\mathbb{Z},b+n\mathbb{Z})=ab+d\mathbb{Z}$. This is well-defined,
since if $a'+m\mathbb{Z}=a+m\mathbb{Z}$
and $b'+n\mathbb{Z}=b+n\mathbb{Z}$ then $a'=a+mr$ and $b'=b+ns$ for some
$r,s$ and
thus $a'b'+d\mathbb{Z}=ab+(mrb+nsa+mnrs)+d\mathbb{Z}=ab+d\mathbb{Z}$
(since $d=\gcd(m,n)$
divides $m$ and $n$). This is obviously bilinear, and hence induces a map
$\tilde{f}:(\mathbb{Z}/m\mathbb{Z})\otimes(\mathbb{Z}/n\mathbb{Z})\rightarrow(\mathbb{Z}/d\mathbb{Z})$,
which
has $\tilde{f}(1\otimes1)=1+d\mathbb{Z}$. But the order of $1+d\mathbb{Z}$
in $\mathbb{Z}/d\mathbb{Z}$ is $d$, so that the order of $1\otimes1$ in
$(\mathbb{Z}/m\mathbb{Z})\otimes(\mathbb{Z}/n\mathbb{Z})$ must be at least
$d$. Thus $1\otimes1$ is in fact
of order $d$, and the map $\tilde{f}$ is an isomorphism between cyclic groups
of order $d$.
\end{example}

Finally, we present an example involving the interaction of $\hom$ and the
tensor product.

\begin{example}
Given an $R$-module $M$, let us use the notation $M^* = \hom_R(M,R)$.
We shall define a functorial map
\[ M^* \otimes_R N \to \hom_R(M,N),  \]
and show that it is an isomorphism when $M$ is finitely generated and free.

Define $\rho':M^*\times N\rightarrow\hom_R(M,N)$ by
$\rho'(f,n)(m)=f(m)n$ (note that $f(m)\in R$, and the multiplication $f(m)n$
is that between an element of $R$ and an element of $N$). This is bilinear,
\[\rho'(af+bg,n)(m)=(af+bg)(m)n=(af(m)+bg(m))n=af(m)n+bg(m)n=a\rho'(f,n)(m)+b\rho'(g,n)(m)\]

\[\rho'(f,an_1+bn_2)(m)=f(m)(an_1+bn_2)=af(m)n_1+bf(m)n_2=a\rho'(f,n_1)(m)+b\rho'(f,n_2)(m)\]

so it induces a map $\rho:M^*\otimes N \rightarrow \hom(M,N)$ with
$\rho(f\otimes n)(m)=f(m)n$. This homomorphism is unique since the $f\otimes
n$ generate $M^*\otimes N$. \\

\noindent Suppose $M$ is free on the set $\{a_1,\ldots,a_k\}$. Then
$M^*=\hom(M,R)$ is free on the set $\{f_i:M\rightarrow R,$ $
f_i(r_1a_1+\cdots+r_ka_k)=r_i\}$, because there are clearly no
relations among the $f_i$ and because any $f:M\rightarrow R$ has
$f=f(a_1)f_1+\cdots+f(a_n)f_n$. Also note that any element $\sum h_j\otimes
p_j \in M^*\otimes N$ can be written in the form $\sum_{i=1}^k f_i\otimes
n_i$, by setting $n_i=\sum h_j(a_i)p_j$, and \textit{that this is unique}
because the $f_i$ are a basis for $M^*$.\\

\noindent We claim that the map $\psi:\hom_R(M,N)\rightarrow M^*\otimes N$
defined by $\psi(g)=\sum_{i=1}^k f_i\otimes g(a_i)$ is inverse to $\rho$. Given
any $\sum_{i=1}^k f_i\otimes n_i\in M^*\otimes N$, we have
\[\rho(\sum_{i=1}^k f_i\otimes n_i)(a_j)=\sum_{i=1}^k\rho(f_i\otimes
n_i)(a_j)=\sum_{i=1}^kf_i(a_j)n_i=n_j\]
 Thus, $\rho(\sum_{i=1}^k f_i\otimes n_i)(a_i)=n_i$, and thus
 $\psi(\rho(\sum_{i=1}^k f_i\otimes n_i))=\sum_{i=1}^k f_i\otimes n_i$. Thus,
 $\psi\circ\rho=\id_{M^*\otimes N}$.\\

 \noindent Conversely, recall that for $g:M\rightarrow N\in\hom_R(M,N)$,
 we defined $\psi(g)=\sum_{i=1}^k f_i\otimes g(a_i)$. Thus,
\[\rho(\psi(g))(a_j)=\rho(\sum_{i=1}^k f_i\otimes
g(a_i))(a_j)=\sum_{i=1}^k\rho(f_i\otimes g(a_i))(a_j)=\sum_{i=1}^k
f_i(a_j)g(a_i)=g(a_j)\]
and because $\rho(\psi(g))$ agrees with $g$ on the $a_i$, it is the
same element of $\hom_R(M,N)$ because the $a_i$ generate $M$. Thus,
$\rho\circ\psi=\id_{\hom_R(M,N)}$.\\

\noindent Thus, $\rho$ is an isomorphism.


\end{example}


We now interpret localization as a tensor product.
\begin{proposition} \label{locisbasechange}
Let $R$ be a commutative ring, $S \subset R$ a multiplicative subset. Then
there
exists a canonical isomorphism of functors:
\[ \phi:  S^{-1}M \simeq S^{-1 }R \otimes_R M . \]
\end{proposition}
\begin{proof}
Here is a construction of $\phi$. If $x/s \in S^{-1}M$ where $x \in M, s \in
S$, we define
\[ \phi(x/s) = (1/s) \otimes m.  \]
Let us check that this is well-defined. Suppose $x/s = x'/s'$; then this means
there is $t \in S$ with
\[ xs't = x'st . \]

From this we need to check that $\phi(x/s) = \phi(x'/s')$, i.e. that $1/s
\otimes x$ and $1/s' \otimes x'$ represent the same elements in the tensor
product. But we know from the last statement that
\[ \frac{1}{ss't} \otimes xs't = \frac{1}{ss't} x'st \in S^{-1}R \otimes M \]
and the first is just
\[ s't( \frac{1}{ss't} \otimes x) = \frac{1}{s} \otimes x  \]
by linearity, while the second is just
\[ \frac{1}{s'} \otimes x'  \]
similarly. One next checks that $\phi$ is an $R$-module homomorphism, which we
leave to the reader.

Finally, we need to describe the inverse. The inverse $\psi: S^{-1}R \otimes M
\to S^{-1}M$ is easy to construct because it's a map out of the tensor product,
and we just need to give a bilinear map
\[ S^{-1} R \times M \to S^{-1}M , \]
and this sends $(r/s, m)$ to $mr/s$.

It is easy to see that $\phi, \psi$ are inverses to each other by the
definitions.
\end{proof}

It is, perhaps, worth making a small categorical comment, and offering an
alternative argument.
We are given two functors $F,G$ from $R$-modules to $S^{-1}R$-modules, where
$F(M) = S^{-1}R \otimes_R M$ and $G(M) = S^{-1}M$.
By the universal property, the map $M \to S^{-1}M$ from an $R$-module to a
tensor product gives  a natural map
\[ S^{-1}R \otimes_R M \to S^{-1}M,  \]
that is a natural transformation $F \to G$.
Since it is an isomorphism for free modules, it is an isomorphism for all
modules by a standard argument.


\subsection{Tensor products of algebras}
\label{tensprodalg}
There is one other basic property of tensor products to discuss before moving
on: namely, what happens when one tensors a ring with another ring. We shall
see that this gives rise to  \emph{push-outs} in the category of rings, or
alternatively, coproducts in the category of $R$-algebras.
Let $R$ be a commutative ring and suppose $R_1, R_2$ are $R$-algebras. That is,  we have ring homomorphisms
\( \phi_0: R \to R_0, \quad \phi_1: R \to R_1.	\)

\begin{proposition}
$R_0 \otimes_R R_1$ has the structure of a commutative ring in a natural way.
\end{proposition}

 Indeed, this
multiplication multiplies two typical elements $x \otimes y, x' \otimes y'$ of
the tensor product by
sending them to
$xx' \otimes yy'$.
The ring structure is determined by this formula.  One ought to check that this
approach respects the relations of the tensor product. We will do so in an
indirect way.


\begin{proof}
Notice that giving a multiplication law on $R_0 \otimes_R R_1$ is equivalent to giving an $R$-bilinear map
\[ (R_0 \otimes_R R_1) \times (R_0 \otimes R_1) \to R_0 \otimes_R R_1,\]
i.e. an $R$-linear map
\[ (R_0 \otimes_R R_1) \otimes_R (R_0 \otimes R_1) \to R_0 \otimes_R R_1\]
which satisfies certain constraints (associativity, commutativity, etc.).
But the left side is isomorphic to $(R_0 \otimes_R R_0) \otimes_R (R_1
\otimes_R R_1)$. Since we have bilinear maps $R_0 \times R_0 \to R_0$ and $R_1
\times R_1 \to R_1$, we get linear maps
$R_0 \otimes_R R_0 \to R_0$ and $R_1 \otimes_R R_1 \to R_1$.
Tensoring these maps gives the multiplication as a bilinear map. It is easy to
see that these two approaches are the same.

We now need to check that this operation is commutative and associative, with
$1 \otimes 1$ as a unit; moreover, it distributes over addition. Distributivity
over addition is built into the construction (i.e. in view of bilinearity). The
rest (commutativity, associativity, units) can be checked directly on the
generators, since we have distributivity.
We shall leave the details to the reader.
\end{proof}


We can in fact describe the tensor product of $R$-algebras by a universal
property. We will
describe a commutative diagram:
\[
\xymatrix{
& R \ar[rd] \ar[ld] & \\
R_0 \ar[rd] & & R_1 \ar[ld] \\
& R_0 \otimes_R R_1
}
\]
Here $R_0 \to R_0 \otimes_R R_1$ sends $x \mapsto x \otimes 1$; similarly for $R_1
\mapsto R_0 \otimes_R R_1$. These are ring-homomorphisms, and it is easy to
see that
the above
diagram commutes, since $r \otimes 1 = 1 \otimes r = r(1 \otimes 1)$ for $r \in
R$.
In fact,
\begin{proposition}
$R_0 \otimes_R R_1$ is universal with respect to this property: in the language
of category theory, the above diagram is a pushout square.
\end{proposition}

This means for any commutative ring $B$, and every pair of maps $u_0: R_0 \to
B$ and $u_1: R_1 \to B$ such that the pull-backs $R \to R_0 \to B$ and $R \to
R_1 \to B$ are the same, then we get a unique map of rings
\[ R_0 \otimes_R R_1 \to B  \]
which restricts on $R_0, R_1$ to the morphisms $u_0, u_1$ that we started with.
\begin{proof} If $B$ is a ring as in the previous paragraph, we make $B$ into an $R$-module by the map $R \to R_0 \to B$ (or
$R \to R_1 \to B$, it is the same by assumption).
This map $R_0 \otimes_R R_1 \to B$ sends
\[ x \otimes y \to u_0(x) u_1(y).  \]
It is easy to check that $(x,y) \to u_0(x)u_1(y)$ is $R$-bilinear (because of
the condition that the two pull-backs of $u_0, u_1$ to $R$ are the same), and
that it gives a homomorphism of rings $R_0 \otimes_R R_1 \to B$ which
restricts to $u_0, u_1$ on $R_0,
R_1$. One can check, for instance, that this is a homomorphism of rings by
looking at the generators.

It is also clear that $R_0 \otimes_R R_1 \to B$ is unique, because we know
that the
map on elements of the form $x \otimes 1$ and $1 \otimes y$ is determined by
$u_0, u_1$; these generate $R_0 \otimes_R R_1$, though.
\end{proof}

In fact, we now claim that the category of rings has \emph{all} coproducts. We
see that the coproduct of any two elements exists (as the tensor product over
$\mathbb{Z}$). It turns out that arbitrary coproducts exist. More generally,
if $\left\{R_\alpha\right\}$ is a family of $R$-algebras, then one can define
an object
\[ \bigotimes_\alpha R_\alpha,  \]
which is a coproduct of the $R_\alpha$ in the category of $R$-algebras. To do
this, we simply take the generators as before, as formal objects
\[ \bigotimes r_\alpha, \quad r_\alpha \in R_\alpha,  \]
except that all but finitely many of  the $r_\alpha$ are required to be the
identity. One quotients by the usual relations.

Alternatively, one may use the fact that filtered colimits exist, and
construct the infinite coproduct as a colimit of finite coproducts (which are
just ordinary tensor products).

\section{Exactness properties of the tensor product}

In general, the tensor product is not exact; it is only exact on the right,
but it can fail to preserve injections. Yet in some important cases it
\emph{is}
exact. We study that in the present section.

\subsection{Right-exactness of the tensor product}

We will start by talking about extent to which tensor products do preserve
exactness under any circumstance.
First, let's recall what is going on. If $M,N$ are $R$-modules over the
commutative ring $R$, we have defined another $R$-module $\hom_R(M,N)$
of morphisms
$M \to N$. This is left-exact as a functor of $N$. In other words, if we fix
$M$ and let $N$ vary, then the construction of homming out of $M$ preserves
kernels.

In the language of category theory, this construction $N \to \hom_R(M,N)$ has
an adjoint. The other construction we discussed last time was this adjoint,
and it is  the tensor
product. Namely, given $M,N$ we defined a \textbf{tensor product} $M \otimes_R
N$ such that giving a map $M \otimes_R N \to P$ into some $R$-module $P$
is the same as giving a
bilinear map $\lambda: M \times N \to P$, which in turn is the same as giving
an $R$-linear map
\[ M \to \hom_R(N, P).	\]
So we have a functorial isomorphism
\[ \hom_R(M \otimes_R N, P) \simeq \hom_R(M, \hom_R(N,P)).  \]
Alternatively, tensoring is the left-adjoint to the
hom functor. By abstract nonsense, it follows that since $\hom(M, \cdot)$
preserves cokernels, the left-adjoint preserves cokernels and is right-exact.
We shall see this directly.

\begin{proposition}
The functor $N \to M \otimes_R N$ is right-exact, i.e. preserves cokernels.
\end{proposition}
In fact, the tensor product is symmetric, so it's right exact in either
variable.

\begin{proof}
We have to show that if $N' \to N \to N'' \to 0$ is exact, then so is
\[ M \otimes_R N' \to M \otimes_R N \to M \otimes_R N'' \to 0.	\]
There are a lot of different ways to think about this. For instance, we can
look at the direct construction.  The tensor product is a certain quotient of a
free module.

$M \otimes_R N''$ is the quotient of the free module generated by $m \otimes
n'', m \in M, n \in N''$ modulo the usual relations.  The map $M \otimes N \to
M \otimes N''$ sends $m \otimes n \to m \otimes n''$ if $n'' $ is the image of
$n$ in $N''$. Since each $n''$ can be lifted to some $n$, it is obvious that
the map $M \otimes_R N \to M \otimes_R N''$ is surjective.

Now we know that $M \otimes_R N''$ is a quotient of $M \otimes_R N$. But which
relations do you have to impose on $M \otimes_R N$ to get $M \otimes_R
N''$? In fact, each relation in $M \otimes_R N''$
can be lifted to a relation in $M \otimes_R N$, but with some redundancy. So
the only thing to quotient
out by is the statement that $x \otimes y, x \otimes y'$ have the same image in
$M \otimes N''$.  In particular, we have to quotient out by
\[ x \otimes y - x\otimes y' \ , y - y' \in N'	 \]
so that if we kill off $x \otimes n'$ for $n' \in N' \subset N$, then we get $M
\otimes N''$. This is a direct proof.

One can also give a conceptual proof.  We would like to know that $M \otimes N''$
is the cokernel of $M \otimes N' \to M \otimes N''$. In other words, we'd like
to know that if we mapped $M \otimes_R N$ into some $P$ and the pull-back to $M
\otimes_R N'$, it'd factor uniquely through $M \otimes_R N''$.
Namely, we need to show that
\[ \hom_R(M \otimes N'', P) = \ker(\hom_R(M \otimes N, P) \to \hom_R(M
\otimes N'', P)).  \]
But the first is just $\hom_R(N'', \hom_R(M,P))$ by the adjointness property.
Similarly, the second is just
\[ \ker( \hom_R(N, \hom(M,P)) \to \hom_R(N', \hom_R(M,P))  \]
but this last statement is $\hom_R(N'', \hom_R(M,P))$ by just the statement
that $N'' = \mathrm{coker}(N ' \to N)$.
To give a map $N'' $ into some module (e.g. $\hom_R(M,P)$) is the same thing as
giving a map out of $N$ which kills $N'$.
So we get the functorial isomorphism.
\end{proof}

\begin{remark}
Formation of tensor products is, in general, \textbf{not} exact.
\end{remark}

\begin{example} \label{tensorbad}
Let $R = \mathbb{Z}$. Let $M = \mathbb{Z}/2\mathbb{Z}$. Consider the exact
sequence
\[ 0 \to \mathbb{Z} \to \mathbb{Q} \to \mathbb{Q}/\mathbb{Z} \to 0  \]
which we can tensor with $M$, yielding
\[ 0 \to \mathbb{Z}/2\mathbb{Z} \to \mathbb{Q} \otimes_{}
\mathbb{Z}/2\mathbb{Z} \to  \mathbb{Q}/\mathbb{Z} \otimes
\mathbb{Z}/2\mathbb{Z} \to 0  \]
I claim that the second thing $\mathbb{Q} \otimes \mathbb{Z}/2\mathbb{Z}$
is zero.  This is because by tensoring with
$\mathbb{Z}/2\mathbb{Z}$, we've made multiplication by 2 identically zero. By
tensoring with $\mathbb{Q}$, we've made multiplication by 2 invertible. The
only way to reconcile this is to have the second term zero. In particular, the
sequence becomes
\[ 0 \to \mathbb{Z}/2\mathbb{Z} \to 0 \to 0 \to 0  \]
which is not exact.
\end{example}

\begin{exercise}
Let $R$ be a ring, $I, J \subset R$ ideals. Show that $R/I \otimes_R R/J
\simeq R/(I+J)$.
\end{exercise}

\subsection{A characterization of right-exact functors}

Let us consider additive functors on the category of $R$-modules. So far,
we know a very easy way of getting such functors: given an $R$-module $N$, we
have a functor
\[ T_N: M \to M \otimes_R N.  \]
In other words, we have a way of generating a functor on the category of
$R$-modules for each $R$-module. These functors are all right-exact, as we
have seen.
Now we will prove a converse.

\begin{proposition}
Let $F$ be a right-exact functor on the category of $R$-modules that commutes
with direct sums. Then $F$ is isomorphic to some $T_N$.
\end{proposition}
\begin{proof}
The idea is that $N$ will be $F(R)$.

Without the right-exactness hypothesis, we shall construct a natural morphism
\[  F(R) \otimes M \to F(M) \]
as follows. Given $m \in M$, there is a natural map $R \to M$ sending $1 \to
m$. This identifies $M = \hom_R(R, M)$. But functoriality gives a map $F(R)
\times \hom_R(R, M) \to F(M)$, which is clearly $R$-linear; the universal
property of the tensor product now produces the desired transformation
$T_{F(R)} \to F$.

It is clear that $T_{F(R)}(M) \to F(M)$ is an isomorphism for $M = R$, and
thus for $M$ free, as both $T_{F(R)}$ and $F$ commute with direct sums. Now
let $M$ be any $R$-module. There is a ``free presentation,'' that is an exact
sequence
\[ R^I \to R^J \to M \to 0  \]
for some sets $I,J$; we get a commutative, exact diagram
\[ \xymatrix{
T_{F(R)}(R^I)\ar[d]  \ar[r] & T_{F(R)} (R^J) \ar[d]  \ar[r] & T_{F(R)} (M) \ar[d]  \ar[r] &  0  \\
F(R^I) \ar[r] &  F(R^J) \ar[r] & F( M )\ar[r] &  0
}\]
where the leftmost two vertical arrows are isomorphisms. A diagram chase now
shows that $T_{F(R)}(M) \to F(M)$ is an isomorphism. In particular, $F \simeq
T_{F(R)}$ as functors.
\end{proof}

Without the hypothesis that $F$ commutes with arbitrary direct sums, we could only draw
the same conclusion on the category of \emph{finitely presented} modules; the
same proof as above goes through, though $I$ and $J$ are required to be
finite.\footnote{Recall that an additive functor commutes with finite direct
sums.}
\begin{proposition}
Let $F$ be a right-exact functor on the category of finitely presented $R$-modules that commutes
with direct sums. Then $F$ is isomorphic to some $T_N$.
\end{proposition}

From this we can easily see that localization at a multiplicative subset $S
\subset R$ is given by tensoring with $S^{-1}R$. Indeed, localization is a
right-exact functor on the category of $R$-modules, so it is given by
tensoring with some module $M$; applying to $R$ shows that $M=S^{-1}R$.

\subsection{Flatness}
In some cases, though, the tensor product is exact.

\begin{definition} \label{flatdefn}
Let $R$ be a commutative ring. An $R$-module $M$ is called \textbf{flat} if the
functor $N \to M \otimes_R N$ is exact.  An $R$-algebra is \textbf{flat} if it is flat as an
$R$-module.
\end{definition}

We already know that tensoring with anything is right exact,
so the only thing to be checked for flatness of $M$ is that the operation of  tensoring by $M$
preserves injections.

\begin{example}
$\mathbb{Z}/2\mathbb{Z}$ is not flat as a $\mathbb{Z}$-module by
\rref{tensorbad}.

\end{example}

\begin{example} \label{projmoduleisflat}
If $R$ is a ring, then $R$ is flat as an $R$-module, because tensoring by $R$
is the identity functor.

More generally, if $P$ is a projective module (i.e., homming out of $P$
is exact), then $P$ is flat.
\end{example}
\begin{proof}
If $P  = \bigoplus_A R$ is free, then tensoring with $P$ corresponds to taking
the direct sum $|A|$ times, i.e.
\[ P \otimes_R M = \bigoplus_A M.  \]
This is because tensoring with $R$ preserves (finite or direct) infinite sums.
 The functor $M \to \bigoplus_A M$ is exact, so free
modules are flat.

A projective module, as discussed earlier, is a direct summand of a free
module. So if $P$ is projective, $P \oplus P' \simeq \bigoplus_A R$ for some
$P'$. Then we have that
\[ (P \otimes_R M) \oplus (P' \otimes_R M) \simeq \bigoplus_A M.  \]
If we had an injection $M \to M'$, then there is a direct sum decomposition
yields a diagram of maps
\[ \xymatrix{
P \otimes_R M \ar[d] \ar[r] &  \bigoplus_A M \ar[d]  \\
P \otimes_R M' \ar[r] &  \bigoplus_A M'
}.\]
A diagram-chase now shows that the vertical map is injective. Namely, the
composition $P \otimes_R M \to \bigoplus_A M'$ is injective, so the vertical
map has to be injective too.
\end{proof}

\begin{example}
If $S \subset R$ is a multiplicative subset, then  $S^{-1}R $ is a flat $R$-module, because localization is an
exact functor.
\end{example}

Let us make a few other comments.

\begin{remark}
Let $\phi: R \to R'$ be a homomorphism of rings. Then, first of all, any
$R'$-module can be regarded as an $R$-module by composition with $\phi$. In
particular, $R'$ is an $R$-module.

If $M$ is an $R$-module, we can define
\[ M \otimes_R R'  \]
as an $R$-module. But in fact this tensor product is an $R'$-module; it has
an action of $R'$.   If $x \in M$ and $a \in R'$ and $b \in R'$, multiplication
of $(x \otimes a) \in M \otimes_R R'$ by $b \in R'$ sends this, \emph{by
definition}, to
\[ b(x \otimes a) = x \otimes ab.  \]
It is easy to check that this defines an action of $R'$ on $M \otimes_R R'$.
(One has to check that this action factors through the appropriate relations,
etc.)

\end{remark}

The following fact shows that the hom-sets behave nicely with respect to flat
base change.
\begin{proposition}
Let $M$ be a finitely presented $R$-module, $N$ an $R$-module. Let $S$ be a
flat $R$-algebra.  Then the natural map
\[ \hom_R(M,N) \otimes_R S \to \hom_S( M \otimes_R S, N \otimes_R S)  \]
is an isomorphism.
\end{proposition}
\begin{proof}
Indeed, it is clear that there is a natural map
\[ \hom_R(M, N) \to \hom_S(M \otimes_R S, N \otimes_R S)  \]
of $R$-modules. The latter is an $S$-module, so the universal property gives
the map $\hom_R(M, N) \otimes_R S \to \hom_S(M \otimes_R S, N \otimes_R S)$ as
claimed.
If $N$ is fixed, then we have two contravariant functors
in $M$,
\[ T_1(M) = \hom_R(M, N) \otimes_R S, \quad T_2(M) =  \hom_S(M \otimes_R S, N
\otimes_R S). \]
We also have a natural transformation $T_1(M) \to T_2(M)$.
It is clear that if $M$ is \emph{finitely generated} and \emph{free}, then the
natural transformation is an isomorphism (for example, if $M = R$, then we just
have the map $N \otimes_R S \to N \otimes_R S$).

Note moreover that both functors are left-exact: that is, given an exact
sequence
\[ M' \to M \to M'' \to 0,  \]
there are induced exact sequences
\[ 0 \to T_1(M'') \to T_1(M) \to T_1(M'), \quad  0 \to T_2(M'') \to T_2(M) \to
T_2(M') .\]
Here we are using the fact that $\hom$ is always a left-exact functor and the
fact that tensoring with $S$ preserves exactness. (Thus it is here that we use
flatness.)

Now the following lemma will complete the proof:
\begin{lemma}
Let $T_1, T_2$ be contravariant, left-exact additive functors from the category of
$R$-modules to the category of abelian groups. Suppose a natural transformation
$t: T_1(M) \to T_2(M)$ is given, and suppose this is an isomorphism whenever
$M$ is finitely generated and free. Then it is an isomorphism for any finitely
presented module $M$.
\end{lemma}
\begin{proof}
This lemma is a diagram chase. Fix a finitely presented $M$, and choose a
presentation
\[ F' \to F  \to M \to 0, \]
with $F', F$ finitely generated and free.
Then we have an exact and commutative diagram
\[ \xymatrix{
0 \ar[r] & T_1(M) \ar[d]^{}  \ar[r] &  T_1(F) \ar[d]^{\simeq}  \ar[r] &
T_1(F') \ar[d]^{\simeq}  \\
0 \ar[r] & T_2(M)   \ar[r] &  T_2(F)   \ar[r] &  T_2(F')  .
}\]
By hypotheses, the two vertical arrows to the right are isomorphisms, as
indicated. A diagram chase now shows that the remaining arrow is an
isomorphism, which is what we wanted to prove.
\end{proof}
\end{proof}

\begin{example}
Let us now consider finitely generated flat modules over a principal ideal
domain $R$. By \rref{structurePID}, we know that any such $M$ is isomorphic to a
direct sum $\bigoplus R/a_i$ for some $a_i \in R$. But if any of the $a_i$ is
not zero, then that $a_i$ would be a nonzero zerodivisor on $M$. However, we
know no element of $R - \left\{0\right\}$ can be a zerodivisor on $M$. It
follows that all the $a_i = 0$. In particular, we have proved:

\begin{proposition}
A finitely generated module over a PID is flat if and only if it is free.
\end{proposition}
\end{example}

\subsection{Finitely presented flat modules}
In \cref{projmoduleisflat}, we saw that a projective module over any ring $R$
was automatically flat. In general, the converse is flat. For instance,
$\mathbb{Q}$ is a flat $\mathbb{Z}$-module (as tensoring by $\mathbb{Q}$ is a
form of localization). However, because $\mathbb{Q}$ is divisible (namely,
multiplication by $n$ is surjective for any $n$), $\mathbb{Q}$ cannot be a free
abelian group.

Nonetheless:

\begin{theorem} \label{fpflatmeansprojective}
A finitely presented flat module over a ring $R$ is projective.
\end{theorem}
\begin{proof}
We follow \cite{We95}.

Let us define the following contravariant functor from $R$-modules to $R$-modules.
Given $M$, we send it to $M^* = \hom_\mathbb{Z}(M, \mathbb{Q}/\mathbb{Z})$.
This is made into an $R$-module in the following manner: given $\phi: M \to
\mathbb{Q}/\mathbb{Z}$ (which is just a homomorphism of abelian groups!) and $r
\in R$, we send this to $r\phi$ defined by $(r\phi)(m) = \phi(rm)$.
Since $\mathbb{Q}/\mathbb{Z}$ is an injective abelian group, we see that $M
\mapsto M^*$ is an \emph{exact} contravariant functor from $R$-modules to
$R$-modules.
In fact, we note that $0 \to A \to B \to C \to 0$ is exact  implies $0 \to C^* \to B^* \to A^* \to 0$ is exact.

Let $F$ be any $R$-module. There is a natural homomorphism
\begin{equation} \label{twoduals} M^* \otimes_R F \to \hom_R(F, M)^*.
\end{equation}
This is defined as follows. Given $\phi: M \to \mathbb{Q}/\mathbb{Z}$ and $x \in
F$, we define a new map $\hom(F, M) \to \mathbb{Q}/\mathbb{Z}$ by sending a
homomorphism $\psi: F \to M$ to $\phi(\psi(x))$.
In other words, we have a natural map
\[ \hom_{\mathbb{Z}}(M, \mathbb{Q}/\mathbb{Z} ) \otimes_R F \to
\hom_{\mathbb{Z}}( \hom_R(F, M)^*, \mathbb{Q}/\mathbb{Z}). \]

Now fix $M$.
This map \eqref{twoduals} is an isomorphism if $F$ is \emph{finitely
generated} and  free.
 Both are right-exact (because dualizing is contravariant-exact!).
The ``finite presentation trick'' now shows that the map is an isomorphism if
$F$ is finitely presented.
 \add{this should be elaborated on}

Fix now $F$  finitely presented and flat, and consider the above two quantities
in \eqref{twoduals} as functors in $M$.
Then the first functor is exact, so the second one is too.
In particular, $\hom_R(F, M)^*$ is an exact functor in $M$; in particular, if
$M \twoheadrightarrow M''$ is a surjection, then
\[ \hom_R(F, M'')^* \to \hom_R(F, M)^*  \]
is an injection. But this implies that
\[ \hom_R(F, M) \to \hom_R(F, M'')  \]
is a \emph{surjection,} i.e. that $F$ is projective.
Indeed:
\begin{lemma} $ A \to B \to C $ is exact if and only if $C^* \to B^* \to A^* $ is exact.
\end{lemma}
\begin{proof}
Indeed, one direction was already clear (from $\mathbb{Q}/\mathbb{Z}$ being an
injective abelian group).
Conversely, we note that $M = 0$ if and only if $M^* = 0$ (again by
injectivity and the fact that $(\mathbb{Z}/a)^* \neq 0$ for any $a$).
Thus dualizing reflects isomorphisms: if a map becomes an isomorphism after
dualized, then it was an isomorphism already. From here it is easy to deduce
the result (by applying the above fact to the kernel and image).
\end{proof}
\end{proof}


\part{Commutative algebra}
% ============================ chapters/spec.tex}
\chapter{The $\spec$ of a ring}
\label{spec}

The notion of the $\spec$ of a ring is fundamental in modern
algebraic
geometry. It is the scheme-theoretic analog of classical affine
schemes. The
identification occurs when one identifies the maximal ideals of
the polynomial
ring $k[x_1, \dots, x_n]$ (for $k$ an algebraically closed
field) with the
points of the classical variety $\mathbb{A}^n_k = k^n$. In
modern algebraic
geometry, one adds the ``non-closed points'' given by the other
prime ideals.
Just as general varieties were classically defined by gluing
affine varieties, a
scheme is defined by gluing open affines.

This is not a book on schemes, but it will nonetheless be
convenient to introduce the $\spec$ construction, outside of the obvious
benefits of including preparatory material for algebraic geometry. First of
all, it will provide a convenient
notation. Second, and more importantly, it will provide a
convenient geometric
intuition. For example, an $R$-module can be thought of as a
kind of ``vector
bundle''---technically, a sheaf---over the space $\spec R$, with
the caveat
that the rank might not be locally constant (which is, however,
the case when the module
is projective).

\section{The spectrum of a ring}

We shall now associate to every commutative ring a topological
space $\spec R$
in a functorial manner.
That is, there will be a contravariant functor
\[\spec:  \mathbf{CRing} \to \mathbf{Top}  \]
where $\mathbf{Top}$ is the category of topological spaces.
This construction is the basis for scheme-theoretic
algebraic geometry and will be used frequently in the sequel.

The motivating observation is the following. If $k$ is an algebraically closed
field, then the maximal ideals in $k[x_1, \dots, x_n]$ are of the form
$(x_1-a_1, \dots, x_n  - a_n)$ for $(a_1, \dots, a_n) \in k[x_1, \dots, x_n]$.
This is the Nullstellensatz, which we have not proved yet. We can thus
identify the maximal ideals in the polynomial ring with the space $k^n$.
If $I \subset k[x_1, \dots, x_n]$ is an ideal, then the maximal ideals in
$k[x_1,\dots,x_n]$ correspond to points where everything in $I$ vanishes. See
\rref{twovarpoly} for a more detailed explanation. Classical affine algebraic
geometry thus studies the set of maximal ideals in an algebra finitely
generated over an algebraically closed field.

The $\mathrm{Spec}$ of a ring is a generalization of this construction.
In general, it is more natural to
use all prime ideals instead of just maximal ideals.
\subsection{Definition and examples}

We start by defining $\spec$ as a set. We will next
construct the
Zariski topology and later the functoriality.
\begin{definition}
Let $R$ be a commutative ring. The \textbf{spectrum} of $R$,
denoted $\spec R$, is
the set of prime ideals of $R$.
\end{definition}

We shall now make $\spec R$ into a topological space. First, we
describe a
collection of sets which will become the closed sets.
If $I \subset R$ is an ideal, let
\[ V(I) = \left\{\mathfrak{p}: \mathfrak{p} \supset I\right\}
\subset \spec R.
\]

\begin{proposition}
There is a topology on $\spec R$ such that the closed subsets
are of the form
$V(I)$ for $I \subset R$ an ideal.
\end{proposition}

\begin{proof}
Indeed, we have to check the familiar axioms for a topology:
\begin{enumerate}
\item $\emptyset = V((1))$ because no prime contains $1$. So
$\emptyset$ is closed.
\item $\spec R = V((0))$ because any ideal contains zero. So
$\spec R$ is
closed.
\item We show the closed sets are stable under intersections.
Let
$K_{\alpha} = V(I_{\alpha})$ be closed subsets of $\spec R$ for
$\alpha$
ranging over some index set.  Let $I
= \sum I_{\alpha}$. Then
\[ V(I) = \bigcap K_{\alpha} = \bigcap V(I_{\alpha}),  \]
which follows because $I$ is the smallest ideal containing each
$I_{\alpha}$,
so a prime contains every $I_{\alpha}$ iff it contains $I$.
\item The union of two closed sets is closed. Indeed, if $K,K'
\subset \spec
R$ are closed, we show $K \cup K'$ is closed. Say $K= V(I), K' =
V(I')$. Then
we claim:
\[ K \cup K'  = V(II').  \]
Here, as usual, $II'$ is the ideal generated by products $ii', i \in I, i'
\in I'$. If
$\mathfrak{p}$ is \textbf{prime} and contains $II'$, it must
contain one of $I$, $I'$;
this implies the displayed equation above and implies the
result.
\end{enumerate}
\end{proof}
\begin{definition}
The topology on $\spec R$ defined above is called the
\textbf{Zariski
topology}. With it,  $\spec R$ is now a topological space.
\end{definition}

\begin{exercise}
What is the $\spec$ of the zero ring?
\end{exercise}

In order to see the geometry of this construction, let us work
several examples.

\begin{example}
Let $R = \mathbb{Z}$, and consider $\spec \mathbb{Z}$. Then
every prime is generated by one element, since
$\mathbb{Z}$ is a PID. We have that $\spec \mathbb{Z} = \{(0)\}
\cup \bigcup_{p \
\mathrm{prime}} \{ (p)\}$. The picture is that one has all the
familiar primes $(2), (3),
(5), \dots, $ and then a special point $(0)$.

Let us now describe the closed subsets. These are of the form
$V(I)$ where $I
\subset \mathbb{Z}$ is an ideal, so $I = (n)$ for some $n \in
\mathbb{Z}$.

\begin{enumerate}
\item If $n=0$, the closed subset is all of $\spec \mathbb{Z}$.
\item If $n \neq 0$, then $n$ has finitely many prime divisors.
So $V((n))$ consists
of the prime ideals corresponding to these prime divisors.
\end{enumerate}

The only closed subsets besides the entire space are the finite
subsets
that exclude $(0)$.
\end{example}

\begin{example} \label{twovarpoly}
Say $R = \mathbb{C}[x,y]$ is a polynomial ring in two variables.
We will not give a complete description of $\spec R$ here. But we will write
down several
prime ideals.

\begin{enumerate}
\item For every pair of complex numbers $s,t \in \mathbb{C}$,
the collection of polynomials
$f \in R$ such that $f(s,t) = 0$ is a prime ideal $\mathfrak{m}
_{s,t} \subset R$. In
fact, it is maximal, as the residue ring is all of
$\mathbb{C}$. Indeed,
$R/\mathfrak{m}_{s,t} \simeq \mathbb{C}$ under the map $f \to
f(s,t)$.

In fact,
\begin{theorem}
The $\mathfrak{m}_{s,t}$ are all the maximal ideals in $R$.
\end{theorem}
This will follow from the \emph{Hilbert Nullstellensatz} to be
proved later
(\rref{gennullstellensatz}).
\item $(0) \subset R$ is a prime ideal since $R$ is a domain.
\item If $f(x,y) \in R$ is an irreducible polynomial, then $(f)$
is a prime
ideal. This is equivalent to unique factorization in
$R$.\footnote{To be
proved later \rref{}.}
\end{enumerate}

To draw $\spec R$, we start by drawing $\mathbb{C}^2$, which is identified
with the
collection of
maximal ideals $\mathfrak{m}_{s,t}, s, t \in \mathbb{C}$. $\spec R$ has
additional (non-closed) points
too, as
described above, but for now let us
consider the topology induced on $\mathbb{C}^2$ as a subspace of
$\spec R$.

The closed subsets of $\spec R$ are subsets $V(I)$ where $I$ is
an ideal,
generated by polynomials $\left\{f_{\alpha}(x,y)\right\}$. It is of interest to
determine the subset of $\mathbb{C}^2$ that
$V(I)$
induces. In other words, we ask:
\begin{quote}
What points of $\mathbb{C}^2$ (with $(s,t)$ identified with
$\mathfrak{m}_{s,t}$) lie in $V(I)$?
\end{quote}
Now, by definition, we know that $(s,t)$ corresponds to a point of $V(I)$ if
and only if $I
\subset \mathfrak{m}_{s,t}$.
This is true iff all the
$f_{\alpha} $ lie in $ \mathfrak{m}_{s,t}$, i.e. if
$f_{\alpha}(s,t) =0$ for all
$\alpha$. So the closed subsets of $\mathbb{C}^2$ (with the
induced Zariski
topology) are \emph{precisely the subsets
that can be defined by polynomial equations}.

This is
\textbf{much} coarser
than the usual topology. For instance, $\left\{(z_1,z_2):
\Re(z_1) \geq 0\right\}$ is
not Zariski-closed.
The Zariski topology is so coarse because one has only algebraic
data (namely,
polynomials, or elements of $R$) to define the topology.
\end{example}

\begin{exercise}
Let $R_1, R_2$ be commutative rings. Give $R_1 \times R_2$ a
natural structure
of a ring, and describe $\spec( R_1 \times R_2)$ in terms of
$\spec R_1$ and
$\spec R_2$.
\end{exercise}


\begin{exercise}
Let $X$ be a compact Hausdorff space, $C(X)$ the ring of real
continuous
functions $X \to \mathbb{R}$.
The maximal ideals in $\spec C(X)$ are in bijection with the
points of $X$,
and the topology induced on $X $ (as a subset of $\spec C(X)$ with the Zariski
topology)
is just the usual topology.
\end{exercise}

\begin{exercise}
Prove the following result: if $X, Y$ are compact Hausdorff
spaces and $C(X),
C(Y)$ the associated rings of continuous functions, if $C(X),
C(Y)$ are
isomorphic as $\mathbb{R}$-algebras, then $X$ is homeomorphic to
$Y$.
\end{exercise}


\subsection{The radical ideal-closed subset correspondence}

We now return to the case of an arbitrary commutative ring $R$.
If $I \subset R$, we get a closed
subset $V(I) \subset \spec R$. It is called $V(I)$ because one
is supposed to
think of it as the places where the elements of $I$ ``vanish,''
as the
elements of $R$ are something like ``functions.'' This analogy
is perhaps best
seen in the example of a polynomial ring over an algebraically
closed field,
e.g. \rref{twovarpoly} above.

The map from ideals into closed sets is very far from being
injective in
general, though by definition it is surjective.

\begin{example}
If $R = \mathbb{Z}$ and $p$ is prime, then $I = (p), I' = (p^2)$
define the
same subset (namely, $\left\{(p)\right\}$) of
$\spec R$.
\end{example}

We now ask why the map from ideals to closed
subsets fails to
be injective. As we shall see, the entire problem disappears if
we restrict to
\emph{radical} ideals.

\begin{definition}
If $I$ is an ideal, then the \textbf{radical} $\rad(I) $ or $
\sqrt{I}$ is
defined as $$\rad(I) =
\left\{x \in R: x^n \in I \ \mathrm{for} \ \mathrm{some} \ n
\right\}.$$
An ideal is \textbf{radical} if it is equal to its radical.
(This is
equivalent to the earlier \rref{def-radical-ideal}.)
\end{definition}

Before proceeding, we must check:
\begin{lemma}
If $I$ an ideal, so is $\rad(I)$.
\end{lemma}
\begin{proof}
Clearly $\rad(I)$ is closed under multiplication since $I$ is.
Suppose $x,y \in \rad(I)$; we show $x+y \in \rad(I)$. Then $x^n,
y^n \in I$
for some $n$ (large) and thus for all larger $n$. The binomial
expansion now
gives
\[ (x+y)^{2n} = x^{2n} + \binom{2n}{1} x^{2n-1}y + \dots +
y^{2n}, \]
where every term contains either $x,y$ with power $ \geq n$, so
every term
belongs to $I$. Thus $(x+y)^{2n} \in I$ and, by definition, we
see then that $x+y \in \rad(I)$.
\end{proof}

The map $I \to V(I)$ does in fact depend only on the radical of
$I$. In fact, if $I,J$ have the same radical $\rad(I) =
\rad(J)$, then $V(I) = V(J)$.
Indeed, $V(I) = V(\rad(I)) = V(\rad(J)) = V(J)$ by:
\begin{lemma}
For any $I$, $V(I) = V(\rad(I))$.
\end{lemma}
\begin{proof}
Indeed, $I \subset \rad(I)$ and therefore obviously $V(\rad(I))
\subset V(I)$. We have to show the
converse inclusion. Namely, we must prove:
\begin{quote}
If $\mathfrak{p} \supset I$, then $\mathfrak{p} \supset
\rad(I).$
\end{quote}
So suppose $\mathfrak{p} \supset I$ is prime and $x \in
\rad(I)$; then $x^n \in I \subset \mathfrak{p}$ for some $n$.
But $\mathfrak{p}$ is prime, so whenever a product of things
belongs to
$\mathfrak{p}$, a factor does. Thus since $x^n = x \cdot x
\cdots x$, we must
have $x \in \mathfrak{p}$. So
\[ \rad(I) \subset \mathfrak{p},  \]
proving the quoted claim, and thus the lemma.
\end{proof}

There is a converse to this remark:
\begin{proposition}
If $V(I) = V(J)$, then $\rad(I) = \rad(J)$.
\end{proposition}
So two ideals define the same closed subset iff they have the
same radical.
\begin{proof}
We write down a formula for $\rad(I)$ that will imply this at
once.
\begin{lemma} \label{radprimescontaining} For a commutative ring $R$ and an
ideal $I \subset
R$,
\[ \rad(I) = \bigcap_{\mathfrak{p} \supset I} \mathfrak{p}.  \]
\end{lemma}
From this, it follows that $V(I)$ determines $\rad(I)$. This
will thus imply
the proposition.
We now prove the lemma:
\begin{proof}
\begin{enumerate}
\item We show $\rad(I) \subset \bigcap_{\mathfrak{p} \in V(I)}
\mathfrak{p} $. In
particular, this follows if we show that if a prime contains
$I$, it contains $\rad(I)$; but we have already
discussed this above.
\item If $x \notin \rad(I)$, we will show that there is a prime
ideal $\mathfrak{p}
\supset I$ not containing $x$. This will imply the reverse
inclusion and the
lemma.
\end{enumerate}


We want to find $\mathfrak{p}$ not containing $x$, more
generally not
containing any power of $x$. In particular, we want
$\mathfrak{p} \cap \left\{1,
x, x^2 \dots, \right\} = \emptyset$. This set $S = \left\{1, x,
\dots\right\}$
is multiplicatively closed, in that it contains 1 and is closed
under
finite products. Right now, it does not interset $I$; we want to find
a
\emph{prime} containing $I$ that still does not intersect $\left\{x^n, n
\geq 0\right\}$.


More generally, we will prove:

\begin{sublemma}\label{sublemmamultclosed}
Let $S$ be multiplicatively closed set in any ring $R$ and let
$I$ be any ideal with $I \cap S =
\emptyset$. There is a prime ideal $\mathfrak{p} \supset I$ and
does not
intersect $S$ (in fact, any ideal maximal with respect to the condition of
not intersecting $S$ will do).
\end{sublemma}
In English, any ideal missing $S$ can be enlarged to a prime
ideal missing $S$.
This is actually fancier version of a previous argument. We
showed earlier that any ideal not
containing the multiplicatively closed subset $\left\{1\right\}$
can be
contained in a prime ideal not containing $1$, in
\rref{anycontainedinmaximal}.

Note that the sublemma clearly implies the lemma when applied to
$S =
\left\{1, x, \dots\right\}.$

\begin{proof}[Proof of the sublemma]
Let $P = \left\{J: J \supset I, J \cap S = \emptyset \right\}$.
Then $P$ is a
poset with respect to inclusion. Note that $P \neq \emptyset$
because $I \in P$. Also,
for any nonempty linearly ordered subset of $P$, the union is in
$P$ (i.e. there is an
upper bound).
We can invoke Zorn's lemma to get a maximal element of $P$. This
element is an
ideal $\mathfrak{p} \supset I$ with $\mathfrak{p} \cap S =
\emptyset$. We claim
that $\mathfrak{p}$ is prime.

First of all, $1 \notin \mathfrak{p}$ because $1 \in S$. We need
only check
that if $xy \in \mathfrak{p}$, then $x \in \mathfrak{p}$ or $y
\in
\mathfrak{p}$. Suppose otherwise, so $x,y \notin \mathfrak{p}$.
Then $(x,\mathfrak{p}) \notin P$ or
$\mathfrak{p}$ would not be maximal. Ditto for $(y,
\mathfrak{p})$.

In particular, we have that these bigger ideals both intersect
$S$. This means
that there are
\[ a \in \mathfrak{p} , r \in R \quad \text{such that}\quad a+rx
\in S \]
and
\[ b \in \mathfrak{p} , r' \in R \quad \text{such that}\quad
b+r'y \in S .\]
Now $S$ is multiplicatively closed, so multiply $(a+rx)(b+r'y)
\in S$.
We find:
\[ ab + ar'y+brx+rr'xy \in S.  \]
Now $a,b \in \mathfrak{p}$ and $xy \in \mathfrak{p}$, so all the
terms above are in $\mathfrak{p}$, and the sum is too. But this contradicts
$\mathfrak{p}
\cap S = \emptyset$.
\end{proof}
\end{proof}
\end{proof}
The upshot of the previous lemmata is:
\begin{proposition}
There is a bijection between the closed subsets of $\spec R$ and
radical ideals
$I \subset R$.
\end{proposition}

\subsection{A meta-observation about prime ideals}

We saw in the previous subsection (\cref{sublemmamultclosed})
that an ideal maximal with respect to the property of not intersecting a
multiplicatively closed subset is prime.
It turns out that this is the case for many such properties of ideals.
A general method of seeing this was developed in \cite{LaRe08}.
In this (optional) subsection, we digress to explain this phenomenon.

If $I$ is an ideal and $a \in R$, we define the notation
\[ (I:a) = \left\{ x\in R: xa \in I\right\} . \]
More generally, if $J$ is an ideal, we define
\[ (I:J) = \left\{x \in R: xJ \subset I\right\} . \]

Let $R$ be a ring, and $\mathcal{F}$ a collection of ideals of $R$.
We are interested in conditions that will guarantee that the maximal elements
of $\mathcal{F}$ are \emph{prime}.
Actually, we will do the opposite: the following condition will guarantee that
the ideals maximal at \emph{not} being in $\mathcal{F}$ are prime.

\begin{definition} \label{okafamily}
The family $\mathcal{F}$ is called an \textbf{Oka family} if $R \in
\mathcal{F}$ (where $R$ is considered as an ideal) and whenever $I \subset R$ is an
ideal and $(I:a), (I,a) \in \mathcal{F}$ (for some $a \in R$), then $I \in
\mathcal{F}$.
\end{definition}

\begin{example} \label{exm:okacard}
Let us begin with a simple observation. If $(I:a)$ is generated by
$a_1, \dots, a_n$ and $(I,a)$ is generated by $a, b_1, \dots, b_m$ (where we
may take
$b_1, \dots, b_m \in I$, without loss of generality), then $I$
is generated by $aa_1, \dots, aa_n, b_1, \dots, b_m$.
To see this, note that if $x \in I$, then $x \in (I,a)$ is a linear
combination of the $\left\{a, b_1, \dots, b_m\right\}$, but the coefficient of
$a$ must
lie in $(I:a)$.

As a result, we may deduce that
the family of finitely generated ideals is an Oka family.
\end{example}

\begin{example}
Let us now show that the family of \emph{principal} ideals is an Oka family.
Indeed, suppose $I \subset R$ is an ideal, and $(I,a)$ and $(I:a)$ are
principal.
One can easily check that
$(I:a) = (I: (I, a))$.
Setting $J = (I,a)$, we find that $J$ is principal and $(I:J)$ is too.
However, for \emph{any} principal ideal $J$, and for any ideal $I \subset J$,
\[ I = J (I: J)  \]
as one easily checks. Thus we find in our situation that since $J=(I,a)$ and
$(I:J)$
are principal, $I$ is principal.
\end{example}

\begin{proposition}[\cite{LaRe08}]\label{okathm} If $\mathcal{F}$ is an Oka
family of
ideals, then any maximal element of the complement of $\mathcal{F}$ is prime.
\end{proposition}
\begin{proof}
Suppose $I \notin \mathcal{F}$ is maximal with respect
to not being in $\mathcal{F}$
but $I$ is  not prime. Note that $I \neq R$ by hypothesis.
Then there is $a \in R$ such that $(I:a), (I,a)$ both strictly contain $I$,
so they must belong to $\mathcal{F}$.
Indeed, we can find $a,b \in R - I$ with $ab \in I$; it follows that $(I,a)
\neq I$ and $(I:a)$ contains $b \notin I$.

By the Oka condition, we have $I \in
\mathcal{F}$, a contradiction.
\end{proof}

\begin{corollary}[Cohen] \label{primenoetherian}
If every prime ideal of $R$ is finitely generated, then every ideal of $R$ is
finitely generated.\footnote{Later we will say that $R$ is \emph{noetherian.}}
\end{corollary}

\begin{proof}
Suppose that there existed ideals $I \subset R$ which were not finitely
generated.
The union of a totally ordered chain $\left\{I_\alpha\right\}$ of ideals that
are not finitely generated is not finitely
generated; indeed, if $I = \bigcup I_\alpha$ were generated by $a_1, \dots,
a_n$, then all the generators would belong to some $I_\alpha $ and would
consequently generate it.

By Zorn's lemma, there is an ideal maximal with respect to being not finitely
generated. However, by \rref{okathm}, this ideal is necessarily
prime (since the family of finitely generated ideals is an Oka family). This contradicts the hypothesis.
\end{proof}

\begin{corollary}
If every prime ideal of $R$ is principal, then every ideal of $R$ is principal.
\end{corollary}
\begin{proof}
This is proved in the same way.
\end{proof}

\begin{exercise}
Suppose every nonzero prime ideal in $R$ contains a non-zerodivisor. Then $R$
is a domain. (Hint: consider the set $S$ of nonzerodivisors, and argue that
any ideal maximal with respect to not intersecting $S$ is prime. Thus, $(0)$
is prime.)
\end{exercise}


\begin{remark}
\label{remark-cohen-bound-cardinality}
Let $R$ be a ring. Let $\kappa$ be an infinite cardinal.
By applying
\rref{exm:okacard} and
\rref{okathm}
we see that any ideal maximal with respect to the property of not being
generated by $\kappa$ elements is prime. This result is not so
useful because there exists a ring for which every prime ideal
of $R$ can be generated by $\aleph_0$ elements, but some
ideal cannot. Namely, let $k$ be a field, let $T$ be a set whose
cardinality is greater than $\aleph_0$ and let
\[ R = k[\{x_n\}_{n \geq 1}, \{z_{t, n}\}_{t \in T, n \geq 0}]/
(x_n^2, z_{t, n}^2, x_n z_{t, n} - z_{t, n - 1}) \]
This is a local ring with unique prime ideal
$\mathfrak m = (x_n)$. But the ideal $(z_{t, n})$ cannot
be generated by countably many elements.
\end{remark}

\subsection{Functoriality of $\spec$}
 The construction $R \to \spec R$ is functorial in $R$ in a
contravariant sense. That is, if $f: R \to R'$, there is a
continuous map $\spec
R' \to \spec R$. This map sends $\mathfrak{p} \subset R'$ to
$f^{-1}(\mathfrak{p}) \subset R$, which is easily seen to be a
prime ideal
in $R$. Call this map $F: \spec R' \to \spec R$. So far, we have
seen that
$\spec R$ induces a contravariant functor from $\mathbf{Rings}
\to \mathbf{Sets}$.

\begin{exercise}
A contravariant functor $F: \mathcal{C} \to \mathbf{Sets}$ (for
some category
$\mathcal{C}$) is called \textbf{representable} if it is
naturally isomorphic
to a functor of the form $X \to \hom(X, X_0)$ for some $X_0 \in
\mathcal{C}$,
or equivalently if the induced covariant functor on
$\mathcal{C}^{\mathrm{op}}$ is corepresentable.

The functor $R \to \spec R $ is not representable. (Hint:
Indeed, a representable
functor must send the initial object into a one-point set.)
\end{exercise}

Next, we check that the morphisms induced on $\spec$'s from a
ring-homomorphism are in fact \emph{continuous} maps of
topological spaces.

\begin{proposition}
$\spec $ induces a contravariant functor from $\mathbf{Rings}$
to the category
$\mathbf{Top}$ of topological spaces.
\end{proposition}
\begin{proof} Let $f : R \to R'$.
We need to check that this map $ \spec R' \to \spec R$, which we
call $F$, is
continuous.
That is, we must check that $F^{-1}$ sends closed
subsets of $\spec R$ to closed subsets of $\spec R'$.

More precisely, if $I \subset
R$ and we take the inverse image $F^{-1}(V(I)) \subset \spec
R'$, it is just
the closed set $V(f(I))$. This is best left to the reader, but
here is the justification. If $\mathfrak{p} \in \spec R'$, then
$F(\mathfrak{p}) = f^{-1}(\mathfrak{p})
\supset I$ if and only if $\mathfrak{p} \supset f(I)$. So
$F(\mathfrak{p}) \in
V(I)$ if and only if $\mathfrak{p} \in V(f(I))$.

\end{proof}



\begin{example}
Let $R$ be a commutative ring, $I \subset R$ an ideal, $f: R \to
R/I$. There is a map
of topological spaces
\[ F: \spec (R/I) \to \spec R  .\]
This map is a closed embedding whose image is $V(I)$. Most of
this follows because
there is a bijection between ideals of $R$ containing $I$ and
ideals of $R/I$, and this bijection preserves primality.

\begin{exercise}
Show that this map $\spec R/I \to \spec R$ is indeed a
homeomorphism from $\spec R/I
\to V(I)$.
\end{exercise}
\end{example}


\subsection{A basis for the Zariski topology}
In the previous section, we were talking about the Zariski
topology. If $R$ is a
commutative ring, we recall that $\spec R$ is defined to be the
collection of
prime ideals in $R$. This has a topology where the closed sets
are the sets of
the form
\[ V(I) = \left\{\mathfrak{p} \in \spec R: \mathfrak{p} \supset
I\right\} . \]
There is another way to describe the Zariski topology in terms
of
\emph{open} sets.

\begin{definition}
If $f \in R$, we let
\[ U_f = \left\{\mathfrak{p}: f \notin \mathfrak{p}\right\}  \]
so that $U_f$ is the subset of $\spec R$ consisting of primes
not containing
$f$. This is the complement of $V((f))$, so it is open.
\end{definition}

\begin{proposition}
The sets $U_f$ form a basis for the Zariski topology.
\end{proposition}

\begin{proof}
Suppose $U \subset \spec R$ is open. We claim that $U$ is a
union of basic
open sets $U_f$.

Now $U = \spec R - V(I)$ for some ideal $I$.  Then
\[ U = \bigcup_{f \in I} U_f  \]
because if an ideal is not in $V(I)$, then it fails to contain
some $f \in I$,
i.e. is in $U_f$ for that $f$. Alternatively, we could take
complements, whence
the above statement becomes
\[ V(I) = \bigcap_{f \in I} V((f))  \]
which is clear.
\end{proof}

The basic open sets have nice properties.
\begin{enumerate}
\item $U_1 = \spec R$ because prime ideals are not allowed to
contain the
unit element.
\item $U_0 = \emptyset$ because every prime ideal contains $0$.
\item $U_{fg} = U_f \cap U_g$ because $fg$ lies in a prime ideal
$\mathfrak{p}$ if and only if one of $f,g$ does.
\end{enumerate}

Now let us describe what the Zariski topology has to do with
localization.
Let $R$ be a ring and $f \in R$. Consider $S = \left\{1, f, f^2,
\dots
\right\}$; this is a multiplicatively closed subset. Last week,
we defined
$S^{-1}R$.

\begin{definition}
For $S$ the powers of $f$, we write $R_f$ or  $R[f^{-1}]$ for the
localization $S^{-1}R$.
\end{definition}

There is  a map $\phi: R \to R[f^{-1}]$ and a corresponding map
\[ \spec R[f^{-1}] \to \spec R  \]
sending a prime $\mathfrak{p} \subset R[f^{-1}]$ to
$\phi^{-1}(\mathfrak{p})$.

\begin{proposition}
This map induces a homeomorphism of $\spec R[f^{-1}]$ onto $U_f
\subset \spec
R$.
\end{proposition}
So if one takes a commutative ring and inverts an element, one
just gets an open
subset of $\spec$. This is why it's called localization: one is
restricting to
an open subset on the $\spec $ level when one inverts something.

\begin{proof}
The reader is encouraged to work this proof out for herself.

\begin{enumerate}
\item
First, we show that $\spec R[f^{-1}] \to \spec R$ lands in
$U_f$. If
$\mathfrak{p} \subset R[f^{-1}]$, then we must show that the
inverse image
$\phi^{-1}(\mathfrak{p})$ can't contain $f$. If otherwise, that
would imply that
$\phi(f) \in \mathfrak{p}$; however, $\phi(f)$ is invertible,
and then
$\mathfrak{p}$ would be $(1)$.
\item Let's show that the map surjects onto $U_f$. If
$\mathfrak{p} \subset R$ is a prime
ideal not containing $f$, i.e. $\mathfrak{p} \in U_f$. We want
to construct a
corresponding prime in the ring $R[f^{-1}]$ whose inverse image
is $\mathfrak{p}$.

Let $\mathfrak{p}[f^{-1}]$ be the collection of all fractions
\[ \{\frac{x}{f^n}, x \in \mathfrak{p}\} \subset R[f^{-1}],  \]
which is evidently an ideal. Note that whether the numerator is
in
$\mathfrak{p}$ is \textbf{independent} of the
representing fraction $\frac{x}{f^n}$ used.\footnote{Suppose
$\frac{x}{f^n} =
\frac{y}{f^k}$ for $y \in \mathfrak{p}$. Then there is $N$ such
that
$f^N(f^k x - f^n y) = 0 \in \mathfrak{p}$; since $y \in
\mathfrak{p}$ and $f
\notin \mathfrak{p}$, it follows that $x \in \mathfrak{p}$.}
In fact, $\mathfrak{p}[f^{-1}]$ is a prime ideal. Indeed,
suppose
\[  \frac{a}{f^m} \frac{b}{f^n} \in \mathfrak{p}[f^{-1}] .\]
Then $\frac{ab}{f^{m+n}}$ belongs to this ideal, which means $ab
\in
\mathfrak{p}$; so one of $a,b \in \mathfrak{p}$ and one of the
two fractions
$\frac{a}{f^m}, \frac{b}{f^n}$ belongs to
$\mathfrak{p}[f^{-1}]$. Also, $1/1
\notin \mathfrak{p}[f^{-1}]$.

It is clear that the inverse image of $\mathfrak{p}[f^{-1}]$ is
$\mathfrak{p}$,
because the image of $x \in R$ is $x/1$, and this belongs to
$\mathfrak{p}[f^{-1}]$ precisely when $x \in \mathfrak{p}$.
\item The map $\spec R[f^{-1}] \to \spec R$ is injective.
Suppose
$\mathfrak{p}, \mathfrak{p'}$ are prime ideals in the
localization and the
inverse images are the same.
We must show that $\mathfrak{p} = \mathfrak{p'}$.

Suppose $\frac{x}{f^n} \in \mathfrak{p}$. Then $x/1 \in
\mathfrak{p}$, so $x
\in \phi^{-1}(\mathfrak{p}) = \phi^{-1}(\mathfrak{p}')$. This
means that $x/1
\in \mathfrak{p}'$, so
$\frac{x}{f^n} \in \mathfrak{p}'$ too. So a fraction that
belongs to
$\mathfrak{p}$ belongs to $\mathfrak{p}'$. By symmetry the two
ideals must be
the same.
\item We now know that the map $\psi: \spec R[f^{-1}] \to U_f$
is a continuous
bijection. It is left to see that it is a homeomorphism. We will
show that it
is open.
In particular, we have to show that a basic open set on the left
side is mapped
to an open set on the right side.
If $y/f^n \in R[f^{-1}]$, we have to show that $U_{y/f^n}
\subset \spec
R[f^{-1}]$ has open image under $\psi$. We'll in fact show what
open set it is.

We claim that
\[ \psi(U_{y/f^n}) = U_{fy} \subset \spec R.  \]
To see this, $\mathfrak{p}$ is contained in $U_{f/y^n}$. This
mean that
$\mathfrak{p}$ doesn't contain $y/f^n$. In particular,
$\mathfrak{p}$ doesn't
contain the multiple $yf/1$. So $\psi(\mathfrak{p})$ doesn't
contain $yf$.
This proves the inclusion $\subset$.

\item
To complete the proof of the claim, and
the result, we must show that if $\mathfrak{p} \subset \spec
R[f^{-1}]$ and
$\psi(\mathfrak{p}) = \phi^{-1}(\mathfrak{p}) \in U_{fy}$, then
$y/f^n$ doesn't
belong to $\mathfrak{p}$. (This is kosher and dandy because we
have a bijection.) But the hypothesis implies that $fy \notin
\phi^{-1}(\mathfrak{p})$, so $fy/1 \notin \mathfrak{p}$.
Dividing by $f^{n+1}$
implies that
\[ y/f^{n} \notin \mathfrak{p}  \]
and $\mathfrak{p} \in U_{f/y^n}$.
\end{enumerate}
\end{proof}

If $\spec R$ is a space, and $f$ is thought of as a ``function''
defined on
$\spec R$, the space $U_f$ is to be thought of as the set of
points where $f$
``doesn't vanish'' or ``is invertible.''
Thinking about rings in terms of their spectra is a very useful
idea. We will bring it up when appropriate.

\begin{remark}
The construction $R \to R[f^{-1}]$ as discussed above is an
instance of
localization. More generally, we defined $S^{-1}R$ for $S
\subset R$
multiplicatively closed. We can thus define maps
\( \spec S^{-1}R \to \spec R . \)
To understand $S^{-1}R$, it may help to note that
\[ \varinjlim_{f \in S} R[f^{-1}]  \]
which is a direct limit of rings where one inverts more and more elements.

As an example, consider $S = R - \mathfrak{p}$ for a prime
$\mathfrak{p}$, and for
simplicity that $R$ is countable. We can write $S =
S_0 \cup S_1 \cup \dots$, where each $S_k$ is generated by a
finite number of
elements $f_0, \dots, f_k$. Then $R_{\mathfrak{p}} = \varinjlim
S_k^{-1} R$.
So we have
\[ S^{-1}R = \varinjlim_k R[f_0^{-1} , f_1^{-1}, \dots, f_k^{-1}
] = \varinjlim
R[(f_0\dots f_k)^{-1}]. \]
The functions we invert in this construction are precisely those
which do not
contain $\mathfrak{p}$, or where ``the functions don't vanish.''

The geometric idea is
that to construct $\spec S^{-1}R = \spec R_{\mathfrak{p}}$, we
keep cutting out
from $\spec R$ vanishing locuses of various functions that do
not
intersect $\mathfrak{p}$. In the end, you don't restrict to an
open set, but
to an intersection of them.
\end{remark}
\begin{exercise} \label{semilocal}
Say that    $R$ is \emph{semi-local} if it has finitely many maximal ideals.
Let $\mathfrak{p}_1$, \dots, $\mathfrak{p}_n\subset R$ be primes. The complement of
the union, $S=R\smallsetminus \bigcup \mathfrak{p}_i$, is closed under
multiplication, so we can
 localize. $R[S^{-1}] = R_S$ is called the \emph{semi-localization}
 \index{semi-localization} of $R$ at the $\mathfrak{p}_i$.

The result of semi-localization is always semi-local. To see this, recall that
the ideals
 in $R_S$ are in bijection with ideals in $R$ contained in $\bigcup
 \mathfrak{p}_i$. Now use prime avoidance.
\end{exercise}

\begin{definition}
For a finitely generated $R$-module $M$, define $\mu_R(M)$ to be the smallest
number
   of elements that can generate $M$.
 \end{definition}
This is not the same as the cardinality of a minimal set of generators. For
example, 2
and 3 are a minimal set of generators for $\mathbb{Z}$ over itself, but
$\mu_\mathbb{Z} (\mathbb{Z}) =1$.

 \begin{theorem}
Let $R$ be semi-local with maximal ideals $\mathfrak{m}_1,\dots,
\mathfrak{m}_n$. Let $k_i = R/\mathfrak{m}_i$. Then
   \[
     \mathfrak{m}u_R(M) = \mathfrak{m}ax \{\dim_{k_i} M/\mathfrak{m}_i M\}
   \]
 \end{theorem}
\begin{proof}
\add{proof}
\end{proof}

\section{Nilpotent elements}

We will now prove a few general results about nilpotent results in a ring.
Topologically, the nilpotents do very little: quotienting by them will not
change the $\spec$. Nonetheless, they carry geometric importance, and one
thinks of these nilpotents as ``infinitesimal thickenings'' (in a sense to be
elucidated below).

\subsection{The radical of a ring}
There is a useful corollary of the analysis in the previous section about the
$\spec$ of a ring.

\begin{definition}
 $x \in R$ is called \textbf{nilpotent} if a power of $x$ is zero. The set of
 nilpotent elements in $R$ is called the \textbf{radical} of $R$ and is denoted
 $\rad(R)$ (which is an abuse of notation).
\end{definition}

The set of nilpotents is just the radical $\rad((0))$ of the zero ideal, so it
is an ideal. It can vary greatly.
A domain clearly has no nonzero nilpotents. On the other hand, many rings do:

\begin{example}
For any $n \geq 2$, the ring $\mathbb{Z}[X]/(X^n)$ has a nilpotent, namely $X$.
The ideal of nilpotent elements is $(X)$.
\end{example}

It is easy to see that a nilpotent must lie in any prime ideal. The converse
is also true by the previous analysis.
As a corollary of it, we find in fact:

\begin{corollary} \label{nilradicalisprimes}
Let $R$ be a commutative ring. Then the set of nilpotent elements of $R$ is
precisely $\bigcap_{\mathfrak{p} \in \spec R} \mathfrak{p}$.
\end{corollary}
\begin{proof}
Apply \rref{radprimescontaining} to the zero ideal.
\end{proof}

We now consider a few examples of nilpotent elements.
\begin{example}[Nilpotents in polynomial rings]
Let us now compute the nilpotent elements in the polynomial $R[x]$.
The claim is that a polynomial $\sum_{m=0}^n a_m x^m \in R[x]$ is nilpotent if
and only
if all the coefficients $a_m \in R$ are nilpotent. That is, $\rad(R[x]) =
(\rad(R))R[x]$.

If $a_0,\ldots,a_n$ are nilpotent, then because the nilpotent
elements form an ideal, $f=a_0+\cdots+a_nx^n$ is nilpotent. Conversely,
if $f$ is nilpotent, then $f^m=0$ and thus $(a_nx^n)^m=0$. Thus $a_nx^n$
is nilpotent, and because the nilpotent elements form an ideal, $f-a_nx^n$
is nilpotent. By induction, $a_ix^i$ is nilpotent for all $i$, so that all
$a_i$ are nilpotent.
\end{example}

Before the next example, we need to define a new notion.
We now define a power series ring intuitively in the same way they are used in
calculus. In fact, we will use power series rings much the same way we used them
in calculus; they will serve as keeping track of fine local data that the
Zariski topology might ``miss'' due to its coarseness.
\begin{definition} \label{powerseriesring} Let $R$ be a ring. The \textbf{power series ring} $R[[x]]$ is just the set of all
expressions of the form $\sum_{i=0}^\infty c_i x^i$. The arithmetic for the
power series ring will be done term by term formally (since we have no topology,
we can't consider questions of convergence, though a natural topology can be
defined making $R[[x]]$ the \emph{completion} of another ring, as we shall
see later). \end{definition}




\begin{example}[Nilpotence in power series rings]
Let $R$ be  a ring such that $\rad(R)$ is a finitely generated ideal. (This is
satisfied, e.g., if $R$ is \emph{noetherian}, cf. \rref{noetherian}.)
Let us consider the question of how $\rad(R)$ and $\rad(R[[x]])$ are related.
The claim is that
\[ \rad(R[[x]]) = (\rad(R))R[[x]].  \]

If $f\in R[[x]]$ is nilpotent, say with $f^n=0$, then
certainly $a_0^n=0$, so that $a_0$ is nilpotent. Because the nilpotent elements
form an ideal, we have that $f-a_0$ is also nilpotent, and hence by induction
every coefficient of $f$ must be nilpotent in $R$.
For the converse, let $I =
\rad(R)$. There
exists an $N>0$ such that the ideal power $I^N  = 0$ by finite generation.
Thus if $f \in IR[[x]]$, then $f^N \in I^N R[[x]] = 0$.
\end{example}
\begin{exercise} \label{nilpcriterion}
Prove that $x \in R$ is nilpotent if and only if the localization $R_x$ is the
zero ring.
\end{exercise}

\begin{exercise}
Construct an example where $\rad(R) R[[x]] \neq \rad(R[[x]])$. (Hint: consider
$R = \mathbb{C}[X_1, X_2, X_3, \dots]/(X_1, X_2^2, X_3^3, \dots)$.)
\end{exercise}

\subsection{Lifting idempotents}

If $R$ is a ring, and $I \subset R$ a nilpotent ideal, then we want to think
of $R/I$ as somehow close to $R$. For instance, the inclusion $\spec R/I
\hookrightarrow \spec R$ is a homeomorphism, and one pictures that $\spec R$
has some ``fuzz'' added (with the extra nilpotents in $I$) that is killed in
$\spec R/I$.

One manifestation of the ``closeness'' of $R$ and $R/I$ is the following
result, which states that the idempotent elements\footnote{Recall that an
element $e \in R$ is idempotent if $e^2 = e$.} of the two are in natural
bijection.
For convenience, we state it in additional generality (that is, for
noncommutative rings).

\begin{lemma}[Lifting idempotents]
Suppose $I \subset R$ is a nilpotent two-sided ideal, for $R$ any\footnote{Not
necessarily commutative.} ring. Let
$\overline{e} \in R/I$ be an idempotent. Then there is an idempotent $e
\in R$ which reduces to $\overline{e}$.
\end{lemma}

Note that if $J$ is a two-sided ideal in a noncommutative ring, then so are the
powers of $J$.

\begin{proof} Let us first assume that $I^2 = 0$.
We can find $e_1 \in R$ which reduces to $e$, but $e_1$ is not necessarily
idempotent.
By replacing $R$ with $\mathbb{Z}[e_1]$ and $I$ with $\mathbb{Z}[e_1] \cap I$,
we may assume that $R$ is in fact commutative. 	
However,
\[ e_1^2 \in e_1 + I.  \]
Suppose we want to modify $e_1$ by $i$ such that $e = e_1 + i$ is
idempotent and $i \in I$; then $e$ will do as in the lemma. We would then
necessarily have
\[ e_1 + i = (e_1 + i)^2 = e_1^2 + 2e_1 i\quad \mathrm{as} \ I^2 =0 .  \]
In particular, we must satisfy
\[ i(1-2e_1) = e_1^2 - e_1  \in I. \]

We claim that $1 - 2e_1 \in R$ is invertible, so that we can solve for $i \in I$.
However, $R$ is commutative. It thus suffices to check that $1 - 2e_1$ lies in
no maximal ideal of $R$. But the image of $e_1$ in $R/\mathfrak{m}$ for any
maximal ideal $\mathfrak{m} \subset R$ is either zero or one. So $1 - 2e_1$ has
image either $1$ or $-1$ in $R/\mathfrak{m}$. Thus it is invertible.

This establishes the result when $I$ has zero square. In general, suppose $I^n
= 0$. We have the sequence of noncommutative rings:
\[ R \twoheadrightarrow R/I^{n-1} \twoheadrightarrow R/I^{n-2} \dots
\twoheadrightarrow R/I. \]
The kernel at each step is an ideal whose square is zero. Thus, we can use the
lifting idempotents partial result proved above each step of the way and left
$\overline{e}  \in R/I$ to some $e \in R$.
\end{proof}


While the above proof has the virtue of applying to noncommutative rings,
there is a more conceptual argument for commutative rings. The idea is that
idempotents in $A$ measure disconnections of $\spec A$.\footnote{More
generally, in any \emph{ringed space} (a space with a sheaf of rings), the
idempotents in the ring of global sections correspond to the disconnections of
the topological space.} Since the topological space underlying $\spec A$ is
unchanged when one quotients by nilpotents, idempotents are unaffected.
We prove:

\begin{proposition} If $X = \mathrm{Spec} \   A$, then there is a one-to-one
correspondence between $\idem(A)$ and the open and closed subsets of $X$.
\end{proposition}
\begin{proof} Suppose $I$ is the radical of $(e)$ for an
an idempotent $e \in R$. We show that $V(I)$ is open and closed. Since $V$ is
unaffected by passing to the radical, we will assume without loss of
generality that
\[ I = (e).  \]

I claim that $\spec R - V(I)$ is just $V(1-e) = V((1-e))$. This is a closed
set, so proving this claim will imply that $V(I)$ is open.  Indeed,
$V(e)=V((e))$ cannot intersect $V(1-e)$ because if
\[ \mathfrak{p} \in V(e) \cap V(1-e),  \]
then $e, 1-e \in \mathfrak{p}$, so $1 \in \mathfrak{p}$. This is a
contradiction since $\mathfrak{p}$ is necessarily prime.

Conversely, suppose that $\mathfrak{p} \in \spec R$ belongs to neither $V(e)$
nor $V(1-e)$. Then $e \notin \mathfrak{p}$ and $1-e \notin \mathfrak{p}$. So
the product
\[ e(1-e)  = e-e^2 = 0  \]
cannot lie in $\mathfrak{p}$. But necessarily $0 \in \mathfrak{p}$,
contradiction. So $V(e) \cup V(1-e) = \spec R$. This implies the claim.

Next, we show that if $V(I)$ is open, then $I$ is the radical of $(e)$ for an
idempotent $e$. For this it is sufficient to  prove:

\begin{lemma}
Let $I \subset R$ be such that $V(I) \subset \spec R$ is open. Then $I$
is principal, generated by $(e)$ for some idempotent $e \in R$.
\end{lemma}
\begin{proof}
Suppose that $\spec R - V(I) = V(J)$ for some ideal $J \subset R$. Then the
intersection $V(I) \cap V(J) = V(I+J)$ is all of $R$, so $I+J$ cannot be a
proper ideal (or it would be contained in a prime ideal). In particular, $I+J =
R$. So we can write
\[ 1 = x + y, \quad x \in I, y \in J.  \]

Now $V(I) \cup V(J) = V(IJ) = \spec R$. This implies that every element of
$IJ$  is nilpotent by the next lemma.
\end{proof}
\begin{lemma}
Suppose $V(X)=\spec R$ for $X \subset R$ an ideal. Then every element of $X$ is
nilpotent.
\end{lemma}
\begin{proof}
Indeed, suppose $x \in X$ were non-nilpotent.  Then the ring $R_x$ is not the
zero ring, so it has a prime ideal. The map $\spec R_x \to \spec R$ is, as
discussed in class, a homeomorphism of $\spec R_x$ onto $D(x)$.  So $D(x)
\subset \spec R$ (the collection of primes not containing $x$) is nonempty. In
particular, there is $\mathfrak{p} \in \spec R$ with $x \notin \mathfrak{p}$,
so $\mathfrak{p} \notin V(X)$. So $V(X) \neq \spec R$, contradiction.
\end{proof}

Return to the proof of the main result.  We have shown that $IJ$ is nilpotent.
In particular, in the expression $x+y=1$ we had earlier, we have that $xy$ is
nilpotent.  Say $(xy)^k = 0$. Then expand
\[ 1 = (x+y)^{2k} = \sum_{i=0}^{2k} \binom{2k}{i}x^i y^{2k-i} = \sum' + \sum''  \]
where $\sum'$ is the sum from $i=0$ to $i=k$ and $\sum''$ is the sum from
$k+1$ to $2k$. Then $\sum' \sum'' = 0$ because in every term occurring in the
expansion, a multiple of $x^k y^k$ occurs. Also, $\sum' \in I$ and $\sum'' \in
J$ because $x \in I, y \in J$.

All in all, we find that it is possible to write
\[ 1 = x' + y', \quad x' \in I, y' \in J, \ x'y' = 0.  \]
(We take $x' = \sum', y' = \sum''$.)
Then $x'(1-x') = 0$ so $x' \in I$ is idempotent. Similarly $y' = 1-x'$ is.
We have that
\[ V(I) \subset V(x'), \quad V(J) \subset V(y')  \]
and $V(x'), V(y')$ are complementary by the earlier arguments, so necessarily
\[ V(I) = V(x'), \quad V(J) = V(y').  \]
Since an ideal generated by an idempotent is automatically radical, it follows
that:
\[ I = (x'), \quad, J = (y').  \]
\end{proof}


There are some useful applications of this in representation theory, because
one can look for idempotents in endomorphism rings; these indicate whether a module can be decomposed as a direct sum into smaller parts.  Except, of course, that endomorphism rings aren't necessarily commutative and this proof breaks down.

Thus we get:
\begin{proposition} Let $A$ be a ring and $I$ a nilpotent ideal.  Then
$\idem(A) \to \idem(A/I)$ is bijective.
\end{proposition}
\begin{proof}
Indeed, the topological spaces of $\mathrm{Spec} \   A$ and $\mathrm{Spec} \
A/I$ are the same.   The result then follows from \cref{}.
\end{proof}


\subsection{Units}
Finally, we make a few remarks on \emph{units} modulo nilideals.
It is a useful and frequently used trick that adding a nilpotent does not
affect the collection of units. This trick is essentially an algebraic version of
the
familiar ``geometric series;'' convergence questions do not appear thanks to
nilpotence.

\begin{example}
Suppose $u$ is a unit in a ring $R$ and $v \in R$ is nilpotent; we show that $a+v$ is a unit.

Suppose $ua=1$ and $v^m=0$ for some
$m>1$. Then  $(u+v)\cdot a(1-av+(av)^2-\cdots\pm(av)^{m-1})=$
$(1-(-av))(1+(-av)+(-av)^2+\cdots+(-av)^{m-1})=1-(-av)^m=1-0=1$, so $u+v$
is a unit.
\end{example}




So let $R$ be a ring, $I \subset R$ a nilpotent ideal \emph{of square zero}.
Let $R^*$ denote the group of units in $R$, as usual, and let $(R/I)^*$ denote
the
group of units in $R/I$.
We have an exact sequence of abelian groups:
\[ 0 \to I \to R^* \to (R/I)^* \to 0  \]
where the second map is reduction and the first map sends $i \to 1+i$.
The hypothesis that $I^2 = 0$ shows that the first map is a homomorphism.
We should check that the last map is surjective. But if any $a \in R$ maps to a
unit in $R/I$, it clearly can lie in no prime ideal of $R$, so is a unit itself.
\section{Vista: sheaves on $\spec R$}

\subsection{Presheaves}
Let $X$ be a topological space.
\begin{definition}
A \textbf{presheaf of sets} $\mathcal{F}$ on $X$ assigns to
every open subset
$U \subset X$ a set $\mathcal{F} (U)$, and to every inclusion $U
\subset V$ a
\textbf{restriction map}
$\mathrm{res}^V_U : \mathcal{F}(V) \to \mathcal{F}(U)$. The
restriction map is
required to satisfy:
\begin{enumerate}
\item $\res^U_U = \id_{\mathcal{F}(U)} $ for all open sets $U$.
\item $\res^W_U = \res^V_U \circ \res^W_V $ if $U \subset V
\subset W$.
\end{enumerate}

If the sets $\mathcal{F}(U)$ are all groups (resp. rings), and
the restriction
maps are morphisms of groups (resp. rings), then we say that
$\mathcal{F}$ is a
sheaf of groups (resp. rings). Often the restriction of an
element $a\in U$ to a subset $W$ is denoted $a|_W$.

A \textbf{morphism} of presheaves $\mathcal{F} \to \mathcal{G}$ is a
collection of maps $\mathcal{F}(U) \to \mathcal{G}(U)$ for each open set $U$,
that commute with the restriction maps in the obvious way. Thus the collection
of presheaves on a topological space forms a category.
\end{definition}


One should think of the restriction maps as kind of like
restricting the
domain of a function.
The standard example of presheaves is given in this way, in
fact.

\begin{example}
Let $X$ be a topological space, and $\mathcal{F}$ the presheaf
assigning to
each $U \subset X$ the set of continuous functions $U \to
\mathbb{R}$. The
restriction maps come from restricting the domain of a function.\end{example}

Now, in classical algebraic geometry, there are likely to be
more
continuous functions in the Zariski topology than one really
wants. One wants
to focus on functions that are given by polynomial equations.

\begin{example}
Let $X$ be the topological space $\mathbb{C}^n$ with the
topology where the
closed sets are those defined by the zero loci of polynomials
(that is, the
topology induced on $\mathbb{C}^n$ from the Zariski topology of
$\spec
\mathbb{C}[x_1, \dots, x_n]$ via the canonical imbedding
$\mathbb{C}^n
\hookrightarrow \spec \mathbb{C}[x_1, \dots, x_n]$). Then there
is a presheaf
assigning to each open set $U$ the collection of rational
functions defined
everywhere on $U$, with the restriction maps being the obvious
ones.
\end{example}




\begin{remark}
The notion of presheaf thus defined relied very little on the topology of $X$.
In fact, we could phrase it in purely categorical terms. Let $\mathcal{C}$ be
the category consisting of open subsets $U \subset X$ and inclusions of open
subsets $U
\subset U'$. This is a rather simple category (the hom-sets are either empty
or consist of one element). Then a \emph{presheaf} is just a contravariant
functor from $\mathcal{C}$ to $\mathbf{Sets}$ (or $\mathbf{Grp}$, etc.). A
morphism of presheaves is a natural transformation of functors.

In fact, given any category $\mathcal{C}$, we can define the \emph{category of
presheaves} on it to be the category of functors $\mathbf{Fun}(\mathcal{C}^{op}, \mathbf{Set})$.
This category is complete and cocomplete (we can calculate limits and colimits
``pointwise''), and the Yoneda embedding realizes $\mathcal{C}$ as a full
subcategory of it. So if $X \in \mathcal{C}$, we get a presheaf $Y \mapsto
\hom_{\mathcal{C}}(Y, X)$. In general, however, such representable presheaves
are rather special; for instance, what do they look like for the category of
open sets in a topological space?
\end{remark}

\subsection{Sheaves}

\begin{definition} Let $\mathcal{F}$ be a presheaf of sets
 on a topological space $X$. We call $\mathbb{F}$ a
\textbf{sheaf} if $\mathcal{F}$ further satisfies the following two
``sheaf conditions.''
\begin{enumerate}
\item(Separatedness) {If $U$ is an open set of $X$ covered by a family of open subsets $\{U_i\}$ and there
are two elements $a,b\in \mathcal{F}(U)$ such that
$a|_{U_i}=b|_{U_i}$ for all $U_i$, then $a=b$.}
\item(Gluability) {If $U$ is an open set of $X$ covered by $U_i$ and there
are elements $a_i\in \mathcal{F}(U_i)$ such that $a_i|_{U_i\cap
U_j} = a_j|_{U_i\cap U_j}$ for all $i$ and $j$, then there
exists an element $a\in\mathcal{F}(U)$ that restricts to the
$a_i$. Notice that by the first axiom, this element is unique.}
\end{enumerate}
A \emph{morphism} of sheaves is just a morphism of presheaves, so the sheaves
on a topological space $X$ form a
full subcategory of presheaves on $X$.
\end{definition}

The above two conditions can be phrased more compactly as follows. Whenever
$\left\{U_i\right\}_{i \in I}$ is an open cover of $U \subset X$, we require that the
following sequence be an equalizer of sets:
\[  \mathcal{F}(U) \to \prod_{i \in I} \mathcal{F}(U_i) \rightrightarrows \prod_{i,j \in I}
\mathcal{F}(U_i \cap U_j) \]
where the two arrows correspond to the two allowable restriction maps.
Similarly, we say that a presheaf of abelian groups (resp. rings) is a
\textbf{sheaf} if it is a sheaf of sets.

\begin{example}
The example of functions gives an example of a sheaf, because functions are
determined by their restrictions to an open cover! Namely, if $X$ is a
topological space, and we consider the presheaf
\[ U \mapsto \left\{\text{continuous functions } U \to \mathbb{R}\right\} , \]
then this is clearly a presheaf, because we can piece together continuous
functions in a unique manner.
\end{example}

\begin{example}
Here is a refinement of the above example. Let $X$ be a smooth manifold.
For each $U$, let $\mathcal{F} (U)$ denote the group of smooth functions $U
\to \mathbb{R}$. This is easily checked to be a sheaf.

We could, of course, replace ``smooth'' by ``$C^r$'' or by ``holomorphic'' in
the case of a complex manifold.
\end{example}


\begin{remark}
As remarked above, the notion of presheaf can be defined on any category, and
does not really require a topological space. The definition of a sheaf
requires a bit more topologically, because the idea that a family
$\left\{U_i\right\}$ \emph{covers} an open set $U$ was used inescapably in the
definition. The idea of covering required the internal structure of the open
sets and was not a purely categorical idea. However, Grothendieck developed a
way to axiomatize this, and introduced the idea of a \emph{Grothendieck
topology} on a category (which is basically a notion of when a family of maps
\emph{covers} something). On a category with a Grothendieck topology (also
known as a \emph{site}), one can define the notion of a sheaf in a similar
manner as above. See \cite{Vi08}.
\end{remark}




There is a process that allows one to take any presheaf and
associate a sheaf to it. In some sense, this associated sheaf should also be the best ``approximation'' of our presheaf with a sheaf. This motivates the
following universal property:

\begin{definition} Let $\mathcal{F}$ be a presheaf. Then $\mathcal{F'}$ is said
to be the sheafification of $\mathcal{F}$ if for any sheaf $\mathcal{G}$ and a
morphism $\mathcal{F}\rightarrow \mathcal{G}$, there is a unique factorization
of this morphism as $\mathcal{F}\rightarrow\mathcal{F'}\rightarrow\mathcal{G}$.
\end{definition}

\begin{theorem} We can construct the sheafification of a presheaf $\mathcal{F}$
as follows: $\mathcal{F}'(U)=\{s:U\rightarrow\coprod_{x\in U}\mathcal{F}_x |
\text{for all }x\in U, s(x)\in\mathcal{F}_x \text{ and there is a neighborhood
}V\subset U \text{ and }t\in \mathcal{F}(V) \text{ such that for all }y\in V,
s(y) \text{ is the image of } t \text{ in the local ring }\mathcal{F}_y\}$.
\end{theorem}
\add{proof}

In the theory of schemes, when one wishes to replace polynomial
rings over
$\mathbb{C}$ (or an algebraically closed field) with arbitrary
commutative
rings, one must drop the idea that a sheaf is necessarily given
by functions.
A \emph{scheme} is defined as a space with a certain type of
sheaf of rings on
it. We shall not define a scheme formally, but show how on the
building blocks
of schemes---objects of the form $\spec A$---a sheaf of rings
can be defined.



\subsection{Sheaves on $\spec A$}

\add{we need to describe how giving sections over basic open sets gives  a
presheaf in general}.

\begin{proposition}
Let $ A$ be a ring and let $ X = \mathrm{Spec}(A)$. Then the
assignment of the ring $A_f$ to the basic open set $X_f$ defines
a presheaf of rings on $X$.
\end{proposition}

\begin{proof} \mbox{}

\emph{Part (i)}. If $ X_g \subset X_f$ are basic open sets,
then there exist $ n \geq 1$ and $ u \in A$ such that $ g^n =
uf$.

\emph{Proof of part (i)}. Let $ S = \{g^n : n \geq 0\}$ and
suppose $ S \cap (f) = \emptyset$. Then the extension $ (f)^e$
into $ S^{-1}A$ is a proper ideal, so there exists a maximal
ideal $ S^{-1}\mathfrak{p}$ of $ S^{-1}A$, where $ \mathfrak{p}
\cap S = \emptyset$. Since $ (f)^e \in S^{-1}\mathfrak{p}$, we
see that $ f/1 \in S^{-1}\mathfrak{p}$, so $ f \in
\mathfrak{p}$. But $ S \cap \mathfrak{p} = \emptyset$ implies
that $ g \notin \mathfrak{p}$. This is a contradiction, since
then $ \mathfrak{p} \in X_g \setminus X_f$.

\emph{Part (ii)}. If $ X_g \subset X_f$, then there exists a
unique map $ \rho : A_f \to A_g$, called the restriction map,
which makes the following diagram commute.
\[ \xymatrix{ & A \ar[dl] \ar[dr] & \\ A_f \ar[rr] & & A_g } \]

\emph{Proof of part (ii)}.
Let $ n \geq 1$ and $ u \in A$ be such that $ g^n = uf$ by part
(i). Note that in $ A_g$,
\[ (f/1)(u/g^n) = (fu/g^n) = 1/1 = 1 \]
which means that $ f$ maps to a unit in $ A_g$. Hence every $
f^m$ maps to a unit in $ A_g$, so the universal property of $
A_f$ yields the desired unique map $ \rho : A_f \to A_g$.

\emph{Part (iii)}.
If $ X_g = X_f$, then the corresponding restriction $ \rho : A_f
\to A_g$ is an isomorphism.

\emph{Proof of part (iii)}.
The reverse inclusion yields a $ \rho' : A_g \to A_f$ such that
the diagram
\[ \xymatrix{
& A \ar[dr] \ar[dl] & \\
A_f \ar@/^/[rr]^{\rho} & & A_g \ar@/^/[ll]^{\rho'}
} \]
commutes. But since the localization map is epic, this implies
that $ \rho \rho' = \rho' \rho = \mathbf{1}$.

\emph{Part (iv)}.
If $ X_h \subset X_g \subset X_f$, then the diagram
\[ \xymatrix{
A_f \ar[rr] \ar[dr] & & A_h \\
& A_g \ar[ur] &
} \]
of restriction maps commutes.

\emph{Proof of part (iv)}.
Consider the following tetrahedron.
\[ \xymatrix{
& A \ar[dl] \ar[dr] \ar[dd] & \\
A_f \ar@{.>}[rr] \ar[dr] & & A_h \\
& A_g \ar[ur] &
} \]
Except for the base, the commutativity of each face of the
tetrahedron follows from the universal property of part (ii).
But its easy to see that commutativity of the those faces
implies commutativity of the base, which is what we want to
show.

\emph{Part (v)}.
If $ X_{\tilde{g}} = X_g \subset X_f = X_{\tilde{f}}$, then
the diagram
\[ \xymatrix{
A_f \ar[r] \ar[d] & A_g \ar[d] \\
A_{\tilde{f}} \ar[r] & A_{\tilde{g}}
} \]
of restriction maps commutes. (Note that the vertical maps here
are isomorphisms.)

\emph{Proof of part (v)}.
By part (iv), the two triangles of
\[ \xymatrix{
A_f \ar[r] \ar[d] \ar[dr] & A_g \ar[d] \\
A_{\tilde{f}} \ar[r] & A_{\tilde{g}}
} \]
commute. Therefore the square commutes.

\emph{Part (vi)}.
Fix a prime ideal $ \mathfrak{p}$ in $ A$. Consider the direct
system consisting of rings $ A_f$ for every $ f \notin
\mathfrak{p}$ and restriction maps $ \rho_{fg} : A_f \to A_g$
whenever $ X_g \subset X_f$. Then $ \varinjlim A_f \cong
A_{\mathfrak{p}}$.

\emph{proof of part (vi)}.
First, note that since $ f \notin \mathfrak{p}$ and $
\mathfrak{p}$ is prime, we know that $ f^m \notin \mathfrak{p}$
for all $ m \geq 0$. Therefore the image of $ f^m$ under the
localization $ A \to A_\mathfrak{p}$ is a unit, which means the
universal property of $ A_f$ yields a unique map $ \alpha_f :
A_f \to A_\mathfrak{p}$ such that the following diagram
commutes.
\[ \xymatrix{
& A \ar[dr] \ar[dl] & \\
A_f \ar[rr]^{\alpha_f} & & A_{\mathfrak{p}}
} \]
Then consider the following tetrahedron.
\[ \xymatrix{
& A \ar[dl] \ar[dr] \ar[dd] & \\
A_f \ar@{.>}[rr] \ar[dr] & & A_h \\
& A_\mathfrak{p} \ar[ur] &
} \]
All faces except the bottom commute by construction, so the
bottom face commutes as well. This implies that the $ \alpha_f$
commute with the restriction maps, as necessary. Now, to see
that $ \varinjlim A_f \cong A_\mathfrak{p}$, we show that $
A_\mathfrak{p}$ satisfies the universal property of $ \varinjlim
A_f$.

Suppose $ B$ is a ring and there exist maps $ \beta_f : A_f \to
B$ which commute with the restrictions. Define $ \beta : A \to
B$ as the composition $ A \to A_f \to B$. The fact that $ \beta$
is independent of choice of $ f$ follows from the commutativity
of the following diagram.
\[ \xymatrix{
& A \ar[dr] \ar[dl] & \\
A_f \ar[rr]^{\rho_{fg}} \ar[dr]^{\beta_f} & & A_g
\ar[dl]_{\beta_g} \\
& B
} \]
Now, for every $ f \notin \mathfrak{p}$, we know that $
\beta(f)$ must be a unit since $ \beta(f) = \beta_f(f/1)$ and $
f/1$ is a unit in $ A_f$. Therefore the universal property of $
A_\mathfrak{p}$ yields a unique map $ A_{\mathfrak{p}} \to B$,
which clearly commutes with all the arrows necessary to make $
\varinjlim A_f \cong A_\mathfrak{p}$.
\end{proof}


\begin{proposition}
Let $ A$ be a ring and let $ X = \mathrm{Spec}(A)$. The presheaf
of rings $ \mathcal{O}_X$ defined on $ X$ is a sheaf.
\end{proposition}

\begin{proof}
The proof proceeds in two parts. Let $ (U_i)_{i \in I}$ be a
covering of $ X$ by basic open sets.

\emph{Part 1}. If $ s \in A$ is such that $ s_i := \rho_{X,
U_i}(s) = 0$ for all $ i \in I$, then $ s = 0$.

\emph{Proof of part 1}. Suppose $ U_i = X_{f_i}$. Note that $
s_i$ is the fraction $ s/1$ in the ring $ A_{f_i}$, so $ s_i =
0$ implies that there exists some integer $ m_i$ such that $
sf_i^{m_i} = 0$. Define $ g_i = f_i ^{m_i}$, and note that we
still have an open cover by sets $ X_{g_i}$ since $ X_{f_i} =
X_{g_i}$ (a prime ideal contains an element if and only if it
contains every power of that element). Also $ s g_i = 0$, so the
fraction $ s/1$ is still $ 0$ in the ring $ A_{g_i}$.
(Essentially, all we're observing here is that we are free to
change representation of the basic open sets in our cover to
make notation more convenient).

Since $ X$ is quasi-compact, choose a finite subcover $ X =
X_{g_1} \cup \dotsb \cup X_{g_n}$. This means that $ g_1,
\dotsc, g_n$ must generate the unit ideal, so there exists some
linear combination $ \sum x_i g_i = 1$ with $ x_i \in A$. But
then
\[ s = s \cdot 1 = s \left( \sum x_i g_i \right) = \sum x_i (s
g_i) = 0.\]

\emph{Part 2}. Let $ s_i \in \mathcal{O}_X(U_i)$ be such that
for every $ i, j \in I$,
\[ \rho_{U_i, U_i \cap U_j}(s_i) = \rho_{U_j, U_i \cap
U_j}(s_j).\]
(That is, the collection $ (s_i)_{i \in I}$ agrees on overlaps).
Then there exists a unique $ s \in A$ such that $ \rho_{X,
U_i}(s) = s_i$ for every $ i \in I$.

\emph{Proof of part 2}. Let $ U_i = X_{f_i}$, so that $ s_i =
a_i/(f_i^{m_i})$ for some integers $ m_i$. As in part 1, we can
clean up notation by defining $ g_i = f_i^{m_i}$, so that $ s_i
= a_i/g_i$. Choose a finite subcover $ X = X_{g_1} \cup \dotsb
\cup X_{g_n}$. Then the condition that the cover agrees on
overlaps means that
\[ \frac{a_i g_j}{g_i g_j} = \frac{a_j g_i}{g_i g_j} \]
for all $ i, j$ in the finite subcover. This is equivalent to
the existence of some $ k_{ij}$ such that
\[ (a_i g_j - a_j g_i) (g_i g_j)^{k_{ij}} = 0.\]
Let $ k$ be the maximum of all the $ k_{ij}$, so that $ (a_i g_j
- a_j g_i)(g_i g_j)^k = 0$ for all $ i, j$ in the finite
subcover. Define $ b_i = a_i g_i^k$ and $ h_i = g_i^{k+1}$. We
make the following observations:
\[ b_i h_j - b_j h_i = 0, X_{g_i} = X_{h_i}, \text{ and } s_i =
a_i/g_i = b_i/h_i \]
The first observation implies that the $ X_{h_i}$ cover $ X$, so
the $ h_i$ generate the unit ideal. Then there exists some
linear combination $ \sum x_i h_i = 1$. Define $ s = \sum x_i
b_i$. I claim that this is the global section that restricts to
$ s_i$ on the open cover.

The first step is to show that it restricts to $ s_i$ on our
chosen finite subcover. In other words, we want to show that $
s/1 = s_i = b_i/h_i$ in $ A_{h_i}$, which is equivalent to the
condition that there exist some $ l_i$ such that $ (sh_i b_i)
h_i^{l_i} = 0$. But in fact, even $ l_i = 0$ works:
\[ sh_i - b_i = \left(\sum x_j b_j\right) h_i - b_i\left(\sum
x_j h_j\right) = \sum x_j\left(h_i b_j - b_i h_j\right) = 0. \]
This shows that $ s$ restricts to $ s_i$ on each set in our
finite subcover. Now we need to show that in fact, it restricts
to $ s_i$ for all of the sets in our cover. Choose any $ j \in
I$. Then $ U_1, \dotsc, U_n, U_j$ still cover $ X$, so the above
process yields an $ s'$ such that $ s'$ restricts to $ s_i$ for
all $ i \in \{1, \dotsc, n, j\}$. But then $ s - s'$ satisfies
the assumptions of part 1 using the cover $ \{U_1, \dotsc, U_n,
U_j\}$, so this means $ s = s'$. Hence the restriction of $ s$
to $ U_j$ is also $ s_j$.
\end{proof}


% ============================ chapters/noetherian.tex}
\chapter{Noetherian rings and modules}
\label{noetherian}

The finiteness condition of a noetherian ring is necessary for much of
commutative algebra; many of the results we prove after this will apply only (or mostly) to the
noetherian case. In algebraic geometry, the noetherian condition guarantees
that the topological space associated to the ring (the $\spec $) has all its
sets quasi-compact; this condition can be phrased as saying that the space
itself is noetherian in a certain sense.

We shall start by proving the basic properties of noetherian rings. These are
fairly standard and straightforward; they could have been placed after
\rref{foundations}, in fact. More subtle is the structure theory for
finitely generated modules over a noetherian ring. While there is nothing as
concrete as there is for PIDs (there, one has a very explicit descrition for
the isomorphism classes), one can still construct a so-called ``primary
decomposition.'' This will be the primary focus after the basic properties of
noetherian rings and modules have been established. Finally, we finish with an
important subclass of noetherian rings, the \emph{artinian} ones.


\section{Basics}

\subsection{The noetherian condition}


\begin{definition}
Let $R$ be a commutative ring and $M$ an $R$-module. We say that $M$ is
\textbf{noetherian} if every submodule of $M$ is finitely generated.
\end{definition}


There is a convenient
reformulation of the finiteness hypothesis above in terms of the
\emph{ascending chain condition}.

\begin{proposition} $M$ is a module over $R$.
The following are equivalent:
\begin{enumerate}
\item $M$ is noetherian.
\item Every chain of submodules  $M_0 \subset M_1 \subset \dots \subset M$,
eventually stabilizes at some $M_N$. (Ascending chain condition.)
\item Every nonempty collection of submodules of $M$ has a maximal element.
\end{enumerate}
\end{proposition}
\begin{proof}
Say $M$ is noetherian and we have such a chain
\[ M_0 \subset M_1 \subset \dots.  \]
Write
\[ M' = \bigcup M_i \subset M,  \]
which is finitely generated since $M$ is noetherian. Let it be generated by
$x_1, \dots,x_n$. Each of these finitely many elements is in the union, so
they are all contained in some $M_N$. This means that
\[ M' \subset M_N, \quad \mathrm{so} \quad M_N = M'  \]
and the chain stabilizes.

For the converse, assume the ACC.  Let $M' \subset M$ be any submodule.  Define
a chain of submodules $M_0 \subset M_1 \subset  \dots \subset M'$ inductively as follows. First, just take
$M_0 = \left\{0\right\}$. Take $M_{n+1}$ to be $M_n + Rx$ for  some $x \in
M' - M_n$, if such an $x$ exists; if not take $M_{n+1}=M_n$.
So $M_0$ is zero,
$M_1$ is generated by some nonzero element of $M'$, $M_2$ is $M_1$ together
with some element of $M'$ not in $M_1$, and so on, until (if ever) the chain
stabilizes.

However, by construction, we have an ascending
chain, so it stabilizes at some finite place by the ascending chain condition.
Thus, at some point, it is
impossible to choose something in $M'$ that does not belong to  $M_N$. In
particular, $M'$ is generated by $N$ elements, since $M_N$ is and $M' = M_N$.
This proves the reverse implication. Thus the equivalence of 1 and 2 is clear.
The equivalence of 2 and 3 is left to the reader.
\end{proof}


Working with noetherian modules over non-noetherian rings can be a little
funny, though, so normally this definition is combined with:


\begin{definition}
The ring $R$ is \textbf{noetherian} if $R$ is noetherian as an $R$-module.
Equivalently phrased, $R$ is noetherian if all of its ideals are finitely generated.
\end{definition}

We start with the basic examples:

\begin{example}
\begin{enumerate}
\item Any field is noetherian. There are two ideals: $(1)$ and $(0)$.
\item Any PID is noetherian: any ideal is generated by one element. So
$\mathbb{Z}$ is noetherian.
\end{enumerate}
\end{example}

The first basic result we want to prove is that over a noetherian ring, the
noetherian modules are precisely the finitely generated ones.  This will
follow from \rref{exactnoetherian} in the next subsection. So the defining
property of noetherian rings is that a submodule of a finitely generated
module is finitely generated. (Compare
\rref{noetherianiffg}.)

\begin{exercise}
The ring $\mathbb{C}[X_1, X_2, \dots]$ of polynomials in infinitely many
variables is not noetherian. Note that the ring itself is finitely generated
(by the element $1$), but there are ideals that are not finitely generated.
\end{exercise}

\begin{remark}
Let $R$ be a ring such that every \emph{prime} ideal is finitely generated.
Then $R$ is noetherian. See \rref{primenoetherian}, or prove it as
an exercise. \end{remark}

\subsection{Stability properties}

The class of noetherian rings is fairly robust. If one starts with a
noetherian ring, most of the elementary operations one can do to it lead to
noetherian rings.

\begin{proposition} \label{exactnoetherian}
If
\[ 0 \to M' \to  M \to M'' \to 0  \]
is an exact sequence of modules, then $M$ is noetherian if and only if $M',
M''$ are.
\end{proposition}

One direction states that noetherianness is preserved under subobjects and
quotients. The other direction states that noetherianness is preserved under
extensions.
\begin{proof}
If $M$ is noetherian, then every submodule of $M'$ is a submodule of $M$, so is
finitely generated. So $M'$ is noetherian too. Now we show that $M''$ is
noetherian. Let $N \subset M''$ and let
$\widetilde{N} \subset M$ the inverse image. Then $\widetilde{N}$ is finitely generated, so
$N$---as the homomorphic image of $\widetilde{N}$---is finitely generated
So $M''$ is noetherian.

Suppose $M', M''$ noetherian. We prove $M$ noetherian.
We verify the ascending chain condition. Consider
\[ M_1 \subset M_2 \subset \dots \subset M.  \]
Let $M_i''$ denote the image of $M_i$ in $M''$ and let $M'_i$ be the
intersection of $M_i$ with $M'$. Here we think of $M'$ as a submodule of $M$.
These are ascending chains of submodules of $M', M''$, respectively, so they
stabilize by noetherianness.
So for some $N$, we have
that $n \geq N$ implies
\[ M'_n = M'_{n+1}, \quad M''_n = M''_{n+1}.  \]

We claim that this implies, for such $n$,
\[ M_n = M_{n+1}.  \]
Indeed, say $x \in M_{n+1} \subset M$. Then $x$ maps into something in $M''_{n+1} = M''_n$.
So there is something in $M_n$, call it $y$, such that $x,y$ go to the same
thing in $M''$. In particular,
\[ x - y \in M_{n+1} \]
goes to zero in $M''$, so $x-y \in M'$. Thus $x-y \in M'_{n+1} = M'_n$. In
particular,
\[ x = (x-y) + y \in M'_n + M_n = M_n.  \]
So $x \in M_n$, and
\[ M_n = M_{n+1} . \]
This proves the result.
\end{proof}

The class of noetherian modules is thus ``robust.'' We can get from that the
following.

\begin{proposition}
If $\phi: A \to B$ is a surjection of commutative rings and $A$ is noetherian, then $B$ is
noetherian too.
\end{proposition}
\begin{proof}
Indeed, $B$ is noetherian as an $A$-module; indeed, it is the quotient of a
noetherian $A$-module (namely, $A$). However, it is easy to see that the
$A$-submodules of $B$ are just the $B$-modules in $B$, so $B$ is noetherian as a
$B$-module too. So $B$ is noetherian.
\end{proof}

We know show that noetherianness of a ring is preserved by localization:
\begin{proposition}
Let $R$ be a commutative ring, $S \subset R$ a multiplicatively closed subset.   If
$R$ is noetherian, then $S^{-1}R$ is noetherian.
\end{proposition}
I.e., the class of noetherian rings is closed under localization.
\begin{proof}
Say $\phi: R \to S^{-1}R$ is the canonical map. Let $I \subset S^{-1}R$ be an
ideal. Then $\phi^{-1}(I) \subset R$ is an ideal, so finitely generated. It
follows that
\[ \phi^{-1}(I)( S^{-1}R )\subset S^{-1}R  \]
is finitely generated as an ideal in $S^{-1}R$; the generators are the images
of the generators of $\phi^{-1}(I)$.

Now we claim that
\[  \phi^{-1}(I)( S^{-1}R ) = I . \]
The inclusion $\subset$ is trivial. For the latter inclusion, if $x/s \in I$,
then $x \in \phi^{-1}(I)$, so
\[ x = (1/s) x \in (S^{-1}R) \phi^{-1}(I).  \] This proves the claim and
implies that $I$ is finitely generated.
\end{proof}

Let $R$ be a noetherian ring.  We now characterize the noetherian $R$-modules.
\begin{proposition} \label{noetherianiffg}
An $R$-module $M$ is noetherian if and only if $M$ is finitely generated.
\end{proposition}
\begin{proof}
The only if direction is obvious. A module is noetherian if and only if every
submodule is finitely generated.

For the if direction, if $M$ is finitely generated, then there is  a surjection
of $R$-modules
\[ R^n \to M  \]
where $R$ is noetherian. But $R^n$ is noetherian by
\rref{exactnoetherian} because it is a direct sum
of copies of $R$. So $M$ is a quotient of a noetherian module and is noetherian.

\end{proof}
\subsection{The basis theorem}
Let us now prove something a little less formal. This is, in fact, the biggest
of the ``stability'' properties of a noetherian ring: we are going to see that  finitely generated
algebras over noetherian rings are still noetherian.

\begin{theorem}[Hilbert basis theorem]\label{hilbbasis}
If $R$ is a noetherian ring, then the polynomial ring $R[X]$ is noetherian.
\end{theorem}
\begin{proof}
Let $I \subset R[X]$ be an ideal. We prove that it is finitely generated. For
each $m \in \mathbb{Z}_{\geq 0}$, let $I(n)$ be the collection of elements
$ a\in R$ consisting of the coefficients of $x^n$ of elements of $I$ of degree
$\leq n$.
This is an ideal, as is easily seen.

In fact, we claim that
\[ I(1) \subset I(2) \subset \dots  \]
which follows because if $ a\in I(1)$, there is an element $aX + \dots$ in $I$.
Thus $X(aX + \dots) = aX^2 + \dots \in I$, so $a \in I(2)$. And so on.

Since $R$ is noetherian, this chain stabilizes at some $I(N). $
Also, because $R$ is noetherian, each $I(n)$ is generated by finitely many
elements $a_{n,1}, \dots, a_{n, m_n} \in I(n)$. All of these come from polynomials
$P_{n,i} \in I$ such that $P_{n,i} = a_{n,i} X^n + \dots$.

The claim is that the $P_{n,i}$ for $n \leq N$ and $i \leq m_n$ generate $I$.
This is a finite set of polynomials, so if we prove the claim, we will have
proved the basis theorem. Let $J$ be the ideal generated by
$\left\{P_{n,i}, n \leq N, i \leq m_n \right\}$. We know $J \subset I$. We must
prove $I \subset J$.

We will show that any element $P(X) \in I$ of degree $n$ belongs to $J$ by
induction on $n$. The degree is the largest nonzero coefficient. In particular,
the zero polynomial does not have a degree, but the zero polynomial is
obviously in $J$.

There are two cases. In the first case, $n \geq N$. Then we write
\[ P(X) = a X^n + \dots .  \] By definition, $a \in I(n) = I(N)$ since the
chain of ideals $I(n)$ stabilized. Thus we can write $a$ in terms of the
generators:  $a = \sum a_{N, i} \lambda_i$ for some
$\lambda_i \in R$. Define the polynomial
\[ Q = \sum \lambda_i P_{N, i} x^{n-N} \in J.  \] Then $Q$ has degree $n$ and
the leading term is just $a$.  In particular,
\[ P - Q  \]
is in $I$ and has degree less than $n$. By the inductive hypothesis, this
belongs to $J$, and since $Q \in J$, it follows that $P \in J$.

Now consider the case of $n < N$.
Again, we write $P(X) = a X^n + \dots$. Then $a \in I(n)$.  We can write
\[ a = \sum a_{n,i} \lambda_i, \quad \lambda_i \in R.  \]
But the $a_{n,i} \in I(n)$. The polynomial
\[ Q = \sum \lambda_i P_{n,i}   \]
belongs to $J$ since $n  < N$. In the same way, $P-Q \in I$ has a lower degree.
Induction as before implies that $P \in J$.
\end{proof}


\begin{example}
Let $k$ be a field. Then $k[x_1, \dots, x_n]$ is noetherian for any $n$, by the
Hilbert basis theorem and induction on $n$.
\end{example}


\begin{corollary}  \label{hilbbasiscor}
If $R$ is a noetherian ring and $R'$ a finitely generated $R$-algebra, then
$R'$ is noetherian too.
\end{corollary}
\begin{proof}
Each polynomial ring $R[X_1, \dots, X_n]$ is noetherian by \cref{hilbbasis} and an easy
induction on $n$. Consequently, any quotient of a polynomial ring (i.e. any
finitely generated $R$-algebra, such as $R'$) is noetherian.
\end{proof}

\begin{example}
Any finitely generated commutative ring $R$ is noetherian. Indeed, then there
is a surjection
\[ \mathbb{Z}[x_1, \dots, x_n] \twoheadrightarrow R  \]
where the $x_i$ get mapped onto generators in $R$. The former is noetherian by
the basis theorem, and $R$ is as a quotient noetherian.
\end{example}


\begin{corollary}
Any ring $R$ can be obtained as a filtered direct limit of noetherian rings.
\end{corollary}
\begin{proof}
Indeed, $R$ is the filtered direct limit of its finitely generated subrings.
\end{proof}

This observation is sometimes useful in commutative algebra and algebraic
geometry, in order to reduce questions about arbitrary commutative rings to
noetherian rings. Noetherian rings have strong finiteness hypotheses that let
you get numerical invariants that may be useful. For instance, we can do things
like inducting on the dimension for noetherian local rings.

\begin{example}
Take $R = \mathbb{C}[x_1, \dots, x_n]$. For any algebraic variety $V$ defined
by polynomial equations, we know that $V$ is  the vanishing locus of some ideal
$I \subset R$. Using the Hilbert basis theorem, we have shown that $I$ is
finitely generated. This implies that $V$ can be described by \emph{finitely}
many polynomial equations.
\end{example}

\subsection{Noetherian induction}

The finiteness condition on a noetherian ring allows for ``induction''
arguments to be made; we shall see examples of this in the future.
\begin{proposition}[Noetherian Induction Principle]
   Let $R$ be a noetherian ring, let $\mathcal{P}$ be a property, and let $\mathcal{F}$ be a family of
   ideals $R$. Suppose the inductive step: if all ideals in $\mathcal{F}$ strictly larger than
   $I\in \mathcal{F}$ satisfy $\mathcal{P}$, then $I$ satisfies $\mathcal{P}$. Then all ideals in
   $\mathcal{F}$ satisfy $\mathcal{P}$.
 \end{proposition}
 \begin{proof}
   Assume $\mathcal{F}_\text{crim} = \{J\in \mathcal{F}|J\text{ does not satisfy }\mathcal{P}\}\neq \varnothing$.
   Since $R$ is noetherian, $\mathcal{F}_\text{crim}$ has a maximal member $I$. By maximality, all
   ideals in $\mathcal{F}$ strictly containing $I$ satisfy $\mathcal{P}$, so $I$ also does by the inductive
   step.
 \end{proof}


\section{Associated primes}

We shall now begin the structure theory for noetherian modules. The first step
will be to associate to each module a collection of primes, called the
\emph{associated primes}, which lie in a bigger collection of primes (the
\emph{support}) where the
localizations are nonzero.

\subsection{The support}
 Let $R$ be a  noetherian ring.  An $R$-module $M$ is supposed to be thought
 of as something like a vector bundle, somehow
spread out over the topological space $\spec R$. If $\mathfrak{p} \in \spec R$, then  let
\( \k(\mathfrak{p}) = \mathrm{fr.  \ field \ } R/\mathfrak{p}  ,\)
which is the residue field of $R_{\mathfrak{p}}$. If $M$ is any $R$-module, we
can consider $M \otimes_R \k(\mathfrak{p})$ for each $\mathfrak{p}$; it is a
vector space over $\k(\mathfrak{p})$. If $M$ is finitely generated, then $M \otimes_R
\k(\mathfrak{p})$ is a finite-dimensional vector space.

\begin{definition}
Let $M$ be a finitely generated $R$-module. Then $\supp M$, the
\textbf{support} of $M$,  is defined to be the set of primes
$\mathfrak{p} \in \spec R$ such that
\( M \otimes_R \k(\mathfrak{p}) \neq 0.  \)
\end{definition}

One is  supposed to think of a module $M$ as something like a vector bundle
over the topological space
$\spec R$. At each $\mathfrak{p} \in \spec R$, we associate the vector space $M
\otimes_R \k(\mathfrak{p})$; this is the ``fiber.'' Of course, the intuition
of  $M$'s being a vector bundle is somewhat limited, since the fibers
do not generally have  the same dimension.
Nonetheless, we can talk about the support, i.e. the set of spaces where the
``fiber'' is not zero.

Note that $\mathfrak{p} \in \supp M$ if and only if $M_{\mathfrak{p}} \neq 0$. This is
because
\[ (M \otimes_R R_{\mathfrak{p}})/( \mathfrak{p} R_{\mathfrak{p}} (M \otimes_R
R_{\mathfrak{p}}))  = M_{\mathfrak{p}}
\otimes_{R_{\mathfrak{p}}} \k(\mathfrak{p})  \]
and we can use Nakayama's lemma over the local ring $R_{\mathfrak{p}}$.  (We
are using the fact that $M$ is finitely generated.)

A vector bundle whose support is empty is zero. Thus the following easy
proposition is intuitive:

\begin{proposition}
$M = 0$ if and only if $\supp M = \emptyset$.
\end{proposition}
\begin{proof}
Indeed, $M=0$ if and only if $M_{\mathfrak{p}} = 0$ for all primes
$\mathfrak{p} \in \spec R$. This is equivalent to $\supp M = \emptyset$.
\end{proof}

\begin{exercise}
Let $0 \to M' \to M \to M'' \to 0$ be exact. Then
\[ \supp M = \supp M' \cup \supp M''.  \]
\end{exercise}


We will see soon that that $\supp M$ is closed in $\spec R$. One imagines that
$M$ lives on this closed subset $\supp M$, in some sense.



\subsection{Associated primes}
Throughout this section, $R$ is a noetherian ring. The \emph{associated
primes} of a module $M$ will refer to primes that arise as the annihilators of
elements in $M$. As we shall see, the support of  a module is determined by
the associated primes. Namely, the associated primes contain the ``generic
points'' (that is, the minimal primes) of the support. In some cases, however,
they may contain more.

\add{We are currently using the notation $\ann(x)$ for the annihilator of $x
\in M$. This has not been defined before. Should we add this in a previous
chapter?}

\begin{definition}
Let $M$ be a finitely generated $R$-module.  The prime ideal $\mathfrak{p}$ is said to be
\textbf{associated} to $M$ if there exists an element $x \in M$ such that
$\mathfrak{p}$ is the annihilator of $x$.  The set of associated primes is
$\ass(M)$.
\end{definition}

Note that the annihilator of an element $x \in M$ is not necessarily prime, but
it is possible that the annihilator might be prime, in which case it is
associated.

\begin{exercise}
Show that $\mathfrak{p} \in \ass(M)$ if and only if there is an injection
$R/\mathfrak{p} \hookrightarrow M$.
\end{exercise}

\begin{exercise}
Let $\mathfrak{p} \in \spec R$. Then $\ass(R/\mathfrak{p}) =
\left\{\mathfrak{p}\right\}$.
\end{exercise}

\begin{example}
Take $R=k[x,y,z]$, where $k$ is an integral domain, and let $I = (x^2-yz,x(z-1))$. Any
 prime associated to $I$ must contain $I$, so let's consider
   $\mathfrak{p}=(x^2-yz,z-1)=(x^2-y,z-1)$, which is $I:x$. It is prime because $R/\mathfrak{p} = k[x]$,
   which is a domain. To see that $(I:x)\subset \mathfrak{p}$, assume $tx\in I\subset \mathfrak{p}$; since
   $x\not\in \mathfrak{p}$, $t\in p$, as desired.

   There are two more associated primes, but we will not find them here.
 \end{example}


We shall start by proving that $\ass(M) \neq \emptyset$ for nonzero modules.
\begin{proposition} \label{assmnonempty}
If $M \neq 0$, then $M$ has an associated prime.
\end{proposition}
\begin{proof}  Consider the collection of ideals in $R$ that arise as the
annihilator of a nonzero element in $M$.
Let $I \subset R$ be a maximal element among this collection.  The existence of $I$ is guaranteed thanks to the noetherianness of
$R$.
Then $I = \ann(x)$ for some $x \in M$, so  $1 \notin I$ because the annihilator of a nonzero element is not the full
ring.

I claim that
$I$ is prime,  and hence $I \in \ass(M)$.
Indeed, suppose $ab \in I$ where $a,b \in R$. This means that
\[ (ab)x = 0.  \]
Consider the annihilator $\ann(bx)$ of $bx$. This contains the annihilator of $x$, so $I$;
it also contains $a$.

There are two cases. If $bx = 0$, then $ b \in I$ and we are done. Suppose to
the contrary $bx \neq 0$. In this case, $\ann(bx)$ contains $(a) + I$, which
 contains $I$. By maximality, it must happen that $\ann(bx) = I$ and $ a \in
 I$.

 In either case, we find that one of $a,b $ belongs to $I$, so that $I$ is
 prime.

\end{proof}

\begin{example}[A module with no associated prime]
Without the noetherian hypothesis, \rref{assmnonempty} is
\emph{false}. Consider $R = \mathbb{C}[x_1, x_2, \dots]$, the polynomial ring
over $\mathbb{C}$ in infinitely many variables, and the ideal $I = (x_1,
x_2^2, x_3^3, \dots) \subset R$.
The claim is that
\[ \ass(R/I ) = \emptyset.  \]
To see this, suppose a prime $\mathfrak{p}$ was the annihilator of some
$\overline{f}\in R/I$.  Then $\overline{f}$ lifts to $f \in R$; it follows
that $\mathfrak{p}$ is precisely the set of $g \in R$ such that $fg \in I$.
Now $f$ contains only finitely many of the variables $x_i$, say $x_1, \dots,
x_n$. It is then clear that $x_{n+1}^{n+1} f \in I$  (so $x_{n+1}^{n+1} \in
\mathfrak{p}$), but $x_{n+1} f \notin I$ (so $x_{n+1} \notin \mathfrak{p}$).
It follows that $\mathfrak{p}$ is not a prime, a contradiction.
\end{example}

We shall now show that the associated primes are finite in number.

\begin{proposition} \label{finiteassm}
If $M$ is finitely generated, then $\ass(M)$ is finite.
\end{proposition}

The idea is going to be to use the fact that $M$ is finitely generated to build
$M$ out of finitely many pieces, and use that to bound the number of associated
primes to each piece. For this, we need:

\begin{lemma} \label{assexact}
Suppose we have an exact sequence of finitely generated $R$-modules
\[ 0 \to M' \to M \to M'' \to 0.  \]
Then
\[\ass(M') \subset \ass(M) \subset \ass(M') \cup \ass(M'')  \]
\end{lemma}
\begin{proof}
The first claim is obvious. If $\mathfrak{p}$ is the annihilator of
in $x \in M'$, it is an annihilator of something in $M$ (namely the image of
$x$), because
$M' \to M$ is injective. So $\ass(M') \subset \ass(M)$.

The harder direction is the other inclusion. Suppose $\mathfrak{p} \in \ass(M)$.
Then there is $x \in M$ such that
$\mathfrak{p} = \ann(x).$
Consider the submodule $Rx \subset M$.  If $Rx \cap M' \neq 0$, then we can
choose $y \in Rx \cap M' - \left\{0\right\}$. I claim that $\ann(y) =
\mathfrak{p}$ and so $\mathfrak{p} \in \ass(M')$.
To see this, $ y = ax$ for some $a \in R$. The annihilator of $y$ is the set of elements
$b \in R$ such that
\[ abx = 0  \]
or, equivalently, the set of $b \in R$ such that $ab \in \mathfrak{p} =
\ann(x)$. But $y = ax \neq 0$, so $a \notin \mathfrak{p}$. As a
result, the condition $b \in \ann(y)$ is the same as $b \in \mathfrak{p}$. In
other words,
\[ \ann(y) = \mathfrak{p}  \]
which proves the claim.

Suppose now that  $Rx \cap M' = 0$. Let $\phi: M \twoheadrightarrow M''$
be the surjection. I claim that $\mathfrak{p} = \ann(\phi(x))$ and
consequently that
$\mathfrak{p} \in \ass(M'')$.  The proof is as follows. Clearly $\mathfrak{p}$
annihilates $\phi(x)$ as it annihilates $x$. Suppose $a \in \ann(\phi(x))$.
This means that $\phi(ax) = 0$, so $ax \in \ker \phi=M'$; but $\ker \phi \cap Rx =
0$. So $ax = 0$ and consequently $a \in \mathfrak{p}$. It follows $\ann(\phi(x)) = \mathfrak{p}$.
\end{proof}

The next step in the proof of \rref{finiteassm} is that any
finitely generated module
admits a filtration each of whose quotients are of a particularly nice form.
This result is quite useful and will be referred to in the future.

\begin{proposition}[D{\'e}vissage] \label{filtrationlemma} \label{devissage}
For any finitely generated $R$-module $M$, there exists a finite filtration
\[ 0 = M_0 \subset M_1 \subset \dots \subset M_k = M  \]
such that the successive quotients $M_{i+1}/M_i$ are isomorphic to various
$R/\mathfrak{p}_i$ with the $\mathfrak{p}_i \subset R$ prime.
\end{proposition}
\begin{proof}
Let $M' \subset M$ be maximal among submodules for which such a filtration
(ending with $M'$)
exists. We would like to show that $M' = M$.  Now $M'$ is well-defined since
$0$ has such a filtration and $M$ is
noetherian.

There is a filtration
\[ 0 = M_0 \subset M_1 \subset \dots \subset M_l = M' \subset M  \]
where the successive quotients, \emph{except} possibly the last $M/M'$, are of
the form $R/\mathfrak{p}_i $ for $\mathfrak{p}_i \in \spec R$.
If $M' = M$, we are done. Otherwise, consider
the quotient $M/M' \neq 0$. There is an associated prime of $M/M'$. So there is
a prime $\mathfrak{p}$ which is the annihilator of $x \in M/M'$. This means
that there is an injection
\[ R/\mathfrak{p} \hookrightarrow M/M'.  \]
Now, take $M_{l+1}$ as the inverse image in $M$
of $R/\mathfrak{p} \subset M/M'$.
Then, we can consider the finite filtration
\[ 0 = M_0 \subset M_1 \subset \dots \subset M_{l+1} , \]
all of whose successive quotients are of the form $R/\mathfrak{p}_i$; this is
because $M_{l+1}/M_l = M_{l+1}/M'$ is of this form by construction.
We have thus extended this filtration one
step further,  a contradiction since
$M'$ was assumed to be maximal.
\end{proof}

Now we are in a position to meet the goal, and prove that $\ass(M)$ is
always a finite set.
\begin{proof}[Proof of \rref{finiteassm}]
Suppose $M$ is finitely generated Take our filtration
\[ 0 = M_0 \subset M_1 \subset \dots \subset M_k = M.  \]
By induction, we show that $\ass(M_i)$ is finite for each $i$. It is obviously
true for $i=0$. Assume now that $\ass(M_i)$ is finite; we prove the same for
$\ass(M_{i+1})$. We have an exact sequence
\[ 0 \to M_i \to M_{i+1} \to R/\mathfrak{p}_i \to 0  \]
which implies that, by \rref{assexact},
\[ \ass(M_{i+1}) \subset \ass(M_i) \cup \ass(R/\mathfrak{p}_i) = \ass(M_i)
\cup \left\{\mathfrak{p}_i\right\} , \]
so $\ass(M_{i+1})$ is also finite.
By induction, it is now clear that $\ass(M_i)$ is finite for every $i$.

This proves the proposition; it also shows that the number of
associated primes is at most the length of the filtration.
\end{proof}


Finally, we characterize the zerodivisors on $M$ in terms of the associated
primes. The last characterization of the result will be useful in the future.
It implies, for instance, that if $R$ is local and $\mathfrak{m}$ the maximal
ideal, then if every element of $\mathfrak{m}$ is a zerodivisor on a finitely
generated module
$M$, then $\mathfrak{m} \in \ass(M)$.

\begin{proposition} \label{assmdichotomy}
If $M$ is a finitely generated module over a noetherian ring $R$, then the
zerodivisors on $M$ are the union $\bigcup_{\mathfrak{p} \in \ass(M)}
\mathfrak{p}$.

More strongly, if $I \subset R$ is any ideal consisting of zerodivisors on
$M$, then $I$ is contained in an associated prime.
\end{proposition}
\begin{proof}
Any associated prime is an annihilator of some element of $M$, so it consists
of zerodivisors. Conversely, if $a \in R$ annihilates $x \in M$, then $a$
belongs to every associated prime of the nonzero module $Ra \subset M$. (There
is at least one by \cref{finiteassm}.)

For the last statement, we use prime avoidance (\cref{primeavoidance}): if $I$ consists of
zerodivisors, then $I$ is contained in the union $\bigcup_{\mathfrak{p} \in \ass(M)}
\mathfrak{p}$ by the first part of the proof. This is a finite union by
\cref{assmfinite}, so prime avoidance implies $I$ is contained one of these
primes.
\end{proof}


\begin{exercise}
For every module $M$ over any (not necessarily noetherian) ring $R$,
the set of $M$-zerodivisors$\mathcal{Z}(M)$ is a union of prime ideals. In general, there is an easy
 characterization of sets $Z$ which are a union of primes: it is exactly when
 $R\smallsetminus Z$ is a \emph{saturated multiplicative set}. This is Kaplansky's
 Theorem 2.
 \begin{definition}
   A multiplicative set $S\neq \varnothing$ is a \emph{saturated multiplicative set} if
   for all $a,b\in R$, $a,b\in S$ if and only if $ab\in S$. (``multiplicative set'' just
   means the ``if'' part)
 \end{definition}
 To see that $\mathcal{Z}(M)$ is a union of primes, just verify that its complement is a saturated
 multiplicative set.
\end{exercise}

\subsection{Localization and $\ass(M)$}

It turns out to be extremely convenient that the construction $M  \to \ass(M)$
behaves about as nicely with respect to localization as we could possibly
want. This lets us, in fact, reduce arguments to the case of a local ring,
which is a significant simplification.

So, as usual, let $R $ be noetherian, and $M$ a finitely generated $R$-module.
Let further $S \subset R$ be a multiplicative subset.
Then $S^{-1}M$ is a finitely generated module over the noetherian ring
$S^{-1}M$. So it makes sense to consider both $\ass(M) \subset \spec R$ and
$\ass(S^{-1}M) \subset \spec S^{-1}R$. But we also know that $\spec S^{-1}R
\subset \spec R$ is just the set of primes of $R$ that do not intersect $S$.
Thus, we can directly compare $\ass(M)$ and $\ass(S^{-1}M)$, and one might
conjecture (correctly, as it happens) that $\ass(S^{-1}M) = \ass(M) \cap \spec
S^{-1}R$.
\begin{proposition} \label{assmlocalization}
Let $R$ noetherian, $M$ finitely generated and $S \subset R$ multiplicatively closed.
Then
\[ \ass(S^{-1}M)  = \left\{S^{-1}\mathfrak{p}: \mathfrak{p} \in \ass(M),
\mathfrak{p}\cap S  = \emptyset \right\} . \]
\end{proposition}
\begin{proof}
We first prove the easy direction, namely that $\ass(S^{-1}M)$
\emph{contains} primes in $\spec S^{-1}R \cap \ass(M)$.

Suppose $\mathfrak{p} \in \ass(M)$ and
$\mathfrak{p} \cap S = \emptyset$. Then $\mathfrak{p} = \ann(x)$ for some $x
\in M$. Then the annihilator of $x/1 \in S^{-1}M$ is just $S^{-1}\mathfrak{p}$, as one
can directly check. Thus $S^{-1}\mathfrak{p} \in \ass(S^{-1}M)$.
So we get the easy inclusion.

Let us now do the harder inclusion.
Call the localization map $R \to S^{-1}R  $ as $\phi$.
Let $\mathfrak{q} \in \ass(S^{-1}M)$. By definition, this means that $\mathfrak{q} =
\ann(x/s)$ for some $x \in M$, $s \in S$. We want to see that
$\phi^{-1}(\mathfrak{q}) \in \ass(M) \subset \spec R$.
By definition $\phi^{-1}(\mathfrak{q})$ is the set of elements $a \in R$ such that
\[ \frac{ax}{s} = 0 \in S^{-1}M . \]
In other words, by definition of the localization, this is
\[  \phi^{-1}(\mathfrak{q}) = \bigcup_{t \in S} \left\{a \in R: atx = 0 \in M\right\} = \bigcup \ann(tx)
\subset R.\]
We know, however, that among elements of the form $\ann(tx)$, there is a
\emph{maximal} element $I=\ann(t_0 x)$ for some $t_0 \in S$, since $R$ is
noetherian.  The claim is that $I = \phi^{-1}(\mathfrak{q})$, so
$\phi^{-1}(\mathfrak{q}) \in \ass(M)$.

Indeed,  any other annihilator $I' = \ann(tx)$ (for $t \in S$) must be contained in $\ann(t_0 t x)$. However,
\( I \subset \ann(t_0 x)  \)
and $I$ is maximal, so $I = \ann(t_0 t x)$ and
\( I' \subset I.  \) In other words, $I$ contains all the other annihilators
$\ann(tx)$ for $t \in S$.
In particular, the big union above, i.e. $\phi^{-1}(\mathfrak{q})$, is just
\( I = \ann(t_0 x).  \)
In particular, $\phi^{-1}(\mathfrak{q}) = \ann(t_0x)$ is in $\ass(M)$.
This means that every associated prime
of $S^{-1}M$ comes from an associated prime of $M$, which completes the proof.
\end{proof}



\begin{exercise}
Show that, if $M$ is a finitely generated module over a noetherian ring, that
the map
\[ M \to \bigoplus_{\mathfrak{p} \in \ass(M)} M_{\mathfrak{p}}  \]
is injective. Is this true if $M$ is not finitely generated?
\end{exercise}

\subsection{Associated primes determine the support}
The next claim is that the support and the associated primes are related.

\begin{proposition}\label{supportassociated} The support is the closure of the associated primes:
\[ \supp M  = \bigcup_{\mathfrak{q} \in \ass(M)}
\overline{\left\{\mathfrak{q}\right\}} \]
\end{proposition}

By definition of the Zariski topology, this means that a prime $\mathfrak{p}
\in \spec R$ belongs to $\supp M$ if and only if it contains an associated
prime.

\begin{proof}
First,  we show that $\supp(M)$ contains the set of primes
$\mathfrak{p} \in \spec R$ containing an associated prime; this will imply
that $\supp(M) \supset \bigcup_{\mathfrak{q} \in \ass(M)}
\overline{\left\{\mathfrak{q}\right\}}$. So let $\mathfrak{q}$ be an
associated prime and $\mathfrak{p} \supset \mathfrak{q}$. We need to show that
\[ \mathfrak{p} \in \supp M, \ \text{i.e.} \ M_{\mathfrak{p}} \neq 0.  \]
But, since $\mathfrak{q} \in \ass(M)$,  there is an injective map
\[ R/\mathfrak{q} \hookrightarrow M , \]
so localization gives an injective map
\[ (R/\mathfrak{q})_{\mathfrak{p}} \hookrightarrow M_{\mathfrak{p}}.  \]
Here, however, the first object $(R/\mathfrak{q})_{\mathfrak{p}}$ is nonzero since nothing nonzero in $R/\mathfrak{q}$ can be
annihilated by something outside $\mathfrak{p}$. So $M_{\mathfrak{p}} \neq
0$, and $\mathfrak{p} \in \supp M$.

Let us now prove the converse inclusion. Suppose that $\mathfrak{p} \in \supp M$. We
have to show that $\mathfrak{p}$ contains an associated prime.
By assumption, $M_{\mathfrak{p}} \neq 0$, and $M_{\mathfrak{p}}$ is a finitely generated
module over the noetherian ring $R_{\mathfrak{p}}$. So $M_{\mathfrak{p}}$ has
an associated prime.
It follows by \rref{assmlocalization} that $\ass(M) \cap \spec
R_{\mathfrak{p}}$ is nonempty. Since the primes of $R_{\mathfrak{p}}$
correspond to the primes contained in $\mathfrak{p}$, it follows that there
is  a prime contained in $\mathfrak{p}$ that lies in $\ass(M)$. This is
precisely what we wanted to prove.
\end{proof}


\begin{corollary} \label{suppisclosed} For $M$ finitely generated,
$\supp M$ is closed. Further, every minimal element of $\supp M$ lies in
$\ass(M)$.
\end{corollary}
\begin{proof}
Indeed, the above result says that
\[ \supp M  = \bigcup_{\mathfrak{q} \in \ass(M)}
\overline{\left\{\mathfrak{q}\right\}}. \]
Since $\ass(M)$ is finite, it follows that $\supp M$ is closed.
The above equality also shows that any minimal element of $\supp M$ must be an
associated prime.
\end{proof}

\begin{example}
\rref{suppisclosed} is \emph{false} for modules that are not finitely
generated. Consider for instance the abelian group $\bigoplus_p \mathbb{Z}/p$.
The support of this as a $\mathbb{Z}$-module is precisely the set of all
closed points (i.e., maximal ideals) of $\spec \mathbb{Z}$, and is
consequently is not closed.
\end{example}

\begin{corollary}
The ring $R$ has finitely many minimal prime ideals.
\end{corollary}
\begin{proof}
Clearly, $\supp R = \spec R$. Thus every prime ideal of $R$
contains an associated prime of $R$ by \rref{supportassociated}.
\end{proof}

So $\spec R$ is the finite union of the  irreducible closed  pieces
$\overline{\mathfrak{q}}$ if $R$ is noetherian.
\add{I am not sure if ``irreducibility'' has already been defined. Check this.}

We have just seen that $\supp M$ is a closed subset of $\spec R$ and is a union
of finitely many irreducible subsets.  More precisely,
\[ \supp M = \bigcup_{\mathfrak{q} \in \ass(M)}
\overline{\left\{\mathfrak{q}\right\}}  \]
though there might be some redundancy in this expression. Some associated prime might be contained
in others.

\begin{definition}
A prime $\mathfrak{p} \in \ass(M)$ is an \textbf{isolated} associated prime of
$M$ if it is minimal (with respect to the ordering on $\ass(M)$); it is
\textbf{embedded} otherwise.
\end{definition}

So the embedded primes are not needed to describe the support of $M$.

\add{Examples of embedded primes}

\begin{remark}
It follows that in a noetherian ring, every minimal prime consists of
zerodivisors. Although we shall not use this in the future, the same is true
in non-noetherian rings as well.  Here is an argument.

Let $R$ be a ring and $\mathfrak{p} \subset R$ a minimal prime. Then
$R_{\mathfrak{p}}$ has precisely one prime ideal.
We now use:

\begin{lemma}
If a ring $R$ has precisely one prime ideal $\mathfrak{p}$, then any $x \in
\mathfrak{p}$ is nilpotent.
\end{lemma}
\begin{proof}
Indeed, it suffices to see that $R_x = 0$ (\rref{nilpcriterion} in
\rref{spec}) if $x \in
\mathfrak{p}$. But $\spec R_x$
consists of the primes of $R$ not containing $x$. However, there are no such
primes. Thus $\spec R_x = \emptyset$, so $R_x = 0$.
\end{proof}

It follows that every element in $\mathfrak{p}$ is a zerodivisor in
$R_{\mathfrak{p}}$.
As a result, if $x \in \mathfrak{p}$, there is $\frac{s}{t} \in
R_{\mathfrak{p}}$ such that $xs/t = 0$ but $\frac{s}{t} \neq 0$.
In particular, there is $t' \notin \mathfrak{p}$ with
\[ xst' = 0, \quad st' \neq 0,  \]
so that $x$ is a zerodivisor.
\end{remark}



\subsection{Primary modules}

A primary modules are ones that has only one associated prime. It is equivalent
to say that any homothety is either injective or nilpotent.
As we will see in the next section, any module has a ``primary
decomposition:'' in fact, it embeds as a submodule of a sum of primary
modules.

\begin{definition}
Let $\mathfrak{p} \subset R$ be prime, $M$ a finitely generated  $R$-module. Then $M$ is
\textbf{$\mathfrak{p}$-primary} if
\[ \ass(M) = \left\{\mathfrak{p}\right\}.  \]

A module is \textbf{primary} if it is $\mathfrak{p}$-primary for some
prime $\mathfrak{p}$, i.e., has precisely one associated prime.
\end{definition}

\begin{proposition} \label{whenisprimary}
Let $M$ be a finitely generated $R$-module. Then $M$ is \textbf{$\mathfrak{p}$}-primary if
and only if, for every $m \in M - \left\{0\right\}$,
the annihilator $\ann(m)$ has radical $\mathfrak{p}$.
\end{proposition}
\begin{proof}
We first need a small observation.

\begin{lemma}
If $M$ is $\mathfrak{p}$-primary, then any nonzero submodule $M' \subset M$ is
$\mathfrak{p}$-primary.
\end{lemma}
\begin{proof}
Indeed, we know that $\ass(M') \subset \ass(M)$ by \rref{assexact}.
Since $M' \neq 0$, we also know that $M'$ has an associated prime
(\rref{assmnonempty}). Thus $ \ass(M') = \{\mathfrak{p}\}$, so
$M'$ is $\mathfrak{p}$-primary.
\end{proof}

Let us now return to the proof of the main result,
\rref{whenisprimary}.
Assume first that $M$ is $\mathfrak{p}$-primary. Let $x \in M$, $x \neq 0$. Let
$I = \ann(x)$; we are to show that $\rad(I)  =\mathfrak{p}$. By definition, there is an injection
\[ R/I \hookrightarrow M  \]
sending $1 \to x$. As a result, $R/I$ is $\mathfrak{p}$-primary by the above
lemma. We want to know that $\mathfrak{p}  = \rad(I)$.
We saw that the support $\supp R/I = \left\{\mathfrak{q}: \mathfrak{q}
\supset I\right\}$ is the union of the closures of the associated primes. In
this case,
\[ \supp(R/I) = \left\{\mathfrak{q}: \mathfrak{q} \supset \mathfrak{p}\right\}
.\]
But we know that $\rad(I) = \bigcap_{\mathfrak{q} \supset I} \mathfrak{q}$,
which by the above is just $\mathfrak{p}$. This proves that $\rad(I) =
\mathfrak{p}$.
We have shown that if $R/I$ is primary, then $I$ has radical $\mathfrak{p}$.

The converse is easy.
Suppose the condition holds and $\mathfrak{q} \in \ass(M)$, so $\mathfrak{q} =
\ann(x)$ for $x \neq 0$. But then $\rad(\mathfrak{q}) = \mathfrak{p}$, so
\[ \mathfrak{q} = \mathfrak{p}  \] and $\ass(M) = \left\{\mathfrak{p}\right\}$.
\end{proof}

We have another characterization.

\begin{proposition} \label{whenisprimary2}
Let $M \neq 0$ be a finitely generated $R$-module. Then $M$ is primary if and
only if for each $a \in
R$, then the homothety $ M \stackrel{a}{\to} M$ is either injective or nilpotent.
\end{proposition}
\begin{proof}
Suppose first that $M$ is $\mathfrak{p}$-primary. Then multiplication by anything in
$\mathfrak{p}$ is nilpotent because the annihilator of everything nonzero has
radical $\mathfrak{p}$ by \rref{whenisprimary}. But if $a \notin \mathfrak{p}$, then $\ann(x)$ for
$x \in M - \left\{0\right\}$ has radical $\mathfrak{p}$ and cannot contain $a$.

Let us now do the other direction. Assume that every element of $a$ acts either injectively or nilpotently on $M$.
Let $I \subset R$ be the collection of elements $a \in R$ such that $a^n M = 0$
for $n$ large. Then $I$ is an ideal, since it is closed under addition by the
binomial formula: if $a, b \in I$ and $a^n, b^n$ act by zero, then $(a+b)^{2n}$
acts by zero as well.


I claim that $I$ is actually prime. If $a,b \notin I$, then  $a,b$ act by
multiplication injectively on $M$. So $a: M \to M, b: M \to M$ are injective.
However, a composition of injections is injective, so $ab$ acts injectively and
$ab \notin I$. So $I$ is prime.

We need now to check that if $x \in M$ is nonzero, then $\ann(x)$ has radical
$I$. Indeed, if $a \in R$   annihilates $x$,
then the homothety  $M \stackrel{a}{\to} M$ cannot be injective, so it must be
nilpotent (i.e. in $I$). Conversely, if $a \in I$, then a power of $a$ is
nilpotent, so a power of $a$
must kill $x$.
It follows that $\ann(x) = I$. Now, by \rref{whenisprimary}, we see
that $M$ is $I$-primary.
\end{proof}

We now have this notion of a primary module. The idea is that all the torsion is
somehow concentrated in some prime.

\begin{example}
If $R$ is a noetherian ring and $\mathfrak{p} \in \spec R$, then
$R/\mathfrak{p}$ is $\mathfrak{p}$-primary. More generally, if $I \subset R$
is an ideal, then $R/I$ is ideal if and only if $\rad(I) $ is prime. This
follows from \rref{whenisprimary2}.
\end{example}

\begin{exercise}
If $0 \to M' \to M \to M'' \to 0$ is an exact sequence with $M', M, M''$
nonzero and finitely generated, then $M$ is $\mathfrak{p}$-primary if and only if $M', M''$ are.
\end{exercise}

\begin{exercise}
Let $M$ be a finitely generated $R$-module. Let $\mathfrak{p} \in \spec R$. Show that the sum of two
$\mathfrak{p}$-primary  submodules is $\mathfrak{p}$-primary. Deduce that
there is a $\mathfrak{p}$-primary submodule of $M$ which contains every
$\mathfrak{p}$-primary submodule.
\end{exercise}

\begin{exercise}[Bourbaki]
Let $M$ be a finitely generated $R$-module. Let $T \subset \ass(M)$ be a
subset of the associated primes. Prove that there is a submodule $N \subset M$
such that
\[ \ass(N) = T, \quad \ass(M/N) = \ass(M) - T.  \]

\end{exercise}

\section{Primary decomposition} This is the structure theorem for modules
over a noetherian ring, in some sense.
Throuoghout, we fix a noetherian ring $R$.

\subsection{Irreducible and coprimary modules}

\begin{definition}
Let $M$ be a finitely generated $R$-module. A submodule $N \subset M$ is
\textbf{$\mathfrak{p}$-coprimary} if $M/N$ is $\mathfrak{p}$-primary.

Similarly, we can say that $N \subset M$ is \textbf{coprimary} if it is
$\mathfrak{p}$-coprimary for some $\mathfrak{p} \in \spec R$.
\end{definition}

We shall now show we can represent any submodule of $M$ as an intersection of
coprimary submodules. In order to do this, we will define a submodule of $M$ to be
\emph{irreducible} if it cannot be written as a nontrivial intersection of
submodules of $M$. It
will follow by general nonsense that any submodule is an intersection of
irreducible submodueles. We will then see that any irreducible submodule is
coprimary.

\begin{definition}
The submomdule $N \subsetneq M$ is \textbf{irreducible} if whenever $N = N_1 \cap N_2$ for $N_1,
N_2 \subset M$ submodules, then either one of $N_1, N_2$ equals $N$. In other words, it is not
 the intersection of larger submodules.
\end{definition}

\begin{proposition} \label{irrediscoprimary}
An irreducible submodule $N \subset M$ is coprimary.
\end{proposition}
\begin{proof}
Say $a \in R$. We would like to show that the homothety
\[ M/N \stackrel{a}{\to} M/N  \]
is either injective or nilpotent.
Consider  the following submodules of $M/N$:
\[ K(n) =  \left\{x \in M/N: a^n x = 0\right\} . \]
Then clearly $K(0) \subset K(1) \subset \dots$; this chain stabilizes  as
the quotient module is noetherian.
In particular, $K(n) = K(2n)$ for large $n$.

It follows that if $x \in M/N$ is divisible by $a^n$ ($n$ large) and nonzero, then $a^n x$
is also nonzero. Indeed, say $x = a^n y \neq 0$; then $y \notin K(n)$, so $a^{n}x =
a^{2n}y \neq 0$ or we would have $y \in K(2n) = K(n)$. In $M/N$, the submodules
\[ a^n(M/N) \cap \ker(a^n)  \]
are equal to zero for large $n$. But our assumption was that $N$ is
irreducible.  So one of these submodules of $M/N$ is zero. That is, either
$a^n(M/N) = 0$ or $\ker a^n = 0$. We get either injectivity or nilpotence on
$M/N$. This proves the result.
\end{proof}

\subsection{Irreducible and primary decompositions}

We shall now show that in a finitely generated module over a noetherian ring,
we can write $0$ as an intersection of coprimary modules. This decomposition,
which is called a \emph{primary decomposition}, will be deduced from purely
general reasoning.

\begin{definition}
An \textbf{irreducible decomposition} of the module $M$ is a representation
$N_1 \cap N_2 \dots \cap N_k  = 0$, where the $N_i \subset M$ are irreducible
submodules.
\end{definition}

\begin{proposition}
If $M$ is finitely generated, then $M$ has an irreducible decomposition. There exist finitely many irreducible
submodules $N_1, \dots, N_k$ with
\[  N_1 \cap \dots \cap N_k = 0. \]
\end{proposition}
In other words,
\[  M \to \bigoplus M/N_i  \]
is injective.
So a finitely generated module over a noetherian ring can be imbedded in a direct sum of
primary modules, since by \rref{irrediscoprimary} the $M/N_i$ are
primary.

\begin{proof} This is now purely formal.

Among the submodules of $M$, some may be expressible as intersections of
finitely many irreducibles, while some may not be. Our goal is to show that
$0$ is such an intersection.
Let $M' \subset M$ be a maximal submodule of $M$ such that $M'$ \emph{cannot} be
written as such an intersection. If no such
$M'$ exists, then we are done, because then $0$ can be written as an
intersection of finitely many irreducible submodules.

Now $M'$ is not irreducible, or it would be the intersection of one irreducible
submodule.
It follows $M'$ can be written as $M'=M_1' \cap M_2'$ for two strictly
larger submodules of $M$.  But by maximality, $M_1', M_2'$ admit decompositions as
intersections of irreducibles. So $M'$ admits such a decomposition as well, a contradiction.
\end{proof}

\begin{corollary}
For any finitely generated $M$, there exist coprimary submodules $N_1, \dots,
N_k \subset M$ such that $N_1 \cap \dots \cap N_k  = 0$.
\end{corollary}
\begin{proof}
Indeed, every irreducible submodule is coprimary.
\end{proof}


For any $M$, we have an \textbf{irreducible decomposition}
\[ 0 = \bigcap N_i  \]
for the $N_i$ a finite set of irreducible (and thus coprimary) submodules.
This decomposition here is highly non-unique and non-canonical. Let's try to
pare it down to something which is a lot more canonical.

The first claim is that we can collect together modules which are coprimary for
some prime.
\begin{lemma}
Let $N_1, N_2 \subset M$ be $\mathfrak{p}$-coprimary submodules. Then $N_1 \cap
N_2$ is also $\mathfrak{p}$-coprimary.
\end{lemma}
\begin{proof}
We have to show that $M/N_1 \cap N_2$ is $\mathfrak{p}$-primary. Indeed, we have an injection
\[ M/N_1 \cap N_2 \rightarrowtail  M/N_1 \oplus M/N_2  \]
which implies that $\ass(M/N_1 \cap N_2) \subset \ass(M/N_1) \cup \ass(M/N_2) =
\left\{\mathfrak{p}\right\}$. So we are done.
\end{proof}

In particular, if we do not want irreducibility but only primariness in the
decomposition
\[ 0 = \bigcap N_i,  \]
we can assume that each $N_i$ is $\mathfrak{p}_i$ coprimary for some
 prime
$\mathfrak{p}_i$ with the $\mathfrak{p}_i$ \emph{distinct}.

\begin{definition}
Such a decomposition of zero, where the different modules $N_i$ are
$\mathfrak{p}_i$-coprimary for different $\mathfrak{p}_i$, is called a \textbf{primary decomposition}.
\end{definition}



\subsection{Uniqueness questions}

In general, primary decomposition is \emph{not} unique. Nonetheless, we shall
see that a limited amount of uniqueness does hold. For instance, the primes
that occur are determined.

Let $M$ be a finitely generated module over a noetherian ring $R$, and suppose
$N_1 \cap \dots \cap N_k = 0$ is a primary decomposition.
Let us assume that the decomposition is
\emph{minimal}: that is, if we dropped one of the $N_i$, the intersection would no
longer be zero.
This implies that
\[ N_i \not\supset \bigcap_{j \neq i} N_j  \]
or we could omit one of the $N_i$. Then the decomposition is called a \textbf{reduced primary decomposition}.

Again, what this tells us is that $M \rightarrowtail  \bigoplus M/N_i$. What we
have shown is that $M$ can be imbedded in a sum of pieces, each of which is
$\mathfrak{p}$-primary for some prime, and the different primes are distinct.

This is \textbf{not} unique. However,

\begin{proposition}
The primes $\mathfrak{p}_i$ that appear in a reduced primary decomposition of zero are
uniquely determined. They are the associated primes of $M$.
\end{proposition}
\begin{proof}
All the associated primes of $M$ have to be there, because we have the injection
\[ M \rightarrowtail  \bigoplus M/N_i  \]
so the associated primes of $M$ are among those of $M/N_i$ (i.e. the
$\mathfrak{p}_i$).

The hard direction is to see that each $\mathfrak{p}_i$ is an associated prime.
I.e. if $M/N_i$ is $\mathfrak{p}_i$-primary, then $\mathfrak{p}_i \in \ass(M)$;
we don't need to use primary modules except for primes in the associated primes.
Here we need to use the fact that our decomposition has no redundancy.  Without
loss of generality, it suffices to show that $\mathfrak{p}_1$, for instance,
belongs to $\ass(M)$. We will use the fact that
\[ N_1 \not\supset N_2 \cap \dots .  \]
So this tells us that $N_2 \cap N_3 \cap \dots$ is not equal to zero, or we
would have a containment. We have a map
\[ N_2 \cap \dots \cap N_k \to M/N_1;  \]
it is injective, since the kernel is $N_1 \cap N_2 \cap \dots \cap N_k = 0$ as
this is a decomposition.
However, $M/N_1$ is $\mathfrak{p}_1$-primary, so $N_2 \cap \dots \cap N_k$ is
$\mathfrak{p}_1$-primary. In particular, $\mathfrak{p}_1$ is an associated
prime of $N_2 \cap \dots \cap N_k$, hence of  $M$.
\end{proof}

The primes are determined. The factors are not. However, in some cases they are.

\begin{proposition}
Let $\mathfrak{p}_i$ be a minimal associated prime of $M$, i.e. not containing
any smaller associated prime. Then the submodule $N_i$  corresponding to
$\mathfrak{p}_i$ in the reduced primary decomposition is uniquely determined:
it is the kernel of
\[ M \to M_{\mathfrak{p}_i}.  \]
\end{proposition}

\begin{proof}
We have that $\bigcap N_j = \left\{0\right\} \subset M$. When we localize at
$\mathfrak{p}_i$, we find that
\[ (\bigcap N_j)_{\mathfrak{p}_i} = \bigcap (N_j)_{\mathfrak{p}_i} =0 \]
as localization is an exact functor. If $j \neq i$, then $M/N_j$ is
$\mathfrak{p}_j$ primary, and has only $\mathfrak{p}_j$ as an associated prime.
It follows that $(M/N_j)_{\mathfrak{p}_i}$ has no associated primes, since the
only associated prime could be $\mathfrak{p}_j$, and that's not contained in
$\mathfrak{p}_j$.
In particular, $(N_j)_{\mathfrak{p}_i} = M_{\mathfrak{p}_i}$.

Thus, when we localize the primary decomposition at $\mathfrak{p}_i$, we get
a trivial primary decomposition: most of the factors are the full
$M_{\mathfrak{p}_i}$.  It follows that $(N_i)_{\mathfrak{p}_i}=0$. When we draw
a commutative diagram
\[
\xymatrix{
N_i \ar[r] \ar[d]  &  (N_i)_{\mathfrak{p}_i} = 0 \ar[d]  \\
M \ar[r] &  M_{\mathfrak{p}_i}.
}
\]
we find that $N_i$ goes to zero in the localization.

Now if $x \in \ker(M \to M_{\mathfrak{p}_i}$, then $sx = 0$ for some $s \notin
\mathfrak{p}_i$. When we take the map $M \to M/N_i$, $sx$ maps to zero; but $s$
acts injectively on $M/N_i$, so $x$ maps to zero in $M/N_i$, i.e. is zero in
$N_i$.
\end{proof}

This has been abstract, so:
\begin{example} Let $ R = \mathbb{Z}$.
Let $M = \mathbb{Z} \oplus \mathbb{Z}/p$. Then zero can be written as
\[ \mathbb{Z} \cap \mathbb{Z}/p  \]
as submodules of $M$. But $\mathbb{Z}$ is $\mathfrak{p}$-coprimary, while
$\mathbb{Z}/p$ is $(0)$-coprimary.

This is not unique. We could have considered
\[ \{(n,n), n \in \mathbb{Z}\} \subset M.  \]
However, the zero-coprimary part has to be the $p$-torsion. This is because
$(0)$ is the minimal ideal.

The decomposition is always unique, in general, if
we have no inclusions among the prime ideals. For $\mathbb{Z}$-modules, this
means that primary decomposition is unique for torsion modules.
Any torsion group is a direct sum of the $p$-power torsion over all primes $p$.
\end{example}

\begin{exercise}
Suppose $R$ is a noetherian ring and $R_{\mathfrak{p}}$ is a domain for each prime ideal
$\mathfrak{p} \subset R$. Then $R$ is a finite direct product $\prod R_i$ for
each $R_i$ a domain.

To see this, consider the minimal primes $\mathfrak{p}_i \in \spec R$. There
are finitely many of them, and argue that since every localization is a domain,
$\spec R$ is disconnected into the pieces $V(\mathfrak{p}_i)$.
It follows that there is a decomposition $R = \prod R_{i}$ where $\spec R_i$
has $\mathfrak{p}_i$ as the unique minimal prime.
Each $R_i$ satisfies the same condition as $R$, so we may reduce to the case
of $R$ having a unique minimal prime ideal. In this case, however, $R$ is
reduced, so its unique minimal prime ideal must be zero.
\end{exercise}



\section{Artinian rings and modules}

The notion of an \emph{artinian ring}  appears to be dual to that of a
noetherian ring, since the chain condition is simply reversed in the
definition. However, the artinian condition is much stronger than the
noetherian one. In fact,
artinianness actually implies noetherianness, and much more.
Artinian modules over non-artinian rings are frequently of interest as well;
for instance, if $R$ is a noetherian ring and $\mathfrak{m}$ is a maximal
ideal, then for any finitely generated $R$-module $M$, the module
$M/\mathfrak{m}M$ is artinian.

\subsection{Definitions}

\begin{definition}
A commutative ring $R$ is \textbf{Artinian} every descending chain of ideals
$I_0 \supset I_1 \supset I_2 \supset \dots$
stabilizes.
\end{definition}

\begin{definition}
The same definition makes sense for modules. We can define an $R$-module $M$ to
be \textbf{Artinian} if every descending chain of submodules stabilizes.
\end{definition}

In fact, as we shall see when we study dimension theory, we actually often do
want to study artinian modules over non-artinian rings, so this definition is
useful.

\begin{exercise}
A module is artinian if and only if every nonempty collection of submodules
has a minimal element.
\end{exercise}
\begin{exercise}
A ring which is a finite-dimensional algebra over a field is artinian.
\end{exercise}
\begin{proposition}  \label{exactartinian}
If $0 \to M' \to M \to M'' \to 0$ is an exact sequence, then $M$ is Artinian
if and only if $M', M''$ are.
\end{proposition}

This is proved in the same way as for noetherianness.

\begin{corollary}
Let $R$ be artinian. Then every finitely generated $R$-module is artinian.
\end{corollary}
\begin{proof}
Standard.
\end{proof}

\subsection{The main result}
This definition is obviously dual to the notion of noetherianness, but it is
much more restrictive.
The main result is:

\begin{theorem} \label{artinianclassification}
A commutative ring $R$ is artinian if and only if:
\begin{enumerate}
\item $R$ is noetherian.
\item Every prime ideal of $R$ is maximal.\footnote{This is much different from
the Dedekind ring condition---there, zero is not maximal. An artinian domain is
necessarily a field, in fact.}
\end{enumerate}
\end{theorem}


So artinian rings are very simple---small in some sense.
They all look kind of like fields.

We shall prove this result in a series of small pieces. We begin with a piece
of the forward implication in \rref{artinianclassification}:
\begin{lemma} Let $R$ be artinian.
Every prime $\mathfrak{p} \subset R$ is maximal.
\end{lemma}
\begin{proof}
Indeed, if $\mathfrak{p} \subset R$ is a prime ideal, $R/\mathfrak{p}$ is
artinian, as it is a quotient of an artinian ring. We want to show that
$R/\mathfrak{p}$ is a field,
which is the same thing as saying that $\mathfrak{p}$ is maximal.
(In particular, we are essentially proving that an artinian \emph{domain} is a
field.)

Let $x \in
R/\mathfrak{p}$ be nonzero. We have a descending chain
\[ R/\mathfrak{p} \supset (x) \supset (x^{2}) \dots  \]
which necessarily stabilizes. Then we have $(x^n) = (x^{n+1})$ for some $n$. In
particular, we have $x^n = y x^{n+1}$ for some $y \in R/\mathfrak{p}$. But $x$
is a nonzerodivisor, and  we find $ 1 = xy$. So $x$ is invertible. Thus
$R/\mathfrak{p}$ is a field.
\end{proof}

Next, we claim there are only a few primes in an artinian ring:
\begin{lemma}
If $R$ is artinian, there are only finitely many maximal ideals.
\end{lemma}
\begin{proof}
Assume otherwise. Then we have an infinite sequence
\[ \mathfrak{m}_1,  \mathfrak{m}_2, \dots  \]
of distinct maximal ideals. Then we have the descending chain
\[ R \supset \mathfrak{m}_1 \supset \mathfrak{m}_1 \cap \mathfrak{m}_2 \supset \dots.  \]
This necessarily stabilizes. So for some $n$, we have that $\mathfrak{m}_1 \cap \dots \cap
\mathfrak{m}_n \subset \mathfrak{m}_{n+1}$. However, this means that
$\mathfrak{m}_{n+1}$ contains one of the $\mathfrak{m}_1, \dots,
\mathfrak{m}_n$ since these are prime ideals (a familiar argument).  Maximality
and distinctness of the $\mathfrak{m}_i$ give a contradiction.
\end{proof}

In particular, we see that $\spec R$ for an artinian ring is just a finite set.
In fact, since each point is closed, as each prime is maximal, the set has the
\emph{discrete topology.} As a result, $\spec R$ for an artinian ring is
\emph{Hausdorff}. (There are very few other cases.)

This means that $R$ factors as a product of rings. Whenever $\spec R$ can be
written as a disjoint union of components, there is a factoring of $R$ into a
product $\prod R_i$. So $R = \prod R_i$ where each $R_i$ has
only one maximal ideal. Each $R_i$, as a homomorphic image of $R$, is artinian. We find, as a result,

\add{mention that disconnections of $\spec R$ are the same thing as
idempotents.}

\begin{proposition}
Any artinian ring is a finite product of local artinian rings.
\end{proposition}

Now, let us continue our analysis. We may as well assume that we are working
with \emph{local} artinian rings $R$ in the future. In particular, $R$ has a unique
prime $\mathfrak{m}$, which must be the radical of $R$ as the radical is the
intersection of all primes.

We shall now see that the unique prime ideal $\mathfrak{m} \subset R$ is
nilpotent by:
\begin{lemma} \label{radnilpotentartinian}
If $R$ is artinian (not necessarily local), then $\rad (R) $ is nilpotent.
\end{lemma}

It is, of course, always true that any \emph{element} of the radical $\rad(R)$
is nilpotent, but it is not true for a general ring $R$ that $\rad(R)$ is
nilpotent as an \emph{ideal}.

\begin{proof}
Call $J = \rad(R)$. Consider the decreasing filtration
\[ R \supset J \supset J^2 \supset J^3 \supset \dots.  \]
We want to show that this stabilizes at zero. A priori, we know that it
stabilizes \emph{somewhere}. For some $n$, we have
\[ J^n = J^{n'}, \quad n' \geq n.  \]
Call the eventual stabilization of these ideals $I$. Consider ideals $I'$ such
that
\[ II' \neq 0.  \]
There are now two cases:
\begin{enumerate}
\item No such $I'$ exists. Then $I = 0$, and we are done: the powers of
$J^n$ stabilize at zero.
\item Otherwise,  there is a
\emph{minimal} such $I'$ (minimal for satisfying $II' \neq 0$) as $R$ is
artinian. Necessarily $I'$ is nonzero, and furthermore there is $x \in I'$ with $x I \neq
0$.

It follows by minimality that
\[ I' = (x) , \]
so $I'$ is principal. Then $xI \neq 0$; observe
that $xI$ is also $(xI)I $ as $I^2  = I$ from the definition of $I$. Since
$(xI) I \neq 0$, it follows again by minimality that
\[ xI = (x).  \] Hence, there is $y \in I$ such that $xy = x$; but now, by construction $I \subset J = \rad (R)$, implying that $y $ is nilpotent.
It follows that
\[ x = xy = xy^2 = \dots = 0  \]
as $y$ is nilpotent. However, $x \neq 0$ as $xI \neq 0$. This is a
contradiction, which implies that the second case cannot occur.
\end{enumerate}
We have now proved the lemma.
\end{proof}

Finally, we may prove:

\begin{lemma}
A local artinian ring $R$ is noetherian.
\end{lemma}
\begin{proof}
We have the filtration $R \supset \mathfrak{m} \supset \mathfrak{m}^2 \supset
\dots$. This eventually stabilizes at zero by \rref{radnilpotentartinian}. I
claim that $R$ is noetherian as an $R$-module. To prove this, it suffices to
show that $\mathfrak{m}^k/\mathfrak{m}^{k+1}$ is noetherian as an $R$-module.
But of course, this is annihilated by $\mathfrak{m}$, so it is really a vector
space over the field $R/\mathfrak{m}$. But $\mathfrak{m}^k/\mathfrak{m}^{k+1}$
is a subquotient of an artinian module, so is artinian itself. We have to show
that it is noetherian.
It suffices to show now that if $k$ is a field, and $V$ a $k$-vector space,
then TFAE:
\begin{enumerate}
\item $V$ is artinian.
\item $V$ is noetherian.
\item $V$ is finite-dimensional.
\end{enumerate}
This is evident by linear algebra. 	
\end{proof}

Now, finally, we have shown that an artinian ring is noetherian. We have to
discuss the converse. Let us assume now that $R$ is noetherian and has only
maximal prime ideals. We show that $R$ is artinian. Let us consider $\spec R$;
there are only finitely many minimal primes by the theory of associated
primes: every prime ideal is minimal in this case. Once again, we learn that $\spec R$
is finite and has the discrete topology. This means that $R$ is a product of
factors $\prod R_i$ where each $R_i$ is a local noetherian ring with a unique
prime ideal. We might as well now prove:

\begin{lemma}
Let $(R, \mathfrak{m})$ be a local noetherian ring with one prime ideal. Then
$R$ is artinian.
\end{lemma}
\begin{proof}
We know that $\mathfrak{m} = \mathrm{rad}(R)$. So $\mathfrak{m}$ consists of
nilpotent elements, so by finite generatedness it is nilpotent.  Then we have a
finite filtration
\[ R \supset \mathfrak{m} \supset \dots \supset \mathfrak{m}^k = 0.  \]
Each of the quotients are finite-dimensional vector spaces, so artinian; this
implies that $R$ itself is artinian.
\end{proof}

 \begin{remark}
 Note that artinian implies noetherian! This statement is true for rings (even
 non-commutative rings), but not for modules. Take the same example $M = \varinjlim
   \mathbb{Z}/p^n\mathbb{Z}$ over $\mathbb{Z}$. However, there is a module-theoretic statement which is
   related.
 \end{remark}
 \begin{corollary}
   For a finitely generated module $M$ over any commutative ring $R$, the following are
   equivalent.
   \begin{enumerate}
     \item $M$ is an artinian module.
     \item $M$ has finite length (i.e.\ is noetherian and artinian).
     \item $R/\ann M$ is an artinian ring.
   \end{enumerate}
 \end{corollary}
\begin{proof}
\add{proof}
\end{proof}
\begin{exercise}
If $R$ is an artinian ring, and $S$ is a finite $R$-algebra (finite as an
$R$-module), then $S$ is artinian.
\end{exercise}

\begin{exercise}
Let $M$ be an artinian module over a commutative ring $R$, $f: M \to M$ an \emph{injective} homomorphism.
Show that $f$ is surjective, hence an isomorphism.
\end{exercise}


\subsection{Vista: zero-dimensional non-noetherian rings}
 \begin{definition}[von Neumann]
   An element $a\in R$ is called \emph{von Neumann regular} if there is some $x\in R$
   such that $a=axa$.
 \end{definition}
 \begin{definition}[McCoy]
   A element $a\in R$ is \emph{$\pi$-regular} if some power of $a$ is von Neumann
   regular.
 \end{definition}
 \begin{definition}
   A element $a\in R$ is \emph{strongly $\pi$-regular} (in the commutative case)
   if the chain $aR\supset a^2R\supset a^3R\supset \cdots$ stabilizes.
 \end{definition}
 A ring $R$ is von Neumann regular (resp.\ (strongly) $\pi$-regular) if every element of
 $R$ is.

 \begin{theorem}[5.2]
   For a commutative ring $R$, the following are equivalent.
   \begin{enumerate}
     \item $\dim R=0$.
     \item $R$ is rad-nil (i.e. the Jacobson radical $J(R)$ is the nilradical ) and $R/\rad R$ is von Neumann regular.
     \item $R$ is strongly $\pi$-regular.
     \item $R$ is $\pi$-regular.

     \item[] \hspace{-7ex} And any one of these implies
     \item Any non-zero-divisor is a unit.
   \end{enumerate}
 \end{theorem}
 \begin{proof}
   $1\Rightarrow 2\Rightarrow 3\Rightarrow 4 \Rightarrow 1$ and $4\Rightarrow 5$. We will
   not do $1\Rightarrow 2\Rightarrow 3$ here.

   ($3\Rightarrow 4$) Given $a\in R$, there is some $n$ such that $a^n R = a^{n+1}
   R=a^{2n}R$, which implies that $a^n = a^n x a^n$ for some $x$.

   ($4\Rightarrow 1$) Is $\mathfrak{p}$ maximal? Let $a\not\in \mathfrak{p}$.
	Since $a$ is $\pi$-regular, we
   have $a^n=a^{2n}x$, so $a^n(1-a^nx)=0$, so $1-a^nx\in \mathfrak{p}$. It follows that $a$ has an
   inverse mod $\mathfrak{p}$.

   ($4\Rightarrow 5$) Using $1-a^nx=0$, we get an inverse for $a$.
 \end{proof}
 \begin{example}
   Any local rad-nil ring is zero dimensional, since $2$ holds.
   In particular, for a ring $S$ and maximal ideal $\mathfrak{m}$,
	$R=S/\mathfrak{m}^n$ is zero dimensional
   because it is a rad-nil local ring.
 \end{example}
 \begin{example}[Split-Null Extension]
   For a ring $A$ and $A$-module $M$, let $R=A\oplus M$
   with the multiplication $(a,m)(a',m')=(aa',am'+a'm)$ (i.e.\ take the multiplication on
   $M$ to be zero). In $R$, $M$ is an ideal of square zero. ($A$ is called a
   \emph{retract} of $R$ because it sits in $R$ and can be recovered by quotienting by
   some complement.) If $A$ is a field, then $R$ is a rad-nil local ring, with maximal ideal $M$.
 \end{example}


% ============================ chapters/graded.tex}
\chapter{Graded and filtered rings}

In algebraic geometry, working in classical affine space
$\mathbb{A}^n_{\mathbb{C}}$ of points in $\mathbb{C}^n$ turns out to be
insufficient for various reasons.
Instead, it is often more convenient to consider varieties in \emph{projective
space} $\mathbb{P}^n_{\mathbb{C}}$, which is the set of lines through the
origin in $\mathbb{C}^{n+1}$.
In other words, it is the set of all $n+1$-tuples $[z_0, \dots, z_n] \in
\mathbb{C}^{n+1} - \left\{0\right\}$ modulo the relation that
\begin{equation} \label{rescaling} [z_0, \dots, z_n] = [\lambda z_0, \dots, \lambda z_n], \quad \lambda \in
\mathbb{C}^*.  \end{equation}
Varieties in projective space  have many
convenient properties that affine varieties do not: for instance,
intersections work out much more nicely when intersections at the extra
``points at infinity'' are included.
Moreover, when endowed with the complex topology, (complex) projective
varieties are \emph{compact}, unlike all but degenerate affine varieties (i.e.
finite sets).

It is when defining the notion of a ``variety'' in projective space that one
encounters gradedness. Now a variety in $\mathbb{P}^n$ must be cut out by
polynomials $F_1, \dots, F_k \in \mathbb{C}[x_0, \dots, x_n]$; that is, a
point represented by $[z_0, \dots, z_n]$ lies in the associated variety if and
only if $F_i(z_0, \dots, z_n) = 0$ for each $i$. For this to make sense, or to
be independent of the choice of $z_0, \dots, z_n$ up to rescaling as in
\eqref{rescaling}, it is necessary to assume
that each $F_i$ is \emph{homogeneous.}

Algebraically, $\mathbb{A}^n_{\mathbb{C}}$ is the set of maximal ideals in the
polynomial ring $\mathbb{C}^{n}$. Projective space is defined somewhat more
geometrically (as a set of lines) but it turns out that there is an
algebraic interpretation here too. The points of projective space are in
bijection with the \emph{homogeneous maximal ideals} of the polynomial ring
$\mathbb{C}[x_0, \dots, x_n]$. We shall define  more generally the $\proj$ of a
\emph{graded} ring in this chapter. Although we shall not repeatedly refer to
this concept in the sequel, it will be useful for readers interested in
algebraic geometry.

We shall also introduce the notion of a \emph{filtration}. A filtration allows
one to endow a given module with a topology, and one can in fact complete with
respect to this topology. This construction will be studied in
\rref{completions}.

\section{Graded rings and modules}

Much of the material in the present section is motivated by algebraic
geometry; see \cite{EGA}, volume II for the construction of $\proj R$ as a
scheme.

\subsection{Basic definitions}
\begin{definition}
A \textbf{graded ring} $R$ is a ring together with a decomposition (as abelian
groups)
\[  R = R_0 \oplus R_1 \oplus \dots   \]
such that $R_m R_n \subset R_{m+n}$ for all $m, n \in \mathbb{Z}_{\geq 0}$,
and where $R_0$ is a subring (i.e. $1 \in R_0$).
A \textbf{$\mathbb{Z}$-graded ring} is one where the decomposition is into
$\bigoplus_{n \in \mathbb{Z}} R_n$.
In either case, the elements of the subgroup $R_n$ are called
\textbf{homogeneous of degree $n$}.
\end{definition}

The basic example to keep in mind is, of course, the polynomial ring $R[x_1,
\dots, x_n]$ for $R$ any ring. The graded piece of degree $n$ consists of the
homogeneous polynomials of degree $n$.

Consider a graded ring $R$.
\begin{definition}
A \textbf{graded} $R$-module is an ordinary $R$-module $M$ together with a
decomposition
\[  M = \bigoplus_{k \in \mathbb{Z}} M_k  \]
as abelian groups, such that $R_m M_n \subset M_{m+n}$ for all $m \in
\mathbb{Z}_{\geq 0}, n \in \mathbb{Z}$. Elements in one of these pieces are
called \textbf{homogeneous.}
Any $m \in M$ is thus uniquely a finite sum $\sum m_{n_i}$ where each $m_{n_i}
\in M_{n_i}$ is homogeneous of degree $n_i$.
\end{definition}

Clearly there is a \emph{category} of graded $R$-modules, where the morphisms
are the morphisms of $R$-modules that preserve the grading (i.e. take
homogeneous elements to homogeneous elements of the same degree).

Since we shall focus on positively graded rings, we shall simply call them
graded rings; when we do have to consider rings with possibly negative
gradings, we shall highlight this explicitly. Note, however, that we allow
modules with negative gradings freely.

In fact, we shall note an important construction that will generally shift
the graded pieces such that some of them might be negative:

\begin{definition}
Given a graded module $M$, we define the \textbf{twist} $M(n)$ as the
same $R$-module but with the grading
\[  M(n)_k = M_{n+k} . \]
This is a functor on the category of graded $R$-modules.
\end{definition}

In algebraic geometry, the process of twisting allows one to construct
canonical line bundles on projective space. Namely, a twist of $R$ itself
will lead to a line bundle on projective space that in general is not
trivial. See \cite{Ha77}, II.5.

Here are examples:
\begin{example}[An easy example]
If $R$ is  a graded ring, then $R$ is a graded module over itself.
\end{example}

\begin{example}[Another easy example]
If $S$ is any ring, then $S$ can be considered as a graded ring with $S_0 = S$
and $S_i = 0$ for $i>0$. Then a \emph{graded} $S$-module is just a
$\mathbb{Z}$-indexed collection of (ordinary) $S$-modules.
\end{example}

\begin{example}[The blowup algebra]
\label{blowupalg}
This example is a bit more interesting, and will be used in the sequel. Let $S$
be any ring, and let $J \subset S$ be an ideal. We can make $R = S \oplus J \oplus
J^2 \oplus \dots$ (the so-called \emph{blowup algebra}) into a graded ring, by defining the multiplication the normal
way except that something in the $i$th component times something in the $j$th
component goes into the $i+j$th component.

Given any $S$-module $M$, there is a graded $R$-module $M \oplus JM \oplus J^2
M \oplus \dots$, where multiplication is defined in the obvious way. We thus
get a functor from $S$-modules to graded $R$-modules. 	
\end{example}

\begin{definition} Fix a graded ring $R$.
Let $M$ be a graded $R$-module and $N \subset M$ an $R$-submodule. Then $N$ is
called a
\textbf{graded submodule} if the homogeneous components of anything in $N$ are
in $N$. If $M=R$, then a graded ideal is also called a \textbf{homogeneous
ideal}.
\end{definition}

In particular, a graded submodule is automatically a graded module in its own
right.

\begin{lemma}
\begin{enumerate}
\item The sum of two graded submodules (in particular, homogeneous ideals) is
graded.
\item  The intersection of two graded submodules is graded.
\end{enumerate}
\end{lemma}
\begin{proof}
Immediate.
\end{proof}

One can grade the quotients of a graded module by a graded submodule.
If $N \subset M$ is a graded submodule, then $M/N$ can be made into a graded
module,  via the isomorphism of abelian groups
\[  M/N \simeq \bigoplus_{k \in \mathbb{Z}} M_k/N_k.  \]
In particular, if $\mathfrak{a} \subset R$ is a homogeneous ideal, then
$R/\mathfrak{a}$ is a graded ring in a natural way.


\begin{exercise}
Let $R$ be a graded ring. Does the category of graded $R$-modules admit limits and colimits?
\end{exercise}
\subsection{Homogeneous ideals}

Recall that a homogeneous ideal in a graded ring $R$ is simply a graded
submodule of $R$. We now prove a useful result that enables us tell when an
ideal is homogeneous.

\begin{proposition} \label{homgideal}
Let $R$ be a graded ring, $I \subset R$ an ideal. Then $I$ is a homogeneous
ideal
if and only if it can be generated by homogeneous elements.
\end{proposition}
\begin{proof}
If $I$ is a homogeneous ideal, then by definition
\[ I = \bigoplus_i I \cap R_i,  \]
so $I$ is generated by the sets $\left\{I \cap R_i\right\}_{i \in
\mathbb{Z}_{\geq 0}}$ of homogeneous elements.

Conversely, let us suppose that $I$ is generated by homogeneous elements
$\left\{h_\alpha\right\}$. Let $x \in I$ be arbitrary; we can uniquely
decompose $x$ as a sum of homogeneous elements, $x = \sum x_i$, where each
$x_i \in R_i$. We need to show that each $x_i \in I$ in fact.

To do this, note that $x = \sum q_\alpha h_\alpha$ where the $q_\alpha $
belong to $R$. If we take $i$th homogeneous components, we find that
\[ x_i = \sum ( q_{\alpha})_{i - \deg h_\alpha} h_\alpha, \]
where $(q_\alpha)_{i - \deg h_\alpha}$ refers to the homogeneous component of $q_\alpha$
concentrated in the degree $i - \deg h_\alpha$.
From this it is easy to see that each $x_i$ is a linear combination of the
$h_\alpha$ and consequently lies in $I$.
\end{proof}

\begin{example}
If $\mathfrak{a}, \mathfrak{b} \subset R$ are homogeneous ideals, then so is
$\mathfrak{a}\mathfrak{b}$. This is clear from \cref{homgideal}.
\end{example}

\begin{example} Let $k$ be a field.
The ideal $(x^2 + y)$ in $k[x,y]$ is \emph{not} homogeneous.
However, we find from \cref{homgideal} that the ideal $(x^2 + y^2, y^3)$ is.
\end{example}

Since we shall need to use them to define $\proj R$ in the future, we now
prove a result about homogeneous \emph{prime} ideals specifically. Namely,
``primeness''
can be checked just on homogeneous elements for a homogeneous ideal.
\begin{lemma} \label{homogeneousprimeideal}
Let $\mathfrak{p} \subset R$ be a homogeneous ideal. In order that
$\mathfrak{p}$ be prime, it is
necessary and sufficient that whenever $x,y$ are \emph{homogeneous} elements
such that $xy \in \mathfrak{p}$, then at least one of $x,y \in \mathfrak{p}$.
\end{lemma}
\begin{proof}
Necessity is immediate. For sufficiency, suppose $a,b  \in R$ and $ab \in
\mathfrak{p}$. We must prove that one of these is in $\mathfrak{p}$. Write
\[  a = a_{k_1} + a_1  + \dots + a_{k_2},  \ b = b_{m_1} + \dots + b_{m_2}  \]
as a decomposition into homogeneous components (i.e. $a_i$ is the $i$th
component of $a$),  where $a_{k_2}, b_{m_2}$ are nonzero
and of the highest degree.

Let $k = k_2 - k_1, m = m_2 - m_1$. So there are $k$ homogeneous terms in the
expression for $a$, $m$ in the expression for $b$.
We will prove that one of $a,b \in \mathfrak{p}$ by induction on $m+n$. When
$m+n = 0$, then it is just the condition of the lemma.
Suppose it true for smaller values of $m+n$.
Then $ab$ has highest homogeneous component $a_{k_2} b_{m_2}$, which must be in
$\mathfrak{p}$
by homogeneity.  Thus one of $a_{k_2}, b_{m_2}$ belongs to $\mathfrak{p}$. Say for
definiteness it is $a_k$. Then we have that
\[  (a-a_{k_2})b \equiv ab \equiv 0 \  \mathrm{mod} \  \mathfrak{p}  \]
so that $(a-a_{k_2})b \in \mathfrak{p}$. But the resolutions of $a-a_{k_2}, b$ have a
smaller
$m+n$-value: $a - a_{k_2}$ can be expressed with $k-1$ terms. By the inductive hypothesis, it follows that one of these is in
$\mathfrak{p}$, and since $a_k \in \mathfrak{p}$, we find that one of $a,b \in
\mathfrak{p}$.
\end{proof}

\subsection{Finiteness conditions}
There are various finiteness conditions (e.g. noetherianness) that one often wants to impose in
algebraic geometry.
Since projective varieties (and schemes) are obtained from graded rings,
we briefly discuss these finiteness conditions for them.

\begin{definition}
For a graded ring $R$, write $R_+ = R_1 \oplus R_2 \oplus \dots$. Clearly $R_+
\subset R$ is a homogeneous ideal. It is called the \textbf{irrelevant ideal.}
\end{definition}

When we define the $\proj$ of a ring, prime ideals containing the irrelevant ideal
will be no good. The intuition is that when one is working with
$\mathbb{P}^n_{\mathbb{C}}$, the irrelevant ideal in the corresponding ring
$\mathbb{C}[x_0, \dots, x_n]$ corresponds to \emph{all} homogeneous polynomials
of positive degree. Clearly these have no zeros except for the origin, which is
not included in projective space: thus the common zero locus of the irrelevant
ideal should be $\emptyset \subset \mathbb{P}^n_{\mathbb{C}}$.

\begin{proposition} \label{genirrelevant}
Suppose $R = R_0 \oplus R_1 \oplus \dots$ is  a graded ring. Then if a subset
$S \subset R_+$ generates the irrelevant ideal $R_+$ as $R$-ideal, it generates $R$ as $R_0$-algebra.
\end{proposition}
The converse is clear as well.
Indeed, if $S \subset R_+$ generates $R$ as an $R_0$-algebra, clearly it
generates $R_+$ as an $R$-ideal.
\begin{proof}
Let $T \subset R$ be the $R_0$-algebra generated by $S$. We shall show
inductively that $R_n \subset T$. This is true for $n=0$. Suppose $n>0$ and the
assertion true for smaller $n$. Then, we have
\begin{align*}
R_n  & = RS \cap R_n   \ \text{by assumption} \\
& = (R_0 \oplus R_1 \oplus \dots \oplus R_{n-1})(S) \cap R_n \ \text{because $S
\subset R_+$} \\
& \subset (R_0[S]) (S) \cap R_n \ \text{by inductive hypothesis} \\
& \subset R_0(S). \end{align*}
\end{proof}
\begin{theorem} \label{gradednoetherian}
The graded ring $R$ is noetherian if and only if $R_0$ is noetherian and $R$ is finitely
generated as $R_0$-algebra.
\end{theorem}
\begin{proof}
One direction is clear by Hilbert's basis theorem. For the other, suppose $R$
noetherian. Then $R_0$ is noetherian because any sequence $I_1 \subset I_2
\subset \dots$ of ideals of $R_0$ leads to a sequence of ideals $I_1 R \subset
I_2 R \subset \dots$, and since these stabilize, the original $I_1 \subset I_2
\subset \dots$ must stabilize too. (Alternatively, $R_0 = R/R_+$, and taking
quotients preserves noetherianness.)
Moreover, since $R_+$ is a finitely generated
$R$-ideal by noetherianness, it follows that $R$ is a finitely generated
$R_0$-algebra too: we can, by \cref{genirrelevant}, take as $R_0$-algebra
generators for $R$ a set of generators for the \emph{ideal} $R_+$.
\end{proof}

The basic finiteness condition one often needs is that $R$ should be finitely generated as an
$R_0$-algebra. We may also want to have that $R$ is generated by $R_1$, quite
frequently---in algebraic geometry, this implies a bunch of useful things about certain sheaves
being invertible. (See \cite{EGA}, volume II.2.)
As one example, having $R$ generated as $R_0$-algebra by $R_1$ is equivalent to
having $R$ a \emph{graded} quotient of a polynomial algebra over $R_0$ (with
the usual grading).
Geometrically, this equates to having $\proj R$ contained as a closed subset of
some projective space over $R_0$.

However, sometimes we have the first condition and not the second, though if
we massage things we can often assure generation by $R_1$. Then the
next idea comes in handy.

\begin{definition}
\label{dpowerofring}
Let $R$ be a graded ring and $d \in \mathbb{N}$. We set $R^{(d)} = \bigoplus_{k
\in \mathbb{Z}_{\geq 0}} R_{kd}$; this is a graded ring and $R_0$-algebra.  If $M$ is a graded $R$-module and $l \in
\left\{0, 1, \dots, d-1\right\}$, we write $M^{(d,l)} = \bigoplus_{k \equiv l
 \ \mathrm{mod} \  d} M_k$. Then $M^{(d,l)}$ is a graded $R^{(d)}$-module.
\end{definition}

We in fact have a functor $\cdot^{(d,l)}$ from graded $R$-modules to graded
$R^{(d)}$-modules.


One of the implications of the next few results is that, by replacing $R$ with
$R^{(d)}$, we can make the condition ``generated by terms of degree 1'' happen.
But first, we show that basic finiteness is preserved if we filter out some of
the terms.

\begin{proposition} \label{duple preserves finiteness}
Let $R$ be a graded ring and a finitely generated $R_0$-algebra. Let $M$ be a
finitely generated $R$-module.
\begin{enumerate}
\item Each $M_i$ is finitely generated over $R_0$, and the $M_i$ become zero
when $i \ll
0$.
\item  $M^{(d,l)}$ is a finitely generated $R^{(d)}$ module for each $d,l$. In
particular, $M$ itself is a finitely generated $R^{(d)}$-module.
\item $R^{(d)}$ is a finitely generated $R_0$-algebra.
\end{enumerate}
\end{proposition}
\begin{proof}
Choose homogeneous generators $m_1, \dots, m_k \in M$.
For instance, we can choose the homogeneous components of a finite set of
generators for $M$.
Then every nonzero
element of $M$ has degree at least $\min(\deg m_i)$.  This proves the
last part of (1). Moreover, let $r_1, \dots, r_p$ be algebra generators of $R$ over
$R_0$.
We can assume that these are homogeneous with positive degrees $d_1, \dots,
d_p>0$.
Then the $R_0$-module $M_i$ is generated by the elements
\[  r_1^{a_1} \dots r_p^{a_p} m_s  \]
where $\sum a_j d_j + \deg m_s = i$.  Since the $d_j>0$ and there are only
finitely many $m_s$'s, there are only finitely many such elements. This proves
the rest of (1).

To prove (2), note first that it is sufficient to show that $M$ is finitely
generated over $R^{(d)}$, because the $M^{(d,l)}$ are $R^{(d)}$-homomorphic
images (i.e. quotient by the $M^{(d', l)}$ for $d' \neq d$).
Now $M$ is generated as $R_0$-module by the $r_1^{a_1} \dots r_p^{a_p} m_s $
for $a_1, \dots, a_p \geq 0$ and $s = 1, \dots,  k$.
In particular, by the euclidean algorithm in elementary number theory, it
follows that the
$r_1^{a_1} \dots r_p^{a_p} m_s $
for $a_1, \dots, a_p \in [0, d-1]$ and $s = 1, \dots,  k$ generate $M$ over
$R^{(d)}$, as each power $r_i^{d} \in R^{(d)}$.
In particular, $R$ is finitely generated over $R^{(d)}$.

When we apply (2) to the finitely generated $R$-module $R_+$, it follows that
$R^{(d)}_+$ is a finitely generated
$R^{(d)}$-module. This implies that $R^{(d)}$ is a finitely generated
$R_0$-algebra by \cref{genirrelevant}.
\end{proof}

In particular, by \cref{finitelygeneratedintegral} (later in the book!) $R$ is \emph{integral} over
$R^{(d)}$: this means that each element of $R$ satisfies a monic polynomial
equation with $R^{(d)}$-coefficients. This can easily be seen
directly. The $d$th power of a homogeneous element lies in $R^{(d)}$.
\begin{remark}
Part (3), the preservation of the basic finiteness condition, could also be
proved as follows, at least in the noetherian case (with $S = R^{(d)}$).
We shall assume familiarity with the material in \cref{intchapter} for this
brief digression.
\begin{lemma} \label{descintegrality}
Suppose $R_0 \subset S \subset R$ is an inclusion of rings with $R_0$ noetherian.
Suppose $R$ is a
finitely generated $R_0$-algebra and $R/S$ is an integral extension. Then $S$
is a finitely generated $R_0$-algebra.
\end{lemma}
In the case of interest,
we can take $S = R^{(d)}$.
The point of the lemma is that finite generation can be deduced for
\emph{subrings} under nice conditions.
\begin{proof}
We shall start by finding a subalgebra $S' \subset S$ such that $R$ is
integral over $S'$, but $S'$ is a finitely generated $R_0$-algebra. The
procedure will be a general observation of the flavor of ``noetherian descent''
to be developed in \cref{noethdescent}.
Then, since $R$ is integral over $S'$ and finitely generated as an
\emph{algebra}, it will be finitely generated as a $S'$-module. $S$, which
is a sub-$S'$-module, will equally be finitely generated as a $S'$-module,
hence as an $R_0$-algebra. So the point is to make $S$ finitely generated as a
module over a ``good'' ring.


Indeed, let $r_1, \dots, r_m$ be generators of $R/R_0$. Each satisfies an
integral equation $r_k^{n_k} + P_k(r_k) = 0$, where $P_k \in S[X]$ has degree
less than $n_k$. Let $S' \subset S \subset R$ be the subring generated over $R_0$ by the
coefficients of all these polynomials $P_k$.

Then $R$ is, by definition, integral over $S'$.
Since $R$ is a finitely generated $S'$-algebra, it follows by
\cref{finitelygeneratedintegral} that it is a finitely generated $S'$-module.
Then $S$, as a $S'$-submodule is a finitely generated $S'$-module by
noetherianness.
Therefore, $S$ is a finitely generated
$R_0$-algebra.
\end{proof}
This result implies, incidentally, the following useful corollary:

\begin{corollary} Let $R$ be a noetherian ring. If a finite group
$G$ acts on a finitely generated $R$-algebra $S$, the ring of invariants
$S^G$ is finitely generated.
\end{corollary}
\begin{proof}
Apply \cref{descintegrality} to $R, S^G, S$. One needs to check that $S$ is
integral over $S^G$. But each $s \in S$ satisfies the
equation
\[ \prod_{\sigma \in G} (X - \sigma(s))  ,\]
which has coefficients in $S^G$.
\end{proof}
This ends the digression.
\end{remark}


We next return to our main goals, and let $R$ be a graded ring, finitely
generated as an $R_0$-algebra, as before; let $M$ be a finitely
generated $R$-module. We show that we can have $R^{(d)}$ generated by terms of degree $d$ (i.e.
``degree 1'' if we rescale) for $d$ chosen large.
\begin{lemma} \label{quickfinitenesslem}
Hypotheses as above, there is a pair $(d, n_0)$ such that
\[  R_d M_n = M_{n+d}  \]
for $n \geq n_0$.
\end{lemma}
\begin{proof}
Indeed, select $R$-module generators $m_1, \dots, m_k \in M$ and
$R_0$-algebra generators $r_1, \dots, r_p \in R$
as in the proof of \cref{duple preserves finiteness}; use the same
notation for their degrees, i.e. $d_j = \deg r_j$.
Let $d $ be the least common multiple of the $d_j$.  Consider the family of
elements
\[  s_i = r_i^{d/d_i} \in R_d. \]
Then suppose $m \in M_n$ for $n>d + \sup \deg m_i$.  We have that $m$ is a sum
of products of powers of the $\{r_j\}$ and the $\{m_i\}$, each term of which we can assume
is
of degree $n$.  In this case, since in each term, at least one
of the $\{r_j\}$ must occur to power $\geq \frac{d}{d_j}$, we can write each term
in the sum as some $s_j$ times something in $M_{n-d}$.

In particular,
\( M_n  = R_d M_{n-d}.  \)
\end{proof}

\begin{proposition} \label{auxfinitenessgraded}
Suppose $R$ is a graded ring and finitely generated $R_0$-algebra. Then there
is $d \in \mathbb{N}$ such that $R^{(d)}$ is generated over $R_0$ by $R_d$.
\end{proposition}
What this proposition states geometrically is that if we apply the
functor $R \mapsto R^{(d)}$ for large $d$ (which, geometrically, is actually
harmless), one can arrange things so that $\proj R$ (not defined yet!) is
contained as a closed subscheme of ordinary projective space.

\begin{proof} Consider $R$ as a finitely generated, graded $R$-module.
Suppose $d'$ is as in the \cref{auxfinitenessgraded} (replacing $d$, which we reserve for
something else), and choose $n_0$ accordingly.
So we have $R_{d'} R_{m} = R_{m + d'}$ whenever $m \geq n_0$.
Let $d$ be a multiple of $d'$
which is greater than $n_0$.

Then, iterating, we have $R_d R_n = R_{d+n}$ if $n \geq d$ since $d$ is a multiple of $d'$.
In particular, it follows that $R_{nd} = (R_d)^n$ for each $n \in \mathbb{N}$,
which implies the statement of the proposition.
\end{proof}

As we will see below, taking $R^{(d)}$ does not affect the $\proj$, so this is
extremely useful.

\begin{example} Let $k$ be a field. Then
$R = k[x^2] \subset k[x]$ (with the grading induced from $k[x]$) is a finitely generated graded $k$-algebra,
which is not generated by its elements in degree one (there are none!).
However, $R^{(2)} = k[x^2]$ is generated by $x^2$.
\end{example}


We next show that taking the $R^{(d)}$ \emph{always} preserves noetherianness.

\begin{proposition} \label{filtnoetherian}
If $R$ is noetherian, then so is $R^{(d)}$ for any $d>0$.
\end{proposition}
\begin{proof}
If $R$ is noetherian, then $R_0$ is noetherian and $R$ is a finitely generated
$R_0$-algebra by \cref{gradednoetherian}.  \cref{duple preserves
finiteness}  now implies that $R^{(d)} $ is also a
finitely generated $R_0$-algebra, so it is noetherian.
\end{proof}

The converse is also true, since $R$ is a finitely generated $R^{(d)}$-module.




\subsection{Localization of graded rings}
Next, we include a few topics that we shall invoke later on.
First, we discuss the interaction of homogeneity and localization.
Under favorable circumstances, we can give $\mathbb{Z}$-gradings to localizations of
graded rings.

\begin{definition}
If $S \subset R$ is a multiplicative subset of a graded (or
$\mathbb{Z}$-graded) ring $R$ consisting of homogeneous elements, then $S^{-1}
R$ is a $\mathbb{Z}$-graded ring: we let the homogeneous elements of
degree $n$ be of the form $r/s$ where $r \in R_{n + \deg s}$.  We write $R_{(S)}$ for the subring of
elements of degree zero; there is thus a map $R_0 \to R_{(S)}$.

If $S$ consists of the powers of a homogeneous element $f$, we write $R_{(f)}$
for $R_S$. If $\mathfrak{p}$ is a homogeneous ideal and $S$ the set of
homogeneous elements of $R$ not in $\mathfrak{p}$, we write
$R_{(\mathfrak{p})}$ for $R_{(S)}$.
\end{definition}
Of course, $R_{(S)}$ has a trivial grading, and is best thought of as a
plain, unadorned ring.
We shall show that $R_{(f)}$ is a special case of something familiar.

\begin{proposition} \label{loc interpret as quotient ring}
Suppose $f$ is of degree $d$. Then, as plain rings,  there is a
canonical isomorphism $R_{(f)} \simeq R^{(d)}/(f-1)$.
\end{proposition}
\begin{proof}
The homomorphism $R^{(d)} \to R_{(f)}$ is defined to map $g \in R_{kd}$ to
$g/f^d \in
R_{(f)}$.  This is then extended by additivity to non-homogeneous elements. It
is clear that this is multiplicative, and that the ideal $(f-1)$ is annihilated
by the homomorphism.
Moreover, this is surjective.

We shall now define an inverse map. Let $x/f^n \in R_{(f)}$; then $x$ must be
a homogeneous element of degree divisible by $d$. We map this to
the residue class of $x$ in $R^{(d)}/(f-1)$.  This is well-defined; if $x/f^n =
y/f^m$, then there is $N$ with
\[ f^N( xf^m - yf^n) = 0,  \]
so upon reduction (note that $f$ gets reduced to $1$!), we find that the
residue classes of $x,y$ are the same, so the images are the same.

Clearly this defines an inverse to our map.
\end{proof}

\begin{corollary}
Suppose $R$ is a graded noetherian ring. Then each of the $R_{(f)}$ is
noetherian.
\end{corollary}
\begin{proof}
This follows from the previous result and the fact that $R^{(d)}$ is noetherian
(\rref{filtnoetherian}).\end{proof}

More generally, we can define the localization procedure for graded modules.
\begin{definition}
Let $M$ be a graded $R$-module and $S \subset R$ a multiplicative subset
consisting of homogeneous elements. Then we define $M_{(S)}$ as the submodule
of the graded module $S^{-1}M$ consisting of elements of degree zero. When $S$
consists of the powers of a homogeneous element $f \in R$, we write $M_{(f)}$
instead of $M_{(S)}$. We similarly define $M_{(\mathfrak{p})}$ for a
homogeneous prime ideal $\mathfrak{p}$.
\end{definition}

Then clearly $M_{(S)}$ is a $R_{(S)}$-module. This is evidently a functor from
graded $R$-modules to $R_{(S)}$-modules.

We next observe that there is a generalization of \rref{loc interpret as
quotient ring}.
\begin{proposition} \label{loc
module as quotient}
Suppose $M$ is a graded $R$-module, $f \in R$ homogeneous of degree $d$. Then
there is  an isomorphism
\[ M_{(f)} \simeq M^{(d)}/(f-1)M^{(d)}  \]
of $R^{(d)}$-modules.
\end{proposition}
\begin{proof}
This is proved in the same way as \rref{loc interpret as quotient
ring}. Alternatively, both are right-exact functors that commute with
arbitrary direct sums and coincide on $R$, so must be naturally isomorphic by
a well-known bit of abstract nonsense.\footnote{Citation needed.}
\end{proof}

In particular:
\begin{corollary}
Suppose $M$ is a graded $R$-module, $f \in R$ homogeneous of degree 1. Then we
have
\[  M_{(f)} \simeq M/(f-1)M \simeq M\otimes_R R/(f-1).  \]
\end{corollary}

\subsection{The $\proj$ of a ring}
Let $R=R_0 \oplus R_1 \oplus \dots$ be a \textbf{graded ring}.

\begin{definition}
Let $\proj R$ denote the set of \emph{homogeneous prime ideals} of
$R$ that do not contain the \textbf{irrelevant ideal} $R_+$.\footnote{Recall
that an ideal $\mathfrak{a} \subset R$ for $R$ graded is
\emph{homogeneous} if the homogeneous components of $\mathfrak{a}$ belong to
$\mathfrak{a}$.}

\end{definition}

We can put a topology on $\proj R$ by setting, for a homogeneous ideal
$\mathfrak{b}$, $$V(\mathfrak{b}) = \{ \mathfrak{p} \in \proj R:
\mathfrak{p} \supset \mathfrak{b}\}$$.  These sets satisfy
\begin{enumerate}
\item $V( \sum \mathfrak{b_i}) = \bigcap V(\mathfrak{b_i})$.
\item  $V( \mathfrak{a}\mathfrak{b}) = V(\mathfrak{a}) \cup V(\mathfrak{b})$.
\item  $V( \rad \mathfrak{a}) = V(\mathfrak{a})$.
\end{enumerate}
Note incidentally that we would not get any more closed sets if we allowed all
ideals $\mathfrak{b}$, since to any $\mathfrak{b}$ we can consider its
``homogenization.''
We could even allow all sets.

In particular,  the $V$'s do in fact yield a topology on $\proj R$ (setting
the open sets to be complements of the $V$'s).
As with the affine case, we can define basic open sets. For $f$
homogeneous of positive degree, define $D'(f)$ to be the
collection of homogeneous ideals (not containing $R_+$) that do not contain $f$;
clearly these are
open sets.

Let $\mathfrak{a}$ be a homogeneous ideal. Then we claim that:
\begin{lemma}
\(  V(\mathfrak{a}) = V(\mathfrak{a} \cap R_+).  \)
\end{lemma}
\begin{proof}
Indeed, suppose $\mathfrak{p}$ is a homogeneous prime not containing $S_+$ such
that all homogeneous
elements of positive degree in $\mathfrak{a}$ (i.e., anything in $\mathfrak{a}
\cap R_+$) belongs to $\mathfrak{p}$. We will
show that $\mathfrak{a} \subset \mathfrak{p}$.

Choose $a \in \mathfrak{a} \cap R_0$. It is sufficient to show that any such
$a$ belongs to $\mathfrak{p}$ since we are working with homogeneous ideals.
Let $f$ be a homogeneous element of positive degree that is not in
$\mathfrak{p}$.  Then $af \in \mathfrak{a} \cap R_+$, so $af \in \mathfrak{p}$.
But $f \notin \mathfrak{p}$, so $a \in \mathfrak{p}$.
\end{proof}

Thus, when constructing these closed sets $V(\mathfrak{a})$, it suffices to
work with ideals contained in the irrelevant ideal. In fact, we could take
$\mathfrak{a}$ in any prescribed power of the irrelevant ideal, since taking
radicals does not affect $V$.

\begin{proposition}
We have $D'(f) \cap D'(g) = D'(fg)$. Also, the $D'(f)$ form a basis for the
topology on $\proj R$.
\end{proposition}
\begin{proof} The first part is evident, by the definition of a prime ideal. We
prove the second.
Note that $V(\mathfrak{a})$ is the intersection of the $V((f))$ for the
homogeneous $f \in
\mathfrak{a} \cap R_+$. Thus $\proj R - V(\mathfrak{a})$ is the union of these
$D'(f)$.
So every open set is a union of sets of the form $D'(f)$.
\end{proof}

We shall now
show that the topology is actually rather familiar from the affine case, which
is not surprising, since the definition is similar.

\begin{proposition}
$D'(f)$ is homeomorphic to $\spec R_{(f)}$ under the map
\[  \mathfrak{p}  \to \mathfrak{p} R_f \cap R_{(f)}  \]
sending homogeneous prime ideals of $R$ not containing $f$ into primes of
$R_{(f)}$.
\end{proposition}
\begin{proof}
Indeed, let $\mathfrak{p}$ be a homogeneous prime ideal of $R$ not containing
$f$. Consider $\phi(\mathfrak{p}) = \mathfrak{p} R_f \cap R_{(f)} $ as above.
This is a prime ideal, since $\mathfrak{p}  R_f$ is a prime ideal in $R_f$ by
basic properties of localization, and $R_{(f)} \subset R_f$ is a subring. (It
cannot contain the identity, because that would imply that a power of $f$ lay
in $\mathfrak{p}$.)

So we have defined a map $\phi: D'(f) \to \spec R_{(f)}$.  We can define its
inverse $\psi$ as follows. Given $\mathfrak{q} \subset R_{(f)} $ prime, we
define a
prime ideal $\mathfrak{p} = \psi(\mathfrak{q})$ of $R$ by saying that a
\textit{homogeneous} element $x \in
R$ belongs to $\mathfrak{p}$ if and only if $x^{\deg f}/f^{\deg x} \in
\mathfrak{q}$. It is easy to see that this is indeed an ideal, and that it is
prime by \rref{homogeneousprimeideal}.

Furthermore, it is clear that $\phi \circ \psi $ and $\psi \circ \phi$ are the
identity.
This is because $x \in \mathfrak{p}$ for $\mathfrak{p} \in D'(f)$ if and only
if $f^n x \in \mathfrak{p}$ for some $n$.

We next need to check that these are continuous, hence homeomorphisms.  If
$\mathfrak{a} \subset R$ is a homogeneous ideal, then $V(\mathfrak{a}) \cap
D'(f)$ is
mapped to $V(\mathfrak{a}R_f \cap R_{(f)}) \subset \spec R_{(f)}$, and vice
versa.
\end{proof}

\section{Filtered rings}

In practice, one often has something weaker than a grading. Instead of a way
of saying that an element is of degree $d$, one simply has a way of saying
that an element is ``of degree at most $d$.'' This leads to the definition of a
\emph{filtered} ring (and a filtered module). We shall use this definition in
placing topologies on rings and modules and, later, completing them.

\subsection{Definition}

\begin{definition}
A \textbf{filtration} on a ring $R$ is a sequence of ideals $R = I_0
\supset I_1 \supset \dots$ such that $I_m I_n \subset I_{m + n}$ for each
$m, n \in \mathbb{Z}_{ \geq 0}$. A ring with a filtration is called a
\textbf{filtered ring}.
\end{definition}

A filtered ring is supposed to be a generalization of a graded ring. If $R =
\bigoplus R_k$ is graded, then we can make $R$ into a filtered ring in a
canonical way by taking the ideal $I_m = \bigoplus_{k \geq m} R_k$ (notice
that we are using the fact that $R$ has only pieces in nonnegative gradings!).

We can make filtered rings into a category: a morphism of filtered rings $\phi:
R \to S$ is a ring-homomorphism preserving the filtration.


\begin{example}[The $I$-adic filtration]
Given an ideal $I \subset R$, we
can take powers of $I$ to generate a filtration. This filtration $R \supset I
\supset I^2 \supset \dots$ is called the \textbf{$I$-adic filtration,} and is
especially important when $R$ is local and $I$ the maximal ideal.

If one chooses the polynomial ring $k[x_1, \dots, x_n]$ over a field with $n$
variables and takes the $(x_1, \dots, x_n)$-adic filtration, one gets the same
as the filtration induced by the usual grading.
\end{example}

\begin{example}
As a specialization of the previous example, consider the power series ring
$R=k[[x]]$ over a field $k$ with one indeterminate $x$. This is a local ring
(with maximal ideal $(x)$), and it has a filtration with $R_i = (x^i)$.
Note that this ring, unlike the polynomial ring, is \emph{not} a graded ring in
any obvious way.
\end{example}




When we defined graded rings, the first thing we did thereafter was to define
the notion of a graded module over a graded ring. We do the analogous thing
for filtered modules.

\begin{definition}
Let $R$ be a filtered ring with a filtration $I_0 \supset I_1 \supset \dots$.
A \textbf{filtration} on an $R$-module $M$ is a decreasing sequence of submodules
\[ M = M_0 \supset M_1 \supset M_2 \supset \dots  \]
such that $I_m M_n \subset M_{n+m}$ for each $m, n$. A module together with a
filtration is called a \textbf{filtered module.}
\end{definition}


As usual, there is a category of filtered modules over a fixed filtered ring
$R$, with morphisms the module-homomorphisms that preserve the filtrations.

\begin{example}[The $I$-adic filtration for modules]
Let $R$ be any ring and $I \subset R$ any ideal. Then if we make $R$ into a
filtered ring with the $I$-adic filtration, we can make any $R$-module $M$
into a filtered $R$-module by giving $M$ the filtration
\[ M \supset IM \supset I^2M \supset \dots,  \]
which is also called the \textbf{$I$-adic filtration.}
\end{example}





\subsection{The associated graded}

We shall now describe a construction that produces graded things from filtered
ones.

\begin{definition} Given a filtered ring $R$ (with filtration
$\left\{I_n\right\}$), the
\textbf{associated graded ring} $\gr(R)$ is the graded ring
$$\gr(R) = \bigoplus_{n=0}^\infty I_n /I_{n+1}.$$

This is made into a ring by the following procedure. Given $a \in I_n$
representing a class $\overline{a} \in I_n/I_{n+1}$ and $b \in I_m$
representing a class $\overline{b} \in I_m/I_{m+1}$, we define
$\overline{a}\overline{b} $ to be the class in $I_{n+m}/I_{n+m+1}$ represented
by $ab$.
\end{definition}

It is easy to check that if different choices of representing elements $a,b$ were made in the above
description, the value of $\overline{a}\overline{b}$ thus defined would still
be the same, so that the definition is reasonable.

\begin{example}
Consider $R = \mathbb{Z}_{(p)}$ (the localization at $(p)$) with the $(p)$-adic
topology. Then $\gr(R) = \mathbb{Z}/p[t]$, as a graded ring.
For the successive quotients of ideals are of the form $\mathbb{Z}/p$, and it
is easy to check that multiplication lines up in the appropriate form.
\end{example}

In general, as we will see below, when one takes the $\gr$ of a noetherian ring
with the $I$-adic topology for some ideal $I$, one always gets a noetherian
ring.



\begin{definition}
Let $R$ be a filtered ring, and $M$ a filtered $R$-module (with filtration
$\left\{M_n\right\}$). We define the \textbf{associated graded module}
$\gr(M)$ as the graded $\gr(R)$-module
\[ \gr(M) = \bigoplus_{n} M_n/M_{n+1}  \]
where multiplication by an element of $\gr(R)$ is defined in a similar manner as above.
\end{definition}

In other words, we have defined a \emph{functor} $\gr$ from the category of filtered
$R$-modules to the category of \emph{graded} $\gr(R)$ modules.


Let $R$ be a filtered ring, and $M$ a finitely generated filtered $R$-module.
In general, $\gr(M)$ \emph{cannot} be expected to be a finitely generated
$\gr(R)$-module.
\begin{example}
Consider the ring $\mathbb{Z}_{(p)}$ (the localization of
$\mathbb{Z}$ at $p$), which we endow with the $p^2$-adic (i.e., $(p^2)$-adic)
filtration.
The associated graded is $\mathbb{Z}/p^2[t]$.

Consider $M=\mathbb{Z}_{(p)}$ with the filtration $M_m = (p^{m})$, i.e. the
usual $(p)$-adic topology. The claim is that $\gr(M)$ is
\emph{not} a finitely generated $\mathbb{Z}/p^2[t]$-module. This will follow
from \cref{} below, but we can see it directly: multiplication by $t$ acts by
zero on $\gr(M)$ (because this corresponds to multiplying by $p^2$ and shifting
the degree by one).
However, $\gr(M)$ is nonzero in every degree. If $\gr(M)$ were finitely
generated, it would be a finitely generated $\mathbb{Z}/p^2 \mathbb{Z}$-module,
which it is not.
\end{example}

\subsection{Topologies}

We shall now see that filtered rings and modules come naturally with
\emph{topologies} on them.

\begin{definition}
A \textbf{topological ring} is a ring $R$ together with a topology such that
the natural maps
\begin{gather*} R \times R \to R, \quad  (x,y) \mapsto x+y \\
R \times R \to R, \quad (x,y) \mapsto xy \\
R \to R, \quad x \mapsto -x
\end{gather*}
are continuous (where $R \times R$ has the product topology).
\end{definition}


\add{discussion of algebraic objects in categories}


In practice, the topological rings that we will be interested will exclusively
be \emph{linearly} topologized rings.

\begin{definition}
A topological ring is \textbf{linearly topologized} if there is a neighborhood
basis at $0$ consisting of open ideals.
\end{definition}

Given a filtered ring $R$ with a filtration of ideals $\left\{I_n\right\}$, we
can naturally linearly topologize $R$. Namely, we take as a basis the cosets
$x+I_n$ for $x \in R, n \in \mathbb{Z}_{\geq 0}$.
It is then clear that the $\left\{I_n\right\}$ form a neighborhood basis at
the origin (because any neighborhood $x+I_n$ containing $0$ must just be
$I_n$!).

\begin{example}
For instance, given any ring $R$ and any ideal $I \subset R$, we can consider
the \textbf{$I$-adic topology} on $R$. Here an element is ``small'' (i.e.,
close to zero) if it lies in a high power of $I$.
\end{example}


\begin{proposition}
A topology on $R$ defined by the filtration $\left\{I_n\right\}$ is Hausdorff
if and only if $\bigcap I_n = 0$.
\end{proposition}
\begin{proof}
Indeed, to say that $R$ is Hausdorff is to say that any two distinct elements
$x,y \in R$ can be separated by disjoint neighborhoods. If $\bigcap I_n = 0$,
we can find $N$ large such that $x -y \notin I_N$. Then $x+I_N, y + I_N$ are
disjoint neighborhoods of $x,y$.
The converse is similar: if $\bigcap I_n \neq 0$, then no neighborhoods can
separate a nonzero element in $\bigcap I_n$ from $0$.
\end{proof}

Similarly, if $M$ is a filtered $R$-module with a filtration
$\left\{M_n\right\}$, we can topologize $M$ by choosing the
$\left\{M_n\right\}$ to be a neighborhood basis at the origin.  Then $M$
becomes a \emph{topological group,} that is a group with a topology such that
the group operations are continuous.
In the same way, we find:

\begin{proposition}
The topology on $M$ is Hausdorff if and only if $\bigcap M_n = 0$.
\end{proposition}

Moreover, because of the requirement that $R_m M_{n}  \subset M_{n+m}$, it is
easy to see that the map
\[ R \times M \to M  \]
is itself continuous. Thus, $M$ is a \emph{topological} module.

Here is another example. Suppose $M$ is a linearly topologized module with a
basis of submodules $\left\{M_\alpha\right\}$ at the origin. Then any
submodule $N \subset M$ becomes a linearly topologized module with a basis of
submodules $\{N \cap M_\alpha\}$ at the origin with the relative topology.


\begin{proposition}
Suppose $M$ is filtered with the $\left\{M_n\right\}$. If $N \subset M$ is any
submodule, then the closure $\overline{N}$ is the intersection $\bigcap N + M_n$.
\end{proposition}
\begin{proof}
Recall that $x \in \overline{N}$ is the same as stipulating that every
neighborhood of $x$ intersect $N$. In other words, any basic neighborhood of
$x$ has to intersect $N$. This means that for each $n$, $x+M_n \cap N \neq
\emptyset$, or in other words $x \in M_n + N$.
\end{proof}

\section{The Artin-Rees Lemma}

We shall now show that for \emph{noetherian} rings and modules, the $I$-adic
topology is stable under passing to submodules; this useful result, the
Artin-Rees lemma, will become indispensable in our analysis of dimension
theory in the future.

More precisely, consider the following problem. Let $R$ be a ring and $I
\subset R$ an ideal. Then for any $R$-module $M$, we can endow $M$ with the
$I$-adic filtration $\left\{I^n M\right\}$, which defines a topology on $M$.
If $N \subset M$ is a submodule, then
$N$ inherits the subspace topology from $M$ (i.e. that defined by the filtration
$\left\{I^n M \cap N\right\}$). But $N$ can also be topologized by simply
taking the $I$-adic topology on it. The Artin-Rees lemma states that these two
approaches give the same result.

\subsection{The Artin-Rees Lemma}

\begin{theorem}[Artin-Rees lemma]
\label{artinrees}
Let $R$ be noetherian, $I \subset R$ an
ideal. Suppose $M$ is a finitely generated $R$-module and $M' \subset M$ a
submodule. Then the $I$-adic topology on $M$ induces the $I$-adic topology on $M'$.
More precisely,
there is a  constant $c$ such that
\[ I^{n+c} M \cap M' \subset I^n M'.  \]
So the two filtrations $\{I^n M \cap M'\}, \{I^n M'\}$ on $M'$ are equivalent up to a
shift.
\end{theorem}
\begin{proof}
The strategy to prove Artin-Rees will be as follows. Call a filtration
$\left\{M_n\right\}$ on an $R$-module $M$ (which is expected to be compatible
with the $I$-adic filtration on $R$, i.e. $I^n M_m \subset M_{m+n}$ for all
$n,m$) \textbf{$I$-good} if $I M_{n} = M_{n+1}$ for large $n \gg 0$.
Right now, we have the very $I$-good filtration $\{I^n M\}$ on $M$, and the induced
filtration $\{I^n M \cap M'\}$ on $M'$. The Artin-Rees lemma can be rephrased
as saying that this filtration on $M'$ is $I$-good: in fact, this is what we
shall prove.
It follows that if one has an $I$-good filtration on $M$, then the induced
filtration on  $M'$ is itself $I$-good.

To do this, we shall give an interpretation of $I$-goodness in terms of the
\emph{blowup algebra}, and use its noetherianness.
Recall that this is defined as $S = R \oplus I \oplus I^2  +
\dots$, where multiplication is defined in the obvious manner (see
\cref{blowupalg}). It can be regarded as a subring
of the polynomial ring
$R[t]$ where the coefficient of $t^i$ is required to be in $I^i$.
The blowup algebra is clearly a graded ring.

Given a filtration $\left\{M_n\right\}$ on an $R$-module $M$ (compatible with
the $I$-adic filtration of $M$), we can  make $\bigoplus_{n=0}^{\infty} M_n$
into a \emph{graded} $S$-module in an obvious manner.

Here is the promised interpretation of $I$-goodness:
\begin{lemma} \label{subartinrees}
 Then the
filtration $\left\{M_n\right\}$ of the finitely generated $R$-module $M$ is
$I$-good if and only if $\bigoplus M_n$ is a finitely generated $S$-module.
\end{lemma}
\begin{proof}
Let $S_1 \subset S$ be the subset of elements of degree one.
If $\bigoplus M_n$ is finitely generated as an $S$-module, then $S_1
(\bigoplus M_n) $ and $\bigoplus M_n$ agree in large degrees by
\cref{quickfinitenesslem};
however, this means that $IM_{n-1} = M_{n}$ for $n\gg 0$, which is $I$-goodness.

Conversely, if $\left\{M_n\right\}$ is an $I$-good filtration, then once the
$I$-goodness starts (say, for $n>N$, we have $IM_{n} = M_{n+1}$), there is no
need to add generators beyond $M_{N}$. In fact, we can use $R$-generators for
$M_0, \dots, M_N$ in the appropriate degrees to generate $\bigoplus M_n$ as an
$R'$-module.
\end{proof}

Finally, let $\left\{M_n\right\}$ be an $I$-good filtration on the finitely
generated $R$-module $M$. Let $M' \subset M$ be a submodule; we will, as
promised, show that the  induced filtration on $M'$ is $I$-good.
Now the associated module $\bigoplus_{n=0}^{\infty} (I^n M \cap M') $
is an $S$-submodule of $\bigoplus_{n=0}^{\infty} M_n$, which
by \cref{subartinrees} is finitely generated. We will show next that $S$
is noetherian, and consequently submodules of finitely generated
modules are finitely generated. Applying \cref{subartinrees} again, we will find
that the induced filtration must be $I$-good.

\begin{lemma}
Hypotheses as above,  the blowup algebra $R'$ is noetherian.
\end{lemma}
\begin{proof}
Choose generators $x_1, \dots, x_n \in I$; then there is a map $R[y_1, \dots,
y_n] \to S$ sending $y_i \to x_i $ (where $x_i$ is in degree one). This is surjective. Hence by the basis
theorem (\cref{hilbbasiscor}), $R'$ is noetherian.
\end{proof}


\end{proof}


\subsection{The Krull intersection theorem}

We now prove a useful consequence of the Artin-Rees lemma and Nakayama's
lemma. In fancier language, this states that the map from a noetherian local
ring into its
completion is an \emph{embedding}. A priori, this might not be obvious. For
instance, it might be surprising that the inverse limit of the highly torsion
groups $\mathbb{Z}/p^n$ turns out to be the torsion-free ring of $p$-adic
integers.

\begin{theorem}[Krull intersection theorem] \label{krullint} Let $R$ be a local noetherian ring with maximal ideal
$\mathfrak{m}$. Then,
\[ \bigcap \mathfrak{m}^i = (0).  \]
\end{theorem}

\begin{proof}
Indeed, the $\mathfrak{m}$-adic topology on $\bigcap \mathfrak{m}^i$ is the
restriction of the $\mathfrak{m}$-adic topology of $R$ on $\bigcap
\mathfrak{m}^i$ by the Artin-Rees lemma (\rref{artinrees}).
However, $\bigcap \mathfrak{m}^i$ is contained in every $\mathfrak{m}$-adic
neighborhood of $0$ in $R$; the induced topology on $\bigcap \mathfrak{m}^i$
is thus the indiscrete topology.

But to say that the $\mathfrak{m}$-adic topology on a module $N$ is indiscrete
is to say that $\mathfrak{m}N=N$, so $N=0$ by Nakayama. The result is thus
clear.

\end{proof}

By similar logic, or by localizing at each maximal ideal, we find:
\begin{corollary}
If $R$ is a commutative ring and $I $ is contained in the Jacobson radical of
$R$, then $\bigcap I^n = 0$.
\end{corollary}

It turns out that the Krull intersection theorem can be proved in the
following elementary manner, due to Perdry in \cite{Pe04}. The argument does
not use the Artin-Rees lemma. One can prove:

\begin{theorem}[\cite{Pe04}]
Suppose $R$ is a noetherian ring, $I \subset R$ an ideal. Suppose $b \in
\bigcap I^n$. Then as ideals $(b) = (b)I$.
\end{theorem}
In particular, it follows easily that $\bigcap I^n = 0$ under either of the
following conditions:
\begin{enumerate}
\item  $I$ is contained in the Jacobson radical of $R$.
\item $R$ is a domain and $I$ is proper.
\end{enumerate}

\begin{proof}
Let $a_1, \dots, a_k \in I$ be generators.
For each $n$, the ideal $I^n$ consists of the values of all homogeneous
polynomials  in $R[x_1, \dots, x_k]$ of degree $n$ evaluated on the tuple
$(a_1, \dots, a_k)$, as one may easily see.

It follows that if $b \in \bigcap I^n$, then for each $n$ there is a polynomial
$P_n \in
R[x_1, \dots, x_k]$ which is homogeneous of degree $n$ and which satisfies
\[ P_n(a_1, \dots, a_k) = b.  \]
The ideal generated by all the $P_n$ in $R[x_1, \dots, x_k]$ is finitely
generated by the Hilbert basis theorem. Thus there is $N$ such that
\[ P_N = Q_1 P_1 + Q_2 P_2 + \dots + Q_{N-1} P_{N-1}  \]
for some polynomials $Q_i \in R[x_1, \dots, x_k]$. By taking homogeneous
components, we can assume moreover that $Q_i$ is homogeneous of degree $N-i$
for each $i$. If we evaluate each at
$(a_1, \dots, a_k)$ we find
\[ b = b (Q_1(a_1, \dots,a_k) + \dots + Q_{N-1}(a_1, \dots, a_k)).  \]
But the $Q_i(a_1, \dots, a_k)$ lie in $I$ as all the $a_i$ do and $Q_i$ is
homogeneous of positive degree. Thus $b$ equals $b$ times something in $I$.
\end{proof}


% ============================ chapters/integrality.tex}
\chapter{Integrality and valuation rings}
\label{intchapter}

The notion of integrality is familiar from number theory: it is similar to
``algebraic'' but with the polynomials involved are required to be monic. In algebraic geometry, integral
extensions of rings correspond to correspondingly nice morphisms on the
$\spec$'s---when the extension is finitely generated, it turns out that the
fibers are finite. That is, there are only finitely many ways to lift a prime
ideal to the extension: if $A \to B$ is integral and finitely generated, then
$\spec B \to \spec A$ has finite fibers.

Integral domains that are \emph{integrally closed} in their quotient field will play an
important role for us. Such ``normal domains'' are, for example, regular in
codimension one, which means that the theory of Weil divisors
(see \cref{weildivsec}) applies
to them. It is particularly nice because Weil divisors are sufficient to
determine whether a function is regular on a normal variety.

A canonical example of an integrally closed ring is a valuation ring; we shall
see in this chapter that any integrally closed ring is an intersection of such.

\section{Integrality}

\subsection{Fundamentals}


As stated in the introduction to the chapter, integrality is a condition on
rings parallel to that of algebraicity for field extensions.
\begin{definition} \label{intdefn}
Let $R$ be a ring, and $R'$ an $R$-algebra.  An element $x \in R'$
is said to be \textbf{integral} over $R$ if $x$ satisfies a monic polynomial
equation in $R[X]$, say
\[ x^n + r_1 x^{n-1} + \dots + r_n = 0, \quad r_1, \dots, r_n \in R.  \]
We can say that $R'$ is \textbf{integral} over $R$ if every $x \in R'$ is
integral over $R$.
\end{definition}

Note that in the definition, we are not requiring $R$ to be a \emph{subring} of
$R'$.

\begin{example} \label{sixthroot}
$\frac{1+\sqrt{-3}}{2}$ is integral over $\mathbb{Z}$; it is in fact a sixth
root of unity, thus satisfying the equation $X^6  -1 = 0$.
However, $\frac{1+\sqrt{5}}{2}$ is not integral over $\mathbb{Z}$. To explain this,
however, we will
need to work a bit more (see \cref{onegeneratorintegral} below).
\end{example}


\begin{example}
Let $L/K$ be a field extension. Then $L/K$ is integral if and only if it is
algebraic, since $K$ is a field and we can divide polynomial equations by the
leading coefficient to make them monic.
\end{example}

\begin{example}
Let $R$ be a graded ring. Then the subring $R^{(d)} \subset R$ was defined in
\cref{dpowerofring}; recall that this consists of elements of $R$ all of whose
nonzero homogeneous components live in degrees that are multiples of $d$.
Then the $d$th power of any homogeneous
element in $R$ is in $R^{(d)}$. As a result, every homogeneous element of $R$
is integral over $R^{(d)}$.
\end{example}

We shall now interpret the condition of integrality in terms of finite
generation of certain modules.
Suppose $R$ is a ring, and $R'$ an $R$-algebra.  Let $x \in R'$.

\begin{proposition}  \label{onegeneratorintegral}
$x \in R'$ is integral over $R$ if and only if the subalgebra $R[x] \subset R'$
(generated by $R, x$) is a finitely generated
$R$-module.
\end{proposition}

This notation is an abuse of notation (usually $R[x]$ refers to a polynomial
ring), but it should not cause confusion.

This result for instance lets us show that $\frac{1+\sqrt{-5}}{2}$ is not integral
over $\mathbb{Z}$, because when you keep taking powers, you get arbitrarily
large denominators: the arbitrarily large denominators imply that it cannot be
integral.

\begin{proof}
If $x  \in R'$ is integral, then $x$ satisfies
\[ x^n + r_1 x^{n-1}+\dots+r_n = 0, \quad r_i \in R.  \]
Then $R[x]$ is generated as an $R$-module by $1, x, \dots, x^{n-1}$.  This is
because the submodule of $R'$ generated by $1, x ,\dots, x^{n-1}$ is closed under
multiplication by $R$ and by multiplication by $x$ (by the above equation).

Now suppose $x$ generates a subalgebra $R[x] \subset R'$ which is a finitely
generated $R$-module.  Then the increasing sequence
of $R$-modules generated by $\{1\}, \left\{1, x\right\}, \left\{1, x,
x^2\right\}
, \dots$ must stabilize, since the union is $R[x]$.\footnote{As an easy
exercise, one may see that if a finitely generated module $M$ is the union of
an increasing sequence of submodules $M_1 \subset M_2 \subset M_3 \subset
\dots$, then $M  = M_n$ for some $n$; we just need to take $n$ large enough
such that $M_n$ contains each of the finitely many generators of $M$.}  It follows that some $x^n$
can be expressed as a linear combination of smaller powers of $x$. Thus $x$ is
integral over $R$.
\end{proof}

So, if $R'$ is an $R$-module, we can say that
an element $x \in R'$ is \textbf{integral} over $R$ if either of the following
equivalent conditions are satisfied:

\begin{enumerate}
\item There is a monic polynomial in $R[X]$ which vanishes on $x$.
\item $R[x] \subset R'$ is a finitely generated $R$-module.
\end{enumerate}

\begin{example}
Let $F$ be a field, $V$ a finite-dimensional $F$-vector space, $T: V \to V$ a
linear transformation. Then the ring generated by $T$ and $F$ inside
$\mathrm{End}_F(V)$ (which is a noncommutative ring) is finite-dimensional
over $F$.
Thus, by similar reasoning, $T$ must satisfy a polynomial equation with
coefficients in $F$ (e.g. the characteristic polynomial).
\end{example}

Of course, if $R'$ is integral over $R$, $R'$ may not be a finitely generated
$R$-module. For instance, $\overline{\mathbb{Q}}$ is not a finitely generated
$\mathbb{Q}$-module, although the extension is integral. As we shall see in
the next section, this is always the case if $R'$ is a finitely
generated $R$-\emph{algebra}.


We now will add a third equivalent condition to this idea of ``integrality,''
at least in the case where the structure map is an injection.

\begin{proposition} \label{thirdintegralitycriterion}
Let $R$ be a ring, and suppose $R$ is a subring of $R'$.
$x \in R'$ is integral if and only if there exists a
 finitely generated faithful $R$-module $M \subset R'$ such that $R \subset M$ and
 $xM \subset M$.
\end{proposition}
A module $M$ is \emph{faithful} if $x M = 0$ implies $x=0$. That is, the map
from $R$ into the $\mathbb{Z}$-endomorphisms of $M$ is injective.
If $R$ is a \emph{subring} of $R'$ (i.e. the structure map $R \to R'$ is
injective), then $R'$ for instance is a faithful $R$-module.
\begin{proof}
It's obvious that the second condition above (equivalent to integrality)
implies the condition of this
proposition. Indeed, one could just take $M = R[x]$.

Now let us prove that if there exists such an $M$ which is finitely generated,
then $x$ is integral. Just because $M$ is finitely generated, the
submodule $R[x]$ is not obviously finitely generated. In particular, this
implication  requires a bit of proof.


We shall prove that the condition of this proposition implies integrality.
Suppose $y_1, \dots, y_k \in M$ generate $M$ as $R$-module. Then multiplication
by $x$ gives an $R$-module map $M \to M$. In particular, we can write
\[ xy_i = \sum a_{ij} y_j  \]
where each $a_{ij} \in R$.
These $\left\{a_{ij}\right\}$ may not be unique, but let us make some choices;
we get a $k$-by-$k$ matrix $A \in M_k(R)$. The claim is that $x$ satisfies the
characteristic polynomial of $A$.

Consider the matrix
\[ (x 1 - A) \in M_n(R').  \]
Note that $(x1-A)$ annihilates each $y_i$, by the choice of $A$.
We can consider the adjoint $B = (x1  -A)^{adj}$.  Then
\[ B(x1 - A) = \det(x1 - A) 1.  \]
This product of matrices obviously annihilates each vector $y_i$.  It follows
that
\[ (\det(x1 - A) y_i = 0, \quad \forall i,  \]
which implies that $\det (x1-A)$ kills $M$. This implies that $\det (x1 -
A)=0$ since $M$ is faithful.

As a result, $x$ satisfies the characteristic polynomial.
\end{proof}

\begin{exercise}
Let $R$ be a noetherian
local domain with maximal ideal $\mathfrak{m}$. As we will define shortly, $R$
is \emph{integrally closed} if every element of the quotient field $K=K(R)$
integral over $R$ belongs to $R$ itself. Then if $x \in K$ and $x \mathfrak{m}
\subset \mathfrak{m}$, we have $x \in R$.
\end{exercise}
\begin{exercise} Let us say that an $A$-module is \emph{$n$-generated}
if it is generated by at most $n$ elements.

Let $A$ and $B$ be two rings such that $A\subset B$, so that $B$ is an
$A$-module.

Let
$n\in\mathbb{N}$. Let $u\in B$. Then, the following four assertions
 are equivalent:

\begin{enumerate}
\item   There exists a monic polynomial
$P\in A\left[  X\right]  $ with $\deg P=n$ and $P\left(  u\right)  =0$.
\item  There exist a $B$-module $C$ and an
$n$-generated $A$-submodule $U$ of $C$ such that $uU\subset U$ and such that
every $v\in B$ satisfying $vU=0$ satisfies $v=0$. (Here, $C$ is an $A$-module,
since $C$ is a $B$-module and $A\subset B$.)
\item  There exists an $n$-generated
$A$-submodule $U$ of $B$ such that $1\in U$ and $uU\subset U$.
\item  As an $A$-module, $A[u]$ is spanned by $1, u, \dots,
u^{n-1}$.\end{enumerate}
\end{exercise}


We proved this to show that the set of integral elements is well behaved.

\begin{proposition}
Let $R \subset R'$. Let $S = \left\{x \in R': x \text{ is integral over }
R\right\}$. Then $S$ is a subring of $R'$. In particular, it is closed under
addition and multiplication.
\end{proposition}
\begin{proof}
Suppose $x,y \in S$.
We can consider the finitely generated modules $R[x], R[y] \subset R'$
generated (as algebras) by $x$ over $R$. By assumption, these are finitely
generated $R$-modules. In particular, the tensor product
\[ R[x] \otimes_R R[y]  \]
is a finitely generated $R$-module (by \cref{fingentensor}).

We have a ring-homomorphism $R[x]\otimes_R R[y] \to R'$
which comes from the inclusions $R[x], R[y] \rightarrowtail R'$.
Let $M$ be the image of $R[x] \otimes_R R[y]$ in $R'$. Then $M$ is an
$R$-submodule of $R'$, indeed an $R$-subalgebra containing $x,y$.  Also, $M$ is
finitely generated. Since $x+y, xy\in M$ and $M$ is a subalgebra, it
follows that
\[ (x+y) M \subset M, \quad xy M \subset M.  \]
Thus $x+y, xy$ are integral over $R$.
\end{proof}

Let us consider the ring $\mathbb{Z}[\sqrt{-5}]$; this is the canonical
example of a ring where unique factorization fails. This is because \( 6 = 2
\times 3 = (1+\sqrt{-5})(1-\sqrt{-5}).  \)
One might ask: what about $\mathbb{Z}[\sqrt{-3}]$? It turns out that
$\mathbb{Z}[\sqrt{-3}]$ lacks unique factorization as well. Indeed, here we have
\[ (1 - \sqrt{-3})(1+\sqrt{-3}) = 4 = 2 \times 2.  \]
These elements can be factored no more, and $1 - \sqrt{-3}$ and $2$ do not
differ by units.
So in this ring, we have a failure of unique factorization. Nonetheless, the
failure of unique factorization in $\mathbb{Z}[\sqrt{-3}]$ is less
noteworthy, because $\mathbb{Z}[\sqrt{-3}]$ is not \emph{integrally closed}. Indeed, it turns out that $\mathbb{Z}[\sqrt{-3}]$ is
contained in the larger ring
\( \mathbb{Z}\left[ \frac{1 + \sqrt{-3}}{2}\right],  \)
which does have unique factorization, and this larger ring is finite over
$\mathbb{Z}[\sqrt{-3}]$.\footnote{In fact, $\mathbb{Z}[\sqrt{-3}]$ is an index two subgroup of $\mathbb{Z}\left[
\frac{1 + \sqrt{-3}}{2}\right]$, as the ring $\mathbb{Z}[ \frac{1 + \sqrt{-3}}{2}]$
can be described as the set of elements $a +
b\sqrt{-3}$ where $a,b$ are either both integers or both integers plus
$\frac{1}{2}$, as is easily seen: this set is closed under addition and
multiplication.}
 Since being integrally closed is a
prerequisite for having unique factorization (see \cref{} below), the failure in
$\mathbb{Z}[\sqrt{-3}]$ is not particularly surprising.

Note that, by contrast, $\mathbb{Z}[ \frac{1 + \sqrt{-5}}{2}]$ does not
contain $\mathbb{Z}[\sqrt{-5}]$ as a finite index subgroup---it cannot be
slightly enlarged in the same sense. When one enlarges $\mathbb{Z}[\sqrt{-5}]$,
one has to add a lot of stuff.
We will see more formally that $\mathbb{Z}[\sqrt{-5}]$ is \emph{integrally
closed} in its quotient field, while $\mathbb{Z}[\sqrt{-3}]$ is not. Since
unique factorization domains are automatically integrally closed, the failure
of $\mathbb{Z}[\sqrt{-5}]$ to be a UFD is much more significant than that of
$\mathbb{Z}[\sqrt{-3}]$.


\subsection{Le sorite for integral extensions}

In commutative algebra and algebraic geometry, there are a lot of standard
properties that a \emph{morphism} of rings $\phi: R \to S$ can have: it could
be of \emph{finite type} (that is, $S$ is finitely generated over $\phi(R)$),
it could be \emph{finite} (that is, $S$ is a finite $R$-module), or it could
be \emph{integral} (which we have defined in \cref{intdefn}). There are many more examples
that we will encounter as we dive deeper into commutative algebra.
In algebraic geometry, there are corresponding properties of morphisms of
\emph{schemes,} and there are many more interesting ones here.

In these cases, there is usually---for any reasonable property---a standard
and familiar list of
properties that one proves about them. We will refer to such lists as
``sorites,'' and prove our first one now.

\begin{proposition}[Le sorite for integral morphisms]
\begin{enumerate}
\item For any ring $R$ and any ideal $I \subset R$, the map $R \to R/I$ is
integral.
\item If $\phi: R \to S$ and $\psi: S \to T$ are integral morphisms, then so
is $\psi \circ \phi: R \to T$.
\item If $\phi: R \to S$ is an integral morphism and $R'$ is an $R$-algebra,
then the base-change
$R' \to R' \otimes_R S$ is integral.
\end{enumerate}
\end{proposition}

\begin{proof}
The first property is obvious. For the second, the condition of
integrality in a morphism of rings depends on the inclusion of the image
in the codomain. So we can suppose that $R \subset S \subset T$. Suppose $t
\in T$. By assumption, there is a monic polynomial equation
\[ t^n + s_1 t^{n-1} + \dots + s_n = 0  \]
that $t$ satisfies, where each $s_i \in S$.

In particular, we find that $t$ is integral over $R[s_1, \dots, s_n]$.
As a result, the module $R[s_1, \dots, s_n, t]$ is finitely generated over the
ring $R'=R[s_1, \dots, s_n]$.
By the following \cref{finitelygeneratedintegral}, $R'$ is a finitely generated
$R$-module. In
particular, $R[s_1, \dots, s_n,t]$ is a finitely generated $R$-module (not
just a
finitely generated $R'$-module).

Thus the $R$-module $R[s_1, \dots, s_n,t]$  is a faithful
$R'$ module, finitely generated over $R$, which is preserved under
multiplication by $t$.
\end{proof}

We now prove a result that can equivalently be phrased as ``finite type plus
integral implies finite'' for a map of rings.

\begin{proposition} \label{finitelygeneratedintegral}
Let $R'$ be a finitely generated, integral $R$-algebra. Then $R'$ is a
finitely generated $R$-module: that is, the map $R \to R'$ is finite.
\end{proposition}
\begin{proof}
Induction on the number of generators of $R'$ as $R$-algebra. For one
generator, this follows from \rref{onegeneratorintegral}.
In general, we will have $R' = R[\alpha_1 ,\dots, \alpha_n]$ for some
$\alpha_i \in R'$.
By the inductive hypothesis, $R[\alpha_1 , \dots, \alpha_{n-1}]$ is a finite
$R$-module; by the case of one generator, $R'$ is a finite $R[\alpha_1, \dots,
\alpha_{n-1}]$-module. This establishes the result by the next exercise.
\end{proof}

\begin{exercise}
Let $R \to S, S \to T$ be morphisms of rings. Suppose $S$ is a finite
$R$-module and $T$ a finite $T$-module. Then $T$ is a finite $R$-module.
\end{exercise}




\subsection{Integral closure}

Let $R, R'$ be rings.
\begin{definition}
If $R \subset R'$, then the set $S = \left\{x \in R': x \ \mathrm{is \
integral  }\right\}$ is called the \textbf{integral closure} of $R$ in $R'$. We
say that $R$ is \textbf{integrally closed in $R'$} if $S = R'$.


When $R$ is a domain, and $K$ is the quotient field,  we shall simply
say that $R$ is \textbf{integrally closed} if it is integrally closed in
$K$.
Alternatively, some people say that $R$ is \textbf{normal} in this case.
\end{definition}

Integral closure (in, say, the latter sense) is thus an operation that maps
integral domains to integral domains. It is easy to see that the operation is
\emph{idempotent:} the integral closure of the integral closure is the integral
closure.


\begin{example}
The integers $\mathbb{Z} \subset \mathbb{C}$ have as integral closure (in
$\mathbb{C}$) the set
of complex numbers  satisfying a monic polynomial with integral
coefficients.  This set is called the set of \textbf{algebraic integers}.

For instance, $i$ is an algebraic integer because it satisfies the equation $X^2 +1 = 0$.
$\frac{1 - \sqrt{-3}}{2}$ is an algebraic integer, as we talked about last
time; it is a sixth root of unity.  On the other hand, $\frac{1+\sqrt{-5}}{2}$
is not an algebraic integer.
\end{example}

\begin{example}
Take $\mathbb{Z} \subset \mathbb{Q}$. The claim is that $\mathbb{Z}$ is
integrally closed in its quotient field $\mathbb{Q}$, or simply---integrally
closed.
\end{example}
\begin{proof}
We will build on this proof later. Here is the point. Suppose $\frac{a}{b}
\in \mathbb{Q}$ satisfying an equation
\[ P(a/b) = 0, \quad P(t) = t^n + c_1 t^{n-1} + \dots + c_0 , \ \forall c_i \in
\mathbb{Z}.\]
Assume that $a,b$ have no common factors; we must prove that $b$ has no prime
factors, so is $\pm 1$.
If $b$ had a prime factor, say $q$, then we must obtain a contradiction.

We interrupt with a definition.
\begin{definition}
The \textbf{valuation at $q$} (or \textbf{$q$-adic valuation}) is the map
$v_q: \mathbb{Q}^* \to \mathbb{Z}$ is the
function sending $q^k (a/b)$ to $k$ if $q \nmid a,b$. We extend this to all
rational numbers via $v(0) = \infty$.
\end{definition}
In general, this just counts the number of factors of $q$ in the expression.


Note the general property that
\begin{equation} \label{val1} v_q(x+y) \geq \min( v_q(x), v_q(y)) .
\end{equation}
If $x,y$ are both divisible by some power of $q$, so is $x+y$; this is the
statement above. We also have the useful property
\begin{equation} \label{val2} v_q(xy) = v_q(x) + v_q(y).  \end{equation}




Now return to the proof that $\mathbb{Z}$ is normal. We would like to show that
\( v_q(a/b) \geq 0.  \)
This will prove that $b$ is not divisible by $q$. When we show this for all
$q$, it will follow that $a/b \in \mathbb{Z}$.

We are assuming that $P(a/b) = 0$. In particular,
\[ \left( \frac{a}{b}  \right)^n = -c_1 \left( \frac{a}{b}  \right)^{n-1} -
\dots - c_0.  \]
Apply $v_q$ to both sides:
\[ n v_q ( a/b) \geq \min_{i>0} v_q( c_i (a/b)^{n-i}).  \]
Since the $c_i \in \mathbb{Z}$, their valuations are nonnegative. In
particular, the right hand side is at least
\[ \min_{i>0}  (n-i) v_q(a/b). \]
This cannot happen if $v_q(a/b)<0$, because $n-i < n$ for each $i>0$.
\end{proof}

This argument applies more generally. If  $K$ is a field, and $R \subset K$ is
a subring  ``defined
by valuations,'' such as the $v_q$, then $R$ is integrally closed in its
quotient field.
More precisely,
note the reasoning of the previous example: the key idea was that $\mathbb{Z}
\subset \mathbb{Q}$ was characterized by the rational numbers $x$ such that
$v_q(x) \geq 0$ for all primes $q$.
We can abstract this idea as follows. If there exists a family of functions $\mathcal{V}$ from $K^*
\to \mathbb{Z}$ (such as
$\left\{v_q: \mathbb{Q}^* \to \mathbb{Z}\right\}$) satisfying \eqref{val1} and
\eqref{val2} above such that $R$ is
the set of elements such that $v(x) \geq 0, v \in \mathcal{V}$ (along with
$0$), then $R$ is integrally closed in $K$.
We will talk more about
this, and about valuation rings, below.

\begin{example}
We saw earlier (\cref{sixthroot}) that $\mathbb{Z}[\sqrt{-3}]$ is not
integrally closed, as $\frac{1 + \sqrt{-3}}{2}$ is integral over this ring and
in the quotient field, but not in the ring.
\end{example}

We shall give more examples in the next subsection.


\subsection{Geometric examples}

Let us now describe the geometry of a non-integrally closed ring.
Recall that finitely generated (reduced) $\mathbb{C}$-algebras are supposed to
correspond to affine algebraic varieties. A \emph{smooth} variety (i.e., one
that is a complex manifold) will always correspond to an integrally closed
ring (though this relies on a deep result that a regular local ring is a
factorization domain, and consequently integrally closed): non-normality is a sign of singularities.
\begin{example}
Here is a ring which is not integrally closed. Take  $\mathbb{C}[x, y]/(x^2
- y^3)$. Algebraically, this is the subring of the polynomial ring
  $\mathbb{C}[t]$ generated by $t^2$ and $t^3$.

In the complex plane, $\mathbb{C}^2$, this corresponds to the subvariety $C
\subset \mathbb{C}^2$ defined by $x^2 =
y^3$.  In $\mathbb{R}^2$, this can be drawn: it has a singularity at $(x,y)=0$.

Note that $x^2 = y^3$ if and only if there is a complex number $z$ such that $x
= z^3, y = z^2$. This complex number $z$ can be recovered via $x/y$ when $x,y
\neq 0$. In particular, there is a map $\mathbb{C} \to C$ which sends $z \to
(z^3, z^2)$.  At every point other than the origin, the inverse can be
recovered using rational functions. But this does not work at the origin.

We can think of $\mathbb{C}[x,y]/(x^2 - y^3)$ as the subring $R'$ of
$\mathbb{C}[z]$
generated by $\left\{z^n, n \neq 1\right\}$.  There is a map from
$\mathbb{C}[x,y]/(x^2 - y^3)$ sending $x \to z^3, y \to z^2$.  Since these two
domains are isomorphic, and $R'$ is not integrally closed, it follows that
$\mathbb{C}[x,y]/(x^2 - y^3)$ is not integrally closed.
The element $z$ can be thought of as an element of the fraction field of $R'$
or of $\mathbb{C}[x,y]/(x^2 - y^3)$.
It is integral, though.

The failure of the ring to be integrally closed has to do with the singularity
at the
origin.
\end{example}


We now give a generalization of the above example.

\begin{example}
This example is outside the scope of the present course.  Say that $X \subset
\mathbb{C}^n$ is given as the zero locus of some holomorphic functions
$\left\{f_i: \mathbb{C}^{n} \to \mathbb{C}\right\}$.  We just gave an example
when $n=2$.
Assume that $0 \in X$, i.e. each $f_i$ vanishes at the origin.

Let $R$ be the ring of germs of holomorphic functions $0$, in other words
holomorphic functions from small open neighborhoods of zero.  Each of these
$f_i$ becomes an  element of $R$.  The ring
\( R/(\left\{f_i\right\} ) \)
is called the ring of germs of holomorphic functions on $X$ at zero.

Assume that $R$ is a domain.  This assumption, geometrically, means that near
the point zero in $X$, $X$ can't be broken into two smaller closed analytic
pieces.  The fraction field of $R$ is to be thought of as the ring of
germs of meromorphic functions on $X$ at zero.

We state the following without proof:

\begin{theorem}
Let $g/g'$ be an element of the fraction field, i.e. $g, g' \in R$. Then $g/g'$
is integral over $R$ if and only if $g/g'$ is bounded near zero.
\end{theorem}

In the previous example of $X$ defined by $x^2 = y^3$, the function $x/y$
(defined near the origin on the curve) is
bounded near the origin, so it is integral over the ring of germs of regular
functions. The reason it is not defined near the origin is \emph{not} that it
blows up. In fact, it extends continuously, but not holomorphically, to the
rest of the variety $X$.
\end{example}

\section{Lying over and going up}
We now interpret integrality in terms of the geometry of $\spec$.
In general, for $R \to S$ a ring-homomorphism, the induced map $\spec S \to
\spec R$ need not be topologically nice; for instance, even if $S$ is a
finitely generated $R$-algebra, the image of $\spec S$ in $\spec R$ need not
be either open or closed.\footnote{It is, however, true that if $R$ is
\emph{noetherian} (see \rref{noetherian}) and $S$ finitely generated over
$R$, then the image of $\spec S$ is \emph{constructible,} that is, a finite
union of locally closed subsets. \add{this result should be added sometime}.}

We shall see that under conditions of integrality, more can be said.



\subsection{Lying over}

In general, given a morphism of algebraic varieties $f: X \to Y$, the image of
a closed subset $Z \subset X$ is far from closed.  For instance, a regular function $f: X \to \mathbb{C}$
that is a closed map would have to be either surjective or constant (if $X$ is
connected, say).
Nonetheless, under integrality hypotheses, we can say more.

\begin{proposition}[Lying over] \label{lyingover}
If $\phi: R \to R'$ is an integral morphism, then the induced map
\[  \spec R' \to \spec R  \]
is a closed map; it is surjective if $\phi$ is injective.
 \end{proposition}

Another way to state the last claim, without mentioning $\spec R'$, is the
following. Assume $\phi$ is injective and integral. Then if
$\mathfrak{p} \subset R$ is prime, then there exists $\mathfrak{q} \subset R'$
such that $\mathfrak{p}$ is the inverse image $\phi^{-1}(\mathfrak{q})$.

\begin{proof} First suppose $\phi$ injective, in which case we must prove the
map $\spec R' \to \spec R$ surjective.
Let us reduce to the case of a local ring.
For a prime $\mathfrak{p} \in \spec R$, we must show that $\mathfrak{p}$
arises as the inverse image of an element of $\spec R'$.
So we replace $R$ with $R_{\mathfrak{p}}$.  We get a map
\[ \phi_{\mathfrak{p}}: R_{\mathfrak{p}} \to (R- \mathfrak{p})^{-1} R'  \]
which is injective if $\phi$ is, since localization is an exact functor. Here
we
have localized both $R, R'$ at the multiplicative subset $R - \mathfrak{p}$.

Note that $\phi_{\mathfrak{p}}$ is an integral extension too. This follows
because integrality is preserved by base-change.
We will now prove the result for $\phi_{\mathfrak{p}}$; in particular, we
will show
that there is a prime ideal of $(R- \mathfrak{p})^{-1} R'$ that pulls back to
$\mathfrak{p}R_{\mathfrak{p}}$. These will imply that if we pull this prime
ideal back to $R'$, it will pull back to $\mathfrak{p}$ in $R$. In detail, we
can consider the diagram
\[ \xymatrix{
\spec (R-\mathfrak{p})^{-1} R'\ar[d]  \ar[r] & \spec R_{\mathfrak{p}} \ar[d] \\
\spec R' \ar[r] &  \spec R
}\]
which shows that if $\mathfrak{p} R_{\mathfrak{p}}$ appears in the image of the top map, then
$\mathfrak{p}$
arises as the image of something in $\spec R'$.
So it is sufficient for the proposition (that is, the case of $\phi$
injective) to handle the case of $R$ local, and
$\mathfrak{p}$ the maximal ideal.


In other words, we need to show that:
\begin{quote}
If $R$ is a \emph{local} ring, $\phi: R \hookrightarrow R'$ an injective
integral morphism, then the maximal ideal of $R$ is the inverse image of
something in $\spec R'$.
\end{quote}

Assume $R$ is local with maximal ideal $\mathfrak{p}$. We want to find a prime ideal $\mathfrak{q} \subset R'$ such that
$\mathfrak{p}  = \phi^{-1}(\mathfrak{q})$. Since $\mathfrak{p}$ is already
maximal, it will suffice to show that $\mathfrak{p} \subset
\phi^{-1}(\mathfrak{q})$. In particular, we need to show that there is a prime
ideal $\mathfrak{q}$ such that
\( \mathfrak{p} R' \subset \mathfrak{q}.  \)
The pull-back of this will be $\mathfrak{p}$.

If $\mathfrak{p}R' \neq R'$, then
$\mathfrak{q}$ exists, since every proper ideal of a ring is contained in a
maximal ideal.  We will in fact show
\begin{equation} \label{thingdoesn'tgenerate} \mathfrak{p} R' \neq R',
\end{equation}
or that $\mathfrak{p}$ does not generate the unit ideal in $R'$.
If we prove \eqref{thingdoesn'tgenerate}, we will thus be able to find our
$\mathfrak{q}$, and we will be done.

Suppose the
contrary, i.e. $\mathfrak{p}R' = R'$. We will derive a contradiction using
Nakayama's lemma (\cref{nakayama}).
Right now, we cannot apply Nakayama's lemma directly because $R'$ is not a
finite $R$-module. The idea is that we will ``descend'' the ``evidence'' that
\eqref{thingdoesn'tgenerate} fails to a small subalgebra of $R'$, and then
obtain a contradiction.
To do this, note that $1 \in \mathfrak{p}R'$, and we can write
\[ 1 = \sum x_i \phi(y_i)  \]
where $x_i \in R', y_i \in \mathfrak{p}$.
This is the ``evidence'' that \eqref{thingdoesn'tgenerate} fails, and it
involves only a finite amount of data.

Let $R''$ be the subalgebra of $R'$ generated by $\phi(R)$ and the $x_i$. Then
$R'' \subset R'$ and is finitely generated as an $R$-algebra, because it is generated by
the $x_i$. However, $R''$ is integral over $R$ and thus finitely generated as an
$R$-module, by \cref{finitelygeneratedintegral}. This
is where integrality comes in.

So $R''$ is a finitely generated $R$-module. Also, the expression
$1 = \sum x_i \phi(y_i)$ shows that $\mathfrak{p}R'' = R''$. However, this
contradicts Nakayama's lemma. That brings the contradiction, showing that
$\mathfrak{p}$ cannot generate $(1)$ in $R'$, and proving the surjectivity
part of  lying over theorem.

Finally, we need to show that if $\phi: R \to R'$ is \emph{any} integral
morphism, then $\spec R' \to \spec R$ is a closed map. Let $X = V(I) $ be a
closed subset of $\spec R'$. Then the image of $X$ in $\spec R$ is the image
of the map
\[ \spec R'/I \to \spec R   \]
obtained from the morphism $R \to R' \to  R'/I$, which is integral; thus we are
reduced to showing that any integral morphism $\phi$ has closed image on the
$\spec$.
Thus we are reduced to $X = \spec R'$, if we throw out $R'$ and replace it by
$R'/I$.

In other words, we must prove the following statement. Let $\phi: R \to R'$ be
an integral morphism; then the image of $\spec R'$ in $\spec R$ is closed.
But, quotienting by $\ker \phi$ and taking the map $R/\ker \phi \to R'$, we
may reduce to the case of $\phi$ injective; however, then this follows from
the surjectivity result already proved.
\end{proof}

In general, there will be \emph{many} lifts of a given prime ideal.
Consider for instance the inclusion $\mathbb{Z} \subset \mathbb{Z}[i]$.
Then the prime ideal $(5) \in \spec \mathbb{Z}$ can be lifted either to $(2+i)
\in \spec \mathbb{Z}[i]$
or $(2-i) \in \spec \mathbb{Z}[i]$.
These are distinct prime ideals: $\frac{2+i}{2-i} \notin \mathbb{Z}[i]$. But
note that any element of $\mathbb{Z}$ divisible by $2+i$ is automatically
divisible by its conjugate $2-i$, and consequently by their product $5$
(because $\mathbb{Z}[i]$ is  a UFD, being a euclidean domain).

Nonetheless, the different lifts are incomparable.

\begin{proposition} \label{incomparableintegral}
Let $\phi: R \to R'$ be an integral morphism. Then given $\mathfrak{p} \in
\spec R$, there are no inclusions among the elements $\mathfrak{q} \in \spec
R'$ lifting $\mathfrak{p}$.
\end{proposition}
In other words, if $\mathfrak{q}, \mathfrak{q}' \in \spec R'$ lift
$\mathfrak{p}$, then $\mathfrak{q} \not\subset \mathfrak{q}'$.
\begin{proof}
We will give a ``slick'' proof by various reductions.
Note that the operations of localization and quotienting only shrink the
$\spec$'s: they do not ``merge'' heretofore distinct prime ideals into one.
Thus, by quotienting $R$ by $\mathfrak{p}$, we may assume $R$ is a
\emph{domain} and that $\mathfrak{p} = 0$.
Suppose we had two primes $\mathfrak{q} \subsetneq \mathfrak{q}'$ of $R'$
lifting $(0) \in \spec R$.
Quotienting $R'$ by $\mathfrak{q}$, we may assume that $\mathfrak{q}  = 0$.
We could even assume $R \subset R'$, by quotienting by the kernel of $\phi$.
The next lemma thus completes the proof, because it shows that $\mathfrak{q}'
= 0$, contradiction.
\end{proof}

\begin{lemma}
Let $R \subset R'$ be an inclusion of integral domains, which is an integral
morphism. If $\mathfrak{q} \in \spec R'$ is a nonzero prime ideal, then
$\mathfrak{q} \cap R$ is nonzero.
\end{lemma}
\begin{proof}
Let $x \in \mathfrak{q}'$ be nonzero. There is an equation
\[ x^n + r_1 x^{n-1} + \dots + r_n = 0,  \quad r_i \in R, \]
that $x$ satisfies, by assumption.
Here we can assume $r_n \neq 0$; then $r_n \in \mathfrak{q}' \cap R$ by
inspection, though. So this intersection is nonzero.

\end{proof}

\begin{corollary}
Let $R \subset R'$ be an inclusion of integral domains, such that $R'$ is
integral over $R$. Then if one of $R, R'$ is a field, so is the other.
\end{corollary}
\begin{proof}
Indeed, $\spec R' \to \spec R$ is surjective by \cref{lyingover}: so if $\spec
R'$ has one element (i.e., $R'$ is a field), the same holds for $\spec R$
(i.e., $R$ is a field). Conversely, suppose $R$ a field.
Then any two prime ideals in $\spec R'$ pull back to the same element of $\spec
R$. So, by \cref{incomparableintegral}, there can be no inclusions among the prime ideals of $\spec
R'$. But $R'$ is a domain, so it must then be a field.
\end{proof}


\begin{exercise} Let $k$ be a field.
Show that $k[\mathbb{Q}_{\geq 0}]$ is integral over the polynomial ring $k[T]$.
Although this is a \emph{huge} extension,  the prime ideal $(T)$ lifts in only
one way to $\spec k[\mathbb{Q}_{\geq 0}]$.
\end{exercise}

\begin{exercise}
Suppose $A \subset B$ is an inclusion of rings over a field of characteristic
$p$. Suppose $B^p \subset A$, so that $B/A$ is integral in a very strong sense.
Show that the map $\spec B \to \spec A$ is a \emph{homeomorphism.}
\end{exercise}



\subsection{Going up}
Let $R \subset R'$ be an inclusion of rings with $R'$ integral over $R$. We saw in the
lying over theorem (\cref{lyingover}) that any prime $\mathfrak{p} \in \spec R$
has a prime $\mathfrak{q} \in \spec R'$ ``lying over'' $\mathfrak{p}$, i.e.
such that $R \cap \mathfrak{q} = \mathfrak{p}$.
We now want to show that we can lift finite \emph{inclusions} of primes to $R'$.

\begin{proposition}[Going up]
Let $R \subset R'$ be an integral inclusion of rings.
Suppose $\mathfrak{p}_1 \subset \mathfrak{p}_2 \subset \dots \subset
\mathfrak{p}_n \subset R$ is a
finite ascending chain of prime ideals in $R$.
Then there is an ascending chain $\mathfrak{q}_1 \subset \mathfrak{q}_2 \subset
\dots \subset \mathfrak{q}_n$ in $\spec R'$ lifting this chain.

Moreover, $\mathfrak{q}_1$ can be chosen arbitrarily so as to lift
$\mathfrak{p}_1$.
\end{proposition}
\begin{proof}
By induction and lying over (\cref{lyingover}), it suffices to show:
\begin{quote}
Let $\mathfrak{p}_1 \subset \mathfrak{p}_2$ be an inclusion of primes in $\spec
R$. Let $\mathfrak{q}_1 \in \spec R'$ lift $\mathfrak{p}_1$. Then there is
$\mathfrak{q}_2 \in \spec R'$, which satisfies the dual conditions of lifting
$\mathfrak{p}_2$ and containing $\mathfrak{q}_1$.
\end{quote}
To show that this is true, we apply \cref{lyingover} to the inclusion
$R/\mathfrak{p}_1 \hookrightarrow R'/\mathfrak{q}_1$. There is an element of
$\spec R'/\mathfrak{q}_1$ lifting $\mathfrak{p}_2/\mathfrak{p}_1$; the
corresponding element of $\spec R'$ will do for $\mathfrak{q}_2$.
\end{proof}

\section{Valuation rings}

A valuation ring is a special type of local ring. Its distinguishing
characteristic is that divisibility is a ``total preorder.'' That is, two
elements of the quotient field are never incompatible under divisibility.
 We shall see in this section that integrality can be detected using
valuation rings only.

Geometrically, the valuation ring is something like a local piece of a smooth
curve. In fact, in algebraic geometry, a more compelling reason to study
valuation rings is provided by the valuative criteria for separatedness and
properness (cf. \cite{EGA} or \cite{Ha77}).  One key observation about
valuation rings that leads the last results is that any local domain can be
``dominated'' by a valuation ring with the same quotient field (i.e. mapped
into a valuation ring via local
homomorphism), but valuation rings are the maximal elements in this relation
of domination.

\subsection{Definition}

\begin{definition}
A \textbf{valuation ring} is a domain $R$ such that for every pair of elements
$a,b \in R$, either $a \mid b$ or $b \mid a$.
\end{definition}

\begin{example}
$\mathbb{Z}$ is not a valuation ring. It is neither true that  2 divides 3
nor that 3 divides 2.
\end{example}

\begin{example}
$\mathbb{Z}_{(p)}$, which is the set of all fractions of the form $a/b \in
\mathbb{Q}$ where $p \nmid b$, is a valuation ring. To check whether $a/b$
divides $a'/b'$ or vice versa, one  just has to check which is divisible by
the larger power of $p$.
\end{example}

\begin{proposition}
Let $R$ be a domain with quotient field $K$. Then $R$ is a valuation ring if
and only if for every $x \in K$, either $x$ or $x^{-1}$ lies in $R$.
\end{proposition}

\begin{proof} Indeed, if $x=a/b , \ a,b \in R$, then either $a \mid
b$ or $b \mid a$, so either $x$ or $x^{-1} \in R$. This condition is equivalent
to $R$'s being a valuation ring.
\end{proof}


\subsection{Valuations}
The reason for the name ``valuation ring'' is provided by the next definition.
As we shall see, any valuation ring comes from a ``valuation.''

By definition, an \emph{ordered abelian group} is an abelian group $A$
together with a set of \emph{positive elements} $A_+ \subset A$. This set is
required to be closed under addition and satisfy the property that if $x \in
A$, then precisely one of the following is true: $x \in A_+$, $-x \in A_+$,
and $x = 0$. This allows one to define an ordering $<$ on $A$ by writing $x<y$
if $y-x \in A_+$.
Given $A$, we often formally adjoin an element $\infty$ which is bigger than
every element in $A$.


\begin{definition}
Let $K$ be a field. A \textbf{valuation} on $K$ is a map $v: K \to A \cup
\left\{\infty\right\}$ for some
 ordered abelian group $A$  satisfying:
\begin{enumerate}
\item  $v(0) = \infty$ and $v(K^*) \subset A$.
\item For $x,y \in K^*$, $v(xy) = v(x) + v(y)$. That is, $v|_{K^*}$ is
a homomorphism.
\item For $x,y \in K$, $v(x+y) \geq \min (v(x), v(y))$.
\end{enumerate}

\end{definition}
Suppose that $K$ is a field and $v: K \to A \cup \left\{\infty\right\}$ is a
valuation (i.e. $v(0) = \infty$). Define $R = \left\{x \in K: v(x) \geq
0\right\}$.
\begin{proposition}
$R$ as just defined is a valuation ring.
\end{proposition}
\begin{proof}  First, we prove that $R$ is a ring.
$R$ is closed under addition and multiplication by the two conditions
\[ v(xy)  = v(x) + v(y)  \]
and
\[ v(x+y) \geq \min v(x), v(y) , \]
so if $x,y \in R$, then $x+y, xy$ have nonnegative valuations.

Note that $0 \in R$ because $v(0) = \infty$. Also $v(1) = 0$ since $v: K^*
\to A$
is a homomorphism. So $1 \in R$ too.
Finally, $-1 \in R$ because $v(-1) =0$ since $A$ is totally ordered.  It
follows that $R$ is also a group.

Let us now show that $R$ is a valuation ring. If $x \in K^*$, either $v(x) \geq
0$ or $v(x^{-1}) \geq 0$ since $A$ is totally ordered.\footnote{Otherwise $0
=v(x)+v(x^{-1}) < 0$, contradiction.} So either $x, x^{-1} \in R$.
\end{proof}

In particular, the set of elements with nonnegative valuation is a valuation
ring.
The converse also holds. Whenever you have a valuation ring, it comes about in
this manner.

\begin{proposition}
Let $R$ be a valuation ring with quotient field $K$. There is an ordered
abelian group
$A$ and a valuation $v: K^* \to A$ such that $R$ is the set of elements with
nonnegative valuation.
\end{proposition}
\begin{proof}
First, we construct $A$. In fact, it is the quotient of $K^*$ by the subgroup
of units  $R^*$ of $R$.
We define an ordering by saying that $x \leq y$ if $y/x \in R$---this doesn't
depend on the representatives in $K^*$ chosen.  Note that either $x \leq y$ or
$y \leq x$ must hold, since $R$ is a valuation ring.
The combination of $ x \leq y$ and $y \leq x$ implies that $x,y$ are equivalent
classes.
The nonnegative elements in this group are those whose representatives in $K^*$
belong to $R$.

It is easy to see that $K^*/R^*$ in this way is a totally ordered abelian
group with
the image of 1 as the unit. The
reduction map $K^* \to K^*/R^*$  defines a valuation whose corresponding ring
is just $R$. We have omitted some details; for instance, it should be checked
that the valuation of $x+y$ is at least the minimum of $v(x), v(y)$.
\end{proof}



To summarize:
\begin{quote}
Every valuation ring $R$ determines a valuation $v$ from the fraction field of
$R$ into $A \cup \left\{\infty\right\}$ for $A$ a totally ordered abelian group
such that $R$ is just the set of elements of $K$ with nonnegative valuation. As
long as we require that $v: K^* \to A$ is surjective, then $A$ is uniquely
determined as well.
\end{quote}

\begin{definition}
A valuation ring $R$ is \textbf{discrete} if we can choose $A$ to be
$\mathbb{Z}$.
\end{definition}

\begin{example}
$\mathbb{Z}_{(p)}$ is a discrete valuation ring.
\end{example}

The notion of a valuation ring is a useful one.

\subsection{General remarks}
Let $R$ be a commutative ring. Then $\spec R$ is the set of primes of $R$,
equipped
with a certain topology. The space $\spec R$ is almost never Hausdorff. It is
almost always a bad idea to apply the familiar ideas from elementary topology
(e.g. the fundamental group) to $\spec R$. Nonetheless, it has some other nice
features that substitute for its non-Hausdorffness.

For instance, if $R = \mathbb{C}[x,y]$, then $\spec R$ corresponds to
$\mathbb{C}^2$ with some additional nonclosed points.  The injection of
$\mathbb{C}^2$ with its usual topology into $\spec R$ is continuous. While in
$\spec R$ you don't want to think of continuous paths, you can in
$\mathbb{C}^2$.

Suppose you had two points $x,y \in \mathbb{C}^2$ and their images in $\spec
R$.  Algebraically, you can still think about algebraic curves passing
through $x,y$.
This is a subset of $x,y$ defined by a single polynomial equation.
This curve will have what's called a ``generic point,'' since the ideal
generated by this curve will be a prime ideal.
The closure of this generic point will be precisely this algebraic
curve---including $x,y$.

\begin{remark}
If $ \mathfrak{p}, \mathfrak{p}' \in \spec R$, then
\[ \mathfrak{p}' \in \overline{\left\{\mathfrak{p}\right\}}  \]
iff
\[ \mathfrak{p}' \supset \mathfrak{p}.  \]
Why is this? Well, the closure of $\left\{\mathfrak{p}\right\}$ is just
$V(\mathfrak{p})$, since this is the smallest closed subset of $\spec R$
containing $\mathfrak{p}$.
\end{remark}

The point of this discussion is that instead of paths, one can transmit
information from point to point in $\spec R$ by having one point be in a
closure of another.
However, we will show that this relation is contained by the theory of
valuation rings.

\begin{theorem}
Let $R$ be a domain containing a prime ideal $\mathfrak{p}$.  Let $K$ be the
fraction field of $R$.

Then there is a valuation  $v$ on $K$ defining a valuation ring $R' \subset
K$  such that
\begin{enumerate}
\item $R \subset R'$.
\item $\mathfrak{p} = \left\{x \in R: v(x) > 0\right\}$.
\end{enumerate}

\end{theorem}

Let us motivate this by the remark:
\begin{remark}
A valuation ring is automatically a local ring. A local ring is a ring where
either $x, 1-x$ is invertible for all $x$ in the ring. Let us show that this is
true for a valuation ring.

If $x $ belongs to a valuation ring $R$ with valuation $v$, it is invertible if
$v(x)=0$.  So if $x, 1-x$ were both noninvertible, then both would have
positive valuation.  However, that would imply that $v(1) \geq \min v(x),
v(1-x)$ is positive, contradiction.
\end{remark}

\begin{quote}
If $R'$ is any valuation ring (say defined by a valuation $v$), then $R'$ is
local with maximal ideal consisting of elements with positive valuation.
\end{quote}

The theorem above says that there's a good supply of valuation rings.
In particular, if $R$ is any domain, $\mathfrak{p} \subset R$ a prime ideal,
then we can choose a valuation ring $R' \supset R$ such that $\mathfrak{p}$ is
the intersection of the maximal ideal of $R'$ intersected with $R$.
So the map $\spec R' \to \spec R$ contains $\mathfrak{p}$.

\begin{proof}
Without loss of generality, replace $R$ by $R_{\mathfrak{p}}$, which is a local
ring with maximal ideal $\mathfrak{p}R_{\mathfrak{p}}$. The maximal ideal
intersects $R$ only in $\mathfrak{p}$.

So, we can assume without loss of generality that
\begin{enumerate}
\item $R$ is local.
\item $\mathfrak{p}$ is maximal.
\end{enumerate}

Let $P$ be the collection of all subrings $R' \subset K$ such that $R' \supset
R$ but $\mathfrak{p}R' \neq R'$.  Then $P$ is a poset under inclusion. The
poset is nonempty, since $R \in P$.  Every totally ordered chain in $P$ has an
upper bound.  If you have a totally ordered subring of elements in $P$, then
you can take the union.
We invoke:
\begin{lemma}
Let $R_\alpha$ be a chain in $P$ and $R' = \bigcup R_\alpha$. Then $R' \in P$.
\end{lemma}
\begin{proof}
Indeed, it is easy to see that this is a subalgebra of $K$ containing $R$. The
thing to observe is that
\[ \mathfrak{p}R' = \bigcup_\alpha \mathfrak{p} R_\alpha  ;\]
since by assumption, $1 \notin \mathfrak{p}R_\alpha$ (because each $R_\alpha
\in P$), $1 \notin \mathfrak{p}R'$. In particular, $R' \notin P$.
\end{proof}

By the lemma, Zorn's lemma to the poset $P$. In particular, $P$ has a maximal
element $R'$. By construction, $R'$ is some subalgebra of $K$ and
$\mathfrak{p}R' \neq R'$. Also, $R'$ is maximal with respect to these
properties.

We show first that $R'$ is local, with maximal ideal $\mathfrak{m}$ satisfying
\[ \mathfrak{m} \cap R = \mathfrak{p}.  \]
The second part is evident from locality of $R'$, since $\mathfrak{m} $
must contain
the proper ideal $\mathfrak{p}R'$, and $\mathfrak{p} \subset R$ is a maximal
ideal.

Suppose that $x \in R'$; we show that either $x, 1-x$ belongs to $R'^*$ (i.e.
is invertible). Take the ring $R'[x^{-1}]$.  If $x$ is noninvertible, this
properly contains $R'$.  By maximality, it follows that $\mathfrak{p}R'[x^{-1}]
= R'[x^{-1}]$.

And we're out of time. We'll pick this up on Monday.

\end{proof}

Let us set a goal.


First, recall the notion introduced last time. A \textbf{valuation ring} is a
domain $R$ where for all $x$ in the fraction field of $R$, either $x$ or
$x^{-1}$ lies in $R$. We saw that if $R$ is a valuation ring, then $R$ is
local. That is, there is a unique maximal ideal $\mathfrak{m} \subset R$,
automatically prime.  Moreover, the zero ideal $(0)$ is prime, as $R$ is a
domain. So if you look at the spectrum $\spec R$ of a valuation ring $R$, there
is a unique closed point $\mathfrak{m}$, and a unique generic point
$(0)$.  There might be some other prime ideals in $\spec R$; this depends on
where the additional valuation lives.

\begin{example}
Suppose the valuation defining the valuation ring $R$ takes values in
$\mathbb{R}$. Then the only primes are $\mathfrak{m}$ and zero.
\end{example}

Let $R$ now be any ring, with $\spec R$ containing prime ideals
$\mathfrak{p} \subset \mathfrak{q}$.  In particular, $\mathfrak{q}$ lies in
the closure of $\mathfrak{p}$.
As we will see, this implies that there is a map
\[  \phi: R \to R'  \]
such that $\mathfrak{p} = \phi^{-1}(0)$ and $\mathfrak{q} =
\phi^{-1}(\mathfrak{m})$, where $\mathfrak{m}$ is the maximal ideal of $R'$.
This statement says that the relation of closure in $\spec R$ is always
controlled by valuation rings.
In yet another phrasing, in the map
\[ \spec R' \to \spec R  \]
the closed point goes to $\mathfrak{q}$ and the generic point to
$\mathfrak{p}$. This is our eventual goal.

To carry out this goal, we need some more elementary facts. Let us discuss
things that don't have any obvious relation to it.

\subsection{Back to the goal} Now we return to the goal of the  lecture. Again,
$R$
was any ring, and we had primes $\mathfrak{p} \subset \mathfrak{q} \subset
R$. We
wanted a valuation ring $R'$ and a map $\phi: R \to R'$ such that zero pulled
back to $\mathfrak{p}$ and the maximal ideal pulled back to $\mathfrak{q}$.

What does it mean for $\mathfrak{p}$ to be the inverse image of $(0) \subset
R'$? This means that $\mathfrak{p} = \ker \phi$. So we get an injection
\[ R/\mathfrak{p} \rightarrowtail R'.  \]
We will let $R'$ be a subring of the quotient field $K$ of the domain
$R/\mathfrak{p}$. Of course, this subring will contain $R/\mathfrak{p}$.

In this case, we will get  a map $R \to R'$ such that the pull-back of zero is
$\mathfrak{p}$.  What we want, further, to be true is that $R'$ is a valuation
ring and the pull-back of the maximal ideal is $\mathfrak{q}$.



This is starting to look at the problem we discussed last time.
Namely, let's throw out $R$, and replace it with  $R/\mathfrak{p}$.
Moreover, we can replace $R$ with $R_{\mathfrak{q}}$ and assume that $R$ is
local with maximal ideal $\mathfrak{q}$.
What we need to show is that a valuation ring $R' $ contained in the fraction
field of $R$, containing $R$, such that the intersection of the maximal
ideal of
$R'$ with $R$ is equal to $\mathfrak{q} \subset R$.
If we do this, then we will have accomplished our goal.

\begin{lemma}
Let $R$ be a local domain. Then there is a valuation subring $R'$ of the
quotient
field of $R$ that \emph{dominates} $R$, i.e .the map $R \to R'$ is a
\emph{local} homomorphism.
\end{lemma}

Let's find $R'$ now.

Choose $R'$ maximal such that $\mathfrak{q} R' \neq R'$. Such a ring exists, by
Zorn's lemma. We gave this argument at the end last time.

\begin{lemma}
$R'$ as described is local.
\end{lemma}
\begin{proof}
Look at $\mathfrak{q}R' \subset R'$; it is a proper subset, too, by assumption.
In particular, $\mathfrak{q}R'$ is contained in some maximal ideal
$\mathfrak{m}\subset R'$.   Replace $R'$ by $R'' = R'_{\mathfrak{m}}$.
Note that
\[ R' \subset R''  \]
and
\[ \mathfrak{q}R'' \neq R''  \]
because $\mathfrak{m}R'' \neq R''$.  But $R'$ is maximal, so $R' = R''$, and
$R''$ is a local ring. So $R'$ is a local ring.
\end{proof}

Let $\mathfrak{m}$ be the maximal ideal of $R'$. Then $\mathfrak{m} \supset
\mathfrak{q}R$, so $\mathfrak{m} \cap R = \mathfrak{q}$.
All that is left to prove now is that $R'$ is a valuation ring.

\begin{lemma}
$R'$ is integrally closed.
\end{lemma}

\begin{proof}
Let $R''$ be its integral closure. Then $\mathfrak{m} R'' \neq R''$ by lying
over, since $\mathfrak{m}$ (the maximal ideal of $R'$) lifts up to $R''$. So
$R''$ satisfies
\[ \mathfrak{q}R'' \neq R''  \]
and by maximality, we have $R'' = R'$.
\end{proof}

To summarize, we know that $R'$ is a  local, integrally closed subring of the
quotient field of $R$, such that the maximal ideal of $R'$ pulls back to
$\mathfrak{q}$ in $R$.
All we now need is:

\begin{lemma}
$R'$ is a valuation ring.
\end{lemma}
\begin{proof}
Let $x$ lie in the fraction field. We must show that either $x$ or $x^{-1} \in
R'$.  Say $x \notin R'$.  This means by maximality of $R'$ that $R'' =
R'[x]$ satisfies
\[ \mathfrak{q}R'' = R''.  \]
In particular, we can write
\[ 1 = \sum q_i x^i, \quad q_i \in \mathfrak{q}R' \subset R'.  \]
This implies that
\[ (1-q_0) + \sum_{i > 0} -q_i x^i  = 0.  \]
But $1-q_0$ is invertible in $R'$, since $R'$ is local.  We can divide by the
highest power of $x$:
\[  x^{-N} + \sum_{i>0} \frac{-q_i}{1-q_0} x^{-N+i} = 0. \]
In particular, $1/x$ is integral over $R'$; this implies that $1/x \in
R'$ since
$R'$ is integrally closed and $q_0$ is a nonunit. So
$R'$ is a valuation ring.
\end{proof}

We can state the result formally.
\begin{theorem}
Let $R$ be a ring, $\mathfrak{p} \subset \mathfrak{q}$ prime ideals. Then there
is a homomorphism $\phi: R \to R'$ into a valuation ring $R'$ with maximal
ideal
$\mathfrak{m}$ such that
\[ \phi^{-1}(0) = \mathfrak{p}  \]
and
\[ \phi^{-1}(\mathfrak{m} ) = \mathfrak{q} .\]
\end{theorem}

There is a related fact which we now state.
\begin{theorem}
Let $R$ be any domain. Then the integral closure of $R$ in the quotient field
$K$ is the intersection
\[ \bigcap R_{\alpha}  \]
of all valuation rings $R_{\alpha} \subset K$ containing $R$.
\end{theorem}
So an element of the quotient field is integral over $R$ if and only if its
valuation is nonnegative at every valuation which is nonnegative on $R$.

\begin{proof}
The $\subset$ argument is easy, because one can check that a valuation ring is
integrally closed. (Exercise.)
The interesting direction is to assume that $v(x) \geq 0$ for all $v$
nonnegative
on $R$.

Let us suppose $x$ is nonintegral. Suppose $R' = R[1/x]$ and $I$ be the ideal
$(x^{-1}) \subset R'$. There are two cases:
\begin{enumerate}
\item $I = R'$. Then in the ring $R'$, $x^{-1} $ is invertible. In particular,
$x^{-1}P(x^{-1}) = 1$. Multiplying by a high power of $x$ shows that $x$ is
integral over $R$.  Contradiction.
\item  Suppose $I \subsetneq R'$. Then $I$ is contained in a maximal ideal
$\mathfrak{q} \subset R'$.  There is a valuation subring $R'' \subset K$ ,
containing $R'$, such that the corresponding valuation is positive on
$\mathfrak{q}$.  In particular, this valuation is positive on $x^{-1}$,
so it is
negative on $x$, contradiction.
\end{enumerate}
\end{proof}

So the integral closure has this nice characterization via valuation rings. In
some sense, the proof that $\mathbb{Z}$ is integrally closed has the property
that every integrally closed ring is integrally closed for that reason:
it's the
common nonnegative locus for some valuations.

\section{The Hilbert Nullstellensatz}

The Nullstellensatz is the basic algebraic fact, which we have invoked in the
past to justify various examples, that connects the idea of
the $\spec$ of a ring to classical algebraic geometry.

\subsection{Statement and initial proof of the Nullstellensatz}

There are several ways in which the Nullstellensatz can be stated. Let us
start with the following very concrete version.

\begin{theorem} \label{nullstellensatzoverC}
All maximal ideals in the polynomial ring $R=\mathbb{C}[x_1, \dots, x_n]$ come
from points in $\mathbb{C}^n$. In other words, if $\mathfrak{m} \subset R$ is
maximal, then there exist $a_1, \dots, a_n \in \mathbb{C}$ such that
$\mathfrak{m} = (x_1 - a_1, \dots, x_n - a_n)$.
\end{theorem}


The maximal spectrum of $R=\mathbb{C}[x_1, \dots, x_n]$ is thus identified with
$\mathbb{C}^n$.

We shall now reduce \rref{nullstellensatzoverC} to an easier claim.
Let
$\mathfrak{m}\subset R$ be a maximal ideal. Then there is a map
\[ \mathbb{C} \to R \to R/\mathfrak{m}  \]
where $R/\mathfrak{m}$ is thus a finitely generated $\mathbb{C}$-algebra, as
$R$ is.  The ring $R/\mathfrak{m}$ is also a field by maximality.

We would like to show that $R/\mathfrak{m}$ is a finitely generated
$\mathbb{C}$-vector
space. This would imply that $R/\mathfrak{m}$ is integral over $\mathbb{C}$,
and there are no proper algebraic extensions of $\mathbb{C}$. Thus, if we
prove this, it will follow that the map $\mathbb{C} \to R/\mathfrak{m}$ is an
isomorphism. If $a_i \in \mathbb{C}$ ($1 \leq i \leq n$) is the image of
$x_i $ in $R/\mathfrak{m} =
\mathbb{C}$, it will follow that $(x_1 - a_1, \dots, x_n - a_n) \subset
\mathfrak{m}$, so $(x_1 - a_1, \dots, x_n - a_n)=
\mathfrak{m}$.


Consequently, the Nullstellensatz in this form would follow from the next
claim:

\begin{proposition}
Let $k$ be a field, $L/k$ an extension of fields. Suppose $L$ is a finitely
generated $k$-algebra. Then $L$ is a finite $k$-vector space.
\end{proposition}
This is what we will prove.

We start with an easy proof in the special case:
\begin{lemma}
Assume $k$ is uncountable (e.g. $\mathbb{C}$, the original case of interest).
Then the above proposition is true.
\end{lemma}
\begin{proof}
Since $L$ is a finitely generated $k$-algebra, it suffices to show that $L/k$
is algebraic.
If not, there exists $x \in L$ which isn't algebraic over $k$. So $x$ satisfies
no nontrivial polynomials.
I claim now that the uncountably many elements $\frac{1}{x-\lambda}, \lambda
\in K$ are linearly
independent over $K$. This will be a contradiction as $L$ is a finitely
generated $k$-algebra, hence at most countably dimensional over $k$. (Note that
the polynomial ring is countably dimensional over $k$, and $L$ is a quotient.)

So let's prove this. Suppose not. Then there is a nontrivial linear dependence
\[ \sum \frac{c_i}{x - \lambda_i}  = 0, \quad c_i, \lambda_i \in K. \]
Here the $\lambda_j$ are all distinct to make this nontrivial. Clearing
denominators, we find
\[ \sum_i c_i \prod_{j \neq i } (x- \lambda_j) = 0. \]
Without loss of generality, $c_1 \neq 0$.
This equality was in the field $L$. But $x$ is transcendental over $k$. So we
can think of this as a polynomial ring relation.
Since we can think of this as a relation in the polynomial ring, we see that
doing so, all but the $i =1$ term in the sum is divisible by $x - \lambda_1$
as a polynomial.
It follows that, as polynomials in the indeterminate $x$,
\[ x - \lambda_1 \mid c_1 \prod_{j \neq 1} (x - \lambda_j).  \]
This is a contradiction since all the $\lambda_i$ are distinct.
\end{proof}

This is kind of a strange proof, as it exploits the fact that $\mathbb{C}$ is
uncountable.
This shouldn't be relevant.

\subsection{The normalization lemma}

Let's now give a more algebraic proof.
We shall exploit the following highly useful fact in commutative algebra:

\begin{theorem}[Noether normalization lemma] Let $k$ be a field, and $R =
k[x_1, \dots, x_n]/\mathfrak{p}$ be a finitely generated domain over $k$ (where
$\mathfrak{p}$ is a prime ideal in the polynomial ring).

Then there exists a polynomial subalgebra $k[y_1, \dots, y_m] \subset R$ such
that $R$ is integral over $k[y_1, \dots, y_m]$.
\end{theorem}

Later we will see that $m$ is the \emph{dimension} of $R$.

There is a geometric picture here. Then $\spec R$ is some irreducible algebraic
variety in $k^n$ (plus some additional points), with a smaller dimension than
$n$ if $\mathfrak{p} \neq 0$. Then there exists a \emph{finite map} to $k^m$.
In particular, we can map surjectively $\spec R \to k^m$ which is integral.
The fibers are in fact finite, because integrality implies finite fibers.  (We
have not actually proved this yet.)

How do we actually find such a finite projection? In fact, in characteristic
zero, we just take a
vector space projection $\mathbb{C}^n \to \mathbb{C}^m$. For a ``generic''
projection onto a subspace of the appropriate dimension, the projection will
will do as our finite map. In characteristic $p$, this may not work.

\begin{proof}
First, note that $m$ is uniquely determined as the transcendence degree of the
quotient field of $R$ over $k$.

Among the variables $x_1, \dots, x_n \in R$ (which we think of as in $R$ by an
abuse of notation), choose a maximal subset which is algebraically independent.
This subset has no nontrivial polynomial relations. In particular, the ring
generated by that subset is just the polynomial ring on that subset.
We can permute these variables and assume that
$$\left\{x_1,\dots, x_m\right\}$$ is the maximal subset. In particular, $R$
contains the \emph{polynomial ring} $k[x_1, \dots, x_m]$ and is generated by
the rest of the variables. The rest of the variables are not adjoined freely
though.

The strategy is as follows.  We will implement finitely many changes of
variable so that $R$ becomes integral over $k[x_1, \dots, x_m]$.

The essential case is where $m=n-1$. Let us handle this. So we have
\[ R_0 = k[x_1, \dots, x_m]  \subset R = R_0[x_n]/\mathfrak{p}.  \]
Since $x_n$ is not algebraically independent, there is a nonzero polynomial
$f(x_1, \dots, x_m, x_n) \in \mathfrak{p}$.

We want $f$ to be monic in $x_n$. This will buy us integrality. A priori, this
might not be true. We will modify the coordinate system to arrange that,
though. Choose $N \gg 0$. Define for $1 \leq i \leq m$,
\[ x_i' = x_i + x_n^{N^i}.  \]
Then the equation becomes:
\[ 0 = f(x_1, \dots, x_m, x_n) = f( \left\{x_i' - x_n^{N^i}\right\} , x_n). \]
Now $f(x_1, \dots, x_n, x_{n+1})$ looks like some sum
\[ \sum \lambda_{a_1 \dots b} x_1^{a_1} \dots x_m^{a_m} x_n^{b} , \quad
\lambda_{a_1 \dots b} \in k. \]
But $N$ is really really big. Let us expand this expression in the $x_i'$ and
pay attention to the largest power of $x_n$ we see.
We find that
\[ f(\left\{x_i' - x_n^{N_i}\right\},x_n)
\]
has the largest power of $x_n$ precisely where, in the expression for $f$,
$a_m$ is maximized first, then
$a_{m-1}, $ and so on. The largest exponent would have the form
\[ x_n^{a_m N^m + a_{m-1}N^{m-1} + \dots + b}.	\]
We can't, however, get any exponents of $x_n$ in the expression
\( f(\left\{x_i' - x_n^{N_i}\right\},x_n)\) other than these. If $N$ is super
large, then all these exponents will be different from each other.
In particular, each power of $x_n$ appears precisely once in the expansion of
$f$. We see in particular that $x_n$ is integral over $x_1', \dots, x_n'$.
Thus each $x_i$ is as well.

So we find
\begin{quote}
$R$ is integral over $k[x_1', \dots, x_m']$.
\end{quote}

We have thus proved the normalization lemma in the codimension one case. What
about the general case? We repeat this.
Say we have
\[ k[x_1, \dots, x_m] \subset R.  \]
Let $R'$ be the subring of $R$ generated by $x_{1}, \dots,x_m, x_{m+1}$. The
argument we just gave implies that we can choose $x_1', \dots, x_m'$ such that
$R'$ is integral over $k[x_1', \dots, x_m']$, and the $x_i'$ are
algebraically independent.
We know in fact that $R' = k[x_1', \dots, x_m', x_{m+1}]$.

Let us try repeating the argument while thinking about $x_{m+2}$. Let $R'' =
k[x_1', \dots, x_m', x_{m+2}]$ modulo whatever relations that $x_{m+2}$ has to
satisfy. So this is a subring of $R$. The same argument shows that we can
change variables such that $x_1'', \dots, x_m''$ are algebraically independent
and $R''$ is integral over $k[x_1'', \dots, x_m'']$. We have furthermore that
$k[x_1'', \dots, x_m'', x_{m+2}] = R''$.

Having done this, let us give the argument where $m=n-2$. You will then see
how to do the general case. Then I claim that:
\begin{quote}
$R$ is integral over $k[x_1'', \dots, x_m'']$.
\end{quote}
For this, we need to check that $x_{m+1}, x_{m+2}$ are integral (because these
together with the $x''_i$ generate $R''[x_{m+2}][x_{m+2}]=R$.
But $x_{m+2}$ is integral over this by construction. The integral closure of
$k[x_1'', \dots, x_{m}'']$ in $R$ thus contains
\[ k[x_1'', \dots, x''_m, x_{m+2}] = R''.  \]
However, $R''$ contains the elements $x_1', \dots, x_m'$. But by construction,
$x_{m+1}$ is integral over the $x_1', \dots, x_m'$. The integral closure of
$k[x_1'', \dots, x_{m}'']$ must contain $x_{m+2}$. This completes the proof in
the case $m=n-2$. The general case is similar; we just make several changes of
variables, successively.

\end{proof}
\subsection{Back to the Nullstellensatz}

Consider a finitely generated $k$-algebra $R$ which is a field. We need to
show that $R$ is a
finite $k$-module. This will prove the proposition.
Well, note that $R$ is integral over a polynomial ring $k[x_1, \dots, x_m]$ for
some $m$.
If $m > 0$, then this polynomial ring has more than one prime.
For instance, $(0)$ and $(x_1, \dots, x_m)$. But these must lift to primes in
$R$. Indeed, we have seen that whenever you have an integral extension, the
induced map on spectra is surjective. So
\[ \spec R \to \spec k[x_1, \dots, x_m]  \]
is surjective. If $R$ is a field, this means $\spec k[x_1, \dots, x_m]$ has one
point and $m=0$. So $R$ is integral over $k$, thus algebraic. This implies that
$R$ is finite as it is finitely generated. This proves one version of the
Nullstellensatz.


 Another version of the Nullstellensatz, which is
more precise, says:

\begin{theorem} \label{gennullstellensatz}
Let $I \subset \mathbb{C}[x_1, \dots, x_n]$. Let $V \subset \mathbb{C}^n$ be
the subset of $\mathbb{C}^n$ defined by the ideal $I$ (i.e. the zero locus of
$I$).

Then $\rad(I)$ is precisely the collection of $f$ such that $f|_V = 0$. In
particular,
\[ \rad(I) = \bigcap_{\mathfrak{m} \supset I, \mathfrak{m} \
\mathrm{maximal}} \mathfrak{m}.  \]
\end{theorem}

In particular, there is a bijection between radical ideals and algebraic
subsets of $\mathbb{C}^n$.

The last form of the theorem, which follows from the expression of maximal
ideals in the polynomial ring, is very similar to the result
\[ \rad(I) = \bigcap_{\mathfrak{p} \supset I, \mathfrak{p} \
\mathrm{prime}} \mathfrak{p},  \]
true in any commutative ring. However, this general result is not necessarily
true.

\begin{example}
The intersection of all primes in a DVR is zero, but the intersection of all
maximals is nonzero.
\end{example}

\begin{proof}[Proof of \cref{gennullstellensatz}]
It now suffices to show that for every $\mathfrak{p} \subset \mathbb{C}[x_1,
\dots, x_n]$ prime, we have
\[ \mathfrak{p} = \bigcap_{\mathfrak{m} \supset I \ \mathrm{maximal}}
\mathfrak{m}  \]
since every radical ideal is an intersection of primes.

Let $R = \mathbb{C}[x_1, \dots,
x_n]/\mathfrak{p}$. This is a domain finitely generated over $\mathbb{C}$. We
want to show that the intersection of maximal ideals in $R$ is zero. This is
equivalent to the above displayed equality.

So fix $f \in R - \left\{0\right\}$. Let $R'$ be the localization $R'= R_f$. Then $R'$ is also an
integral domain, finitely generated over $\mathbb{C}$.	$R'$ has a maximal
ideal $\mathfrak{m}$ (which a priori could be zero). If
we look at the map $R' \to R'/\mathfrak{m}$, we get a map into a field
finitely generated
over $\mathbb{C}$, which is thus $\mathbb{C}$.
The composite map
\[ R \to  R' \to R'/\mathfrak{m}   \]
is just given by an $n$-tuple of complex numbers, i.e. to a point in
$\mathbb{C}^n$ which is even in $V$ as it is a map out of $R$. This corresponds
to a maximal ideal in $R$.
This maximal ideal does not contain $f$ by construction.
\end{proof}

\begin{exercise}
Prove the following result, known as ``Zariski's lemma'' (which easily implies
the Nullstellensatz): if $k$ is a field, $k'$ a field extension of $k$ which
is a finitely generated $k$-\emph{algebra}, then $k'$ is finite algebraic over
$k$. Use the following argument of McCabe (in \cite{Mc76}):
\begin{enumerate}
\item $k'$ contains a subring $S$ of the form $S= k[ x_1, \dots, x_t]$ where
the $x_1, \dots, x_t$ are algebraically independent over $k$, and $k'$ is
algebraic over the quotient field of $S$ (which is a polynomial ring).
\item  If $k'$ is not algebraic over $k$, then $S \neq k$ is not a field.
\item Show that there is $y \in S$ such that $k'$ is integral over $S_y$.
Deduce that $S_y$ is a field.
\item Since $\spec (S_y) = \left\{0\right\}$, argue that $y$ lies in every
non-zero prime ideal of $\spec S$. Conclude that $1+y \in k$, and $S$ is a
field---contradiction.
\end{enumerate}
\end{exercise}

\subsection{A little affine algebraic geometry}

In what follows, let $k$ be algebraically closed, and let $A$ be a finitely generated $k$-algebra.  Recall that $\Specm A$ denotes the set of maximal ideals in $A$.  Consider the natural $k$-algebra structure on $\mathrm{Funct}(\Specm A, k)$.  We have a map
$$A \rightarrow \mathrm{Funct}(\Specm A, k)$$
which comes from the Weak Nullstellensatz as follows.  Maximal ideals $\mathfrak{m}\subset A$ are in bijection with maps $\varphi_\mathfrak{m}:A\rightarrow k$ where $\ker(\varphi_\mathfrak{m})=\mathfrak{m}$, so we define $a\longmapsto [\mathfrak{m}\longmapsto \varphi_\mathfrak{m}(a)]$.  If $A$ is reduced, then this map is injective because if $a\in A$ maps to the zero function, then $a\in \cap\, \mathfrak{m}$ $\rightarrow$ $a$ is nilpotent $\rightarrow$ $a=0$.\\

\begin{definition} A function $f\in \mathrm{Funct}(\Specm A,k)$ is called {\bf algebraic} if it is in the image of $A$ under the above map.  (Alternate words for this are {\bf polynomial} and {\bf regular}.) \end{definition}

Let $A$ and $B$ be finitely generated $k$-algebras and $\phi:A\rightarrow B$ a homomorphism.  This yields a map $\Phi:\Specm B\rightarrow \Specm A$ given by taking pre-images.

\begin{definition} A map $\Phi:\Specm B\rightarrow \Specm A$ is called {\bf algebraic} if it comes from a homomorphism $\phi$ as above.\end{definition}

To demonstrate how these definitions relate to one another we have the following proposition.

\begin{proposition} A map $\Phi:\Specm B\rightarrow \Specm A$ is algebraic if and only if for any algebraic function $f\in \mathrm{Funct}(\Specm A,k)$, the pullback $f\circ \Phi\in \mathrm{Funct}(\Specm B,k)$ is algebraic.\end{proposition}

\begin{proof}
Suppose that $\Phi$ is algebraic.  It suffices to check that the following diagram is commutative:
\[
\xymatrix{
\mathrm{Funct}(\Specm A,k) \ar[r]^{-\circ\Phi} & \mathrm{Funct}(\Specm B,k) \\
A \ar[u] \ar[r]_{\phi} & B \ar[u]\\
}
\]
where $\phi:A\rightarrow B$ is the map that gives rise to $\Phi$.

[$\Leftarrow$] Suppose that for all algebraic functions $f\in \mathrm{Funct}(\Specm A,k)$, the pull-back $f\circ\Phi$ is algebraic.  Then we have an induced map, obtained by chasing the diagram counter-clockwise:
$$
\xymatrix{
\mathrm{Funct}(\Specm A,k) \ar[r]^{-\circ\Phi} & \mathrm{Funct}(\Specm B,k) \\
A \ar[u] \ar@{-->}[r]_{\phi} & B \ar[u]\\
}
$$
From $\phi$, we can construct the map $\Phi':\Specm B \rightarrow \Specm A$ given by $\Phi'(\mathfrak{m})=\phi^{-1}(\mathfrak{m})$.  I claim that $\Phi=\Phi'$.  If not, then for some $\mathfrak{m}\in \Specm B$ we have $\Phi(\mathfrak{m})\neq \Phi'(\mathfrak{m})$.  By definition, for all algebraic functions $f\in \mathrm{Funct}(\Specm A,k)$, $f\circ\Phi=f\circ\Phi'$ so to arrive at a contradiction we show the following lemma:\\
Given any two distinct points in $\Specm A=V(I)\subset k^n$, there exists some
algebraic $f$ that separates them.  This is trivial when we realize that any
polynomial function is algebraic, and such polynomials separate points.
\end{proof}

\section{Serre's criterion and its variants}

We are going to now prove a useful criterion for a noetherian ring to be a
product of
normal domains, due to Serre: it states that a (noetherian) ring is normal if
and only if most of the localizations at prime ideals are discrete valuation
rings (this corresponds to the ring being \emph{regular} in codimension one,
though we have not defined regularity yet) and a more technical condition that
we will later interpret in terms of \emph{depth.} One advantage of this
criterion is that it does \emph{not} require the ring to be a product of
domains a priori.

\subsection{Reducedness}

There is a ``baby'' version of Serre's criterion for testing whether a ring is
reduced, which we star with.

Recall:

\begin{definition}
A ring $R$ is \textbf{reduced} if it has no nonzero nilpotents.
\end{definition}

\begin{proposition} \label{reducedcrit}
If $R$ is noetherian, then $R$ is reduced if and only if it satisfies the
following conditions:
\begin{enumerate}
\item Every associated prime of $R$ is	minimal (no embedded primes).
\item If $\mathfrak{p}$ is minimal, then $R_{\mathfrak{p}}$ is	a field.
\end{enumerate}
\end{proposition}
\begin{proof}
First, assume $R$ reduced. What can we say? Say $\mathfrak{p}$ is a minimal
prime; then $R_{\mathfrak{p}}$ has precisely one prime ideal (namely,
$\mathfrak{m}=\mathfrak{p}R_{\mathfrak{p}}$). It is in fact a local artinian
ring, though we
don't need that fact. The radical of $R_{\mathfrak{p}}$ is just $\mathfrak{m}$.
But $R$ was reduced, so $R_{\mathfrak{p}}$ was reduced; it's an easy argument
that localization preserves reducedness. So $\mathfrak{m}=0$. The fact that 0
is a maximal ideal in $R_{\mathfrak{p}}$ says that it is a field.

On the other hand, we still have to do part 1. $R$ is reduced, so $\rad(R) =
\bigcap_{\mathfrak{p} \in \spec R} \mathfrak{p} = 0$. In particular,
\[ \bigcap_{\mathfrak{p} \ \mathrm{minimal}}\mathfrak{p} = 0.  \]
The map
\[ R \to \prod_{\mathfrak{p} \ \mathrm{minimal}}R/\mathfrak{p}	\]
is injective. The associated primes of the product, however, are just the
minimal primes. So $\ass(R)$ can contain only minimal primes.

That's one direction of the proposition. Let us prove the converse now. Assume
$R$ satisfies the two conditions listed. In other words, $\ass(R)$ consists of
minimal primes, and each $R_{\mathfrak{p}}$ for $\mathfrak{p} \in \ass(R)$ is a
field. We would like to show that $R$ is reduced.
Primary decomposition tells us that there is an injection
\[ R \hookrightarrow \prod_{\mathfrak{p}_i \ \mathrm{minimal}} M_i, \quad M_i
\ \  \mathfrak{p}_i-\mathrm{primary}. \]
In this case, each $M_i$ is primary with respect to a minimal prime. We have a
map
\[ R \hookrightarrow \prod M_i \to \prod (M_i)_{\mathfrak{p}_i},  \]
which is injective, because when you localize a primary module at its
associated prime, you don't kill anything by definition of primariness. Since
we can draw a diagram
\[
\xymatrix{
R \ar[r] \ar[d]  &  \prod M_i \ar[d]  \\
\prod R_{\mathfrak{p}_i} \ar[r] & \prod (M_i)_{\mathfrak{p}_i}
}
\]
and the map $R \to \prod (M_i)_{\mathfrak{p}_i}$ is injective, the downward
arrow on the right injective. Thus $R$ can be embedded in
a product of the fields $\prod R_{\mathfrak{p}_i}$, so is reduced.
\end{proof}

This proof actually shows:
\begin{proposition}[Scholism] A noetherian ring $R$ is reduced iff it injects
into a product of fields. We can take the fields to be the localizations at the
minimal primes.
\end{proposition}

\begin{example}
Let $R = k[X]$ be the coordinate ring of a variety $X$ in
$\mathbb{C}^n$. Assume $X$ is
reduced. Then $\mathrm{MaxSpec} R$ is a union of irreducible components
$X_i$, which
are the closures of the minimal primes of $R$. The fields you get by localizing
at minimal primes depend only on the irreducible components, and in fact are
the rings of meromorphic functions on $X_i$.
Indeed, we have a map
\[ k[X] \to \prod k[X_i] \to \prod k(X_i).  \]

If we don't assume that $R$ is radical, this is \textbf{not} true.
\end{example}

There is a stronger condition than being reduced we could impose. We could say:

\begin{proposition}
If $R$ is a noetherian ring, then $R$ is a domain iff
\begin{enumerate}
\item $R$ is reduced.
\item $R$ has a unique minimal prime.
\end{enumerate}
\end{proposition}
\begin{proof}
One direction is obvious. A domain is reduced and $(0)$ is the minimal prime.

The other direction is proved as follows. Assume 1 and 2. Let $\mathfrak{p}$ be
the unique minimal prime of $R$. Then $\rad (R) = 0 = \mathfrak{p}$ as every
prime ideal contains $\mathfrak{p}$. As $(0)$ is a prime ideal, $R$ is
a domain.
\end{proof}

We close by making some remarks about this embedding of $R$ into a product of
fields.

\begin{definition}
Let $R$ be any ring, not necessarily a domain. Let $K(R)$ be the localized ring
$S^{-1}R$ where $S$ is the multiplicatively closed set of nonzerodivisors in
$R$.  $K(R)$ is called the \textbf{total ring of fractions} of $R$.

When $R$ is a field, this is the quotient field.
\end{definition}

First, to get a feeling for this, we show:

\begin{proposition} Let $R$ be noetherian. The set of nonzerodivisors $S$
can be described by
$S = R- \bigcup_{\mathfrak{p} \in \ass(R)} \mathfrak{p}$.
\end{proposition}
\begin{proof}
If $x \in\mathfrak{p} \in \ass(R)$, then $x$ must kill something in $R$ as it
is in an associated prime.	So $x$ is a zerodivisor.

Conversely, suppose $x$ is a zerodivisor, say $xy = 0$ for some $y \in R -
\left\{0\right\}$. In
particular, $x \in \ann(y)$. We have an injection $R/\ann(y) \hookrightarrow R$
sending 1 to $y$. But $R/\ann(y)$ is nonzero, so it has an associated prime
$\mathfrak{p}$ of $R/\ann(y)$, which contains $\ann(y)$ and thus $x$. But
$\ass(R/\ann(y)) \subset \ass(R)$.
So $x$ is contained in a prime in $\ass(R)$.
\end{proof}

Assume now that $R$ is reduced.  Then $K(R)  = S^{-1}R$ where $S$ is the
complement of the union of the minimal primes.
At least, we can claim:

\begin{proposition} Let $R$ be reduced and noetherian. Then
$K(R) = \prod_{\mathfrak{p}_i \ \mathrm{minimal}} R_{\mathfrak{p}_i}$.
\end{proposition}

So $K(R)$ is the product of fields into which $R$ embeds.

We now continue the discussion begun last time. Let $R$ be noetherian and $M$ a
finitely generated $R$-module. We would like to understand very rough features
of $M$.
We can embed $M$ into a larger $R$-module.
Here are two possible approaches.

\begin{enumerate}
\item  $S^{-1}M$, where $S$ is a large multiplicatively closed subset of $M$.
Let us take $S $ to be the set of all $a \in R$ such that $M
\stackrel{a}{\to}M$ is injective, i.e. $a$ is not a zerodivisor on $M$. Then
the map
\[ M \to S^{-1}M  \]
is an injection. Note that $S$ is the complement of the union of $\ass(R)$.
\item Another approach would be to use a \emph{primary decomposition}
\[ M \hookrightarrow \prod M_i,  \]
where each $M_i$ is $\mathfrak{p}_i$-primary for some prime $\mathfrak{p}_i$
(and these primes range over $\ass(M)$). In this case, it is clear that
anything not in each $\mathfrak{p}_i$ acts injectively. So we can draw a
commutative diagram
\[
\xymatrix{
M \ar[d]  \ar[r] &  \prod M_i \ar[d]  \\
\prod M_{\mathfrak{p}_i} \ar[r] &  \prod (M_i)_{\mathfrak{p}_i}
}.
\]
The map going right and down is injective.
It follows that $M$ injects into the product of its localizations at associated
primes.
\end{enumerate}

The claim is that these constructions agree if $M$ has no embedded primes.
I.e., if there are no nontrivial containments among the associated primes of
$M$, then $S^{-1}M$ (for $S =  R - \bigcup_{\mathfrak{p} \in \ass(M)}
\mathfrak{p}$)
is just $\prod M_{\mathfrak{p}}$.
To see this, note that any element of $S$ must act invertibly on $\prod
M_{\mathfrak{p}}$. We thus see that there is always a map
\[ S^{-1}M \to \prod_{\mathfrak{p} \in \ass(M)} M_{\mathfrak{p}} . \]
\begin{proposition}
This is an isomorphism if $M$ has no embedded primes.
\end{proposition}

\begin{proof}
Let us go through a series of reductions. Let $I = \ann(M) = \left\{a: aM
= 0\right\}$. Without loss of generality, we can replace $R $ by $R/I$. This plays nice with the
associated primes.

The assumption is now that $\ass(M)$ consists of the minimal
primes of $R$.

Without loss of generality, we can next replace $R$ by $S^{-1}R$ and $M$ by
$S^{-1}M$, because that doesn't affect the conclusion; localization plays nice
with associated primes.

Now, however, $R$ is artinian: i.e., all primes of $R$ are minimal (or
maximal). Why is this?
Let $R$ be \emph{any} noetherian ring and $S = R - \bigcup_{\mathfrak{p} \
\mathrm{minimal}} \mathfrak{p}$. Then I claim that $S^{-1}R$ is artinian. We'll
prove this in a moment.

So $R$ is artinian, hence a product $\prod R_i$ where each $R_i$ is local
artinian. Without loss of generality, we can replace $R$ by $R_i$ by taking
products. The condition we are trying to prove is now that
\[ S^{-1}M \to M_{\mathfrak{m}}  \]
for $\mathfrak{m} \subset R$ the maximal ideal. But $S$ is the complement of
the union of the minimal primes, so it is $R - \mathfrak{m}$ as $R$ has one
minimal (and maximal) ideal.  This is obviously an isomorphism: indeed, both
are $M$.
\end{proof}

\add{proof of artianness}
\begin{corollary}
Let $R$ be a noetherian ring with no embedded primes (i.e. $\ass(R)$ consists
of minimal primes).
Then $K(R) = \prod_{\mathfrak{p}_i \ \mathrm{minimal}} R_{\mathfrak{p_i}}$.
\end{corollary}
If $R$ is reduced, we get the statement made last time: there are no
embedded primes, and $K(R)$ is a product of
fields.

\subsection{The image of $M \to S^{-1}M$}
Let's ask now the following question. Let $R$ be a noetherian ring, $M$
a finitely generated
$R$-module, and $S$ the set of nonzerodivisors on $M$, i.e. $R -
\bigcup_{\mathfrak{p} \in \ass(M)} \mathfrak{p}$. We have seen that there is an
imbedding
\[ \phi: M \hookrightarrow S^{-1}M.  \]
What is the image? Given $x \in S^{-1}M$, when does it belong to the imbedding
above.

To answer such a question, it suffices to check locally. In particular:
\begin{proposition}
$x$ belongs to the image of $M $ in $S^{-1}M$ iff for every $\mathfrak{p} \in
\spec R$, the image of $x$ in $(S^{-1}M)_{\mathfrak{p}}$ lies inside
$M_{\mathfrak{p}}$.
\end{proposition}

This isn't all that interesting. However, it turns out that you can check this
at a smaller set of primes.

\begin{proposition}
In fact, it suffices to show that $x$ is in the image of $\phi_{\mathfrak{p}}$
for every $\mathfrak{p} \in \ass(M/sM)$ where $s \in S$.
\end{proposition}
This is a little opaque; soon we'll see what it actually means.
The proof is very simple.

\begin{proof}
Remember that $ x \in S^{-1}M$. In particular, we can write $x = y/s$ where $y
\in M, s \in S$. What we'd like to prove that $x \in M$, or equivalently that
$y \in sM$.\footnote{In general, this would be equivalent to $ty \in tsM$ for
some $t \in S$; but $S$ consists of nonzerodivisors on $M$.}
In particular, we want to know that $y$ maps to zero in $M/sM$. If not, there
exists an associated prime $\mathfrak{p} \in \ass(M/sM)$ such that $y$ does not
get
killed in $(M/sM)_{\mathfrak{p}}$.
We have assumed, however, for every associated prime $\mathfrak{p}\in \ass(M)$,
$x \in ( S^{-1}M)_{\mathfrak{p}}$ lies in the image of $M_{\mathfrak{p}}$. This
states that the image of $y$ in this quotient $(M/sM)_{\mathfrak{p}}$ is zero,
or that $y$ is divisible by $s$ in this localization.
\end{proof}

The case we actually care about is the following:

Take $R$ as a noetherian domain and $M = R$.  Then $S = R - \left\{0\right\}$
and $S^{-1}M $ is just the fraction field $K(R)$.  The goal is to describe $R$
as a subset of $K(R)$. What we have proven is that $R$ is the intersection in
the fraction field
\[ \boxed{ R = \bigcap_{\mathfrak{p} \in \ass(R/s), s \in R - 0}
R_{\mathfrak{p}} . }\]
So to check that something belongs to $R$, we just have to check that in a
\emph{certain set of localizations}.

Let us state this as a result:
\begin{theorem} \label{notreallykrullthm}
If $R$ is a noetherian domain
\[ R = \bigcap_{\mathfrak{p} \in \ass(R/s), s \in R - 0}
R_{\mathfrak{p}}  \]
\end{theorem}

\subsection{Serre's criterion}

We can now state a result.
\begin{theorem}[Serre]
\label{serrecrit1}
Let $R$ be a noetherian domain.	Then $R $ is integrally
closed iff it satisfies
\begin{enumerate}
\item For any $\mathfrak{p} \subset R$ of height one, $R_{\mathfrak{p}}$ is a
DVR.
\item For any $s \neq 0$, $R/s$ has no embedded primes (i.e. all the
associated primes of $R/s$ are height one).
\end{enumerate}
\end{theorem}

Here is the non-preliminary version of the Krull theorem.
\begin{theorem}[Algebraic Hartogs]
Let $R$ be a noetherian integrally closed ring. Then
\[ R = \bigcap_{\mathfrak{p} \ \mathrm{height \ one}} R_{\mathfrak{p}},  \]
where each $R_{\mathfrak{p}}$ is a DVR.
\end{theorem}

\begin{proof}
Now evident from the earlier result \cref{notreallykrullthm} and Serre's criterion.
\end{proof}
Earlier in the class, we proved that a domain was integrally closed if and only
if it could be described as an intersection of valuation rings. We have now
shown that when $R$ is noetherian, we can take \emph{discrete} valuation rings.

\begin{remark}
In algebraic geometry, say $R = \mathbb{C}[x_1, \dots, x_n]/I$.  Its maximal
spectrum is a subset of $\mathbb{C}^n$.  If $I$ is prime, and $R$ a domain,
this variety is
irreducible.  We are trying to describe $R$ inside its field of fractions.

The field of fractions are like the ``meromorphic functions''; $R$ is like the
holomorphic functions. Geometrically, this states to check that a meromorphic
function is holomorphic, you can just check this by computing the ``poleness''
along each codimension one subvariety. If the function doesn't blow up on each
of the codimension one subvarieties,  and $R$ is normal, then you can extend it
globally.

This is an algebraic version of Hartog's theorem: this states that a
holomorphic function on $\mathbb{C}^2 - (0,0)$ extends over the origin, because
this has codimension $>1$.

All the obstructions of extending a function to all of $\spec R$ are in
codimension one.
\end{remark}

Now, we prove Serre's criterion.
\begin{proof}
Let us first prove that $R$ is integrally closed if 1 and 2 occur. We know that
\[ R = \bigcap_{\mathfrak{p} \in \ass(R/x), x \neq 0} R_{\mathfrak{p}} ; \]
by condition 1, each such $\mathfrak{p}$ is of height one, and
$R_{\mathfrak{p}}$ is a DVR. So $R$ is the intersection of DVRs and thus
integrally closed.

The hard part is going in the other direction. Assume $R$ is integrally closed.
We want to prove the two conditions. In $R$, consider the following conditions
on a prime ideal $\mathfrak{p}$:
\begin{enumerate}
\item $\mathfrak{p}$ is an associated prime of $R/x$ for some $x \neq 0$.
\item $\mathfrak{p} $ is height one.
\item $\mathfrak{p}_{\mathfrak{p}}$ is principal in $R_{\mathfrak{p}}$.
\end{enumerate}
First, 3 implies 2 implies 1. 3 implies that $\mathfrak{p}$ contains an element
$x$ which
generates $\mathfrak{p}$ after localizing.
It follows that there can be no prime between $(x)$ and $\mathfrak{p}$ because
that would be preserved under localization.  Similarly, 2 implies 1 is easy. If
$\mathfrak{p}$ is minimal over $(x)$, then $\mathfrak{p} \in \ass R/(x)$ since
the minimal primes in the support are always associated.

We are trying to prove the inverse implications. In that case, the claims
of the theorem will be proved. We have to show that 1 implies 3.
This is an argument we really saw last time, but let's see it again. Say
$\mathfrak{p} \in \ass(R/x)$. We can replace $R$ by $R_{\mathfrak{p}}$ so that
we can assume that $\mathfrak{p}$ is maximal. We want to show that
$\mathfrak{p}$ is generated by one
element.

What does the condition $\mathfrak{p} \in \ass(R/x)$ buy us? It tells us that
there is $\overline{y} \in R/x$ such that $\ann(\overline{y}) = \mathfrak{p}$.
In particular, there is $y \in R$ such that $\mathfrak{p}y \subset (x)$ and $y
\notin (x)$.
We have the element $y/x \in K(R)$ which sends $\mathfrak{p}$ into $R$.  That
is,
\[ (y/x) \mathfrak{p} \subset R.  \]
There are two cases to consider, as in last time:
\begin{enumerate}
\item $(y/x) \mathfrak{p}  = R$. Then $\mathfrak{p} = R (x/y)$ so $\mathfrak{p}
$ is principal.
\item $(y/x) \mathfrak{p} \neq R$. In particular, $(y/x)\mathfrak{p} \subset
\mathfrak{p}$. Then since $\mathfrak{p}$ is finitely generated, we find that
$y/x $ is
integral over $R$, hence in $R$. This is a contradiction as $y \notin (x)$.
\end{enumerate}
Only the first case is now possible. So $\mathfrak{p}$ is in fact principal.
\end{proof}



% ============================ chapters/factorization.tex}
\chapter{Unique factorization and the class group}


Commutative rings in general do not admit unique factorization.
Nonetheless, for many rings (``integrally closed'' rings), which
includes the affine coordinate rings one obtains in algebraic geometry when
one studies smooth varieties, there is an invariant called the ``class
group'' that measures the failure of unique factorization. This ``class
group'' is a certain quotient of codimension one primes (geometrically,
codimension one subvarieties) modulo rational equivalence.

Many even nicer rings have the convenient property that their localizations at prime
ideals \emph{factorial}, a key example being the coordinate ring of an affine
nonsingular variety.
For these even nicer rings, an alternative method of defining the class group
can be given: the class group corresponds to the group of isomorphism
classes of \emph{invertible modules}. Geometrically, such invertible modules
are line bundles on the associated variety (or scheme).

\section{Unique factorization}

\subsection{Definition}
We begin with the nicest of all possible cases, when the ring itself admits
unique factorization.



Let $R$ be a domain.
\begin{definition}
A nonzero element $x \in R$ is \textbf{prime} if $(x)$ is a prime ideal.
\end{definition}

In other words, $x$ is not a unit, and if $x \mid ab$, then either $x \mid a$
or $x \mid b$.

We restate the earlier \cref{earlyUFD} slightly.
\begin{definition}
A domain $R$ is \textbf{factorial} (or a \textbf{unique factorization domain},
or a \textbf{UFD}) if every nonzero noninvertible element $x \in R$ factors as a
product $ x_1 \dots x_n$ where each $x_i$ is prime.
\end{definition}

Recall that a \emph{principal ideal domain} is a UFD (\cref{PIDUFD}), as is a
\emph{euclidean} domain (\cref{EDPID}); actually, a euclidean domain is  a PID.
Previously, we imposed something seemingly slightly stronger: that the
factorization be unique. We next show that we get that for free.

\begin{proposition}[The fundamental theorem of arithmetic]
This factorization is essentially unique, that is, up to multiplication by units.
\end{proposition}
\begin{proof} Let $x \in R$ be a nonunit.
Say $x = x_1 \dots x_n = y_1 \dots y_m$ were two different prime
factorizations. Then $m,n>0$.

We have that $x_1 \mid y_1 \dots y_m$, so $x_1 \mid y_i$ for some $i$. But
$y_i$ is prime. So $x_1$ and $y_i$ differ by a unit. By removing each of these,
we can get  a smaller set of nonunique factorizations.
Namely, we find that
\[ x_2 \dots x_n = y_1 \dots \hat{y_i} \dots y_m  \]
and then we can induct on the number of factors.
\end{proof}

The motivating example is of course:
\begin{example}
$\mathbb{Z}$ is factorial. This is the fundamental theorem of arithmetic, and
follows because $\mathbb{Z}$ is a euclidean domain.  The same observation
applies to a polynomial ring over a field by \cref{polyringED}.
\end{example}

\subsection{Gauss's lemma}

We now show that factorial rings are closed under the operation of forming
polynomial rings.

\begin{theorem}[Gauss's lemma]
If $R$ is factorial, so is the polynomial ring $R[X]$.
\end{theorem}
In general, if $R$ is a PID, $R[X]$ will \emph{not} be a PID. For instance,
$\mathbb{Z}[X]$ is not a PID: the prime ideal $(2, X)$ is not principal.

\begin{proof}
In the course of this proof, we shall identify the prime elements in $R[X]$.
We start with a lemma that allows us to compare factorizations in $K[X]$ (for
$K$ the quotient field) and $R[X]$; the advantage is that we already know the
polynomial ring over a \emph{field} to be  a UFD.
\begin{lemma} Suppose $R$ is a unique factorization domain with
quotient field $K$.
Suppose $f \in R[X]$ is irreducible in $R[X]$ and there is no nontrivial common divisor of
the coefficients of $f$. Then $f$ is irreducible in $K[X]$.
\end{lemma}
With this in mind, we say that a polynomial in $R[X]$ is \textbf{primitive} if
the coefficients have no common divisor in $R$.

\begin{proof} Indeed, suppose we had a factorization
\[ f = gh,  \quad g, h \in K[X], \]
where $g,h$ have degree $\geq 1$.
Then we can clear denominators to find a factorization
\[ rf  = g' h'  \]
where $r \in R - \left\{0\right\}$ and $g', h' \in R[X]$. By clearing
denominators as little as possible, we may assume that $g',h'$ are primitive.
To be precise, we divide $g', h'$ by their \emph{contents.} Let us define:

\begin{definition}
The \textbf{content} $\cont (f)$ of a polynomial $f \in R[X]$ is the greatest common
divisor of its coefficients.  The content of an element $f$ in $K[X]$ is defined
by considering $r \in R$ such that $rf \in R[X]$, and taking $\cont(rf)/r$.
This is well-defined, modulo elements of $R^*$, and we have $\cont(sf) = s \cont f$ if $s \in K$.
\end{definition}

To say that the content lies in $R$ is to say that the polynomial is in $R[X]$;
to say that the content is a unit is to say that the polynomial is primitive.
Note that a monic polynomial in $R[X]$ is primitive.

So we have:
\begin{lemma}
Any element of $K[X]$ is a product of $\cont(f)$ and something primitive in
$R[X]$.
\end{lemma}
\begin{proof}
Indeed, $f/\cont(f)$ has content a unit.  It therefore cannot have anything in the
denominator. Indeed, if it had a term $r/p^i X^n$ where $r ,p \in R$ and $p
\nmid r$ is prime, then the content would divide $r/p^i$. It thus could not be
in $R$.
\end{proof}

\begin{lemma}
$\cont(fg) = \cont(f) \cont(g)$ if $f,g \in K[X]$.
\end{lemma}
\begin{proof}
By dividing $f,g$ by their contents, it suffices to show that the product of
two primitive polynomials in $R[X]$ (i.e. those with no common divisor of all
their coefficients) is itself primitive. Indeed, suppose $f,g$ are primitive
and $p \in R$ is a prime. Then $\overline{f}, \overline{g} \in R/(p)[X]$ are
nonzero. Their product $\overline{f}\overline{g}$ is also not zero because
$R/(p)[X]$ is a domain, $p$ being prime. In particular, $p$ is not a common
factor of the coefficients of $fg$. Since $p$ was arbitrary, this completes the
proof.
\end{proof}

So return to the main proof. We know that $f =  gh$. We divided $g,h$ by their
contents to get $g', h' \in R[X]$. We had then
\[ r f = g' h', \quad r \in K^*.  \]
Taking the contents, and using the fact that $f, g', h'$ are primitive, we have then:
\[ r = \cont(g') \cont(h') = 1 \quad \mathrm{(modulo \ } R^*).  \]
But then $f = r^{-1} g' h'$ shows that $f$ is not irreducible in $R[X]$,
contradiction.
\end{proof}


Let $R$ be a ring. Recall that an element is \textbf{irreducible} if it admits
no nontrivial factorization. The product of an irreducible element and a unit
is irreducible.
Call a ring \textbf{finitely irreducible} if every element in the ring admits a
factorization into finitely many irreducible elements.

\begin{lemma}
A ring $R$ is finitely irreducible if every ascending sequence of
\emph{principal} ideals in $R$ stabilizes.
\end{lemma}
A ring such that every ascending sequence  of ideals (not necessarily
principal) stabilizes is said to be \emph{noetherian;} this is a highly useful
finiteness condition on a ring.
\begin{proof}
Suppose  $R$ satisfies the ascending chain condition on principal ideals. Then
let $x \in R$. We would like to show it can be factored as a product of
irreducibles.
So suppose $x$ is not the product of finitely many irreducibles. In particular,
it is reducible: $x = x_1 x_1'$, where neither factor is a unit. One of this
cannot be written as a finite product of irreducibles. Say it is $x_1$.
Similarly, we can write $x_1 = x_2 x_2''$ where one of the factors, wlog $x_2$,
is not the product of finitely many irreducibles. Repeating inductively gives
the ascending sequence
\[ (x) \subset (x_1) \subset (x_2) \subset \dots,  \]
and since each factorization is nontrivial, the inclusions are each nontrivial.
This is a contradiction.
\end{proof}

\begin{lemma}
Suppose $R$ is a UFD. Then every ascending sequence of principal ideals in
$R[X]$ stabilizes.  In particular, $R[X]$ is finitely irreducible.
\end{lemma}
\begin{proof}
Suppose $(f_1) \subset (f_2) \subset \dots \in R[X]$. Then each $f_{i+1} \mid
f_{i}$. In particular, the degrees of $f_i$ are nonincreasing, and consequently
stabilize. Thus for $i \gg 0$, we have $\deg f_{i+1} = \deg f_i$.
We can thus assume that all the degrees are the same. In this case, if $i \gg
0$ and $k>0$,
$f_{i}/f_{i+k} \in R[X]$ must actually lie in $R$ as $R$ is a domain.
In particular, throwing out the first few elements in the sequence if
necessary, it follows that our sequence looks like
\[ f, f/r_1, f/(r_1r_2), \dots \]
where the $r_i \in R$. However, we can only continue this a finite amount of
time before the $r_i$'s will have to become units since $R$ is a UFD. (Or $f
 = 0$.)
So the sequence of ideals stabilizes.
\end{proof}

\begin{lemma}
Every element in $R[X]$ can be factored into a product of irreducibles.
\end{lemma}
\begin{proof} Now evident from the preceding lemmata.
\end{proof}
Suppose $P$ is an irreducible element in $R[X]$. I claim that $P$ is prime.
There are two cases:
\begin{enumerate}
\item $P \in R$ is a prime in $R$. Then we know that $P \mid f$ if and only if
the coefficients of $f$ are divisible by $P$. In particular, $P \mid f$ iff $P
\mid \cont (f)$. It is now clear that $P \mid fg$ if and only if $P$ divides
one of $\cont(f), \cont(g)$ (since $\cont(fg) = \cont(f) \cont(g)$).
\item $P$ does not belong to $R$. Then $P$ must have content a unit or it would
be divisible by its content.
So $P$ is irreducible in $K[X]$ by the above reasoning.

Say we have an expression
\[ P \mid fg, \quad f,g \in R[X].  \]
Since $P$ is irreducible, hence prime, in the UFD (even PID) $K[X]$, we have
that $P $ divides one of $f,g$ in $K[X]$. Say we can write
\[ f = q P , q \in K[X].  \]
Then taking the content shows that $\cont(q) = \cont(f) \in R$, so $q \in
R[X]$. It follows that $P \mid f$ in $R[X]$.
\end{enumerate}

We have shown that every element in $R[X]$ factors into a product of prime
elements. From this, it is clear that $R[X]$ is a UFD.
\end{proof}


\begin{corollary}
The polynomial ring $k[X_1, \dots, X_n]$ for $k$ a field is factorial.
\end{corollary}
\begin{proof}
Induction on $n$.
\end{proof}

\subsection{Factoriality and height one primes}

We now want to give a fancier criterion for a ring to be a UFD, in terms of the
lattice
structure on $\spec R$. This will require a notion from dimension theory (to be
developed more fully later).
\begin{definition}
Let $R$ be a domain. A prime ideal $\mathfrak{p} \subset R$ is said to be of
\textbf{height one} if $\mathfrak{p}$ is minimal among ideals
containing $x$ for some nonzero $x \in R$.
\end{definition}
So a prime of height one is not the zero prime, but it is as close to zero as
possible, in some sense. When we later talk about dimension theory, we will
talk about primes of any height. In a sense, $\mathfrak{p}$ is ``almost''
generated by one element.

\begin{theorem} \label{heightonefactoriality}
Let $R$ be a noetherian domain. The following are equivalent:
\begin{enumerate}
\item $R$ is factorial.
\item Every height one prime is principal.
\end{enumerate}
\end{theorem}
\begin{proof}
Let's first show 1) implies 2). Assume $R$ is factorial and $\mathfrak{p}$ is
height one, minimal containing $(x)$ for some $x \neq 0 \in R$.
Then $x$ is a nonunit, and it is nonzero, so it has a prime factorization
\[ x = x_1 \dots x_n, \quad \mathrm{each \ } x_i \ \mathrm{prime}.  \]
Some $x_i \in \mathfrak{p}$ because $\mathfrak{p}$ is prime. In particular,
\[ \mathfrak{p} \supset (x_i) \supset (x).  \]
But $(x_i)$ is prime itself, and it contains $(x)$. The minimality of
$\mathfrak{p}$ says that $\mathfrak{p}  = (x_i)$.

Conversely, suppose every height one prime is principal. Let $x \in R$ be
nonzero and a nonunit. We want
to factor $x$ as a product of primes.
Consider the ideal $(x) \subsetneq R$. As a result, $(x)$ is contained in a
prime ideal. Since $R$ is noetherian, there is a minimal prime ideal
$\mathfrak{p}$ containing $(x)$.  Then $\mathfrak{p}$, being a height one
prime, is principal---say $\mathfrak{p}=(x_1)$. It follows that $x_1 \mid x$
and $x_1$ is prime.
Say
\[ x = x_1 x_1'.  \]
If $x_1'$ is a nonunit, repeat this process to get $x_1' = x_2 x_2'$ with $x_2$ a prime element.
Keep going; inductively we have
\[ x_k = x_{k+1}x_{k+1}'.  \]
If this process stops, with one of the $x_k'$  a  unit, we get a prime
factorization of $x$. Suppose the process
continues forever. Then we would have
\[ (x) \subsetneq (x_1') \subsetneq (x_2') \subsetneq (x_3') \subsetneq \dots,  \]
which is impossible by noetherianness.
\end{proof}

We have seen that unique factorization can be formulated in terms of prime
ideals.


\subsection{Factoriality and normality}

We next state a generalization of the ``rational root theorem'' as in high
school algebra.
\begin{proposition} \label{factorialimpliesnormal}
A factorial domain is integrally closed.
\end{proposition}

\begin{proof}
\add{proof -- may be in the queue already}
\end{proof}

\section{Weil divisors}

\label{weildivsec}
\subsection{Definition}
We start by discussing Weil divisors.
\begin{definition}
A \textbf{Weil divisor} for $R$ is a formal linear combination $\sum n_{i}
[\mathfrak{p}_i]$ where the $\mathfrak{p}_i$ range over height one primes of
$R$. So the group of Weil divisors is the free abelian group on the height one
primes of $R$. We denote this group by $\weil(R)$.
\end{definition}


The geometric picture behind Weil divisors is that a Weil divisor is like a
hypersurface: a subvariety of codimension one.

\subsection{Valuations}



\subsection{Nagata's lemma} We finish with a fun application of the exact
sequence of Weil divisors to a purely algebraic statement about factoriality.

\begin{lemma}
Let $A$ be a normal noetherian domain.
\end{lemma}

\begin{theorem}
Let $A$ be a noetherian domain, $x \in A-\left\{0\right\}$. Suppose $(x)$ is
prime and $A_x$ is factorial. Then $A$ is factorial.
\end{theorem}
\begin{proof}
We first show that $A$ is normal (hence regular in codimension one).
Indeed, $A_x$ is normal. So if $t \in K(A)$ is integral over $A$, it lies in
$A_x$.
So we need to check that if $a/x^n \in A_x$ is integral over $A$ and $x \nmid
x$, then $n=0$.
Suppose we had an equation
\[ (a/x^n)^N + b_1 (a/x^n)^{N-1} + \dots + b_N = 0.  \]
Multiplying both sides by $x^{nN}$ gives that
\[ a^N \in xR,  \]
so $x \mid a$ by primality.

Now we use the exact sequence
\[ (x) \to \mathrm{Cl}(A) \to \mathrm{Cl}(A_x) \to 0.  \]
The end is zero, and the image of the first map is zero. So
$\mathrm{Cl}(A)=0$. Thus $A$ is a UFD.
\end{proof}





\section{Locally factorial domains}

\subsection{Definition}
\begin{definition}
A noetherian domain $R$ is said to be \textbf{locally factorial} if
$R_{\mathfrak{p}}$ is factorial for each $\mathfrak{p}$ prime.
\end{definition}

\begin{example}
The coordinate ring $\mathbb{C}[x_1, \dots, x_n/I$ of an algebraic variety is
locally factorial if the variety is smooth. We may talk about this later.
\end{example}

\begin{example}[Nonexample]
Let $R$ be $\mathbb{C}[A,B,C,D]/(AD - BC)$. The spectrum of $R$ has maximal
ideals consisting of 2-by-2 matrices of determinant zero. This variety is very
singular at the origin. It is not even locally factorial at the origin.

The failure of unique factorization comes from the fact that
\[ AD = BC  \]
in this ring $R$. This is a prototypical example of a ring without unique
factorization. The reason has to do with the fact that the variety has a
singularity at the origin.
\end{example}

\subsection{The Picard group}

\begin{definition}
Let $R$ be a commutative ring. An $R$-module $I$ is \textbf{invertible} if
there exists $J$ such that
\[ I \otimes_R J \simeq R.  \]
Invertibility  is with respect to the tensor product.
\end{definition}

\begin{remark} \label{linebundremark}
In topology, one is often interested in classifying \emph{vector bundles} on
spaces. In algebraic geometry, a module $M$ over a ring $R$ gives (as in
\cref{}) a sheaf of abelian groups over the topological space $\spec R$; this
is supposed to be an analogy with the theory of vector bundles. (It is not so
implausible since the Serre-Swan theorem (\cref{}) gives an equivalence of
categories between the vector bundles over a compact space $X$ and the
projective modules over the ring $C(X)$ of continuous functions.)
In this analogy, the invertible modules are the \emph{line bundles}.
The definition has a counterpart in the topological setting: for instance, a
vector bundle $\mathcal{E} \to X$ over a space $X$ is a line bundle (that is,
of rank one) if and only if there is a vector bundle $\mathcal{E}' \to X$ such
that $\mathcal{E} \otimes \mathcal{E}'$ is the trivial bundle $X \times
\mathbb{R}$.
\end{remark}

There are many equivalent characterizations.

\begin{proposition}
Let $R$ be a ring, $I$ an $R$-module. TFAE:
\begin{enumerate}
\item $I$ is invertible. 
\item $I$ is finitely generated and $I_{\mathfrak{p}} \simeq R_{\mathfrak{p}}$ for all primes
$\mathfrak{p} \subset R$.
\item $I$ is finitely generated and there exist $a_1, \dots, a_n \in R$ which generate $(1)$
in $R$ such that
\[ I[a_i^{-1}]\simeq R[a_i^{-1}].  \]
\end{enumerate}
\end{proposition}
\begin{proof}
First, we show that if $I$ is invertible, then $I$ is finitely generated.
Suppose $I \otimes_R J \simeq R$. This means that $1 \in R$ corresponds to an
element
\[ \sum i_k \otimes j_k \in I \otimes_R J .  \]
Thus, there exists a finitely generated submodule $I_0\subset I$ such that the map $I_0 \otimes J \to I
\otimes J$ is surjective. Tensor this with $I$, so we get a surjection
\[ I_0 \simeq I_0 \otimes J \otimes I \to I \otimes J \otimes I \simeq I  \]
which leads to a surjection $I_0 \twoheadrightarrow I$. This implies that $I$
is finitely generated

\textbf{Step 1: 1 implies 2.}
We now show 1 implies 2. Note that if $I$ is invertible, then $I \otimes_R R'$
is an invertible $R'$ module for any $R$-algebra $R'$; to get an inverse of
$I \otimes_R R'$,
tensor the inverse of $I$ with $R'$.
In particular, $I_{\mathfrak{p}}$ is an invertible $R_{\mathfrak{p}}$-module
for each $\mathfrak{p}$. As a result,
\[ I_{\mathfrak{p}}/\mathfrak{p} I_{\mathfrak{p}}  \]
is invertible over the \emph{field} $R_{\mathfrak{p}}/\mathfrak{p}R_{\mathfrak{p}}$. This means
that
$ I_{\mathfrak{p}}/\mathfrak{p} I_{\mathfrak{p}}$ is a one-dimensional vector
space over the residue field. (The invertible modules over a vector space are
the one-dimensional spaces.)
Choose an element $x \in I_{\mathfrak{p}}$ which generates
$I_{\mathfrak{p}}/\mathfrak{p}I_{\mathfrak{p}}$.  Since $I_{\mathfrak{p}}$ is
finitely generated, Nakayama's lemma shows that $x$ generates $I_{\mathfrak{p}}$.

We get a surjection $\alpha: R_{\mathfrak{p}} \twoheadrightarrow I_{\mathfrak{p}}$
carrying $1 \to x$.  We claim that this map is injective.
This will imply that $I_{\mathfrak{p}}$ is free of rank 1. So, let $J$ be an
inverse of $I$ among $R$-modules, so that $I \otimes_R J = R$; the same
argument as above provides a surjection
$ \beta: {R}_{\mathfrak{p}} \to J_{\mathfrak{p}}$.
Then $\beta' = \beta \otimes 1_{I_{\mathfrak{p}}}: I_{\mathfrak{p}} \to
R_{\mathfrak{p}}$ is also a surjection.
Composing, we get a surjective map
\[ R_{\mathfrak{p}} \stackrel{\alpha}{\twoheadrightarrow} I_{\mathfrak{p}}
\stackrel{\beta'}{\twoheadrightarrow} R_{\mathfrak{p}}  \]
whose composite must be multiplication by a unit, since the ring is local. Thus
the composite is injective and $\alpha$ is injective.
It follows that $\alpha$ is an isomorphism, so that $I_{\mathfrak{p}}$ is free
of rank one.

\textbf{Step 2: 2 implies 3.}
Now we show 2 implies 3. Suppose $I$ is finitely generated with generators $\left\{x_1, \dots, x_n\right\} \subset I$ and $I_{\mathfrak{p}} \simeq
R_{\mathfrak{p}}$ for all $\mathfrak{p}$. Then for each $\mathfrak{p}
$, we can choose an element $x$ of $I_{\mathfrak{p}}$ generating
$I_{\mathfrak{p}}$ as $R_{\mathfrak{p}}$-module.
By multiplying by the denominator, we can assume that $x \in I$.
By assumption, we can then find $a_i,s_i \in R$ with
\[ s_i x_i = a_i x \in R  \]
for some $s_i \notin \mathfrak{p}$ as $x$ generates $I_{\mathfrak{p}}$. This means that $x$ generates $I$ after inverting the $s_i$. It
follows that $I[1/a] = R[1/a]$ where $a = \prod s_i \notin \mathfrak{p}$.
In particular, we find that there is an open covering $\{\spec
R[1/a_{\mathfrak{p}}] \}$ of $\spec R$ (where $a_{\mathfrak{p}} \notin
\mathfrak{p}$) on which $I$ is isomorphic to $R$.
To say that these cover $\spec R$ is to say that the $a_{\mathfrak{p}}$
generate $1$.

Finally, let's do the implication 3 implies 1.  Assume that we have the
situation of $I[1/a_i] \simeq R[1/a_i]$. We want to show that $I$ is invertible.
We start by showing that $I$ is \textbf{finitely presented}. This means that
there is an exact sequence
\[ R^m \to R^n \to I \to 0,  \]
i.e. $I$ is the cokernel of a map between free modules of finite rank.
To see this, first, we've assumed that $I$ is finitely generated. So there is a
surjection
\[ R^n \twoheadrightarrow I  \]
with a kernel $K \rightarrowtail  R^n$. We must show that $K$ is finitely
generated. Localization is an exact functor, so $K[1/a_i]$ is the kernel of
$R[1/a_i]^n \to I[1/a_i]$. However, we have an exact sequence
\[ K[1/a_i] \rightarrowtail  R[1/a_i]^n \twoheadrightarrow R[1/a_i]  \]
by the assumed isomorphism $I[1/a_i] \simeq R[1/a_i]$. But since a free module
is projective, this sequence splits and we find that $K[1/a_i]$ is finitely
generated. If it's finitely generated, it's generated by finitely many elements
in $K$.
As a result, we find that there is a map
\[ R^N \to K  \]
such that the localization to $\spec R[1/a_i]$ is surjective. This implies by
the homework that $R^N \to K$ is surjective.\footnote{To check that a map is
surjective, just check at the localizations at any maximal ideal.} Thus $K$ is finitely generated.

In any case, we have shown that the module $I$ is finitely presented.
\textbf{Define} $J = \hom_R(I, R)$ as the candidate for its dual. This
construction is compatible with localization.
We can choose a finite presentation $R^m \to R^n \to I \to 0$, which leads to a
sequence
\[ 0 \to J \to \hom(R^n, R) \to \hom(R^m, R).  \]
It follows that the formation of $J$ commutes with localization.
In particular, this argument shows that
\[ J[1/a] = \hom_{R[1/a]}(I[1/a], R[1/a]).  \]
One can check this by using the description of $J$. By construction, there is a
canonical map $I \otimes J \to R$.
I claim that this map is invertible.

For the proof, we use the fact that one can check for an isomorphism locally.
It suffices to show that
\[ I[1/a] \otimes J[1/a] \to R[1/a]  \]
is an isomorphism for some collection of $a$'s that generate the unit ideal.
However, we have $a_1, \dots, a_n$ that generate the unit ideal such that
$I[1/a_i]$ is free of rank 1, hence so is $J[1/a_i]$. It thus follows that
$I[1/a_i] \otimes J[1/a_i]$ is an isomorphism.
\end{proof}


\begin{definition}
Let $R$ be a commutative ring. We define the \textbf{Picard group} $\pic(R)$ to
be the set of isomorphism classes of invertible $R$-modules. This is an abelian
group; the addition law is defined so that the sum of the classes represented
by $M, N$ is $M \otimes_R N$.
The identity element is given by $R$.
\end{definition}

The Picard group is thus analogous (cf. \cref{linebundleremark}) to the set of
isomorphism classes of line bundles on a topological space (which is also an
abelian group). While the latter can often be easily computed (for a nice space
$X$, the line bundles are classified by elements of $H^2(X, \mathbb{Z})$), the
interpretation in the algebraic setting is more difficult.
\subsection{Cartier divisors}

Assume furthermore that $R$ is a domain. We now introduce:

\begin{definition}
A \textbf{Cartier divisor} for $R$ is a submodule $M \subset K(R)$ such that
$M$ is invertible.
\end{definition}
In other words, a Cartier divisor is an invertible fractional ideal.
Alternatively, it is an invertible $R$-module $M$ with a nonzero map $M \to
K(R)$. \textbf{ Once this map is nonzero, it is automatically injective,} since
injectivity can be checked at the localizations, and any module-homomorphism from a domain into
its quotient field is either zero or injective (because it is multiplication by
some element).


We now make this into a group.
\begin{definition}
Given $(M, a: M \hookrightarrow K(R))$ and $(N, b: N \hookrightarrow K(R))$, we
define the sum to be
\[  (M \otimes N, a \otimes b: M \otimes N \hookrightarrow K(R)). \]
The map $a \otimes b$ is nonzero, so by what was said above, it is an injection.
Thus the Cartier divisors from an abelian group $\cart(R)$.
\end{definition}

By assumption, there is a homomorphism
\[ \cart(R) \to\pic(R)  \]
mapping $(M, M \hookrightarrow K(R)) \to M$.

\begin{proposition}
The map $\cart(R) \to \pic(R)$ is surjective. In other words, any invertible
$R$-module can be embedded in $K(R)$.
\end{proposition}
\begin{proof}  Let $M$ be an invertible $R$-module.
Indeed, we know that $M_{(0)} = M \otimes_R K(R)$ is an invertible
$K(R)$-module, so a one-dimensional vector space over $K(R)$. In particular,
$M_{(0)} \simeq K(R)$. There is a nonzero homomorphic map
\[  M \to M_{(0) } \simeq K(R),  \]
which is automatically injective by the discussion above.
\end{proof}

What is the kernel of $\cart(R) \to \pic(R)$? This is the set of Cartier divisors which are
isomorphic to $R$ itself. In other words, it is the set of $(R, R
\hookrightarrow K(R))$. This data is the same thing as the data of a nonzero
element of $K(R)$.
So the kernel of
\[  \cart(R) \to \pic(R)  \]
has kernel isomorphic to $K(R)^*$. We have a short exact sequence
\[  K(R)^* \to \cart(R) \to \pic(R) \to 0.  \]

\subsection{Weil divisors and Cartier divisors}

Now, we want to assume $\cart(R)$ if $R$ is ``good.'' The ``goodness'' in
question is to assume that $R$ is locally factorial, i.e. that
$R_{\mathfrak{p}}$ is factorial for each $\mathfrak{p}$. This is true, for
instance, if $R$ is the coordinate ring of a smooth algebraic variety.



\begin{proposition}
If $R$ is locally factorial and noetherian, then the group $\cart(R)$ is a free abelian group.
The generators are in bijection with the height one primes of $R$.
\end{proposition}
Now assume that $R$ is a locally factorial, noetherian domain.
We shall produce an isomorphism
\[ \weil(R) \simeq \cart(R)  \]
that sends $[\mathfrak{p}_i]$ to that height one prime $\mathfrak{p}_i$
together with the imbedding $\mathfrak{p}_i \hookrightarrow R \to K(R)$.

We first check that this is well-defined. Since $\weil(R)$ is free, all we have
to do is check that each $\mathfrak{p}_i$ is a legitimate Cartier divisor. In
other words, we need to show that:

\begin{proposition}
If $\mathfrak{p} \subset R$ is a height one prime and $R$ locally factorial, then $\mathfrak{p}$ is
invertible.
\end{proposition}
\begin{proof}
In the last lecture, we gave a criterion for invertibility: namely, being
locally trivial. We have to show that for any prime $\mathfrak{q}$, we have
that $\mathfrak{p}_{\mathfrak{q}}$ is isomorphic to $R_{\mathfrak{q}}$. If
$\mathfrak{p} \not\subset \mathfrak{q}$, then $\mathfrak{p}_{\mathfrak{q}}$ is
the entire ring $R_{\mathfrak{q}}$, so this is obvious. Conversely, suppose
$\mathfrak{p} \subset {\mathfrak{q}}$. Then $\mathfrak{p}_{\mathfrak{q}}$ is
a height one prime of $R_{\mathfrak{q}}$: it is minimal over some element in
$R_{\mathfrak{q}}$.

Thus $\mathfrak{p}_{\mathfrak{q}}$ is principal, in particular free of rank
one, since $R_{\mathfrak{q}}$ is factorial. We saw last time that being
factorial is equivalent to the principalness of height one primes.
\end{proof}

We need to define the inverse map
\[ \cart(R) \to \weil(R).  \]
In order to do this, start with a Cartier divisor $(M, M \hookrightarrow
K(R))$. We then have to describe which coefficient to assign a height one
prime. To do this, we use a local criterion.

Let's first digress a bit.
Consider a locally factorial domain $R$ and a prime $\mathfrak{p}$ of height
one. Then $R_{\mathfrak{p}}$ is factorial. In particular, its maximal ideal
$\mathfrak{p}R_{\mathfrak{p}}$ is height one, so principal.
It is the principal ideal generated by some $t \in R_{\mathfrak{p}}$.
Now we show:
\begin{proposition}
Every nonzero ideal in $R_{\mathfrak{p}}$ is of the form $(t^n)$ for some unique $n
\geq 0$.
\end{proposition}
\begin{proof}
Let $I_0 \subset R_{\mathfrak{p}}$ be nonzero.  If $I_0 = R_{\mathfrak{p}}$, then
we're done---it's generated by $t^0$. Otherwise, $I_0 \subsetneq
R_{\mathfrak{p}}$, so contained in $\mathfrak{p}R_{\mathfrak{p}} = (t)$. So let
$I_1 = \left\{x \in R_{\mathfrak{p}}: tx \in I_0\right\}$. Thus
\[ I_1 = t^{-1} I_0.  \]
I claim now that $I_1 \neq I_0$, i.e. that there exists $x \in R_{\mathfrak{p}}$ such that $x
\notin I_0$ but $tx \in I_0$. The proof comes from the theory of associated
primes.
Look at $R_{\mathfrak{p}}/I_0$; it has at least one associated prime as it is
nonzero.

Since it
is a torsion module, this associated prime must be
$\mathfrak{p}R_{\mathfrak{p}}$ since the only primes in $R_{\mathfrak{p}}$
are $(0)$ and $(t)$, \textbf{which we have not yet shown}.  So there exists an
element in the quotient $R/I_0$ whose annihilator is precisely $(t)$. Lifting
this gives an element in $R$ which when multiplied by $(t)$ is in $I_0$ but
which is not in $I_0$. So $I_0 \subsetneq I_1$.

Proceed as before now. Define $I_2 = \left\{x  \in R_{\mathfrak{p}}: tx \in
I_1\right\}$.  This process must halt since we have assumed noetherianness. We
must have $I_m = I_{m+1}$ for some $m$, which would imply that some $I_m =
R_{\mathfrak{p}}$ by the above argument. It then follows that $I_0 = (t^m)$
since each $I_i$ is just $t I_{i+1}$.
\end{proof}

We thus have a good structure theory for ideals in $R$ localized at a height one prime.
Let us make a more general claim.

\begin{proposition}
Every nonzero finitely generated $R_{\mathfrak{p}}$-submodule of the fraction field $K(R)$ is of the
form $(t^n)$ for some $n \in \mathbb{Z}$.
\end{proposition}
\begin{proof}
Say that $M \subset K(R)$ is such a submodule. Let $I = \left\{x \in
R_{\mathfrak{p}}, x M \subset R_{\mathfrak{p}}\right\}$. Then $I \neq 0$ as $M$
is finitely generated  $M$ is generated over $R_{\mathfrak{p}}$ by a finite number of fractions $a_i/b_i, b_i \in R$.
Then the product $b = \prod b_i$ brings $M$ into $R_{\mathfrak{p}}$.

We know that $I = (t^m) $ for some $m$. In particular, $t^m M$ is an ideal in
$R$. In particular,
\[ t^m M = t^p R  \]
for some $p$, in particular $M = t^{p-m}R$.

\end{proof}

Now let's go back to the main discussion. $R$ is a noetherian locally factorial
domain; we want to construct a map
\[ \cart(R) \to \weil(R).  \]
Given $(M, M \hookrightarrow K(R))$ with $M$ invertible, we want to define a
formal sum $\sum n_i [\mathfrak{p}_i]$. For every height one prime
$\mathfrak{p}$, let us look at the local ring $R_{\mathfrak{p}}$ with maximal
ideal generated by some $t_{\mathfrak{p}} \in R_{\mathfrak{p}}$. Now
$M_{\mathfrak{p}} \subset K(R)$ is a finitely generated
$R_{\mathfrak{p}}$-submodule, so generated by some
$t_{\mathfrak{p}}^{n_{\mathfrak{p}}}$. So we map $(M, M \hookrightarrow K(R))$
to
\[ \sum_{\mathfrak{p}} n_{\mathfrak{p}}[\mathfrak{p}]. \]
First, we have to check that this is well-defined. In particular, we have to
show:

\begin{proposition}
For almost all height one $\mathfrak{p}$, we have $M_{\mathfrak{p}} =
R_{\mathfrak{p}}$. In other words, the integers $n_{\mathfrak{p}}$ are almost all zero.
\end{proposition}
\begin{proof}
We can always assume that $M$ is actually an ideal. Indeed, choose $a \in R$
with $aM = I \subset R$. As Cartier divisors, we have $M  = I  - (a)$. If we
prove the result for $I$ and $(a)$, then we will have proved it for $M$ (note
that the $n_{\mathfrak{p}}$'s are additive invariants\footnote{To see this,
localize at $\mathfrak{p}$---then if $M$ is generated by $t^a$, $N$ generated
by $t^b$, then $M \otimes N$ is generated by $t^{a+b}$.}). So because of this
additivity, it is sufficient to prove the proposition for actual (i.e.
nonfractional) ideals.

Assume thus that $M \subset R$.
All of these $n_{\mathfrak{p}}$ associated to $M$ are at least zero because $M$
is actually an ideal. What we want is that $n_{\mathfrak{p}} \leq 0$ for almost
all $\mathfrak{p}$. In other words, we must show that
\[ M_{\mathfrak{p}} \supset R_{\mathfrak{p}} \quad \mathrm{almost \ all \ }
\mathfrak{p}.  \]
To do this, just choose any $x \in M - 0$. There are finitely many minimal
primes containing $(x)$ (by primary decomposition applied to $R/(x)$). Every
other height one prime $\mathfrak{q}$ does not contain $(x)$.\footnote{Again, we're using
something about height one primes not proved yet.}
This states that $M_{\mathfrak{q}} \supset x/x = 1$, so $M_{\mathfrak{q}}
\supset R_{\mathfrak{q}}$.

The key claim we've used in this proof is the following. If $\mathfrak{q}$ is a
height one prime in a domain $R$ containing some nonzero element $(x)$, then
$\mathfrak{q}$ is minimal among primes containing $(x)$. In other words, we can
test the height one condition at any nonzero element in that prime.
Alternatively:
\begin{lemma}
There are no nontrivial containments among height one primes.
\end{lemma}
\end{proof}

Anyway, we have constructed maps between $\cart(R) $ and $\weil(R)$. The map
$\cart(R) \to \weil(R)$ takes $M \to \sum n_{\mathfrak{p}}[\mathfrak{p}]$. The
other map $\weil(R) \to \cart(R)$ takes $[\mathfrak{p}] \to \mathfrak{p}
\subset K(R)$. The composition $\weil(R) \to \weil(R)$ is the identity. Why is that? Start with a
prime $\mathfrak{p}$; that goes to the Cartier divisor $\mathfrak{p}$. Then we
need to finitely generatedre the multiplicities at other height one primes. But if
$\mathfrak{p}$ is height one and $\mathfrak{q}$ is a height one prime, then if
$\mathfrak{p} \neq \mathfrak{q}$ the lack of nontrivial containment relations
implies that the multiplicity of $\mathfrak{p}$ at $\mathfrak{q}$ is zero. We
have shown that
\[  \weil(R) \to \cart(R) \to \weil(R)  \]
is the identity.

Now we have to show that $\cart(R) \to \weil(R)$ is injective. Say we have a
Cartier divisor $(M, M \hookrightarrow K(R))$ that maps to zero in $\weil(R)$,
i.e. all its multiplicities
$n_{\mathfrak{p}}$ are zero at height one primes.
We show that $M  = R$.

First, assume $M \subset R$.
It is sufficient to show that at any maximal ideal $\mathfrak{m} \subset R$, we
have
\[ M_{\mathfrak{m}} = R_{\mathfrak{m}}.  \]
What can we say? Well, $M_{\mathfrak{m}}$ is principal as $M$ is invertible,
being a Cartier divisor. Let it be generated by $x \in R_{\mathfrak{m}}$;
suppose $x$ is a nonunit (or we're already done). But
$R_{\mathfrak{m}}$ is factorial, so $x = x_1 \dots x_n$ for each $x_i $ prime.
If $n>0$, then however $M$ has nonzero multiplicity at the prime ideal  $(x_i) \subset
R_{\mathfrak{m}} $. This is a contradiction.

The general case of $M$ not really a  subset of $R$ can be handled similarly:
then the generating element $x$ might lie in the fraction field. So $x$, if it
is not a unit in $R$, is a
product of some primes in the numerator and some primes in the denominator.
The nonzero primes that occur lead to nonzero multiplicities.
\lecture{10/13}

\subsection{Recap and a loose end}

Last time, it was claimed that if $R$ is a locally factorial domain, and
$\mathfrak{p} \subset R$ is of height one, then every prime ideal of
$R_{\mathfrak{p}}$ is either maximal or zero. This follows from general
dimension theory. This is equivalent to the following general claim about
height one primes:

\begin{quote}
There are no nontrivial inclusions among height one primes for $R$ a locally
factorial domain.
\end{quote}

\begin{proof}  Suppose $\mathfrak{q} \subsetneq \mathfrak{p}$ is an inclusion
of height one primes.

Replace $R$ by $R_{\mathfrak{p}}$. Then $R$ is local with some maximal ideal
$\mathfrak{m}$, which is principal with some generator $x$.
Then we have an inclusion
\[ 0 \subset \mathfrak{q} \subset \mathfrak{m}.  \]
This inclusion is proper. However, $\mathfrak{q}$ is principal since
it is height one in the factorial ring $R_{\mathfrak{p}}$.
This cannot be since every element is a power of $x$ times a unit.
(Alright, this wasn't live \TeX ed well.)
\end{proof}

Last time, we were talking about $\weil(R)$ and $\cart(R)$ for $R$ a locally
factorial noetherian domain.
\begin{enumerate}
\item $\weil(R)$ is free on the height one primes.
\item $\cart(R)$ is the group of invertible submodules of $K(R)$.
\end{enumerate}
We produced an isomorphism
\[ \weil(R) \simeq \cart(R).  \]

\begin{remark}
Geometrically, what is this? Suppose $R = \mathbb{C}[X_1, \dots, X_n]/I$ for
some ideal $I$. Then the maximal ideals, or closed points in $\spec R$, are
certain points in $\mathbb{C}^n$; they form an irreducible variety if $R$ is
a domain. The locally factorial condition is satisfied, for instance, if the
variety is \emph{smooth}. In this case, the Weil divisors correspond to sums of
irreducible varieties of codimension one---which correspond to the primes of
height one. The Weil divisors are free on the set
of irreducible varieties of codimension one.

The Cartier divisors can be thought of as ``linear combinations'' of
subvarieties which are locally defined by one equation. It is natural to assume
that the condition of being defined by one equation corresponds to being
codimension one. This is true by the condition of $R$ locally factorial.

In general, we can always construct a map
\[ \cart(R) \to \weil(R),  \]
but it is not necessarily an isomorphism.


\end{remark}

\subsection{Further remarks on $\weil(R)$ and $\cart(R)$} Recall that the Cartier group fits in an exact sequence:
\[  K(R)^* \to \cart(R) \to \pic(R) \to 0,   \]
because every element of $\cart(R)$ determines its isomorphism class, and
every element of $K(R)^*$ determines a free module of rank one. Contrary
to what was stated last time, it is \textbf{not true} that exactness holds on
the right. In fact, the kernel is the group $R^*$ of units of $R$. So the exact
sequence runs
\[ 0 \to R^* \to K(R)^* \to  \cart(R) \to \pic(R) \to 0.  \]
This is true for \emph{any} domain $R$. For $R$ locally factorial and
noetherian, we know that $\cart(R) \simeq \weil(R)$, though.

We can think of this as a generalization of unique factorization.
\begin{proposition}
$R$ is factorial if and only if $R$ is locally factorial and $\pic(R) = 0$.
\end{proposition}
\begin{proof}
Assume $R$ is locally factorial and $\pic(R)=0$. Then every prime ideal of
height one (an element of $\weil(R)$, hence of $\cart(R)$) is principal, which
implies that $R$ is factorial. And conversely.
\end{proof}

In general, we can think of the exact sequence above as a form of unique
factorization for a locally factorial domain: any invertible fractional ideal is a product of height one prime
ideals.

Let us now give an example.
\add{?}


% ============================ chapters/dedekind.tex}
\chapter{Dedekind domains}

The notion of a Dedekind domain allows one to generalize the usual unique
factorization in principal ideal domains as in $\mathbb{Z}$ to settings such
as the ring of integers in an algebraic number field. In general, a Dedekind
domain does not have unique factorization, but the \emph{ideals} in a Dedekind
domain do factor uniquely into a product of prime ideals.
We shall see that Dedekind domains have a short characterization in terms of
the characteristics we have developed.

After this, we shall study the case of an \emph{extension} of Dedekind domains $A \subset B$. It will be of
interest to determine how a prime ideal of $A$ factors in $B$. This should
provide background for the study of basic algebraic number theory, e.g. a
rough equivalent of the first chapter of
\cite{La94} or \cite{Se79}.




\section{Discrete valuation rings}


\subsection{Definition}

We start with the simplest case of a \emph{discrete valuation ring,} which is
the local version of a Dedekind domain.
Among the one-dimensional local noetherian rings, these will be the nicest.

\begin{theorem} \label{DVRthm}
Let $R$ be a noetherian local domain whose only prime ideals are $(0)$ and the maximal
ideal
$\mathfrak{m} \neq 0$.
Then, the following are equivalent:
\begin{enumerate}
\item $R$ is factorial.
\item $\mathfrak{m}$ is principal.
\item  $R$ is integrally closed.
\item $R$ is a valuation ring with value group $\mathbb{Z}$.
\end{enumerate}
\end{theorem}
\begin{definition}
A ring satisfying these conditions is called a \textbf{discrete valuation
ring} (\textbf{DVR}).
A discrete valuation ring necessarily has only two prime ideals, namely
$\mathfrak{m}$ and $(0)$.

Alternatively, we can say that a noetherian local domain is a DVR if and only
if it is of dimension one and integrally closed.
\end{definition}



\begin{proof}
Assume 1: that is, suppose $R$ is factorial. Then every prime ideal of height one is principal
by \cref{heightonefactoriality}.
But $\mathfrak{m}$ is the only prime that can be height one: it is minimal over
any nonzero nonunit of $R$, so $\mathfrak{m}$ is principal. Thus 1 implies 2, and similarly 2 implies 1 by
\cref{heightonefactoriality}.

1 implies 3 is true for any $R$: a factorial ring is always integrally
closed, by \cref{factorialimpliesnormal}.

4 implies 2 is easy as well. Indeed, suppose $R$ is a valuation ring with
value group $\mathbb{Z}$. Then, one chooses an element $x \in R$ such that the valuation of
$x$ is one. It is easy to see that  $x$ generates $\mathfrak{m}$: if $y
\in \mathfrak{m}$ is a non-unit, then the valuation of $y$ is at least one,
so $y/x \in R$ and $y \in (x)$.

The proof that 2 implies 4 is also straightforward. Suppose
$\mathfrak{m}$ is principal, generated by $t$.
In this case, we claim that any $x \in R$ is associate (i.e. differs by a
unit from) a power of $t$.
Indeed, since $\bigcap \mathfrak{m}^n = 0$ by the Krull intersection theorem
(\cref{krullintersection}), it follows that there exists $n$ such that $x$ is
divisible by $t^n$ but not by $t^{n+1}$.
In particular, if we write $x = u t^n$, then $u \notin (t)$ is a unit. This
proves the claim.

With this in mind, we need to show that $R$ is a valuation ring with value
group $\mathbb{Z}$.
If $x
\in R$, we define the valuation of $x$ to be the nonnegative integer $n$ such
that  $(x) = (t^n)$. One can
easily check that this is a valuation on $R$, which extends to the quotient
field by additivity.

The interesting part of the argument is the claim that 3
implies 2. Suppose $R$ is integrally closed, noetherian, and of dimension one; we claim that $\mathfrak{m}$ is
principal. Choose $x \in \mathfrak{m} - \left\{0\right\}$. If $(x) =
\mathfrak{m}$, we are done.

Otherwise, we can look at $\mathfrak{m}/(x) \neq
0$.  The module $\mathfrak{m}/(x)$ is finitely generated module a noetherian ring which is
nonzero, so it has an associated prime. That associated prime is either zero or
$\mathfrak{m}$ because $R$ has dimension one. But $0$ is not an associated prime because every element in the
module is killed by $x$. So $\mathfrak{m}$ is an associated prime of
$\mathfrak{m}/(x)$.

There is $\overline{y} \in \mathfrak{m}/(x)$ whose annihilator is
$\mathfrak{m}$.
Thus, there is $y \in \mathfrak{m}$ such that $y \notin (x)$ and $\mathfrak{m}y
\subset (x)$. In particular, $y/x \in K(R) - R$, but
\[ (y/x) \mathfrak{m} \subset R.  \]
There are two cases:
\begin{enumerate}
\item Suppose $(y/x) \mathfrak{m}  = R$. Then we can write $\mathfrak{m} =
R(x/y)$. So $\mathfrak{m}$ is principal. (This argument shows that $x/y \in R$.)	
\item The other possibility is that $y/x \mathfrak{m} \subsetneq R$. In this
case, $(y/x)\mathfrak{m}$ is an ideal, so
\[ (y/x) \mathfrak{m} \subset \mathfrak{m}.  \]
In particular, multiplication by $y/x$ carries $\mathfrak{m}$ to itself, and
stabilizes the finitely generated \emph{faithful} module
$\mathfrak{m}$. By \cref{thirdintegralitycriterion}, we see that
$y/x$ is integral over $R$. In particular, we find that $y/x \in R$, as $R$
was integrally closed, a contradiction as $y \notin (x)$.
\end{enumerate}
\end{proof}

Let us give several examples of DVRs.
\begin{example}
The localization $\mathbb{Z}_{(p)}$ at any prime ideal $(p) \neq 0$ is a DVR.
The associated valuation is the $p$-adic valuation.
\end{example}

\begin{example}
Although we shall not prove (or define) this, the local ring of an
algebraic curve at a smooth point is a DVR. The associated valuation  measures the
extent to which a function (or germ thereof) has a zero (or pole) at  that
point.
\end{example}

\begin{example}
The formal power series ring $\mathbb{C}[[T]]$ is a discrete valuation ring,
with maximal ideal $(T)$.
\end{example}

\subsection{Another approach}

In the proof of \cref{DVRthm}, we freely used the notion of associated primes,
and thus some of the results of \cref{noetherian}.
However, we can avoid all that and give a more ``elementary approach,'' as in
\cite{CaFr67}.


Let us suppose that $R$ is an integrally closed, local noetherian domain of
dimension one. We shall prove that the maximal ideal $\mathfrak{m} \subset R$
is principal. This was the hard part of \cref{DVRthm}, and the only part
where we used associated primes earlier.
\begin{proof}
We will show that $\mathfrak{m}$ is principal, by showing it is \emph{invertible} (as will be seen below).   We divide the proof into steps:

\paragraph{Step one}
For a nonzero ideal $I \subset R$, let $I^{-1} := \{ x \in K(R): xI \subset R \}$,
where $K(R)$ is the quotient field of $R$.  Then clearly $I^{-1} \supset R$
and $I^{-1}$ is an $R$-module, but in general we cannot say that $I^{-1} \neq
R$ even if $I$ is proper.
Nevertheless, we claim that in the present situation, we have  \[
{\mathfrak{m}^{-1} \neq R.}\] This is the conclusion of Step one.

The proof runs across a familiar line: we show that any maximal element in the
set of ideals $I \subset R$ with $I^{-1} \neq R$ is prime.
The set of such ideals is nonempty: it contains   any $(a)$ for $a \in \mathfrak{m}$ (in which case $(a)^{-1} = Ra^{-1} \neq R$).
There must be a maximal element in this set of ideals by noetherianness, which
as we will see is prime; thus,  that maximal element must be $\mathfrak{m}$, which proves our claim.

So to fill in the missing link, we must prove:
\begin{lemma} If $S$ is a noetherian domain, any maximal element in the set of ideals $I \subset S$ with $I^{-1} \neq S$ is prime.
\end{lemma}

\begin{proof}
Let $J$ be a maximal element, and suppose we have $ab \in J$, with  $a,b \notin J$.  I claim that if $z \in J^{-1} - S$, then $za, zb \in J^{-1} - S$.  The $J^{-1}$ part follows since $J^{-1}$ is a $S$-module.

By symmetry it is enough to prove the other half for $a$, namely that $za \notin
S$; but then if $za \in S$, we would have $z( (a) + J ) \subset S$, which implies $ ( (a) + J)^{-1} \neq S$, contradiction, for $J$ was maximal.

Then it follows that $z(ab) = (za) b \in J^{-1} - S$, by applying the claim  just made twice.  But $ab \in J$, so $z(ab) \in S$, contradiction.
\end{proof}



\paragraph{Step two} In the previous step, we have established that
$\mathfrak{m}^{-1} \neq R$.

We now claim that $\mathfrak{m}\mathfrak{m}^{-1} = R$.  First, we know of course
that $\mathfrak{m}\mathfrak{m}^{-1} \subset R$ by definition of inverses,
and equally $\mathfrak{m} \subset \mathfrak{m}\mathfrak{m}^{-1}$ too.  So $\mathfrak{m}\mathfrak{m}^{-1}$ is an ideal sandwiched between $\mathfrak{m}$ and $R$.
Thus we only need to prove that $\mathfrak{m} \mathfrak{m}^{-1} = \mathfrak{m}$
is impossible.  If this were the case, we could choose some $a \in
\mathfrak{m}^{-1} - R$ which must satisfy $a \mathfrak{m} \subset \mathfrak{m}$.
Then $a$ would integral over $R$.
As $R$ is integrally closed, this is impossible.

\paragraph{Step three}

Finally, we  claim that $\mathfrak{m}$ is principal, which is the final step of
the proof.
In fact, let us prove a more general claim.

\begin{proposition}
Let $(R, \mathfrak{m})$ be a local noetherian domain such that $\mathfrak{m}
\mathfrak{m}^{-1} = R$. Then $\mathfrak{m}$ is principal.
\end{proposition}
\begin{proof}
Indeed, since $\mathfrak{m} \mathfrak{m}^{-1} = R$, write
\[ 1 = \sum m_i n_i, \quad m_i \in \mathfrak{m}, \ n_i \in \mathfrak{m}^{-1}.\]
At least one $m_j n_j$ is invertible, since $R$ is local.
It follows that there are $x \in \mathfrak{m}$ and $y \in \mathfrak{m}^{-1}$
whose product $xy$ is a unit in $R$.
We may even assume $xy = 1$.

Then we claim $\mathfrak{m} = (x)$.
Indeed, we need only prove $\mathfrak{m} \subset (x)$.  For this, if $q \in
\mathfrak{m}$, then $qy \in R$ by definition of $\mathfrak{m}^{-1}$, so  \[ q =
x(qy)  \in ( x).\]
\end{proof}

\end{proof}

So we are done in this case too.  Taking stock, we have an effective way to say whether a ring is a DVR.  These three conditions are much easier to check in practice (noetherianness is usually easy, integral closure is usually automatic, and the last one is not too hard either for reasons that will follow) than the existence of an absolute value.


\section{Dedekind rings}

\subsection{Definition}
We now introduce a closely related notion.
\begin{definition}
A \textbf{Dedekind ring} is a noetherian domain $R$ such that
\begin{enumerate}
\item $R$ is integrally closed.
\item Every nonzero prime ideal of $R$ is maximal.
\end{enumerate}
\end{definition}


\begin{remark}
If $R$ is Dedekind, then any nonzero element is height one. This is evident
since every nonzero prime is maximal.

If $R$ is Dedekind, then $R$ is locally factorial. In fact, the localization of
$R$ at a nonzero prime $\mathfrak{p}$ is a DVR.
\begin{proof}
$R_{\mathfrak{p}}$ has precisely two prime ideals: $(0)$ and
$\mathfrak{p}R_{\mathfrak{p}}$. As a localization of an integrally closed
domain, it is integrally closed. So $R_{\mathfrak{p}}$ is a DVR by the above
result (hence
factorial).
\end{proof}
\end{remark}


Assume $R$ is Dedekind now.
We have an exact sequence
\[ 0 \to R^* \to K(R)^* \to \cart(R) \to \pic(R) \to 0.  \]
Here $\cart(R) \simeq \weil(R)$. But $\weil(R)$ is free on the nonzero
primes, or equivalently maximal ideals, $R$ being Dedekind.
In fact, however, $\cart(R)$ has a simpler description.

\begin{proposition}
Suppose $R$ is Dedekind. Then $\cart(R)$ consists of all nonzero finitely generated
submodules of $K(R)$ (i.e. \textbf{fractional ideals}).
\end{proposition}

This is the same thing as saying as every nonzero finitely generated submodule of $K(R)$ is
invertible.
\begin{proof}
Suppose $M \subset K(R)$ is nonzero and finitely generated It suffices to check that $M$ is
invertible after localizing at every prime, i.e. that $M_{\mathfrak{p}}$ is
an invertible---or equivalently, trivial, $R_{\mathfrak{p}}$-module. At the
zero prime, there is nothing to check. We might as well assume that
$\mathfrak{p}$ is maximal. Then $R_{\mathfrak{p}}$ is a DVR and
$M_{\mathfrak{p}}$ is a finitely generated submodule of $K(R_{\mathfrak{p}}) = K(R)$.

Let $S$ be the set of integers $n$ such that there exists $ x \in
M_{\mathfrak{p}}$ with $v(x) = n$, for $v$ the valuation of $R_{\mathfrak{p}}$.
By finite generation of $M$, $S$ is bounded below. Thus $S$ has a least element
$k$. There is an element of $M_{\mathfrak{p}}$, call it $x$, with valuation $k$.

It is easy to check that $M_{\mathfrak{p}}$ is generated by $x$, and is in fact free with
generator $x$. The reason is simply that $x$ has the smallest valuation of
anything in $M_{\mathfrak{p}}$.
\end{proof}

What's the upshot of this?

\begin{theorem}
If $R$ is a Dedekind ring, then any nonzero ideal $I \subset R$ is invertible,
and therefore uniquely described as a product of powers of (nonzero) prime ideals, $I =
\prod \mathfrak{p}_i^{n_i}$.
\end{theorem}
\begin{proof}
This is simply because $I$ is in $\cart(R) = \weil(R)$ by the above result.
\end{proof}

This is Dedekind's generalization of unique factorization.

We now give the standard examples:
\begin{example}
\begin{enumerate}
\item Any PID (in particular, any DVR) is Dedekind.
\item If $K$ is a finite extension of $\mathbb{Q}$, and set $R $ to be the
integral closure of $\mathbb{Z}$ in $K$, then $R$ is a Dedekind ring. The ring
of integers in any number field is a Dedekind ring.
\item If $R$ is the coordinate ring of an algebraic variety which is smooth and
irreducible of dimension one, then $R$ is Dedekind.
\item  Let $X$ be a compact Riemann surface, and let $S \subset X$ be a
nonempty finite subset. Then the ring of meromorphic functions on $X$ with
poles only in $S$ is
Dedekind. The maximal ideals in this ring are precisely those corresponding to
points of $X-S$.
\end{enumerate}
\end{example}



\subsection{A more elementary approach}

We would now like to give  a more elementary approach to the unique
factorization of ideals in Dedekind domains, one which does not use the heavy
machinery of Weil and Cartier divisors.

In particular, we can encapsulate what has already been proved as:
\begin{theorem} Let $A$ be a Dedekind domain with quotient field $K$. Then there is a bijection between the discrete valuations of $K$ that assign nonnegative orders to elements of $A$ and the nonzero prime ideals of $A$.
\end{theorem}
\begin{proof} Indeed, every valuation gives a prime ideal of elements of positive order; every prime ideal $\mathfrak{p}$ gives a discrete valuation on $A_{\mathfrak{p}}$, hence on $K$. \end{proof}


This result, however trivial to prove, is the main reason we can work essentially interchangeably with prime ideals in Dedekind domains and discrete valuations.

Now assume  $A$ is Dedekind. A finitely generated $A$-submodule of the quotient field $F$ is called a \textbf{fractional ideal}; by multiplying by some element of $A$, we can always pull a fractional ideal into $A$, when it becomes an ordinary ideal.  The sum and product of two fractional ideals are fractional ideals.

\begin{theorem}[Invertibility]  If $I$ is a nonzero fractional ideal and $ I^{-1} := \{ x \in F: xI \subset A \}$, then $I^{-1}$ is a fractional ideal and $I I^{-1} = A$.
\end{theorem}

Thus, the nonzero fractional ideals are an \emph{abelian group} under multiplication.

\begin{proof}
To see this, note that invertibility is preserved under localization: for a multiplicative set $S$, we have $S^{-1} ( I^{-1} ) = (S^{-1} I)^{-1}$, where the second ideal inverse is with respect to $S^{-1}A$; this follows from the fact that $I$ is finitely generated.  Note also that invertibility is true for discrete valuation rings: this is because the only ideals are principal, and principal ideals (in any integral domain) are obviously invertible.

So for all primes $\mathfrak{p}$, we have $(I I^{-1})_{\mathfrak{p}} = A_{\mathfrak{p}}$, which means the inclusion of $A$-modules $I I^{-1} \to A$ is an isomorphism at each localization.  Therefore it is an isomorphism, by general algebra.
\end{proof}

The next result says we have unique factorization of \textbf{ideals}:
\begin{theorem}[Factorization] Each ideal $I \subset A$ can be written uniquely as a product of powers of prime ideals.
\end{theorem}
\begin{proof}
Let's use the pseudo-inductive argument to obtain existence of a prime factorization.  Let $I$ be the maximal ideal which can't be written in such a manner, which exists since $A$ is Noetherian.  Then $I$ isn't prime (evidently), so it's contained in some prime $\mathfrak{p}$.  But $I = (I\mathfrak{p}^{-1})\mathfrak{p}$, and $I\mathfrak{p}^{-1} \neq I$ can be written as a product of primes, by the inductive assumption. Whence so can $I$, contradiction.

Uniqueness of factorization follows by localizing at each prime.
\end{proof}

\begin{definition} Let $P$ be the subgroup of nonzero principal ideals in the group $I$ of nonzero ideals.  The quotient $I/P$ is called the \textbf{ideal class group}.
\end{definition}

The ideal class group of the integers, for instance (or any principal ideal domain) is clearly trivial.  In general, this is not the case, because Dedekind domains do not generally admit unique factorization.
\begin{proposition} Let $A$ be a Dedekind domain. Then $A$ is a UFD if and only if its ideal class group is trivial.
\end{proposition}
\begin{proof} If the ideal class group is trivial, then $A$ is a principal ideal domain, hence a UFD by elementary algebra.  Conversely, suppose $A$ admits unique factorization.
Then, by the following lemma, every prime ideal is principal.  Hence every ideal is principal, in view of the unique factorization of ideals.
\end{proof}
\begin{lemma} Let $R$ be a UFD, and let $\mathfrak{p}$ be a prime ideal which contains no proper prime sub-ideal except for $0$.  Then $\mathfrak{p}$ is principal.
\end{lemma}
The converse holds as well; a domain is a UFD if and only if every prime ideal
of height one is principal, by \rref{heightonefactoriality}.
\begin{proof}
First, $\mathfrak{p}$ contains an element $x \neq 0$, which we factor into irreducibles $\pi_1 \dots \pi_k$.  One of these, say $\pi_j$, belongs to $\mathfrak{p}$, so $\mathfrak{p} \supset (\pi_j)$. Since $\mathfrak{p}$ is minimal among nonzero prime ideals, we have $\mathfrak{p} = (\pi_j)$.  (Note that $(\pi_j)$ is prime by unique factorization.)
\end{proof}

\begin{exercise}
This exercise is from \cite{Li02}. If $A$ is the integral closure of
$\mathbb{Z}$ in a number field (so that $A$ is a Dedekind domain), then it is
known (cf. \cite{La94} for a proof) that the ideal class group of $A$ is
\emph{finite}. From this, show that every open subset of $\spec A$ is a
principal open set $D(f)$. Scheme-theoretically, this means that every open
subscheme of $\spec A$ is affine (which is not true for general rings).
\end{exercise}

\subsection{Modules over Dedekind domains}

Let us now consider some properties of Dedekind domains.

\begin{proposition} Let $A$ be a Dedekind domain, and let $M$ be a finitely generated $A$ module. Then
$M$ is projective (or equivalently flat, or locally free) if and only if it is torsion-free.
\label{Dedekind means projective=tors free}
\end{proposition}
\begin{proof}
If $M$ is projective, then it is a direct summand of a free module, so it is torsion-free. So we need to show that if $M$ is torsion-free, then it is projective. Recall that to show $M$ is projective, it suffices to show that $M_\mathfrak{p}$ is projective for any prime $\mathfrak{p} \subset M$. But note that $A_\mathfrak{p}$ is a PID so a module over it is torsion free if and only if it is flat, by Lemma \ref{PID means flat=tors free}. However, it is also a local Noetherian ring, so a module is flat if and only if it is projective. So $M_\mathfrak{p}$ is projective if and only if it is torsion-free, so it now suffices to show that it is torsion-free.

However for any multiplicative set $S \subset A$, if $M$ is torsion-free then $M_S$ is also torsion-free. This is because if
\[\frac{a}{s'} \cdot \frac{m}{s}=0\]
then there is $t$ such that $tam=0$,
as desired.
\end{proof}

\begin{proposition}
Let $A$ be a Dedekind domain. Then any finitely generated module $M$ over it has (not canonically) a decomposition $M=M^{tors} \oplus M^{tors-free}$.
\end{proposition}
\begin{proof}
Note that by Lemma \ref{tors tors-free ses}, we have a short exact sequence
\[ 0 \to M^{tors} \to M \to M^{tors-free} \to 0\]
but by proposition \ref{Dedekind means projective=tors free} the torsion free part is projective, so $M$ can be split, not necessarily canonically as  $M^{tors} \oplus M^{tors-free}$, as desired.
\end{proof}

Note that we may give further information about the torsion free part of the module:
\[M^{tors}=\bigoplus_{\mathfrak{p}} M_{\mathfrak{p}}^{tors}\]
First note that there is a map
\[M^{tors} \to \bigoplus_{\mathfrak{p}} M_{\mathfrak{p}}^{tors}\]
because $M$ is torsion, every element is supported at finitely many points, so the image of $f$ in $M^{tors}_\mathfrak{p}$ is only nonzero for finitely many $\mathfrak{p}$.
It is an isomorphism, because it is an isomorphism after every localization.

So we have pretty much specified what the torsion part is. We can in fact also classify the torsion free part;  in particular, we have
\[M^{tors-free} \simeq \oplus \mathcal{L}\]
where $\mathcal{L}$ are locally free modules of rank 1.
This is because we know from above that the torsion free module is projective, we may apply Problem Set 10, Problem 12, and then since $L$ is a line bundle, and $I_{-D}$ is also, $L \otimes I_{-D}$ is a line bundle, and then $M/L \otimes I_{-D}$ is flat, so it is projective, so we may split it off.



\begin{lemma} For $A$ a Dedekind Domain, and $I \subset A$ an ideal, then $I$ is a locally free module of rank 1.
\end{lemma}
\begin{proof}
First note that $I$ is torsion-free and therefore projective by \ref{Dedekind means projective=tors free}, and it is also finitely generated, because $A$ is Noetherian. But for a finitely generated module over a Noetherian ring, we know that it is projective if and only if it is locally free, so we have shown that it is locally free.

Also recall that for a module which is locally free, the rank is well defined,
i.e, any localization which makes it free makes it free of the same rank. So
to test the rank, it suffices to show that if we tensor with the field of
fractions $K$, it is free of rank 1. But note that since $K$, being a localization of $A$ is flat over $A$ so we have short exact sequence
\[0 \to I \otimes_A K \to A \otimes_A K \to (A/I) \otimes_A K \to 0\]

However, note that $\supp(A/I)=V(\Ann(A/I))=V(I)$, and the prime $(0)$ is not
in $V(I)$, so $A/I \otimes_{A} K$, which is the localization of $A/I$ at $(0)$ vanishes, so we have
\[I\otimes_A K \simeq A\otimes_A K\]
but this is one-dimensional as a free $K$ module, so the rank is 1, as desired.
\end{proof}

We close by listing a collection of useful facts about Dedekind domains.
 \underline{A dozen things every Good Algebraist should know about Dedekind domains}. $R$
 is a Dedekind domain.
 \begin{enumerate}
   \item $R$ is local $\Longleftrightarrow$ $R$ is a field or a DVR.
   \item $R$ semi-local $\Longrightarrow$ it is a PID.
   \item $R$ is a PID $\Longleftrightarrow$ it is a UFD $\Longleftrightarrow$ $C(R)=\{1\}$
   \item $R$ is the full ring of integers of a number field $K$ $\Longrightarrow$ $|C(R)|<
   \infty$, and this number is the \emph{class number} of $K$.
   \item $C(R)$ can be any abelian group. This is Clayborn's Theorem.
   \item For any non-zero prime $\mathfrak{p}\in \spec R$, $\mathfrak{p}^n/\mathfrak{p}^{n+1}\cong R/\mathfrak{p}$ as an
   $R$-module.
   \item ``To contain is to divide'', i.e.~if $A,B\subset R$, then $A\subset B$
   $\Longleftrightarrow$ $A=BC$ for some $C\subset R$.
   \item (Generation of ideals) Every non-zero ideal $B\subset R$ is generated by two elements.
   Moreover, one of the generators can be taken to be any non-zero element of $B$.
   \item (Factor rings) If $A\subset R$ is non-zero, then $R/A$ is a PIR
	(\textbf{principal ideal ring}).
   \item (Steinitz Isomorphism Theorem) If $A,B\subset R$ are non-zero ideals, then $A\oplus
   B\cong {}_RR\oplus AB$ as $R$-modules.
   \item If $M$ is a finitely generated torsion-free $R$-module of rank $n$,\footnote{The
   rank is defined as $rk(M)=\dim_{K(R)} M\otimes_R K(R)$ where $K(R)$ is the
	quotient field.} then it is of the
   form $M\cong R^{n-1}\oplus A$, where $A$ is a non-zero ideal, determined up to
   isomorphism.
   \item If $M$ is a finitely generated torsion $R$-module, then $M$ is uniquely of the
   form $M\cong R/A_1\oplus
   \cdots \oplus R/A_n$ with $A_1\subsetneq A_2\subsetneq \cdots \subsetneq
   A_n\subsetneq R$.
    \end{enumerate}

\add{eventually, proofs of these should be added}

\section{Extensions}


In this section, we will essentially consider the following question: if $A$
is a Dedekind domain, and $L$ a finite extension of the quotient field of $A$,
is the integral closure of $A$ in $L$ a Dedekind domain? The general answer
turns out to be yes, but the result is somewhat simpler for the case of a
separable extension, with which we begin.

\subsection{Integral closure in a finite separable extension}

One of the reasons Dedekind domains are so important is
\begin{theorem} \label{intclosdedekind} Let $A$ be a Dedekind domain with quotient field $K$, $L$ a finite separable extension of $K$, and $B$ the integral closure of $A$ in $L$.  Then $B$ is Dedekind.
\end{theorem}

This can be generalized to the Krull-Akizuki theorem below (\cref{}).

First let us give an alternate definition of ``separable''.
For a finite field extension $k'$ of $k$, we may consider the bilinear pairing
$k' \otimes_k k' \to k$ given by $x,y \mapsto \Tr_{k'/k}(xy)$. Which is to say $xy \in k'$ can be seen as a $k$-linear map of finite dimensional vector spaces $k' \to k'$, and we are considering the trace of this map. Then we claim that $k'$ is separable if and only if the bilinear pairing $k' \times k' \to k$ is non-degenerate.

To show the above claim, first note that the pairing is non-degenerate if and
only if it is non-degenerate after tensoring with the algebraic closure. This
is because if $\Tr(xy)=0$ for all $y \in k'$, then $\Tr((x\otimes
1_{\overline{k}})y)=0$ for all $y \in k' \otimes_k \overline{k}$, which we may see to be true by decomposing into pure tensors. The other direction is obtained by selecting a basis of $\overline{k}$ over $k$, and then noting that for $y_i$ basis elements, if $\Tr(\sum x y_i)=0$ then $\Tr(xy_i)=0$ for each $i$.

So now we just need to show that $X=k'  \otimes_k \overline{k}$ is reduced if
and only if the map $X \otimes_{\overline{k}} X \to \overline{k}$ given by $a \otimes b \mapsto \Tr(ab)$ is non-degenerate. To do this, we show that elements of the kernel of the bilinear map are exactly the nilpotents. But note that $X$ is a finite dimensional algebra over $\overline{k}$, and we may elements as matrices. Then if $\Tr(AB)=0$ for all $B$ if and only if $\Tr(PAP^{-1}PBP^{-1})=0$ for all $B$, so we may assume $A$ is in Upper Triangular Form. From this, the claim becomes clear.


\begin{proof}  We need to check that $B$ is Noetherian, integrally, closed, and of dimension 1.

\begin{itemize}
\item Noetherian.  Indeed, $B$ is a finitely generated $A$-module, which
obviously implies Noetherianness. To see this, note that the $K$-linear map
$(.,.): L \times L \to K$, $a,b \to \mathrm{Tr}(ab)$ is nondegenerate since
$L$ is separable over $K$ (\rref{}).  Let $F \subset B$ be a free module spanned by a $K$-basis for $L$.  Then since traces preserve integrality and $A$ is integrally closed, we have $B \subset F^*$, where $F^* := \{ x \in K: (x,F) \subset A \}$.  Now $F^*$ is $A$-free on the dual basis of $F$ though, so $B$ is a submodule of a finitely generated $A$ module, hence a finitely generated $A$-module.
\item Integrally closed.  $B$ is the integral closure of $A$ in $L$, so it
is integrally closed (integrality being transitive).
\item Dimension 1.  Indeed, if $A \subset B$ is an integral extension of
domains, then $\dim A = \dim B$. This follows essentially from the theorems of
``lying over'' and ``going up.'' Cf. \cite{Ei95}.
\end{itemize}

So, consequently the ring of algebraic integers (integral over $\mathbb{Z}$) in a number field (finite extension of $\mathbb{Q}$) is Dedekind.
\end{proof}



Note that the above proof actually implied (by the argument about traces) the following useful fact:
\begin{proposition}\label{intclosurefgen} Let $A$ be a noetherian integrally closed domain with quotient field $K$.  Let $L$ be a finite separable extension and $B$ the ring of integers. Then $B$ is a finitely generated $A$-module.
\end{proposition}

We shall give another, more explicit proof of \rref{intclosurefgen} whose technique will be useful in the sequel.
Let $\alpha  \in B$ be a generator of $L/K$.  Let $n=[L:K]$ and $\sigma_1, \dots, \sigma_n$ the distinct embeddings of $L$ into the algebraic closure of $K$.
Define the \textbf{discriminant} of $\alpha$ to be
\[ D(\alpha) = \left(\det \begin{bmatrix}
1 & \sigma_1\alpha & (\sigma_1 \alpha)^2 & \dots \\
1 & \sigma_2\alpha & (\sigma_2 \alpha)^2 & \dots \\
\vdots & \vdots & \vdots & \ddots \end{bmatrix}\right)^2 .\]
This maps to the same element under each $\sigma_i$, so is in $K^*$ (and even
$A^*$ by integrality); it is nonzero by basic facts about vanderMonde
determinants since each $\sigma_i$ maps $\alpha$ to a different element.  The  next lemma clearly implies that $B$ is contained in a finitely generated $A$-module, hence is finitely generated (since $A$ is noetherian).
\begin{lemma} We have $B \subset D(\alpha)^{-1} A[\alpha]$.
\end{lemma}
\begin{proof}
Indeed, suppose $x \in B$.  We can write $x = c_0 (1) + c_1 (\alpha) + \dots c_{n-1}(\alpha^{n-1})$ where each $c_i \in K$.  We will show that in fact, each $c_i \in D(\alpha)^{-1}A$, which will prove the lemma.  Applying each $\sigma_i$, we have for each $i$, $\sigma_i x = c_0 (1) + c_1 (\sigma_i \alpha) + \dots + c_{n-1} ( \sigma_i \alpha^{n-1})$.
Now by Cramer's lemma, each $c_i$ can be written as a quotient of determinants of matrices involving $\sigma_jx $ and the $\alpha^{j}$.  The denominator determinant is in fact $D(\alpha)$.  The numerator is in $K$ and must be integral, hence is in $A$.  This proves the claim and the lemma.
\end{proof}

The above technique may be illustrated with an example.
\begin{example} Let $p^i$ be a power of a prime $p$ and consider the extension
$\mathbb{Q}(\zeta_{p^i})/\mathbb{Q}$ for $\zeta_{p^i}$ a primitive $p^i$-th
root of unity.  This is a special case of a cyclotomic extension, an important
example in the subject.  We claim that the ring of integers (that is, the
integral closure of $\mathbb{Z}$)
in $\mathbb{Q}(\zeta_{p^i})$ is precisely $\mathbb{Z}[\zeta_{p^i}]$.  This is true in fact for all cyclotomic extensions, but we will not be able to prove it here.

First of all, $\zeta_{p^i}$ satisfies the equation $X^{p^{i-1}(p-1)} +
X^{p^{i-1}(p-2)} + \dots + 1 = 0$.  This is because if $\zeta_p$ is a $p$-th
root of unity, $(\zeta_p-1)(1+\zeta_p + \dots + \zeta_p^{p-1}) = \zeta_p^p - 1 =
0$.  In particular, $X - \zeta_{p^i} \mid X^{p^{i-1}(p-1)} +
X^{p^{i-1}(p-2)} + \dots + 1 $, and consequently (taking $X=1$), we find that
$1 - \zeta_{p^i}$ divides $p$ in the ring of integers in
$\mathbb{Q}(\zeta_{p^i})/\mathbb{Q}$.  This is true for \emph{any} primitive
$p^i$-th root of unity for \emph{any} $p^i$.  Thus the norm to $\mathbb{Q}$ of $1 - \zeta_{p^i}^j$ for any $j$ is a power of $p$.

I claim that this implies that the discriminant $D(\zeta_{p^i})$ is a power of
$p$, up to sign. But by the vanderMonde formula, this discriminant is a
product of terms of the form $\prod (1 - \zeta_{p^i}^{j})$ up to roots of
unity.  The norm to $\mathbb{Q}$ of each factor is thus a power of $p$, and the discriminant itself plus or minus a power of $p$.

By the lemma, it follows that the ring of integers is contained in
$\mathbb{Z}[p^{-1}, \zeta_{p^i}]$. To get down further to
$\mathbb{Z}[\zeta_{p^i}]$ requires a bit more work. \add{this proof}
\end{example}


\subsection{The Krull-Akizuki theorem}

We are now going to prove a general theorem that will allow us to remove the
separability hypothesis in \cref{}. Let us say that a noetherian domain has
\textbf{dimension at most one} if every nonzero prime ideal is maximal; we shall later
generalize this notion of ``dimension.''

\begin{theorem}[Krull-Akizuki] Suppose $A$ is a noetherian domain of dimension
at most one. Let $L$ be a finite extension of the quotient field $K(A)$, and suppose
$B \subset L$ is a domain containing $A$. Then $B$ is noetherian of  dimension
at most one.
\end{theorem}


From this, it is clear:

\begin{theorem}
The integral closure of a Dedekind domain in any finite extension of the
quotient field is a Dedekind domain.
\end{theorem}
\begin{proof}
Indeed, by Krull-Akizuki, this integral closure is noetherian and of dimension
$\leq 1$; it is obviously integrally closed as well, hence a Dedekind domain.
\end{proof}

Now let us prove Krull-Akizuki.
\add{we need to introduce material about length}
\begin{proof}
We are going to show that for any $a \in A - \left\{0\right\}$, the $A$-module
$B/a B$ has finite length. (This is quite nontrivial, since $B$ need not even
be finitely \emph{generated} as an $A$-module.)
From this it will be relatively easy to deduce the result.

Indeed, if $I \subset B$ is any nonzero ideal, then $I$ contains a nonzero  element of $A$; to
see this, we need only choose an element $b \in I$ and consider an irreducible polynomial
\[ a_0 X^n + \dots + a_n  \in K[X]  \]
that it satisfies. We can assume that all the $a_i \in A$ by clearing
denominators. It then follows that $a_n \in A \cap I$.
So choose some $a \in (A \cap I) - \left\{0\right\}$.
We then know by the previous paragraph (though we have not proved it yet) that
$B/aB$ has finite length as an $A$-module (and a fortiori as a $B$-module); in
particular, the submodule $I/aB$ is finitely generated as a
$B$-module. The
exact sequence
\[ 0 \to a B \to I \to I/aB \to 0  \]
shows that $I$ must be finitely generated as a $B$-module, since the two outer
terms are.
Thus any ideal of $B$ is finitely generated, so $B$ is noetherian.

\add{$B$ has dimension at most one}

To prove the Krull-Akizuki theorem, we are going to prove:
\begin{lemma}[Finite length lemma]
If $A$ is a noetherian domain of dimension at most one, then for any
torsion-free
$A$-module $M$ such that $K(A) \otimes_A M$ is finite-dimensional
(alternatively: $M$ has finite rank) and $a \neq 0$, $M/aM$ has finite length.
\end{lemma}
\begin{proof}
We are going to prove something stronger. If $M$ has rank $n$ and is
torsion-free, then will show
\begin{equation} \label{boundka} \ell(M/aM) \leq n \ell(A/aA).   \end{equation}
Note that $A/aA$ has finite length. This follows because there is a filtration of
$A/aA$ whose quotients are of the form $A/\mathfrak{p}$ for $\mathfrak{p}$
prime; but these $\mathfrak{p}$ cannot be zero as $A/aA$ is torsion. So these
primes are maximal, and $A/aA$ has a filtration whose quotients are
\emph{simple}. Thus $\ell(A/aA) < \infty$. In fact, we see thus that \emph{any
torsion, finitely-generated module has finite length}; this will be used in
the sequel.


There are two cases:
\begin{enumerate}
\item $M$ is finitely generated.
We can choose generators $m_1, \dots, m_n$ in $M$ of $K(A) \otimes_A M$; we
then from these generators get a map
\[ A^n \to M  \]
which becomes an isomorphism after localizing at $A - \left\{0\right\} $. In
particular, the kernel and cokernel are torsion modules. The kernel must be trivial
($A$ being a domain), and $A^n \to M$ is thus injective.
Thus we have found a finite free submodule $F \subset M$ such that $M/F$ is a
torsion module $T$, which is also finitely generated.



We have an exact sequence
\[ 0 \to F/(aM \cap F) \to M/aM \to T/aT \to 0.  \]
Here the former has length at most $\ell(F/aF) = n \ell(A/aA)$, and we get
the bound $\ell(M/aM) \leq n \ell(A/aA) + \ell(T/aT)$. However, we
have the annoying last term to contend with, which makes things somewhat
inconvenient. Thus, we use a trick: for each $t > 0$, we consider the exact
sequence
\[ 0 \to F/(a^tM \cap F) \to M/a^tM \to T/a^tT \to 0.  \]
This gives
\[ \ell(M/a^t M) \leq t n \ell(A/aA) + \ell(T/a^t T) \leq  t n \ell(A/aA) +
\ell(T). \]
However, $\ell(T) < \infty$ as $T$ is torsion (cf. the first paragraph).
If we divide by $t$, we get the inequality
\begin{equation} \label{almostboundka} \frac{1}{t} \ell(M/a^t M) \leq n
\ell(A/aA) + \frac{\ell(T)}{t}.  \end{equation}
However, the filtration $a^t M \subset a^{t-1}M \subset \dots \subset a M
\subset M$ whose quotients are all isomorphic to $M/aM$ ($M$ being
torsion-free) shows that $\ell(M/a^t M ) = t \ell(M/aM)$
In particular, letting $t \to \infty$ in \eqref{almostboundka} gives
\eqref{boundka} in the case where $M$ is finitely generated.
\item  $M$ is not finitely generated. Now we can use a rather cheeky argument.
$M$ is the inductive limit of its finitely generated submodules $M_F \subset
M$, each of which
is itself torsion free and of rank at most $n$. Thus $M/aM $ is the inductive limit
of its submodules $M_F/(aM \cap M_F)$ as $M_F$ ranges over
We know that $\ell(M_F/(aM \cap M_F)) \leq n \ell(A/aA)$ for each finitely
generated $M_F \subset M$ by the first case above (and the fact that
$M_F/(aM \cap M_F)$ is a quotient of $M_F/aM_F$).

But if $M/aM$ is the inductive limit of \emph{submodules} of length at most $n
\ell(A/aA)$, then it itself can have length at most $n \ell(A/aA)$. For $M/aM$
must be in fact equal to the submodule $M_F/(aM \cap M_F)$ that has the
largest length (no other submodule $M_{F'}/(aM \cap M_{F'})$ can properly
contain this).
\end{enumerate}


\end{proof}

With this lemma proved, it is now clear that Krull-Akizuki is proved as well.

\end{proof}

\subsection{Extensions of discrete valuations}

As a result, we find:
\begin{theorem}
Let $K$ be a field, $L$ a finite separable extension.  Then a discrete valuation on $K$ can be extended to one on $L$.
\end{theorem}
\add{This should be clarified --- what is a discrete valuation?}
\begin{proof}
Indeed, let $R \subset K$ be the ring of integers of the valuation, that is
the subset of elements of nonnegative valuation.  Then $R$ is a DVR, hence Dedekind, so the integral closure $S \subset L$ is Dedekind too (though in general it is not   a DVR---it may have several non-zero prime ideals) by \rref{intclosdedekind}.  Now as above, $S$ is a finitely generated $R$-module, so if $\mathfrak{m} \subset R$ is the maximal ideal, then
\[ \mathfrak{m} S \neq S \]
by Nakayama's lemma (cf. for instance \cite{Ei95}).  So $\mathfrak{m} S$ is contained in a maximal ideal $\mathfrak{M}$ of $S$ with, therefore, $\mathfrak{M} \cap R = \mathfrak{m}$.  (This is indeed the basic argument behind lying over, which I could have just invoked.) Now $S_{\mathfrak{M}} \supset R_{\mathfrak{m}}$ is a DVR as it is the localization of a Dedekind domain at a prime ideal, and one can appeal to \rref{niupmeansdvr}.  So there is a discrete valuation on $S_{\mathfrak{M}}$.  Restricted to $R$, it will be a power of the given $R$-valuation, because its value on a uniformizer $\pi$ is $<1$.  However, a power of a discrete valuation is a discrete valuation too.  So we can adjust the discrete valuation on $S_{\mathfrak{M}}$ if necessary to make it an extension.

This completes the proof.
\end{proof}

Note that there is a one-to-one correspondence between extensions of the valuation on $K$ and primes of $S$ lying above $\mathfrak{m}$.   Indeed, the above proof indicated a way of getting valuations on $L$ from primes of $S$.  For an extension of the valuation on $K$ to $L$, let $\mathfrak{M} := \{ x \in S: \left| x \right| < 1\}$.
\section{Action of the Galois group}

 Suppose we have an integral domain (we don't even have to assume it Dedekind) $A$ with quotient field $K$, a finite Galois extension $L/K$, with $B$ the integral closure in $L$.  Then the Galois group $G = G(L/K)$ acts on $B$; it preserves $B$ because it preserves equations in $A[X]$.
In particular, if $\mathfrak{P} \subset B$ is a prime ideal, so is $\sigma \mathfrak{P}$, and the set $\spec B$ of prime ideals in $B$ becomes a $G$-set.

\subsection{The orbits of the Galois group} It is of interest to determine the orbits; this question has  a very clean answer.

\begin{proposition} The orbits of $G$ on the prime ideals of $B$ are in bijection with the primes of $A$, where a prime ideal $\mathfrak{p} \subset A$ corresponds to the set of primes of $B$ lying over $A$.\footnote{It is useful to note here that the lying over theorem works for arbitrary integral extensions.}  Alternatively, any two primes $\mathfrak{P}, \mathfrak{Q} \subset B$ lying over $A$ are conjugate by some element of $G$.
\end{proposition}

In other words, under the natural map $\spec B \to \spec A =\spec B^G$, the latter space is the quotient under the action of $G$, while $A=B^G$ is the ring of invariants in $B$.\footnote{The reader who does not know about the $\spec$ of a ring can disregard these remarks.}

\begin{proof}
We need only prove the second statement.
Let $S$ be the multiplicative set $A - \mathfrak{p}$.  Then $S^{-1}B $ is the integral closure of $S^{-1}A$, and in $S^{-1}A = A_{\mathfrak{p}}$, the ideal $\mathfrak{p}$ is maximal.
Let $\mathfrak{Q}, \mathfrak{P}$ lie over $\mathfrak{p}$; then $S^{-1}\mathfrak{Q},S^{-1} \mathfrak{P}$  lie over $S^{-1}\mathfrak{p}$ and are maximal (to be added).  If we prove that $S^{-1} \mathfrak{Q}, S^{-1} \mathfrak{P}$ are conjugate under the Galois group, then $\mathfrak{Q}, \mathfrak{P}$ must also be conjugate by the properties of localization.  \emph{In particular, we can reduce to the case of $\mathfrak{p}, \mathfrak{Q}, \mathfrak{P}$ all maximal.}

The rest of the proof is now an application of the Chinese remainder theorem.  Suppose that, for all $\sigma \in G$, we have $\sigma \mathfrak{P} \neq \mathfrak{Q}$.  Then the ideals $\sigma \mathfrak{P}, \mathfrak{Q}$ are distinct maximal ideals, so by the remainder theorem, we can find $x \equiv 1 \mod \sigma \mathfrak{P}$ for all $\sigma \in G$ and $x \equiv  0 \mod \mathfrak{Q}$.
Now, consider the norm $N^L_K(x)$; the first condition implies that it is congruent to 1 modulo $\mathfrak{p}$.  But the second implies that  the norm is in $\mathfrak{Q} \cap K = \mathfrak{p}$, contradiction.
\end{proof}

\subsection{The decomposition and inertia groups}
Now, let's zoom in on a given prime $\mathfrak{p} \subset A$.  We know that $G$ acts transitively on the set $\mathfrak{P}_1, \dots, \mathfrak{P}_g$ of primes lying above $\mathfrak{p}$; in particular, there are at most $[L:K]$ of them.

\begin{definition} If $\mathfrak{P}$ is any one of the $\mathfrak{P}_i$, then the stabilizer in $G$ of this prime ideal is called the \textbf{decomposition group} $G_{\mathfrak{P}}$. \end{definition}
We have, clearly, $(G: G_{\mathfrak{P}}) = g$.

Now if $ \sigma \in G_{\mathfrak{P}}$, then $\sigma$ acts on the residue field $B/\mathfrak{P}$ while fixing the subfield $A/\mathfrak{p}$.  In this way, we get a homomorphism $\sigma \to \overline{\sigma}$ from $G$ into the automorphism group of $B/\mathfrak{P}$ over $A/\mathfrak{p})$ (we don't call it a Galois group because we don't yet know whether the extension is Galois).

The following result will be crucial in constructing the so-called ``Frobenius elements'' of crucial use in class field theory.

\begin{proposition} Suppose $A/\mathfrak{p}$ is perfect. Then $B/\mathfrak{P}$ is Galois over $A/\mathfrak{p}$, and the homomorphism $\sigma \to \overline{\sigma}$ is surjective from $G_{\mathfrak{P}} \to G(B/\mathfrak{P}/A/\mathfrak{p})$.
\end{proposition}
\begin{proof}
In this case, the extension $B/\mathfrak{P}/A/\mathfrak{p}$ is separable, and we can choose $\overline{x} \in B/\mathfrak{P}$ generating it by the primitive element theorem.  We will show that $\overline{x}$ satisfies a polynomial equation  $\overline{P}(X) \in A/\mathfrak{p}[X]$ all of whose roots lie in $B/\mathfrak{P}$, which will prove that the residue field extension is Galois.  Moreover, we will show that all the nonzero roots of $\overline{P}$ in $B/\mathfrak{P}$ are conjugates of $\overline{x}$ under elements of $G_{\mathfrak{P}}$.  This latter will imply surjectivity of the homomorphism $\sigma \to \overline{\sigma}$, because it shows that any conjugate of $\overline{x}$ under $G(B/\mathfrak{P}/A/\mathfrak{p})$ is a conjugate under $G_{\mathfrak{P}}$.

We now construct the aforementioned polynomial.   Let $x \in B$ lift $\overline{x}$.  Choose $y \in B$ such that $y \equiv x \mod \mathfrak{P}$ but $y \equiv 0 \mod \mathfrak{Q}$ for the other primes $\mathfrak{Q}$ lying over $\mathfrak{p}$.  We take $P(X) = \prod_{\sigma \in G} (X - \sigma(y)) \in A[X]$. Then the reduction $\overline{P}$ satisfies $\overline{P}(\overline{x})= \overline{P}(\overline{y}) = 0$, and $\overline{P}$ factors completely (via $\prod_{\sigma} (X - \overline{\sigma(t)})$) in $B/\mathfrak{P}[X]$.  This implies that the residue field extension is Galois, as already stated.
But it is also clear that the polynomial $\overline{P}(X)$ has roots of zero and $\sigma(\overline{y}) = \sigma(\overline{x})$ for $\sigma \in G_{\mathfrak{P}}$.  This completes the proof of the other assertion, and hence the proposition.
\end{proof}

\begin{definition}
The kernel of the map $\sigma \to \overline{\sigma}$ is called the \textbf{inertia
group} $T_{\mathfrak{P}}$.  Its fixed field is called the \textbf{inertia
field}.
\end{definition}

These groups will resurface significantly in the future.

\begin{remark} Although we shall never need this in the future, it is of
interest to see what happens when the extension $L/K$ is \emph{purely
inseparable}.\footnote{Cf. \cite{La02}, for instance.}  Suppose $A$ is integrally closed in $K$, and $B$ is the integral closure in $L$.  Let the characteristic be $p$, and the degree $[L:K] = p^i$.
In this case, $x \in B$  if and only if $x^{p^i} \in A$. Indeed, it is clear that the condition mentioned implies integrality.  Conversely, if $x$ is integral, then so is $x^{p^i}$, which belongs to $K$ (by basic facts about purely inseparable extensions).  Since $A$ is integrally closed, it follows that $x^{p^i} \in A$.

Let now $\mathfrak{p} \subset A$ be a prime ideal.  I claim that there is precisely one prime ideal $\mathfrak{P}$ of $B$ lying above $A$, and $\mathfrak{P}^{p^i} = \mathfrak{p}$.  Namely, this ideal consists of $x \in B$ with $x^{p^i} \in \mathfrak{p}$!  The proof is straightforward; if $\mathfrak{P}$ is \emph{any} prime ideal lying over $\mathfrak{p}$, then $x \in \mathfrak{P}$ iff $x^{p^i} \in L \cap \mathfrak{P} = \mathfrak{p}$.   In a terminology to be explained later, $\mathfrak{p}$ is \emph{totally ramified.}
\end{remark}



% ============================ chapters/dimension.tex}
\chapter{Dimension theory}

\label{chdimension}
\textbf{Dimension theory} assigns to each commutative ring---say,
noetherian---an invariant called the dimension. The most standard definition,
that of Krull dimension (which we shall not adopt at first), defines the
dimension in terms of the maximal lengths of ascending chains of prime ideals.
In general, however, the geometric intuition behind dimension is that it
should assign to an affine ring---say, one of the form $\mathbb{C}[x_1, \dots,
X_n]/I$---something like the ``topological dimension'' of the affine variety
in $\mathbb{C}^n$ cut out by the ideal $I$.

In this chapter, we shall obtain three different expressions for the dimension
of a noetherian local ring $(R, \mathfrak{m})$, each of which will be useful
at different times in proving results.

\section{The Hilbert function and the dimension of a local ring}
\subsection{Integer-valued polynomials}

It is now necessary to do a small amount of general algebra.

Let $P \in \mathbb{Q}[t]$. We consider the question of when $P$ maps the
integers $\mathbb{Z}$, or more generally the sufficiently large integers, into
$\mathbb{Z}$. Of course, any polynomial in $\mathbb{Z}[t]$ will do this, but
there are others: consider $\frac{1}{2}(t^2 -t)$, for instance.

\begin{proposition}\label{integervalued}
Let $P \in \mathbb{Q}[t]$. Then $P(m)$ is an integer for $m \gg 0$ integral if and only if
$P$ can be written in the form
\[ P(t) = \sum_n c_n \binom{t}{n}, \quad c_n \in \mathbb{Z}.  \]
In particular, $P(\mathbb{Z}) \subset \mathbb{Z}$.
\end{proposition}
So $P$ is a $\mathbb{Z}$-linear function of binomial coefficients.
\begin{proof}
Note that the set $\left\{\binom{t}{n}\right\}_{n \in \mathbb{Z}_{\geq 0}}$ forms a basis for the set of
polynomials $\mathbb{Q}[t]$. It is thus clear that $P(t)$ can be written as
a rational combination $\sum c_n \binom{t}{n}$ for the $c_n \in \mathbb{Q}$.
We need to argue that the $c_n \in \mathbb{Z}$ in fact.

Consider the operator $\Delta$ defined on functions $\mathbb{Z} \to
\mathbb{C}$ as follows:
\[( \Delta f)(m) = f(m) - f(m-1).  \]
It is obvious that if $f$ takes integer values for $m \gg 0$, then so does
$\Delta f$. It is also easy to check that $\Delta \binom{t}{n} =
\binom{t}{n-1}$.

By looking at the
function $\Delta P = \sum c_n \binom{t}{n-1}$ (which takes values in $\mathbb{Z}$), it is easy to see that the $c_n \in \mathbb{Z}$ by induction
on the degree.
It is also easy to see directly that the binomial coefficients take values in
$\mathbb{Z}$ at \emph{all} arguments.
\end{proof}



\subsection{Definition and examples}
Let $R$ be a   ring.
\begin{question}
What is a good definition for $\dim(R)$? Actually, more generally,
what is the dimension of $R$ at a given ``point'' (i.e. prime ideal)?
\end{question}

Geometrically, think of $\spec R$, for any ring; pick some point corresponding to a maximal
ideal $\mathfrak{m} \subset R$. We want to define the \textbf{dimension of $R$}
at $\mathfrak{m}$. This is to be thought of kind of like ``dimension over the
complex numbers,'' for algebraic varieties defined over $\mathbb{C}$. But it
should be purely algebraic.
What might you do?


Here  is an idea. For a topological space $X$ to be $n$-dimensional at $x \in
X$, there should be $n$ coordinates at the point $x$. In other words, the
point $x$ should be uniquely  defined
by the zero locus of $n$ points on the space.
Motivated by this, we could try defining $\dim_{\mathfrak{m}} R$
to be the number of generators of $\mathfrak{m}$.
However, this is a bad definition, as $\mathfrak{m}$ may not have the same number of
generators as $\mathfrak{m}R_{\mathfrak{m}}$. In other words, it is not a
truly \emph{local} definition.
\begin{example}
Let $R$ be a noetherian integrally closed domain which is not a UFD. Let $\mathfrak{p}
\subset R$ be a prime ideal which is minimal over a principal ideal but which
is not itself principal. Then $\mathfrak{p}R_{\mathfrak{p}}$ is generated by
one element, as we will eventually see, but $\mathfrak{p}$ is not.
\end{example}

We want our definition of dimension to be
local.
So this leads us to:
\begin{definition}
If $R$ is a (noetherian) \emph{local} ring with maximal ideal $\mathfrak{m}$,
then the \textbf{embedding dimension} of $R$, denoted $\emdim R$ is
the minimal number of generators for $\mathfrak{m}$. If $R$ is a  noetherian
ring and $\mathfrak{p} \subset R$ a prime ideal, then the \textbf{embedding
dimension at $\mathfrak{p}$} is that of the local ring $R_{\mathfrak{p}}$.
\end{definition}

In the above definition, it is clearly sufficient to study what happens for
local rings, and we impose that restriction for now. By Nakayama's lemma, the
embedding dimension is the minimal number of generators of
$\mathfrak{m}/\mathfrak{m}^2$, or the $R/\mathfrak{m}$-dimension of that vector
space:
\[ \emdim R = \dim_{R/\mathfrak{m}} \mathfrak{m}/ \mathfrak{m}^2.  \]


In general, however, the embedding dimension is not going to coincide with the
intuitive ``geometric'' dimension of an algebraic
variety.

\begin{example}
Let $R = \mathbb{C}[t^2, t^3] \subset \mathbb{C}[t]$, which is the coordinate
ring of a cubic curve $y^2 =x^3$ as $R \simeq \mathbb{C}[x,y]/(x^2 - y^3)$
via $x = t^3, y = t^2$. Let us localize at the prime ideal $\mathfrak{p} = (t^2,
t^3)$: we get $R_{\mathfrak{p}}$.

Now $\spec R$ is singular at the origin. In fact, as a result, $\mathfrak{p}
R_{\mathfrak{p}} \subset R_{\mathfrak{p}}$ needs two generators, but the
variety it corresponds to is one-dimensional.
\end{example}

So the embedding dimension is the smallest dimension into which you can embed
$R$ into a smooth space.
But for singular varieties this is not the dimension we want.

So instead of considering simply $\mathfrak{m}/\mathfrak{m}^2$, let us
consider the \emph{sequence} of finite-dimensional vector spaces
\[ \mathfrak{m}^k/\mathfrak{m}^{k+1}.  \]
Computing these dimensions as a function of $k$ gives some invariant that describes the local
geometry of $\spec R$.

We shall eventually prove:
\begin{theorem} \label{hilbfnispolynomial}
Let $(R, \mathfrak{m})$ be a local noetherian ring. Then there exists a
polynomial
$f \in \mathbb{Q}[t]$ such that
\[ f(n) =  \ell(R/\mathfrak{m}^n) = \sum_{i=0}^{n-1} \dim
\mathfrak{m}^i/\mathfrak{m}^{i+1} \quad \forall n \gg 0.  \]

Moreover, $\deg f \leq \dim \mathfrak{m}/\mathfrak{m}^2$.
\end{theorem}


Note that this polynomial is well-defined, as any two polynomials agreeing for large $n$
coincide. Note also that $R/\mathfrak{m}^n$ is artinian so of finite length,
and that we have used the fact that the length is additive for short exact
sequences. We would have liked to write $\dim R/\mathfrak{m}^n$, but we can't,
in general, so we use the substitute of the length.

Based on this, we define:
\begin{definition}
The \textbf{dimension} of the local ring $R$ is the degree of the polynomial
$f$ above. For an arbitrary noetherian ring $R$, we define $\dim R =
\sup_{\mathfrak{p} \in \spec R} \dim (R_{\mathfrak{p}})$.
\end{definition}


Let us now do a few example computations.

\begin{example}[The affine line] \label{easydimcomputation}
\label{dimaffineline}
Consider the local ring $(R, \mathfrak{m}) = \mathbb{C}[t]_{(t)}$. Then $\mathfrak{m} = (t)$ and
$\mathfrak{m}^k/\mathfrak{m}^{k+1}$ is one-dimensional, generated by $t^k$. In
particular, the ring has dimension one.
\end{example}

\begin{example}[A singular curve] Consider $R = \mathbb{C}[t^2, t^3]_{(t^2, t^3)}$, the local ring of $y^2 = x^3$
at zero. Then $\mathfrak{m}^n$ is generated by $t^{2n}, t^{2n+1}, \dots$.
$\mathfrak{m}^{n+1}$ is generated by $t^{2n+2}, t^{2n+3}, \dots$. So the
quotients all have dimension two. The dimension of these quotients is a little
larger than in \rref{easydimcomputation}, but they do not grow. The ring still has dimension one.
\end{example}

\begin{example}[The affine plane] \label{dimaffineplane}
Consider $R = \mathbb{C}[x,y]_{(x,y)}$. Then $\mathfrak{m}^k$ is generated by
polynomials in $x,y$ that are homogeneous in degree $k$. So $\mathfrak{m}^k/\mathfrak{m}^{k+1}$
has dimensions that \emph{grow} linearly in $k$. This is a genuinely two-dimensional
example.
\end{example}

It is this difference between constant linear and quadratic growth in
$R/\mathfrak{m}^n$ as $n \to \infty$, and not the size of the initial terms,
that we want for our definition of dimension.

Let us now generalize \rref{dimaffineline} and \rref{dimaffineplane}
above to affine spaces of arbitrary dimension.
\begin{example}[Affine space]
Consider $R = \mathbb{C}[x_1, \dots, x_n]_{(x_1, \dots, x_n)}$.
This represents the variety $\mathbb{C}^n = \mathbb{A}^n_{\mathbb{C}}$ near the origin geometrically, so
it should intuitively have dimension $n$. Let us check that it does.

Namely, we need to compute the polynomial $f$ above. Here $R/\mathfrak{m}^k$ looks like the set of
polynomials of degree $<k$ over $\mathbb{C}$. The dimension as a vector space
of this is
given by some binomial coefficient $\binom{n+k-1}{n}$. This is a polynomial in
$k$ of degree $n$. In particular, $\ell(R/\mathfrak{m}^k)$ grows like $k^n$.
So $R$ is $n$-dimensional.
\end{example}


Finally, we offer one more example, showing that DVRs have dimension one. In
fact, among noetherian integrally closed local domains, DVRs are
\emph{characterized} by this property (\rref{} of \rref{}).

\begin{example}[The dimension of a DVR]
Let $R$ be a DVR. Then $\mathfrak{m}^k/\mathfrak{m}^{k+1}$ is of length one for
each $k$. So $R/\mathfrak{m}^k$ has length $k$. Thus we can take $f(t) = t$, so
$R$ has dimension one.
\end{example}

\subsection{The Hilbert function is a polynomial}

While we have given a definition of dimension and computed various examples,
we have yet to check that our definition is well-defined.
Namely, we have to prove \rref{hilbfnispolynomial}.

\begin{proof}[Proof of  \rref{hilbfnispolynomial}]
Fix a noetherian local ring $(R, \mathfrak{m})$. We are to show that
$\ell(R/\mathfrak{m}^n)$ is a polynomial for $n \gg 0$. We also have to bound
this degree by $\dim_{R/\mathfrak{m}} \mathfrak{m}/\mathfrak{m}^2$, the
embedding dimension. We will do this by reducing to a general fact about
graded modules over a polynomial ring.

Let $S = \bigoplus_n  \mathfrak{m}^n/\mathfrak{m}^{n+1}$. Then $S$ has a
natural grading, and in fact it is a graded ring in a natural way from the
multiplication map
\[ \mathfrak{m}^{n_1} \times \mathfrak{m}^{n_2} \to \mathfrak{m}^{n_1 + n_2}.  \]
In fact, $S$ is the \emph{associated graded ring} of the $\mathfrak{m}$-adic filtration.
Note that $S_0 = R/\mathfrak{m}$ is a field, which we will denote by  $k$.
So $S$ is a graded $k$-algebra.

\begin{lemma}
$S$ is a finitely generated $k$-algebra. In fact, $S$ can be generated by at
most $\emdim(R)$ elements.
\end{lemma}
\begin{proof}
Let $x_1, \dots, x_r$ be generators for $\mathfrak{m} $ with $r = \emdim(R)$.
They  (or rather, their images) are thus a $k$-basis
for $\mathfrak{m}/\mathfrak{m}^2$.
Then their images in $\mathfrak{m}/\mathfrak{m}^2 \subset S$ generate $S$.
This follows because $S_1$ generates $S$ as an $S_0$-algebra: the products of
the elements in $\mathfrak{m}$ generate the higher powers of $\mathfrak{m}$.
\end{proof}

So $S$ is a graded quotient of the polynomial ring $k[t_1, \dots, t_r]$, with
$t_i $ mapping to $x_i$. In particular, $S$ is a finitely generated, graded $k[t_1,
\dots, t_r]$-module.
Note that also $\ell(R/\mathfrak{m}^n)  = \dim_{k}(S_0) + \dots +
\dim_{k}(S_{n-1})$ for any $n$, thanks to the filtration. This is the
invariant we are interested in.

It will now suffice to prove the following more general proposition.
\begin{proposition} \label{hilbfngeneral}
Let $M$ be any finitely generated graded module over the polynomial ring
$k[x_1, \dots, x_r]$. Then
there exists a polynomial $f_M^+ \in \mathbb{Q}[t]$ of degree $ \leq r$, such that
\[ f_M^+(t) = \sum_{s \leq t} \dim M_s \quad t \gg 0.   \]
\end{proposition}
Applying this to $M = S$ will give the desired result. We can forget about
everything else, and look at this problem over graded polynomial rings.

This function is called the \textbf{Hilbert function}.

\begin{proof}[Proof of \rref{hilbfngeneral}]
Note that if we have an exact sequence of graded modules over the polynomial
ring,
\[ 0 \to M' \to M \to M'' \to 0,   \]
and polynomials $f_{M'}, f_{M''}$ as in the proposition, then $f_M$ exists and
\[ f_M = f_{M'} + f_{M''}.  \] This is obvious from the definitions.
Next, we observe that if $M$ is a finitely generated graded module, over two
different polynomial rings, but with the same grading, then the existence (and
value) of $f_M$ is independent of which polynomial ring one considers.
Finally, we observe that it is sufficient to prove that $f_M(t) = \dim M_t$ is a
polynomial in $t$ for $t \gg 0$.

We will
use these three observations and induct on $n$.

If $n  = 0$, then $M$ is a finite-dimensional graded vector space over
$k$, and the grading must be concentrated in finitely many degrees. Thus
the result is evident as $f_{M}(t)$ will just equal $\dim M$ (which will be the
appropriate dimension for $t \gg 0$).

Suppose $n > 0$.  Then
consider the filtration of $M$
\[ 0 \subset \ker( x_1: M \to M) \subset \ker (x_1^2: M \to M) \subset \dots
\subset M.  \]
This must stabilize by noetherianness at some $M' \subset M$. Each of the
quotients $\ker( x_1^i)/\ker (x_1^{i+1})$ is a finitely generated module over
$k[x_1, \dots,
x_n]/(x_1)$, which is a smaller polynomial ring.  So each of these quotients
$\ker (x_1^{i+1})/\ker (x_1^{i})$ has a Hilbert function of degree $\leq n-1$ by
the inductive hypothesis.

Climbing up the filtration, we see that  $M'$ has a Hilbert function which is the sum of the Hilbert functions of
these quotients $\ker(x_1^{i+1})/\ker(x_1^{i})$. In particular, $f_{M'}$ exists. If we show that $f_{M/M'}$
exists, then $f_M$ necessarily exists. So we might as well show that the
Hilbert function $f_M$ exists when $x_1$ is  a non-zerodivisor on $M$.

So, we have reduced to the case where $M \stackrel{x_1}{\to} M$
is injective.
Now $M$ has a filtration
\[ M \supset x_1 M \supset x_1^2 M \supset \dots  \]
which is an exhaustive filtration of $M$ in that nothing can be divisible by
powers of $x_1$ over and over, or the degree would not be finite. So it
follows that  $\bigcap x_1^m M = 0$.

Let $N = M/x_1 M $, which is isomorphic to $ x_1^m M/x_1^{m+1} M$ since $M \stackrel{x_1}{\to} M$ is
injective. Here $N$ is a finitely generated graded module over $k[x_2, \dots, x_n]$, and by the
inductive hypothesis on $n$, we see that there is a polynomial $f_N^+$ of degree $\leq n-1$ such that
\[ f_N^+(t) = \sum_{t' \leq t} \dim N_{t'}, \quad t \gg 0.  \]

Fix $t \gg 0$ and consider the $k$-vector space $M_t$, which has a finite filtration
\[ M_t \supset (x_1 M)_t \supset (x_1^2 M)_t \supset \dots  \]
which has successive quotients that are the  graded pieces of $N \simeq
M/x_1 M \simeq x_1 M/x_1^2 M \simeq \dots$ in dimensions $t, t-1, \dots$. We
find that
\[ (x_1^2 M)_t/(x_1^3 M)_t \simeq N_{t-2},  \]
for instance. Summing this, we find that
\[ \dim M_t = \dim N_t + \dim N_{t-1} + \dots . \]
The sum above is actually finite. In fact, by finite generation, there is $K
\gg 0 $ such that $\dim N_q  = 0$ for $q< -K$. From this, we find that
\[ \dim M_t = \sum_{t' = -K}^{t} \dim N_{t'},  \]
which implies that $\dim M_t$ is a polynomial for $t \gg 0$. This completes
the proof.
\end{proof}
\end{proof}


Let $(R, \mathfrak{m})$ a noetherian local ring and $M$ a finitely generated
$R$-module.
\begin{proposition} \label{hilbertlocalring}
$\ell(M/\mathfrak{m}^m M)$ is a polynomial for $m \gg 0$.
\end{proposition}
\begin{proof}
This follows from \rref{hilbfngeneral}, and in fact we have
essentially seen the argument above. Indeed, we consider the
associated graded module
\[ N = \bigoplus \mathfrak{m}^k M/\mathfrak{m}^{k+1}M , \]
which is finitely generated over the associated graded ring
\[ \bigoplus \mathfrak{m}^k/\mathfrak{m}^{k+1}.  \]
Consequently, the graded pieces of $N$ have dimensions growing polynomially
for large degrees. This implies the result.

\end{proof}
\begin{definition}
We define the \textbf{Hilbert function} $H_M(m)$  to be the unique polynomial
such that
\[ H_M(m) = \ell(M/ \mathfrak{m}^m M), \quad m \gg 0.  \]
\end{definition}

It is clear, incidentally, that $H_M$ is integer-valued, so we see by
\rref{integervalued} that $H_M$ is a $\mathbb{Z}$-linear
combination of binomial coefficients.

\subsection{The dimension of a module}
Let $R $ be a local noetherian ring with maximal ideal $\mathfrak{m}$. We
have seen (\rref{hilbertlocalring}) that  there is a polynomial $H(t)$ with
\[ H(t) = \ell(R/\mathfrak{m}^t), \quad t \gg 0.  \]
Earlier, we defined the \textbf{dimension} of $R$ is the degree of $f_M^+$.
Since the degree of the Hilbert function is at most the number of generators
of the polynomial ring, we saw that
\[ \dim R \leq \emdim R.  \]

Armed with the machinery of the Hilbert function, we can extend this
definition to modules.
\begin{definition}
If $R$ is local noetherian, and $N$ a finite $R$-module, then $N$ has a
Hilbert polynomial $H_N(t)$ which when evaluated at $t \gg 0$ gives
the length $\ell(N/\mathfrak{m}^t N)$.
We say that the \textbf{dimension of
$N$} is the degree of this Hilbert polynomial.
\end{definition}

Clearly, the dimension of the \emph{ring} $R$ is the same thing as that of the
\emph{module} $R$.

We next show that the dimension behaves well with respect to short exact
sequences. This is actually slightly subtle since, in general, tensoring with
$R/\mathfrak{m}^t$ is not exact; it turns out to be \emph{close} to being
exact by the Artin-Rees lemma.
On the other hand, the corresponding fact for modules over a \emph{polynomial
ring} is very easy, as
no tensoring was involved in the definition.

\begin{proposition}
Suppose we have an exact sequence
\[ 0 \to M' \to M \to M'' \to 0 \]
of graded modules over a polynomial ring $k[x_1, \dots, x_n]$.	Then
\[ f_M(t) = f_{M'}(t) + f_{M''}(t), \quad  f_M^+(t) = f_{M'}^+(t) +
f_{M''}^+(t). \]
As a result, $\deg f_M = \max \deg f_{M'}, \deg f_{M''}$.
\end{proposition}
\begin{proof} The first part is obvious as the dimension is additive on vector
spaces. The second part follows because Hilbert functions have nonnegative
leading coefficients.
\end{proof}

\begin{proposition} \label{dimexactseq}
Fix an exact sequence
\[ 0 \to N' \to N \to N'' \to 0  \]
of finite $R$-modules. Then $\dim N = \max (\dim N', \dim N'')$.
\end{proposition}
\begin{proof}
We have an exact sequence
\[ 0 \to K \to N/\mathfrak{m}^t N \to N''/\mathfrak{m}^t N'' \to 0  \]
where $K$ is the kernel. Here $K = (N' + \mathfrak{m}^t N)/ \mathfrak{m}^t N
= N'/( N' \cap \mathfrak{m}^t N)$. This is not quite $N'/\mathfrak{m}^t N'$,
but it's pretty close.
We have a surjection
\[ N'/\mathfrak{m}^t N \twoheadrightarrow N'/(N' \cap \mathfrak{m}^t N) = K. \]
In particular,
\[ \ell(K) \leq \ell(N'/\mathfrak{m}^t N').  \]
On the other hand, we have the Artin-Rees lemma, which gives an inequality in
the opposite direction. We have a containment
\[ \mathfrak{m}^t N' \subset N' \cap \mathfrak{m}^t N \subset
\mathfrak{m}^{t-c} N'  \]
for some $c$. This implies that $\ell(K) \geq \ell( N'/\mathfrak{m}^{t-c} N')$.

Define $M = \bigoplus \mathfrak{m}^t N/\mathfrak{m}^{t+1} N$, and define $M',
M''$ similarly in terms of $N', N''$. Then we have seen that
\[ \boxed{f_M^+(t-c) \leq \ell(K) \leq f_M^+(t).}  \]
We also know that the length of $K$ plus the length of $N''/\mathfrak{m}^t N''$
is $f_M^+(t)$, i.e.
\[ \ell(K) + f_{M''}^+(t) = f_M^+(t).  \]
Now the length of $K$ is a polynomial in $t$ which is pretty similar to
$f_{M'}^+$, in that the leading coefficient is the same. So we have an
approximate equality $f_{M'}^+(t) + f_{M''}^+(t) \simeq f_M^+(t)$. This implies the
result since the degree of $f_M^+$ is $\dim N$ (and similarly for the others).
\end{proof}



\begin{proposition}
$\dim R$ is the same as $\dim R/\rad R$.
\end{proposition}
I.e., the dimension doesn't change when you kill off nilpotent elements, which
is what you would expect, as nilpotents don't affect $\spec (R)$.
\begin{proof}
For this, we need a little more information about Hilbert functions.
We thus digress substantially.


Finally, let us return to the claim about dimension and nilpotents. Let $R$ be
a local noetherian ring and $I = \rad (R)$. Then $I$ is a finite $R$-module. In
particular, $I$ is nilpotent, so $I^n  = 0$ for $n \gg 0$. We will show that
\[ \dim R/I = \dim R/I^2 = \dots \]
which will imply the result, as eventually the powers become zero.

In particular, we have to show for each $k$,
\[ \dim R/I^k  = \dim R/I^{k+1}.  \]
There is an exact sequence
\[ 0 \to I^k/I^{k+1} \to R/I^{k+1} \to R/I^k \to 0.  \]
The dimension of these rings is the same thing as the dimensions as
$R$-modules. So we can use this short exact sequence of modules. By the
previous result, we are reduced to showing that
\[ \dim I^k/I^{k+1} \leq \dim R/I^k.  \]
Well, note that $I$ kills $I^k/I^{k+1}$. In particular, $I^k/I^{k+1}$ is a finitely generated
$R/I^k$-module. There is an exact sequence
\[ \bigoplus_N R/I^k \to I^k/I^{k+1} \to 0  \]
which implies that $\dim I^k/I^{k+1} \leq \dim \bigoplus_N R/I^k = \dim R/I^k$.
\end{proof}

\begin{example}
Let $\mathfrak{p} \subset \mathbb{C}[x_1, \dots, x_n]$ and let $R =
(\mathbb{C}[x_1,\dots, x_n]/\mathfrak{p})_{\mathfrak{m}}$ for some maximal
ideal $\mathfrak{m}$. What is $\dim R$?
What does dimension mean for coordinate rings over $\mathbb{C}$?

Recall by the Noether normalization theorem that there exists a polynomial ring
$\mathbb{C}[y_1, \dots, y_m]$ contained in $S=\mathbb{C}[x_1,\dots,
x_n]/\mathfrak{p}$ and $S$ is a finite integral extension over this polynomial ring.
We claim that
\[ \dim R = m.  \]
There is not sufficient time for that today.
\end{example}

\subsection{Dimension depends only on the support}

Let $(R, \mathfrak{m})$ be a local noetherian ring. Let $M$ be a finitely generated
$R$-module. 	We defined the \textbf{Hilbert polynomial} of $M$ to be the
polynomial which evaluates at $t \gg 0$ to $\ell(M/\mathfrak{m}^tM)$. We proved
last time that such a polynomial always exists, and called its degree the
\textbf{dimension of $M$}. However,
we shall now see that $\dim M$ really depends only on the support\footnote{
Recall that $\supp M = \left\{\mathfrak{p}: M_{\mathfrak{p}}\neq 0\right\}$.} $\supp M$.
In this sense, the dimension is really a statement about the \emph{topological
space} $\supp M \subset \spec R$, not about $M$ itself.


In other words, we will prove:
\begin{proposition}
$\dim M$ depends only on $\supp M$.
\end{proposition}

In fact, we shall show:

\begin{proposition}
$\dim M = \max_{\mathfrak{p} \in \supp M} \dim R/\mathfrak{p}$.
\end{proposition}
\begin{proof}
By \rref{filtrationlemma} in \rref{noetherian}, there is a finite filtration
\[ 0 = M_0 \subset M_1 \subset \dots \subset M_m = M,  \]
such that each of the successive quotients is isomorphic to $R/\mathfrak{p}_i
\subset R$
for some prime ideal $\mathfrak{p}_i$. Given a short exact sequence
of modules, we know that the dimension in the middle is the maximum of the dimensions at the
two ends (\rref{dimexactseq}). Iterating this, we see that the
dimension of $M$ is the maximum of the
dimension of the successive quotients $M_i/M_{i-1}$.

But the $\mathfrak{p}_i$'s that occur
are all in $\supp M$, so we find
\[ \dim M = \max_{\mathfrak{p}_i} R/\mathfrak{p}_i \leq \max_{\mathfrak{p} \in \supp M} \dim R/\mathfrak{p}.  \]
We must show the reverse inequality. But fix any prime $\mathfrak{p} \in \supp
M$. Then $M_{\mathfrak{p}} \neq 0$, so one of the $R/\mathfrak{p}_i$ localized
at  $\mathfrak{p}$ must be nonzero, as localization is an exact functor. Thus
$\mathfrak{p}$ must contain some $\mathfrak{p}_i$. So $R/\mathfrak{p}$ is a
quotient of $R/\mathfrak{p}_i$. In particular,
\[ \dim R/\mathfrak{p} \leq \dim R/\mathfrak{p}_i.  \]
\end{proof}

Having proved this, we throw out the notation $\dim M$, and henceforth write
instead $\dim \supp M$.



%% N. B. This following material on affine rings should be added in
\begin{comment}
\subsection{The dimension of an affine ring} Last time, we made a claim. If $R$
is a domain and a finite module over a polynomial ring $k[x_1, \dots, x_n]$,
then $R_{\mathfrak{m}}$ for any maximal $\mathfrak{m} \subset R$ has dimension
$n$. This connects the dimension with the transcendence degree.

First, let us talk about finite extensions of rings. Let $R$ be a commutative
ring and let $R \to R'$ be a morphism that makes $R'$ a finitely generated $R$-module (in
particular, integral over $R$). Let $\mathfrak{m}' \subset R'$ be maximal. Let
$\mathfrak{m}$ be the pull-back to $R$, which is also maximal (as $R \to R'$ is
integral).
Let $M$ be a finitely generated $R'$-module, hence also a finitely generated $R$-module.

We can look at $M_{\mathfrak{m}}$ as an $R_{\mathfrak{m}}$-module or
$M_{\mathfrak{m}'}$ as an $R'_{\mathfrak{m}'}$-module. Either of these will be
finitely generated.

\begin{proposition}
$\dim \supp M_{\mathfrak{m}}  \geq \dim \supp M_{\mathfrak{m}'}$.
\end{proposition}
Here $M_{\mathfrak{m}}$ is an $R_{\mathfrak{m}}$-module, $M_{\mathfrak{m}'}$ is
an $R'_{\mathfrak{m}'}$-module.

\begin{proof}
Consider $R/\mathfrak{m} \to R'/\mathfrak{m} R' \to R'/\mathfrak{m}'$. Then we
see that $R'/\mathfrak{m} R'$ is a finite $R/\mathfrak{m}$-module, so a
finite-dimensional $R/\mathfrak{m}$-vector space. In particular,
$R'/\mathfrak{m} R'$ is of finite length as an $R/\mathfrak{m}$-module, in
particular an artinian ring. It is thus a product of local artinian rings.
These artinian rings are the localizations of $R'/\mathfrak{m}R'$ at ideals of
$R'$ lying over $\mathfrak{m}$. One of these ideals is $\mathfrak{m}'$.
So in particular
\[ R'/\mathfrak{m}R \simeq R'/\mathfrak{m}'\times \mathrm{other \ factors}.  \]
The nilradical of an artinian ring being nilpotent, we see that
$\mathfrak{m}'^c R'_{\mathfrak{m}'} \subset \mathfrak{m} R'_{\mathfrak{m}}$ for
some $c$.

OK, I'm not following this---too tired. Will pick this up someday.
\end{proof}


\begin{proposition}
$\dim \supp M_{\mathfrak{m}} = \max_{\mathfrak{m}' \mid \mathfrak{m}} \dim
\supp M_{\mathfrak{m}'}$.
\end{proposition}

This means $\mathfrak{m}'$ lies over $\mathfrak{m}$.
\begin{proof}
Done similarly, using artinian techniques. I'm kind of tired.
\end{proof}
\end{comment}
\begin{example}
Let $R' = \mathbb{C}[x_1, \dots, x_n]/\mathfrak{p}$. Noether normalization says
that there exists a finite injective map $\mathbb{C}[y_1, \dots, y_a] \to R'$.
The claim is that
\[ \dim R'_{\mathfrak{m}} =a  \]
for any maximal ideal $\mathfrak{m} \subset R'$. We are set up to prove a
slightly weaker definition. In particular (see below for the definition of the
dimension of a non-local ring), by the proposition, we
find the weaker claim
\[ \dim R' = a,  \]
as the dimension of a polynomial ring $\mathbb{C}[y_1, \dots, y_a]$ is $a$.
(\textbf{I don't think we have proved this yet.})
\end{example}



\section{Other definitions and characterizations of dimension}

\subsection{The topological characterization of dimension} We now want a topological
characterization of dimension. So, first, we want to study how dimension
changes as we do things to a module. Let $M$ be a finitely generated $R$-module over a local
noetherian ring $R$. Let $x \in \mathfrak{m}$ for $\mathfrak{m}$ as the maximal
ideal.
You might ask
\begin{quote}
What is the relation between $\dim \supp M$ and $\dim \supp M/xM$?
\end{quote}
Well, $M$ surjects onto $M/xM$, so we have the inequality $\geq$. But we think
of dimension as describing the number of parameters you need to describe
something. The number of parameters shouldn't change too much with going from
$M$ to $M/xM$. Indeed, as one can check,
\[ \supp M/xM = \supp M \cap V(x)  \]
and intersecting $\supp M$ with the ``hypersurface'' $V(x)$ should shrink the
dimension by one.


We thus make:
\begin{prediction}
\[ \dim \supp M/xM = \dim \supp M - 1.  \]
\end{prediction}
Obviously this is not always true, e.g. if $x$ acts by zero on $M$. But we want
to rule that out.
Under reasonable cases, in fact, the prediction is correct:

\begin{proposition} \label{dimdropsbyone}
Suppose $x \in \mathfrak{m}$ is a nonzerodivisor on $M$. Then
\[ \dim \supp M/xM = \dim \supp M - 1.  \]
\end{proposition}
\begin{proof}
To see this, we look at Hilbert polynomials. Let us consider the exact sequence
\[ 0 \to xM \to M \to M/xM \to 0  \]
which leads to an exact sequence for each $t$,
\[ 0 \to xM/(xM \cap \mathfrak{m}^t M) \to M/\mathfrak{m}^t M \to M/(xM  +
\mathfrak{m}^t M) \to 0 . \]
For $t$ large, the lengths of these things are given by Hilbert polynomials,
as the thing on the right is $M/xM \otimes_R R/\mathfrak{m}^t$.
We have
\[ f_M^+(t) = f_{M/xM}^+(t) + \ell(xM/ (x M \cap \mathfrak{m}^t M), \quad t
\gg 0.  \]
In particular, $\ell( xM/ (xM \cap \mathfrak{m}^t M))$ is a polynomial in $t$.
What can we say about it? Well, $xM \simeq M$ as $x$ is a nonzerodivisor. In
particular
\[ xM / (xM \cap \mathfrak{m}^t M) \simeq M/N_t  \]
where
\[ N_t = \left\{a \in M: xa \in \mathfrak{m}^t M\right\} . \]
In particular, $N_t \supset \mathfrak{m}^{t-1} M$. This tells us that
$\ell(M/N_t) \leq \ell(M/\mathfrak{m}^{t-1} M) = f_M^+(t-1)$ for $t \gg 0$.
Combining this with the above information, we learn that
\[ f_M^+(t) \leq f_{M/xM}^+(t) + f_M^+(t-1),   \]
which implies that $f_{M/xM}^+(t)$ is at least the successive difference
$f_M^+(t) - f_M^+(t-1)$. This last polynomial has degree $\dim \supp M -1$. In
particular, $f_{M/xM}^+(t)$ has degree at least $\dim \supp M -1 $. This gives
us one direction, actually the hard one. We showed that intersecting something with codimension one
doesn't drive the dimension down too much.

Let us now do the other direction. We essentially did this last time via the
Artin-Rees lemma. We know that $N_t = \left\{a \in M: xa \in
\mathfrak{m}^t\right\}$. The Artin-Rees lemma tells us that there is a constant
$c$ such that $N_{t+c} \subset \mathfrak{m}^t M$ for all $t$. Therefore,
$\ell(M/N_{t+c}) \geq \ell(M/\mathfrak{m}^t M) = f_M^+(t), t \gg 0$. Now
remember the exact sequence $0 \to M/N_t \to M/\mathfrak{m}^t M \to M/(xM +
\mathfrak{m}^t M) \to 0$. We see from this that
\[ \ell(M/ \mathfrak{m}^t M) = \ell(M/N_t) + f_{M/xM}^+(t) \geq f_M^+(t-c) +
f_{M/xM}^+(t), \quad t \gg 0,  \]
which implies that
\[ f_{M/xM}^+(t) \leq f_M^+(t) - f_M^+(t-c),  \]
so the degree must go down. And we find that $\deg f_{M/xM}^+ < \deg f_{M}^+$.
\end{proof}

This gives us an algorithm of computing the dimension of an $R$-module $M$.
First, it reduces to computing $\dim R/\mathfrak{p}$ for $\mathfrak{p} \subset
R$ a prime ideal. We may assume that $R$ is a domain and that we are looking
for $\dim R$. Geometrically, this
corresponds to taking an irreducible component of $\spec R$.

Now choose any $x
\in R$ such that $x$ is nonzero but noninvertible. If there is no such element,
then $R$ is a field and has dimension zero. Then compute $\dim R/x$
(recursively) and add one.

Notice that this algorithm said nothing about Hilbert polynomials, and only
talked about the structure of prime ideals.

\subsection{Recap}
Last time, we were talking about dimension theory.
Recall that $R$ is a local noetherian ring with maximal ideal $\mathfrak{m}$,
$M$ a finitely generated $R$-module. We can look at the lengths $\ell(M/\mathfrak{m}^t M)$
for varying $t$; for $t \gg 0$ this is a polynomial function. The degree of
this polynomial is called the \textbf{dimension} of $\supp M$.

\begin{remark}
If $M = 0$, then we define $\dim \supp M = -1$ by convention.
\end{remark}

Last time, we showed that if $M \neq 0$ and $x \in \mathfrak{m}$ such that $x$
is a nonzerodivisor on $M$ (i.e. $M \stackrel{x}{\to} M$ injective), then
\[ \boxed{ \dim \supp M/xM = \dim \supp M - 1.}\]
Using this, we could give a recursion for calculating the dimension.
To compute $\dim R = \dim \spec R$, we note three properties:
\begin{enumerate}
\item $\dim R = \sup_{\mathfrak{p} \ \mathrm{a \ minimal \ prime}}
R/\mathfrak{p}$. Intuitively, this says that a variety which is the union of
irreducible components has dimension equal to the maximum of these irreducibles.
\item $\dim R = 0$ for $R$  a field. This is obvious from the definitions.
\item If $R$ is a domain, and $x \in \mathfrak{m} - \left\{0\right\}$, then
$\dim R/(x) +1 = \dim R $. This is obvious from the boxed formula as $x$ is a nonzerodivisor.
\end{enumerate}

These three properties \emph{uniquely characterize} the dimension invariant.

\textbf{More precisely, if
$d: \left\{\mathrm{local \ noetherian \ rings}\right\} \to \mathbb{Z}_{\geq 0}$
satisfies the above three properties, then $d = \dim $. }
\begin{proof}
Induction on $\dim R$. It is clearly sufficient to prove this for $R$ a domain.
If $R$ is a field, then it's clear; if $\dim R>0$, the third condition lets us
reduce to a case covered by the inductive hypothesis (i.e. go down).
\end{proof}

Let us rephrase 3 above:
\begin{quote}
3': If $R$ is a domain and not a field, then
\[ \dim R = \sup_{x \in \mathfrak{m} - 0} \dim R/(x) + 1. \]
\end{quote}
Obviously 3' implies 3, and it is clear by the same argument that 1,2, 3'
characterize the notion of dimension.

\subsection{Krull dimension} We shall now define another notion of
dimension, and show that it is equivalent to the older one by showing that it
satisfies these axioms.

\begin{definition}
Let $R$ be a commutative ring. A \textbf{chain of prime ideals} in $R$ is a finite
sequence
\[ \mathfrak{p}_0 \subsetneq \mathfrak{p}_1 \subsetneq \dots \subsetneq
\mathfrak{p}_n.  \]
This chain is said to have \textbf{length $n$.}
\end{definition}

\begin{definition}
The \textbf{Krull dimension} of $R$ is equal to the maximum length of any chain
of prime ideals. This might be $\infty$, but we will soon see this cannot
happen for $R$ local and noetherian.
\end{definition}

\begin{remark}
For any maximal chain $\left\{\mathfrak{p}_i, 0 \leq i \leq n\right\}$ of primes (i.e. which can't be expanded), we must have
that $\mathfrak{p}_0$ is minimal prime and $\mathfrak{p}_n$ a maximal ideal.
\end{remark}

\begin{theorem}
For a noetherian local ring $R$, the Krull dimension of $R$ exists and is equal
to the usual $\dim R$.
\end{theorem}
\begin{proof}
We will show that the Krull dimension satisfies the above axioms. For now,
write $\krdim$ for Krull dimension.

\begin{enumerate}
\item First, note that $\krdim(R) = \max_{\mathfrak{p} \in R \
\mathrm{minimal}}  \krdim(R/\mathfrak{p})$. This is because any chain of prime
ideals in $R$ contains a minimal prime. So any chain of prime ideals in $R$ can
be viewed as a chain in \emph{some} $R/\mathfrak{p}$, and conversely.
\item Second, we need to check that $\krdim(R) = 0$ for $R$ a field. This is
obvious, as there is precisely one prime ideal.
\item The third condition is interesting. We must check that for $(R,
\mathfrak{m})$ a local
domain,
\[ \krdim(R) = \max_{x \in \mathfrak{m} - \left\{0\right\}} \krdim(R/(x)) + 1.  \]
If we prove this, we will have shown that condition 3' is satisfied by the
Krull dimension. It will follow by the inductive argument above that $\krdim(R)
= \dim (R)$ for any $R$.
There are two inequalities to prove. First, we must show
\[ \krdim(R) \geq \krdim(R/x) +1, \quad \forall x \in \mathfrak{m} - 0.  \]
So suppose $k = \krdim(R/x)$. We want to show that there is a chain of prime
ideals of length $k+1$ in $R$. So say $\mathfrak{p}_0 \subsetneq \dots
\subsetneq \mathfrak{p}_k$ is a chain of length $k$ in $R/(x)$. The inverse
images in $R$ give a proper chain of primes in $R$ of  length $k$, all of which
contain $(x)$ and thus properly contain $0$. Thus adding zero will give a chain
of primes in $R$ of length $k+1$.

Conversely, we want to show that if there is a chain of primes in $R$ of
length  $k+1$, then there is a chain of length $k$ in $R/(x)$ for some $x \in
\mathfrak{m} - \left\{0\right\}$. Let us write the chain  of length $k+1$:
\[ \mathfrak{q}_{-1} \subset \mathfrak{q}_0 \subsetneq \dots \subsetneq
\mathfrak{q}_k \subset R . \]
Now evidently $\mathfrak{q}_0$ contains some $x \in \mathfrak{m} - 0$. Then the
chain $\mathfrak{q}_0 \subsetneq \dots \subsetneq \mathfrak{q}_k$ can be
identified with a chain in $R/(x)$ for this $x$. So for this $x$, we have that
$\krdim R \leq \sup \krdim R/(x) + 1$.
\end{enumerate}
\end{proof}

There is thus a combinatorial definition of definition.

Geometrically, let $X = \spec R$ for $R$ an affine ring over $\mathbb{C}$ (a
polynomial ring mod some ideal). Then $R$ has Krull dimension $\geq k$ iff there is a
chain of irreducible subvarieties of $X$,
\[ X_0 \supset X_1 \supset \dots \supset X_k . \]
You will meet justification for this in \rref{subsectiondimension} below.

\begin{remark}[\textbf{Warning!}] Let $R$ be a local noetherian ring of dimension $k$. This
means that there is a chain of prime ideals of length $k$, and no longer
chains. Thus there is a maximal chain whose length is $k$. However, not all
maximal chains in $\spec R$ have length $k$.
\end{remark}

\begin{example}
Let $R =( \mathbb{C}[X,Y,Z]/(XY,XZ))_{(X,Y,Z)}$. It is left as an
exercise to the reader to see that there are maximal chains of
length not two.

There are more complicated local noetherian \emph{domains} which have maximal
chains of prime ideals not of the same length. These examples are not what you
would encounter in daily experience, and are necessarily complicated. This
cannot happen for finitely generated domains over a field.
\end{example}

\begin{example}
An easier way all maximal chains could fail to be of the same length is if
$\spec R$ has two components (in which case $R = R_0 \times R_1$ for rings
$R_0, R_1$).
\end{example}


\subsection{Yet another definition}
Let's start by thinking about the definition of a module. Recall that if $(R,
\mathfrak{m})$ is
a local noetherian ring and $M$ a finitely generated $R$-module, and $x \in \mathfrak{m}$ is
a nonzerodivisor on $M$, then
\[ \dim \supp M/xM = \dim \supp M -1.  \]

\begin{question}
What if $x$ is  a zerodivisor?
\end{question}

This is not necessarily true (e.g. if $x \in \ann(M)$). Nonetheless, we claim
that even in this case:
\begin{proposition}
For any $x \in \mathfrak{m}$,
\[ \boxed{ \dim \supp M \geq \dim \supp M/xM \geq \dim \supp M -1 .}\]
\end{proposition}
The upper bound on $\dim M/xM$ is obvious as $M/xM$ is a quotient of $M$. The
lower bound is trickier.

\begin{proof}
Let $N = \left\{a \in M: x^n a = 0 \ \mathrm{for \ some \ } n \right\}$. We can
construct an exact sequence
\[ 0 \to N \to M \to M/N \to 0.  \]
Let $M'' = M/N$.
Now $x$ is a nonzerodivisor on $M/N$ by construction. We claim that
\[ 0 \to N/xN \to M/xM \to M''/xM'' \to 0  \]
is exact as well. For this we only need to see exactness at the beginning,
i.e. injectivity of $N/xN \to M/xM$. So
we need to show that if $a \in N$ and $a \in xM$, then $a \in x N$.

To see this, suppose $a = xb$ where $b \in M$. Then if $\phi: M \to M''$, then
$\phi(b) \in M''$ is killed by $x$ as $x \phi(b) = \phi(bx) = \phi(a)$.
This means that $\phi(b)=0$ as $M'' \stackrel{x}{\to} M''$ is injective. Thus
$b \in N$ in fact. So $a \in xN$ in fact.

From the exactness, we see that (as $x$ is a nonzerodivisor on $M''$)
\begin{align*} \dim M/xM & = \max (\dim M''/xM'', \dim N/xN) \geq \max(\dim M'' -1, \dim
N)\\ &  \geq \max( \dim M'', \dim N)-1  .  \end{align*}
The reason for the last claim is that $\supp N/xN = \supp N$ as $N$ is
$x$-torsion, and the dimension depends only on the support. But the thing on the right is just $\dim M -1$.
\end{proof}

As a result, we find:

\begin{proposition}
$\dim \supp M$ is the minimal integer $n$ such that there exist elements $x_1,
\dots, x_n \in \mathfrak{m}$ with $M/(x_1 , \dots, x_n) M$ has finite length.
\end{proposition}
Note that $n$ always exists, since we can look at a bunch of generators of the
maximal ideal, and $M/\mathfrak{m}M $ is a finite-dimensional vector space and
is thus of finite length.
\begin{proof}
Induction on $\dim \supp M$. Note that $\dim \supp(M)=0$ if and only if the
Hilbert polynomial has degree zero, i.e. $M$ has finite length or that $n=0$
($n$ being defined as in the statement).

Suppose $\dim \supp M > 0$. \begin{enumerate}
\item  We first show that there are $x_1, \dots, x_{\dim M}$
with $M/(x_1, \dots, x_{\dim M})M$ have finite length.
Let $M' \subset M$ be the maximal submodule having finite length. There
is an exact sequence
\[ 0 \to M' \to M \to M'' \to 0  \]
where $M'' = M/M'$ has no finite length submodules. In this case, we can
basically ignore $M'$, and replace $M$ by $M''$. The reason is that modding out
by $M'$ doesn't affect either $n$ or the dimension.

So let us replace $M$ with
$M''$ and thereby assume that $M$ has no finite length submodules. In
particular, $M$ does not contain a copy of $R/\mathfrak{m}$, i.e. $\mathfrak{m}
\notin \ass(M)$.
By prime avoidance, this means that there is $x_1 \in \mathfrak{m}$ that acts as
a nonzerodivisor on $M$. Thus
\[ \dim M/x_1M = \dim M -1.  \]
The inductive hypothesis says that there are $x_2, \dots, x_{\dim M}$ with
$$(M/x_1 M)/(x_2, \dots, x_{\dim M}) (M/xM) \simeq M/(x_1, \dots, x_{\dim M})M $$
of finite length. This shows the claim.
\item Conversely, suppose that there $M/(x_1, \dots, x_n)M$ has finite length.
Then we claim that $n \geq \dim M$. This follows because we had the previous
result that modding out by a single element can chop off the dimension by at
most $1$. Recursively applying this, and using the fact that $\dim$ of a
finite length module is zero, we find
\[ 0 = \dim M/(x_1 , \dots, x_n )M \geq \dim M -n. \]
\end{enumerate}
\end{proof}


\begin{corollary}
Let $(R, \mathfrak{m})$ be a local noetherian ring. Then $\dim R$ is equal to the minimal $n$
such that there exist $x_1, \dots, x_n \in R$ with $R/(x_1, \dots, x_n) R$ is
artinian. Or, equivalently, such that $(x_1, \dots, x_n)$ contains a power of
$\mathfrak{m}$.
\end{corollary}


\begin{remark}
We manifestly have here that the dimension of $R$ is at most the embedding
dimension. Here, we're not worried about generating the maximal ideal, but
simply something containing a power of it.
\end{remark}
\lecture{11/5}

We have been talking about dimension. Let $R$ be a local noetherian ring with
maximal ideal $\mathfrak{m}$. Then, as we have said in previous lectures, $\dim R$ can be characterized by:
\begin{enumerate}
\item The minimal $n$ such that there is an $n$-primary ideal generated by $n$
elements $x_1, \dots, x_n \in \mathfrak{m}$. That is, the closed point
$\mathfrak{m}$ of
$\spec R$ is cut out \emph{set-theoretically} by the intersection $\bigcap
V(x_i)$. This is one way of saying that the closed point can be defined by $n$
parameters.
\item The \emph{maximal} $n$ such that there exists a chain of prime ideals
\[ \mathfrak{p}_0 \subset \mathfrak{p}_1 \subset \dots \subset \mathfrak{p}_n. \]
\item The degree of the Hilbert polynomial $f^+(t)$, which equals
$\ell(R/\mathfrak{m}^t)$ for $t \gg 0$.
\end{enumerate}


\subsection{Krull's Hauptidealsatz}


Let $R$ be a local noetherian ring.
The following is now clear from what we have shown:

\begin{theorem} \label{hauptv1}
$R$ has dimension $1$ if and only if there is a nonzerodivisor $x \in \mathfrak{m}$ such that
$R/(x)$ is artinian.
\end{theorem}



\begin{remark}
Let $R$ be a domain. We said that a nonzero prime $\mathfrak{p} \subset R$ is
\textbf{height one} if $\mathfrak{p}$ is minimal among the prime ideals
containing some nonzero $x \in R$.

According to Krull's Hauptidealsatz, $\mathfrak{p}$ has height one \textbf{if
and only if $\dim R_{\mathfrak{p}} = 1$.}
\end{remark}


We can generalize the notion of $\mathfrak{p}$ as follows.
\begin{definition}
Let $R$ be a noetherian ring (not necessarily local), and $\mathfrak{p} \in
\spec R$. Then we define the \textbf{height} of $\mathfrak{p}$, denoted
$\het(\mathfrak{p})$, as $\dim R_{\mathfrak{p}}$.
We know that this is the length of a maximal chain of primes in
$R_{\mathfrak{p}}$. This is thus the maximal length of prime ideals of $R$,
\[ \mathfrak{p}_0 \subset \dots \subset \mathfrak{p}_n = \mathfrak{p}  \]
that ends in $\mathfrak{p}$. This is the origin of the term ``height.''
\end{definition}

\begin{remark}
Sometimes, the height is called the \textbf{codimension}. This corresponds to
the codimension in $\spec R$ of the corresponding irreducible closed subset of
$\spec R$.
\end{remark}

\begin{theorem}[Krull's Hauptidealsatz]  Let $R$ be a noetherian ring, and $x
\in R$ a nonzerodivisor. If $\mathfrak{p} \in \spec R$ is minimal over $x$,
then $\mathfrak{p}$ has height one.
\end{theorem}
\begin{proof}
Immediate from \cref{hauptv1}.
\end{proof}

\begin{theorem}[Artin-Tate]
Let $A$ be a noetherian domain. Then the following are equivalent:
\begin{enumerate}
\item There is $f \in A-\left\{0\right\} $ such that $A_f$ is a field.
\item $A$ has finitely many maximal ideals and has dimension at most 1.
\end{enumerate}
\end{theorem}
\begin{proof} We follow \cite{EGA}.

Suppose first that there is $f$ with $A_f$ a field.
Then all nonzero prime ideals of $A$ contain $f$.
We need to deduce that $A$ has dimension $\leq 1$. Without loss of generality,
we may assume that $A$ is not a field.

There are finitely many primes $\mathfrak{p}_1,\dots, \mathfrak{p}_k$ which
are minimal over $f$; these are all height one. The claim is that any maximal ideal of $A$ is of this
form. Suppose $\mathfrak{m}$ were maximal and not one of the $\mathfrak{p}_i$.
Then by prime avoidance, there is $g \in \mathfrak{m}$ which
lies in no $\mathfrak{p}_i$. A minimal prime $\mathfrak{P}$ of $g$ has height
one, so by our assumptions contains $f$. However, it is then one of the
$\mathfrak{p}_i$; this is a contradiction as $g \in \mathfrak{P}$.
\end{proof}


\subsection{Further remarks}

We can recast earlier notions in terms of dimension.
\begin{remark}
A noetherian ring has dimension zero if and only if $R$ is artinian. Indeed,
$R$ has dimension zero iff all primes are maximal.
\end{remark}


\begin{remark}
A noetherian domain has dimension zero iff it is a field. Indeed, in this case
$(0)$ is maximal.
\end{remark}

\begin{remark}
$R$ has dimension $\leq 1$ if and only if every non-minimal prime of $R$ is
maximal. That is, there are no chains of length $\geq 2$.
\end{remark}

\begin{remark}
A (noetherian) domain  $R$ has dimension $\leq 1$ iff every nonzero prime ideal
is maximal.
\end{remark}

In particular,
\begin{proposition}
$R$ is Dedekind iff it is a noetherian, integrally closed domain of dimension
$1$.
\end{proposition}


\section{Further topics}

\subsection{Change of rings}
Let $f: R \to R'$ be  a map of noetherian rings.

\begin{question}
What is the relationship between $\dim R$ and $\dim R'$?
\end{question}

A map $f$ gives a map $\spec R' \to \spec R$, where $\spec R'$ is the union
of various fibers over the points of $\spec R$. You might imagine that the
dimension is the dimension of $R$ plus the fiber dimension. This is sometimes
true.

Now assume that $R, R'$ are \emph{local}  with maximal ideals $\mathfrak{m},
\mathfrak{m}'$. Assume furthermore that $f$ is local, i.e. $f(\mathfrak{m})
\subset \mathfrak{m}'$.

\begin{theorem}
$\dim R' \leq \dim R +  \dim R'/\mathfrak{m}R'$. Equality holds if $f: R \to
R'$ is flat.
\end{theorem}

Here $R'/\mathfrak{m}R'$ is to be interpreted as the ``fiber'' of $\spec R'$
above $\mathfrak{m} \in \spec R$. The fibers can behave weirdly as the
basepoint varies in $\spec R$, so we can't
expect equality in general.

\begin{remark}
Let us review flatness as it has been a while. An $R$-module $M$ is \emph{flat} iff
the operation of tensoring with $M$ is an exact functor. The map $f: R \to R'$
is \emph{flat} iff $R'$ is a flat $R$-module. Since the construction of taking
fibers is a tensor product (i.e. $R'/\mathfrak{m}R' = R' \otimes_R
R/\mathfrak{m}$), perhaps the condition of flatness here is not as surprising as
it might be.
\end{remark}

\begin{proof}
Let us first prove the inequality. Say $$\dim R = a,  \ \dim R'/\mathfrak{m}R'
= b.$$ We'd like to see that
\[ \dim R' \leq a+b.  \]
To do this, we need to find $a+b$ elements in the maximal ideal $\mathfrak{m}'$
that generate a $\mathfrak{m}'$-primary ideal of $R'$.

There are elements $x_1, \dots, x_a \in \mathfrak{m}$ that generate an
$\mathfrak{m}$-primary ideal $I = (x_1, \dots, x_a)$ in $R$. There is a surjection $R'/I R'
\twoheadrightarrow R'/\mathfrak{m}R'$.
The kernel $\mathfrak{m}R'/IR'$ is nilpotent since $I$ contains a power of
$\mathfrak{m}$. 	We've seen that nilpotents \emph{don't} affect the dimension.
In particular,
\[ \dim R'/IR' = \dim R'/\mathfrak{m}R' = b.  \]
There are thus elements $y_1, \dots, y_b \in \mathfrak{m}'/IR'$ such that the
ideal $J = (y_1, \dots, y_b) \subset R'/I R'$ is $\mathfrak{m}'/IR'$-primary.
The inverse image of $J$ in $R'$, call it $\overline{J} \subset R'$, is
$\mathfrak{m}'$-primary. However, $\overline{J}$ is generated by the $a+b$
elements
\[ f(x_1), \dots, f(x_a), \overline{y_1}, \dots, \overline{y_b}  \]
if the $\overline{y_i}$ lift $y_i$.

But we don't always have equality. Nonetheless, if all the fibers are similar,
then we should expect that the dimension of the ``total space'' $\spec R'$ is
the dimension of the ``base'' $\spec R$ plus the ``fiber'' dimension $\spec
R'/\mathfrak{m}R'$.
\emph{The precise condition of $f$ flat articulates the condition that the fibers
 ``behave well.'' }
Why this is so is something of a mystery, for now.
But for some evidence, take the present result about fiber dimension.

Anyway, let us now prove equality for flat $R$-algebras. As before, write $a =
\dim R, b = \dim R'/\mathfrak{m}R'$. We'd like to show that
\[ \dim R' \geq a+b.  \]
By what has been shown, this will be enough.
This is going to be tricky since we now need to give \emph{lower bounds} on the
dimension; finding a sequence $x_{1}, \dots, x_{a+b}$ such that the quotient
$R/(x_1, \dots, x_{a+b})$ is artinian would bound \emph{above} the dimension.

So our strategy will be to find a chain of primes of length $a+b$. Well, first
we know that there are primes
\[ \mathfrak{q}_0 \subset \mathfrak{q}_1 \subset \dots \subset \mathfrak{q}_b
\subset R'/\mathfrak{m}R'.  \]
Let $\overline{\mathfrak{q}_i}$ be the inverse images in $R'$. Then the
$\overline{\mathfrak{q}_i}$ are a strictly ascending chain of primes in $R'$ where
$\overline{\mathfrak{q}_0}$ contains $\mathfrak{m}R'$. So we have a chain of
length $b$; we need to extend this by additional terms.

Now $f^{-1}(\overline{\mathfrak{q}_0})$ contains $\mathfrak{m}$, hence is
$\mathfrak{m}$. Since $\dim R = a$, there is a chain
$\left\{\mathfrak{p}_i\right\}$ of prime ideals of length
$a$ going down from $f^{-1}(\overline{\mathfrak{q}_0}) = \mathfrak{m}$. We are
now going to find primes $\mathfrak{p}_i' \subset R'$ forming a chain such that
$f^{-1}(\mathfrak{p}_i') = \mathfrak{p}_i$. In other words, we are going to
\emph{lift} the chain $\mathfrak{p}_i$ to $\spec R'$. We can do this at the
first stage for $i=a$, where $\mathfrak{p}_a = \mathfrak{m}$ and we can set
$\mathfrak{p}'_a = \overline{\mathfrak{q}_0}$. If we can indeed do this
lifting, and catenate the chains $\overline{\mathfrak{q}_j}, \mathfrak{p}'_i$,
then we will have a chain of the appropriate length.

We will proceed by descending induction. Assume that we have
$\mathfrak{p}_{i+1}' \subset R'$ and $f^{-1}(\mathfrak{p}_{i+1}') =
\mathfrak{p}_{i+1} \subset R$. We want to find $\mathfrak{p}_i' \subset
\mathfrak{p}'_{i+1}$ such that $f^{-1}(\mathfrak{p}_i') = \mathfrak{p}_i$. The
existence of that prime is a consequence of the following general fact.

\begin{theorem}[Going down] Let $f: R \to R'$ be a flat map of
noetherian commutative
rings. Suppose $\mathfrak{q} \in \spec R'$, and let $\mathfrak{p}
=f^{-1}(\mathfrak{q})$. Suppose $\mathfrak{p}_0 \subset \mathfrak{p}$ is a
prime of $R$. Then there is a prime $\mathfrak{q}_0 \subset \mathfrak{q}$ with
\[ f^{-1}(\mathfrak{q}_0) = \mathfrak{p}_0.  \]
\end{theorem}
\begin{proof}
We may replace $R'$ with $R'_{\mathfrak{q}}$. There is still a map
\[ R \to R_{\mathfrak{q}}'  \]
which is flat as localization is flat. The maximal ideal in $R'_{\mathfrak{q}}$
has inverse image $\mathfrak{p}$. So the problem now reduces to finding
\emph{some} $\mathfrak{p}_0$ in the localization that pulls back appropriately.

Anyhow, throwing out the old $R$ and replacing with the localization, we may
assume that $R'$ is local and $\mathfrak{q}$ the maximal ideal. (The condition
$\mathfrak{q}_0 \subset \mathfrak{q}$ is now automatic.)

The claim now is that we can replace $R$ with $R/\mathfrak{p}_0$ and $R'$ with
$R'/\mathfrak{p}_0 R' = R' \otimes R/\mathfrak{p}_0$. We can do this because
base change preserves flatness (see below), and in this case we can reduce to the case of
$\mathfrak{p}_0 = (0)$---in particular, $R$ is a domain.
Taking these quotients just replaces $\spec R, \spec R'$ with closed subsets
where all the action happens anyhow.

Under these replacements, we now have:
\begin{enumerate}
\item $R'$ is local with maximal ideal $\mathfrak{q}$
\item $R$ is a domain and $\mathfrak{p}_0 = (0)$.
\end{enumerate}
We want a prime of $R'$ that pulls back to $(0)$ in $R$. I claim that any
minimal prime of $R'$ will work.
Suppose otherwise. Let $\mathfrak{q}_0 \subset R'$ be a minimal prime, and
suppose $x \in R \cap f^{-1}(\mathfrak{q}_0) - \left\{0\right\}$. But
$\mathfrak{q}_0 \in \ass(R')$. So $f(x)$ is
a zerodivisor on $R'$. Thus multiplication by $x$ on $R'$ is not injective.

But, $R$ is a domain, so $R \stackrel{x}{\to} R$ is injective. Tensoring with
$R'$ must preserve this, implying that $R' \stackrel{x}{\to} R'$ is injective
because $R'$ is flat. This is a contradiction.
\end{proof}

We used:
\begin{lemma}
Let $R \to R'$ be a flat map, and $S$ an $R$-algebra. Then $S \to S \otimes_R
R'$ is a flat map.
\end{lemma}
\begin{proof}
The construction of taking an $S$-module with $S \otimes_R R'$ is an exact
functor, because that's the same thing as taking an $S$-module, restricting to
$R$, and tensoring with $R'$.
\end{proof}
The proof of the fiber dimension theorem is now complete.

\end{proof}



\subsection{The dimension of a polynomial ring}

Adding an indeterminate variable corresponds geometrically to taking the
product with the affine line, and so should increase the dimension by one. We
show that this is indeed the case.
\label{dimpoly}
\begin{theorem}
Let $R$ be a noetherian ring. Then $\dim R[X] = \dim R+1$.
\end{theorem}

Interestingly, this is \emph{false} if $R$ is non-noetherian, cf. \cite{}.
Let $R$ be a ring of dimension $n$.

\begin{lemma}
$\dim R[x] \geq \dim R+1$.
\end{lemma}
\begin{proof}
Let $\mathfrak{p}_0 \subset \dots \subset \mathfrak{p}_n$ be a chain of primes of
length $n = \dim R$. Then $\mathfrak{p}_0 R[x] \subset \dots \subset
\mathfrak{p}_n R[x] \subset (x, \mathfrak{p}_n)R[x]$ is a chain of primes in
$R[x]$ of length $n+1$ because of the following fact: if $\mathfrak{q} \subset
R$ is prime, then so is $\mathfrak{q}R[x] \subset R[x]$.\footnote{This is
because $R[x]/\mathfrak{q}R[x] = (R/\mathfrak{q})[x]$ is a domain.} Note also
that as $\mathfrak{p}_n \subsetneq R$, we have that $\mathfrak{p}_n R[x]
\subsetneq (x, \mathfrak{p}_n)$. So this is indeed a legitimate chain.
\end{proof}

Now we need only show:
\begin{lemma}
Let $R$ be noetherian of dimension $n$. Then $\dim R[x] \leq \dim R+1$.
\end{lemma}
\begin{proof}
Let $\mathfrak{q}_0 \subset \dots \subset \mathfrak{q}_m \subset R[x]$ be a chain of primes
in $R[x]$. Let $\mathfrak{m} = \mathfrak{q}_m \cap R$. Then if we localize and
replace $R$ with $R_{\mathfrak{m}}$, we get a chain of primes of length $m$ in
$R_{\mathfrak{m}}[x]$.
In fact, we get more. We get a chain of primes of length $m$ in
$(R[x])_{\mathfrak{q}_m}$, and a \emph{local } inclusion of noetherian local rings
\[ R_{\mathfrak{m}} \hookrightarrow (R[x])_{\mathfrak{q}_m} . \]
To this we can apply the fiber dimension theorem. In particular, this implies
that
\[ m \leq \dim (R[x])_{\mathfrak{q}_m} \leq \dim R_{\mathfrak{m}} + \dim
(R[x])_{\mathfrak{q}_m} /\mathfrak{m} (R[x])_{\mathfrak{q}_m}. \]
Here $\dim R_{\mathfrak{m}} \leq \dim R = n$. So if we show that $\dim
(R[x])_{\mathfrak{q}_m} /\mathfrak{m} (R[x])_{\mathfrak{q}_m} \leq 1$, we will
have seen that $m \leq n+1$, and will be done. But this last ring is a
localization of $(R_{\mathfrak{m}}/\mathfrak{m}R_{\mathfrak{m}})[x]$, which is
a PID by the euclidean algorithm for polynomial rings over a field, and thus of
dimension  $\leq 1$.
\end{proof}

\subsection{A refined fiber dimension theorem}

Let $R$ be a local noetherian domain, and let $R \to S$ be an injection of
rings making $S$ into an $R$-algebra. Suppose $S$ is also a local domain, such
that the morphism $R \to S$ is local. This is essentially the setup of
\cref{dimpoly}, but in this section, we make the refining assumption that $S$
is \emph{essentially of finite type} over $R$; in other words, $S$ is the
localization of a finitely generated $R$-algebra.

Let $k$ be the residue field of $R$, and $k'$ that of $S$; because $R \to S$ is
local, there is induced a morphism of fields $k \to k'$.
We shall prove, following \cite{EGA}:
\newcommand{\trdeg}{\mathrm{tr.deg.}}
\begin{theorem}[Dimension formula]
\begin{equation}\label{strongfiberdim} \dim S + \trdeg S/R \leq \dim R + \trdeg
k'/k.  \end{equation}
\end{theorem}
Here $\trdeg B/A$ is more properly the transcendence degree of the quotient
field of $B$ over that of $A$.
Geometrically, it corresponds to the dimension of the ``generic'' fiber.

\begin{proof} Let $\mathfrak{m} \subset R$ be the maximal ideal.
We know that $S$ is a localization of an algebra of the form
$(R[x_1, \dots, x_k])/\mathfrak{p}$ where $\mathfrak{p} \subset R[x_1, \dots,
x_n]$ is a prime ideal $\mathfrak{q}$.
We induct on $k$.

Since we can ``d\'evissage'' the extension $R \to S$ as the
composite
\[ R \to (R[x_1, \dots, x_{k-1}]/(\mathfrak{p} \cap R[x_1, \dots,
x_{k-1}])_{\mathfrak{q'}}  \to S, \]
(where $\mathfrak{q}' \in \spec R[x_1, \dots, x_{k-1}]/(\mathfrak{p} \cap R[x_1, \dots,
x_{k-1}]$ is the pull-back of $\mathfrak{q}$),
we see that it suffices to prove \eqref{strongfiberdim} when $k=1$, that is $S$
is the localization of a quotient of $R[x]$.

So suppose $k=1$. Then we have $S = (R[x])_{\mathfrak{q}}/\mathfrak{p}$ where
$\mathfrak{q} \subset R[x]$ is another prime ideal lying over $\mathfrak{m}$.
Let us start by considering the case where $\mathfrak{q} = 0$.

\begin{lemma} Let $(R, \mathfrak{m})$ be a local noetherian domain as above.
Let $S = R[x]_{\mathfrak{q}}$ where $\mathfrak{q} \in \spec R[x]$ is a prime
lying over $\mathfrak{m}$. Then \eqref{strongfiberdim} holds with equality.
\end{lemma}
\begin{proof}
In this case, $\trdeg S/R = 1$. Now $\mathfrak{q}$
could be $\mathfrak{m} R[x]$ or a prime ideal containing that, which is then
automatically
maximal, as we know from the proof of \cref{dimpoly}. Indeed, primes
containing $\mathfrak{m}R[x]$ are
in bijection with primes of $R/\mathfrak{m}[x]$, and these come in two forms:
zero, and those generated by one element. (Note that in the former case, the
residue field is the field of rational functions $k(x)$ and in the second, the residue field is finite over
$k$.)

\begin{enumerate}
\item
In the first case, $\dim S = \dim R[x]_{\mathfrak{m}R[x]} = \dim R$ and but the
residue field extension is $(R[x]_{\mathfrak{m}R[x]})/\mathfrak{m}
R[x]_{\mathfrak{m}R[x]} = k(x)$, so $\trdeg k'/k = 1$ and the formula is
satisfied.
\item  In the second case, $\mathfrak{q}$ properly contains $\mathfrak{m}
R[x]$.
Then $\dim R[x]_{\mathfrak{q}} = \dim R + 1$, but the residue field extension
is finite. So in this case too, the formula is satisfied.
\end{enumerate}
\end{proof}


Now, finally, we have to consider the case where $\mathfrak{p} \subset R[x]$ is
not zero, and we have $S = (R[x]/\mathfrak{p})_{\mathfrak{q}}$ for
$\mathfrak{q} \in \spec R[x]/\mathfrak{p}$ lying over $\mathfrak{m}$.
In this case, $\trdeg S/R = 0$. So we need to prove
\[ \dim S \leq \dim R + \trdeg k'/k.  \]
Let us, by abuse of notation, identify $\mathfrak{q}$ with its preimage in
$R[x]$.
(Recall that $\spec R[x]/\mathfrak{p}$ is canonically identified as a closed
subset of $\spec R[x]$.)
Then we know that
\( \dim ( R[x]/\mathfrak{p})_{\mathfrak{q}}  \)
is the largest chain of primes in $R[x]$ between $\mathfrak{p}, \mathfrak{q}$.
In particular, it is at most $\dim R[x]_{\mathfrak{q}} - \mathrm{height}
\mathfrak{p}
\leq \dim R + 1 - 1 = \dim R$. So the result is clear.
\end{proof}

In \cite{EGA}, this is used to prove the geometric result that if $\phi:X  \to
Y$ is a morphism of varieties over an algebraically closed field (or a morphism
of finite type between nice schemes), then the local dimension (that is, the
dimension at $x$) of
the fiber $\phi^{-1}(\phi(x))$ is an upper semi-continuous function of $x \in X$.
\subsection{An infinite-dimensional noetherian ring}

We shall now present an example, due to Nagata, of an infinite-dimensional
noetherian ring. Note that such a ring cannot be \emph{local}.

Consider the ring $R=\mathbb{C}[\{x_{i,j}\}_{0 \leq i \leq j}]$ of polynomials in
infinitely many variables $x_{i,j}$.
This is clearly an infinite-dimensional ring, but it is also not noetherian.
We will localize it suitably to make it noetherian.

Let $\mathfrak{p}_n \subset R$ be the
ideal  $(x_{1,n}, x_{2,n}, \dots, x_{n,n})$ for all $i \leq n$.
Let $S = R - \bigcup \mathfrak{p}_n$; this is a multiplicatively closed set.

\begin{theorem}[Nagata] The ring $S^{-1}R$ is noetherian and has infinite
dimension.
\end{theorem}

We start with
\begin{proposition}
The ring in the statement of the problem is noetherian.
\end{proposition}

The proof is slightly messy, so we first prove a few lemmas.

Let $R' = S^{-1}R$ as in the problem statement. We start by proving that every ideal in $R'$ is contained
in one of the $\mathfrak{p}_n$ (which, by abuse of notation, we identify with
their localizations in $R' = S^{-1}R$).
In particular, the $\mathfrak{p}_n$ are the maximal ideals in $R'$.

\begin{lemma}
The $\mathfrak{p}_n$ are the maximal ideals in $R'$.
\end{lemma}
\begin{proof}
We start with an observation:
\begin{quote}
If $f \neq 0 $, then $f$ belongs to only finitely many $\mathfrak{p}_n$.
\end{quote}
To see this, let us use the following notation. If $M$ is a monomial, we let
$S(M)$ denote the set of subscripts $x_{a,b}$ that occur and $S_2(M)$ the set
of second subscripts (i.e. the $b$'s).
For $f \in R$, we define $S(f)$ to be the intersection of the $S(M)$ for $M$ a
monomial occurring nontrivially in $f$. Similarly we define $S_2(f)$.

Let us prove:
\begin{lemma}
$f \in \mathfrak{p}_n$ iff $n \in S_2(f)$. Moreover, $S(f)$ and $S_2(f)$ are
finite for any $f \neq 0$.
\end{lemma}
\begin{proof}
Indeed, $f \in \mathfrak{p}_n$ iff every monomial in $f$ is divisible by some
$x_{i,n}, i \leq n$, as $\mathfrak{p}_n  = (x_{i,n})_{i \leq n}$. From this the first assertion is clear. The second too,
because $f$ will contain a nonzero monomial, and that can be divisible by only
finitely many $x_{a,b}$.
\end{proof}
From this, it is clear how to define $ S_2(f)$ for any element in $R'$,
not necessarily a polynomial in $R$. Namely, it is the set of $n$ such that $f
\in \mathfrak{p}_n$.
It is now clear, from the second statement of the lemma, that any $f \neq 0$ lies in \emph{only finitely many
$\mathfrak{p}_n$}. In particular, the observation has been proved.

Let $\mathcal{T} = \left\{ S_2(f), f \in I - 0\right\}$. \emph{I claim that
$\emptyset \in \mathcal{T}$ iff $I = (1)$.} For $\emptyset \in \mathcal{T}$ iff
there is a polynomial lying in no $\mathfrak{p}_n$. Since the union $\bigcup
\mathfrak{p}_n$ is the set of non-units (by construction), we find that the
assertion is clear.


\begin{lemma}
$\mathcal{T}$ is closed under finite intersections.
\end{lemma}
\begin{proof}
Suppose $T_1, T_2 \in \mathcal{T}$. Without loss of generality, there are
\emph{polynomials} $F_1, F_2 \in R$ such that $S_2(F_1) = T_1, S_2(F_2) = T_2$.
A generic linear combination $a F_1 + bF_2$ will involve no cancellation for
$a, b \in \mathbb{C}$, and
the monomials in this linear combination will be the union of those in $F_1$
and those in $F_2$ (scaled appropriately). So $S_2(aF_1 + bF_2) = S_2(F_1) \cap S_2(F_2)$.
\end{proof}

Finally, we can prove the result that the $\mathfrak{p}_n$ are the only maximal
ideals. Suppose $I$ was contained in no $\mathfrak{p}_n$, and form the set
$\mathcal{T}$ as above. This is a collection of finite sets. Since $I
\not\subset \mathfrak{p}_n$ for each $n$, we find that $n \notin \bigcap_{T \in
\mathcal{T}} T$. This intersection is thus empty. It follows that there is a
\emph{finite} intersection of sets in $\mathcal{T}$
which is empty as $\mathcal{T}$ consists of finite sets. But $\mathcal{T}$ is closed under intersections. There is thus
an element in $I$ whose $S_2$ is empty, and is thus a unit. Thus $I = (1)$.
\end{proof}

We have proved that the $\mathfrak{p}_n$ are the only maximal ideals. This is
not enough, though. We need:
\begin{lemma}
$R'_{\mathfrak{p}_n}$ is noetherian for each $n$.
\end{lemma}
\begin{proof}
Indeed, any polynomial involving the variables $x_{a,b}$ for $ b \neq n$ is
invertible in this ring. We see that this ring contains the field
\[ \mathbb{C}(\{x_{a,b}, b \neq n\}),  \]
and over it is contained in the field $\mathbb{C}(\left\{x_{a,b}, \forall
a,b\right\})$. It is a localization of the algebra $\mathbb{C}(\{x_{a,b}, b
\neq n\})[x_{1,n} , \dots, x_{n,n}]$ and is consequently noetherian by
Hilbert's basis theorem.
\end{proof}

The proof will be completed with:
\begin{lemma}
Let $R$ be a ring. Suppose every element $x \neq 0$ in the ring belongs to only
finitely many maximal ideals, and suppose that $R_{\mathfrak{m}}$ is noetherian
for each $\mathfrak{m} \subset R$ maximal. Then $R$ is noetherian.
\end{lemma}
\begin{proof}
Let $I \subset R$ be a nonzero ideal. We must show that it is finitely generated. We
know that $I$ is contained in only finitely many maximal ideals $\mathfrak{m}_1
, \dots , \mathfrak{m}_k$.
At each of these maximal ideals, we know that $I_{\mathfrak{m}_i}$ is finitely
generated. Clearing denominators, we can choose a finite set of generators in
$R$. So we can collect them together and get a finite set $a_1, \dots, a_N
\subset I$
which generate $I_{\mathfrak{m}_i} \subset R_{\mathfrak{m}_i}$ for each $i$. It
is not necessarily true that $J = (a_1, \dots, a_N) = I$, though we do have
$\subset$. However, $I_{\mathfrak{m}} = J_{\mathfrak{m}}$ except at finitely
many maximal ideals $\mathfrak{n}_1, \dots, \mathfrak{n}_M$ because a nonzero
element is a.e. a unit. However, these $\mathfrak{n}_j$ are not among the
$\mathfrak{m}_i$. In particular, for each $j$, there is $b_j \in I -
\mathfrak{n}_j$ as $I \not\subset \mathfrak{n}_j$. Then we find that the ideal
\[ (a_1, \dots, a_N, b_1, \dots, b_M) \subset I \]
becomes equal to $I$ in all the localizations. So it is $I$, and $I$ is finitely generated

\end{proof}

We need only see that the ring $R'$ has infinite dimension. But for each $n$, there
is a chain of primes $(x_{1,n}) \subset (x_{1,n}, x_{2,n}) \subset
\dots \subset (x_{1,n}, \dots, x_{n,n})$ of length $n-1$. The supremum of the
lengths is thus infinite.

\subsection{Catenary rings}
 \begin{definition}
   A ring $R$ is \emph{catenary} if given any two primes $\mathfrak{p}\subsetneq \mathfrak{p}'$, any two
   maximal prime chains from $\mathfrak{p}$ to $\mathfrak{p}'$ have the same length.
 \end{definition}
 Nagata showed that there are noetherian domains which are not catenary. We
 shall see that \emph{affine rings}, or rings finitely generated over a field,
 are always catenary.

 \begin{definition}
   If $\mathfrak{p}\in \spec R$, then $\dim \mathfrak{p}:= \dim R/\mathfrak{p}$.
 \end{definition}


\begin{lemma}
   Let $S$ be a $k$-affine domain with $tr.d._k S=n$, and let $\mathfrak{p}\in
	\spec S$ be height one. Then
   $tr.d._k (S/\mathfrak{p})=n-1$.
 \end{lemma}
 \begin{proof}
   \underline{Case 1}: assume $S=k[x_1,\dots, x_n]$ is a polynomial algebra. In this
   case, height 1 primes are principal, so $\mathfrak{p}=(f)$ for some $f$. Say $f$ has positive
   degree with respect to $x_1$, so $f = g_r(x_2,\dots, x_n)x_1^r + \cdots$. We have
   that $k[x_2,\dots, x_n]\cap (f)=(0)$ (just look at degree with respect to $x_1$). It
   follows that $k[x_2,\dots, x_n]\hookrightarrow S/(f)$, so $\bar x_2,\dots, \bar x_n$
   are algebraically independent in $S/\mathfrak{p}$. By $\bar x_1$ is algebraic over $Q(k[\bar
   x_2,\dots, \bar x_n])$ as witnessed by $f$. This, $tr.d._k S/\mathfrak{p}=n-1$.

   \underline{Case 2}: reduction to case 1. Let $R=k[x_1,\dots, x_n]$ be a Noether
   normalization for $S$, and let $\mathfrak{p}_0=\mathfrak{p}\cap R$. Observe that Going Down applies
   (because $S$ is a domain and $R$ is normal). It follows that $ht_R(\mathfrak{p}_0)=ht_S(\mathfrak{p})=1$.
   By case 1, we get that $tr.d. (R/\mathfrak{p}_0)=n-1$. By $(\ast)$, we get that $tr.d.
   R/\mathfrak{p}_0=tr.d. (S/\mathfrak{p})$.
 \end{proof}


 \begin{theorem}
   Any $k$-affine algebra $S$ is catenary (even if $S$ is not a domain). In fact, any
   saturated prime chain from $\mathfrak{p}$ to $\mathfrak{p}'$ has length $\dim \mathfrak{p} - \dim \mathfrak{p}'$. If $S$ is a
   domain, then all maximal ideals have the same height.
 \end{theorem}
 \begin{proof}
   Consider any chain $\mathfrak{p}\subsetneq \mathfrak{p}_1\subsetneq \cdots \subsetneq \mathfrak{p}_r = \mathfrak{p}'$. Then we
   get the chain
   \[
    S/\mathfrak{p} \twoheadrightarrow S/\mathfrak{p}_1 \twoheadrightarrow \cdots \twoheadrightarrow S/\mathfrak{p}_r
    = S/\mathfrak{p}'
   \]
   Here $\mathfrak{p}_i/\mathfrak{p}_{i-1}$ is height 1 in $S/\mathfrak{p}_{i-1}$, so each arrow decreases the
   transcendence degree by exactly 1. Therefore, $tr.d._k S/\mathfrak{p}' = tr.d._k S/\mathfrak{p} -r$.
   \[
    r = tr.d._k S/\mathfrak{p} - tr.d._k S/\mathfrak{p}' = \dim S/\mathfrak{p} - \dim S/\mathfrak{p}' = \dim \mathfrak{p}-\dim \mathfrak{p}'.
   \]
   To get the last statement, take $\mathfrak{p}=0$ and $\mathfrak{p}'=\mathfrak{m}$. Then we get that $ht(\mathfrak{m})=\dim S$.
 \end{proof}
 Note that the last statement fails in general.
 \begin{example}
   Take $S=k\times k[x_1,\dots, x_n]$. Then $ht(0\times k[x_1,\dots, x_n])=0$, but
   $ht\bigl(k\times (x_1,\dots, x_n)\bigr) = n$.
 \end{example}
 But that example is not connected.
 \begin{example}
   $S = k[x,y,z]/(xy,xz)$.
 \end{example}
 But this example is not a domain. In general, for any prime $\mathfrak{p}$ in any ring $S$, we
 have
 \[
    ht(\mathfrak{p}) + \dim \mathfrak{p} \le \dim S.
 \]
 \begin{theorem}
   Let $S$ be an affine algebra, with  minimal primes $ \{\mathfrak{p}_1,\dots, \mathfrak{p}_r\}$. Then the following
   are equivalent.
   \begin{enumerate}
     \item $\dim \mathfrak{p}_i$ are all equal.
     \item $ht(\mathfrak{p})+\dim \mathfrak{p} =\dim S$ for all primes $\mathfrak{p}\in \spec S$. In particular, if $S$
     is a domain, we get this condition.
   \end{enumerate}
 \end{theorem}
 \begin{proof}
   $(1\Rightarrow 2)$ $ht(\mathfrak{p})$ is the length of some saturated prime chain from $\mathfrak{p}$ to
   some minimal prime $\mathfrak{p}_i$. This length is $\dim \mathfrak{p}_i - \dim \mathfrak{p} = \dim S - \dim \mathfrak{p}$ (by
   condition 1). Thus, we get $(2)$.

   $(2\Rightarrow 1)$ Apply (2) to the minimal prime $\mathfrak{p}_i$ to get $\dim \mathfrak{p}_i=\dim S$ for
   all $i$.
 \end{proof}
 We finish with a (non-affine) noetherian domain $S$ with maximal ideals of different
 heights. We need the following fact.\\
 \underline{Fact}: If $R$ is a ring with $a\in R$, then there is a canonical $R$-algebra
 isomorphism $R[x]/(ax-1) \cong R[a^{-1}]$, $x\leftrightarrow a^{-1}$.
 \begin{example}
   Let $\bigl(R,(\mathfrak{p}i)\bigr)$ be a DVR with quotient field $K$. Let $S=R[x]$, and assume
   for now that we know that $\dim S=2$. Look at $\mathfrak{m}_2=(\mathfrak{p}i,x)$ and $\mathfrak{m}_1=(\mathfrak{p}i x-1)$.
   Note that $\mathfrak{m}_1$ is maximal because $S/\mathfrak{m}_1 = K$. It is easy to show that
   $ht(\mathfrak{m}_1)=1$. However, $\mathfrak{m}_2\supsetneq (x)\supsetneq (0)$, so $ht(\mathfrak{m}_2)=2$.
 \end{example}

\subsection{Dimension theory for topological spaces}
\label{subsectiondimension}
The present subsection (which consists mostly of exercises) is a digression   that may illuminate the notion of
Krull dimension.

\begin{definition}
Let $X$ be a topological space.\footnote{We do not include the empty space.} Recall that $ X$ is
\textbf{irreducible} if  cannot be written as the union of
two proper closed subsets $F_1, F_2 \subsetneq X$.

We say that a subset of $X$ is irreducible if it is irreducible with respect
to the induced topology.
\end{definition}

In general, this notion is not valid from the topological spaces familiar from
analysis. For instance:

\begin{exercise}
Points are the only irreducible subsets of $\mathbb{R}$.
\end{exercise}

Nonetheless, irreducible sets behave very nicely with respect to certain
operations. As you will now prove, if $U \subset X$ is an open subset, then
the irreducible closed subsets of $U$ are in bijection with the irreducible
closed subsets of $X$ that intersect $U$.
\begin{exercise} \label{irredifeveryopenisdense}
A space is irreducible if and only if every open set is dense, or
alternatively if every open set is connected.
\end{exercise}

\begin{exercise}
Let $X$ be a space, $Y \subset X$ an irreducible subset. Then
$\overline{Y} \subset X$ is irreducible.
\end{exercise}

\begin{exercise}
Let $X$ be a space, $U \subset X$ an open subset.
Then the map $Z \to Z \cap U$ gives a bijection between the irreducible
closed subsets of $X$ meeting $U$ and the irreducible closed subsets of $U$.
The inverse is given by $Z' \to \overline{Z'}$.
\end{exercise}

As stated above, the  notion of irreducibility is useless for spaces
like manifolds. In fact, by \rref{irredifeveryopenisdense}, a
Hausdorff space cannot be irreducible unless it consists of one point.
However, for the highly non-Hausdorff spaces encountered in algebraic geometry, this notion is very
useful.

Let $R$ be a commutative ring, and $X = \spec R$.

\begin{exercise}
A closed subset $F \subset \spec R$ is irreducible if and only if it can be
written in the form $F = V(\mathfrak{p})$ for $\mathfrak{p} \subset R$ prime.
In particular, $\spec R$ is irreducible if and only if $R$ has one minimal
prime.
\end{exercise}

In fact, spectra of rings are particularly nice: they are \textbf{sober
spaces.}
\begin{definition}
A space $X$ is called \textbf{sober} if to every irreducible closed $F \subset
X$, there is a unique point $\xi \in F$ such that $F = \overline{ \left\{\xi\right\}}$.
This point is called the \textbf{generic point.}
\end{definition}

\begin{exercise}
Check that if $X$ is any topological space and $\xi  \in X$, then the closure
$\overline{\left\{\xi\right\}}$ of the point $\xi$ is irreducible.
\end{exercise}

\begin{exercise}
Show that $\spec R$ for $R$ a ring is sober.
\end{exercise}

\begin{exercise}
Let $X$ be a space with a cover $\left\{X_\alpha\right\}$ by open subsets,
each of which is a sober space. Then $X$ is a sober space. (Hint: any
irreducible closed subset must intersect one of the $X_\alpha$, so is the
closure of its intersection with that one.)
\end{exercise}

We now come to the main motivation of this subsection, and the reason for its
inclusion here.

\begin{definition}
Let $X$ be a topological space. Then the \textbf{dimension} (or
\textbf{combinatorial dimension}) of $X$ is the maximal $k$ such that a chain
\[ F_0 \subsetneq F_1 \subsetneq \dots \subsetneq F_k \subset X  \]
with the $F_i$ irreducible, exists. This number is denoted $\dim X$ and may be
infinite.
\end{definition}

\begin{exercise}
What is the Krull dimension of $\mathbb{R}$?
\end{exercise}

\begin{exercise}
Let $X = \bigcup X_i$ be the finite union of subsets $X_i \subset X$.

\end{exercise}

\begin{exercise}
Let $R$ be a ring. Then $\dim \spec R$ is equal to the Krull dimension of $R$.
\end{exercise}

Most of the spaces one wishes to work with in standard algebraic geometry have a
strong form of compactness. Actually, compactness is the wrong word, since the
spaces of algebraic geometry are not Hausdorff.

\begin{definition}
A space is \textbf{noetherian} if every descending sequence of closed subsets
$F_0 \supset F_1 \supset \dots$ stabilizes.
\end{definition}

\begin{exercise}
If $R$ is noetherian, $\spec R$ is noetherian as a topological space.
\end{exercise}


\subsection{The dimension of a tensor product of fields}

The following very clear result  gives us the dimension of the tensor product
of fields.
\begin{theorem}[Grothendieck-Sharp]
Let $K, L$ be field extensions of a field $k$. Then
\[ \dim K \otimes_k L = \mathrm{min}(\mathrm{tr.deg.} K, \mathrm{tr.deg.} L).  \]
\end{theorem}
This result is stated in the errata of \cite{EGA}, vol IV (4.2.1.5), but that
did not make it
 well-known; apparently it was independently discovered and published again by R. Y. Sharp, ten years
 later.\footnote{Thanks to Georges Elencwajg for a helpful discussion at
\url{http://math.stackexchange.com/questions/56669/a-tensor-product-of-a-power-series/56794}.}
Note that in general, this tensor product is \emph{not} noetherian.

\begin{proof}
We start by assuming $K$ is a finitely generated, purely transcendental extension of $k$.
Then $K $ is the quotient field of a polynomial ring $k[x_1, \dots, x_n]$.
It follows that $K \otimes_k L$ is a localization of $L[x_1, \dots, x_n]$, and
consequently of dimension at most $n = \mathrm{tr.deg.} K$.

Now the claim is that if $\mathrm{tr.deg.} L > n$, then we have equality
\[ \dim K \otimes_k L = n.  \]
To see this, we have to show that $K \otimes_k L$ admits an $L$-homomorphism to
$L$. For then there will be a maximal ideal $\mathfrak{m}$ of $K \otimes_k L$ which comes from
a maximal ideal $\mathfrak{M}$ of $L[x_1, \dots, x_n]$ (corresponding to this
homomorphism). Consequently, we will have $(K \otimes_k L)_{\mathfrak{m}}  =
(L[x_1, \dots, x_n])_{\mathfrak{M}},$ which has dimension $n$.

So we need to produce this homomorphism $K \otimes_k L \to L$. Since $K =
k(x_1, \dots, x_n)$ and $L$ has transcendence degree more than $n$, we just choose $n$
algebraically independent elements of $L$, and use that to define a map of
$k$-algebras $K \to L$. By the universal property of the tensor product, we get
a section $K \otimes_k L \to L$.
This proves the result in the case where $K$ is a finitely generated, purely
transcendental extension.

Now we assume that $K$ has
finite transcendence degree over $k$, but is not necessarily purely
transcendental. Then $K$ contains a subfield $E$ which is purely transcendental
over $k$ and such that $E/K$ is algebraic. Then $K \otimes_k L$ is
\emph{integral} over its subring $E \otimes_k L$. The previous analysis applies
to $E \otimes_k L$, and by integrality the dimensions of the two objects are
the same.

Finally, we need to consider the case when $K$ is allowed to have infinite
transcendence degree over $k$. Again, we may assume that $K$ is the quotient
field of the polynomial ring $k[\left\{x_\alpha\right\}]$ (by the integrality
argument above).
We need to show that if $L$ has \emph{larger} transcendence degree than $K$,
then $\dim K \otimes_k L = \infty$. As before, there is a section $K \otimes_k
L \to L$, and $K \otimes_k L$ is a localization of  the
polynomial ring $L[\left\{x_\alpha\right\}]$.
If we take the maximal ideal in $L[\left\{x_\alpha\right\}]$ corresponding to
this section $K \otimes_k L \to L$, it is of the form $(x_\alpha -
t_\alpha)_\alpha$
for the $t_\alpha \in L$. It is easy to check that the localization of
$L[\left\{x_\alpha\right\}]$ at this maximal ideal, which is a localization of
$K \otimes_k L$, has infinite dimension.
\end{proof}


% ============================ chapters/completion.tex}
\chapter{Completions}
\label{completions}

The algebraic version of completion is essentially analogous to the familiar
process of completing a metric space as in analysis, i.e. the process whereby $\mathbb{R}$ is constructed from
$\mathbb{Q}$. Here, however, the emphasis will be on how the algebraic properties and
structure pass to the completion. For instance, we will see that the
dimension is invariant under completion for noetherian local rings.


Completions are used in geometry and number theory in order to give a finer picture of local structure; for example, taking completions of rings allows for the recovery of a topology that looks more like the Euclidean topology as it has more open sets than the Zariski topology. Completions are also used in algebraic number theory to allow for the study of fields around a prime number (or prime ideal).

\section{Introduction}

\subsection{Motivation}

Let $R$ be a commutative ring. Consider a maximal ideal $\mathfrak{m} \in \spec
R$. If one thinks of $\spec R$ as a space, and $R$ as a collection of functions
on that space, then $R_{\mathfrak{m}}$ is to be interpreted as the collection of ``germs'' of
functions defined near the point $\mathfrak{m}$. (In the language of schemes,
$R_{\mathfrak{m}}$ is the \emph{stalk} of the structure sheaf.)

However, the Zariski topology is coarse, making it difficult small neighborhoods of $\mathfrak{m}$.
Thus the word ``near'' is to be taken with a grain of salt.

\begin{example}
Let $X$ be a compact Riemann surface, and let $x \in X$. Let $R$ be the ring of
holomorphic functions on $X - \left\{x\right\}$ which are meromorphic at $x$.
In this case, $\spec R$ has the ideal $(0)$ and maximal ideals corresponding
to functions vanishing at some point in $X - \left\{x\right\}$. So $\spec R$ is $X -
\left\{x\right\}$ together with a ``generic'' point.

Let us just look at the closed points.  If we pick $y \in X - \left\{x\right\}$,
then we can consider the local ring $R_y = \left\{s^{-1}r, s(y) \neq
0\right\}$. This ring is a direct limit of the rings $\mathcal{O}(U)$ of holomorphic functions
on open sets $U$ that extend meromorphically to $X$. Here, however, $U$ ranges
only over open
subsets of $X$ containing $y$ that  are the nonzero loci of elements $R$. Thus $U$ really ranges over complements of
finite subsets. It does not range over open sets in the \emph{complex} topology.

Near $y$, $X$ looks like $\mathbb{C}$ in the \emph{complex} topology. In the Zariski topology, this
is not the case. Each localization $R_y$ actually remembers the whole Riemann
surface. Indeed, the  quotient field of $R_y$ is the rational function field of
$X$, which determines  $X$. Thus $R_y$ remembers too much, and it fails to
give a truly local picture near $y$.
\end{example}

We would like a variant of localization that would remember much less about the
global topology.

\subsection{Definition}

\begin{definition} \label{defcompletion}
Let $R$ be a commutative ring and $I \subset R$ an ideal. Then we define the
\textbf{completion of $R$ at $I$} as
\[ \hat{R}_I = \varprojlim R/I^n.  \]
By definition, this is the inverse limit of the quotients $R/I^n$, via the tower of
commutative rings
\[ \dots \to  R/I^3 \to R/I^2 \to R/I   \]
where each map is the natural reduction map. Note that $\hat{R}_I$ is
naturally an $R$-algebra. If the map $R \to \hat{R}_I$ is an isomorphism, then
$R$ is said to be \textbf{$I$-adically complete.}
\end{definition}

In general, though, we can be more general. Suppose $R$ is a commutative ring
with a linear topology. Consider a neighborhood basis at the origin consisting
of ideals
$\left\{I_\alpha\right\}$.

\begin{definition}
The \textbf{completion} $\hat{R}$ of the topological ring $R$ is the inverse limit
$R$-algebra
\[ \varprojlim R/I_\alpha,  \]
where the maps $R/I_\alpha \to R/I_\beta$ for $I_\alpha \subset I_\beta$ are
the obvious ones. $\hat{R}$ is given a structure of a topological ring via the
inverse limit topology.

If the map $R \to \hat{R}$ is an isomorphism, then $R$ is said to be
\textbf{complete.}
\end{definition}

The collection of ideals $\left\{I_\alpha\right\}$ is a directed set, so we
can talk about inverse limits over it.
When we endow $R$ with the $I$-adic topology, we see that the above definition
is a generalization of \rref{defcompletion}.

\begin{exercise}
Let $R$ be a linearly topologized ring. Then the map $R \to \hat{R}$ is injective if
and only if $\bigcap I_\alpha = 0$ for the $I_\alpha$ open ideals; that is, if
and only if $R$ is \emph{Hausdorff.}
\end{exercise}

\begin{exercise}
If $R/I_\alpha$ is finite for each open ideal $I_\alpha \subset R$, then
$\hat{R}$ is compact as a topological ring. (Hint: Tychonoff's theorem.)
\end{exercise}

\add{Notation needs to be worked out for the completion}

The case of a local ring is particularly
important. Let $R$ be a local ring and $\mathfrak{m}$ its maximal ideal. Then
the completion of $R$ with respect to $\mathfrak{m}$, denoted $\hat{R}$, is the inverse limit
$
\hat{R}=\lim_{\leftarrow}(R/\mathfrak{m}^nR)$.  We then topologize $\hat{R}$ by setting powers of $\mathfrak{m}$ to be basic open sets around $0$. The topology formed by these basic open sets is called the ``Krull'' or ``$\mathfrak{m}$-adic topology.''

In fact, the case of local rings is the most important one.
Usually, we will complete $R$ at \emph{maximal} ideals.
If we wanted to study $R$ near a prime $\mathfrak{p} \in \spec R$, we might
first replace $R$ by $R_{\mathfrak{p}}$, which is a local ring; we might
make another approximation to $R$ by completing $R_{\mathfrak{p}}$. Then we
get a \emph{complete} local ring.

\begin{definition}
Let $R$ be a ring, $M$ an $R$-module, $I \subset R$ an ideal. We define the
\textbf{completion of $M$ at $I$} as
\[ \hat{M}_I =  \varprojlim M/I^n M.  \]

This is an inverse limit of $R$-modules, so it is an $R$-module. Furthermore,
it is even an $\hat{R}_I$-module, as one easily checks. It is also functorial.
\end{definition}

In fact, we get a functor
\[ R-\mathrm{modules} \to \hat{R}_I - \mathrm{modules}.  \]


\subsection{Classical examples}
Let us give some examples.
\begin{example}
Recall that in algebraic number theory, a number field is a
finite dimensional algebraic extension of $\mathbb{Q}$.
Sitting inside of $\mathbb{Q}$ is the ring of integers, $\mathbb{Z}$. For any prime number $p\in \mathbb{Z}$, we can localize $\mathbb{Z}$ to the
 prime ideal $(p)$ giving us a local ring $\mathbb{Z}_(p)$.
 If we take the completion of this local ring we get the $p$-adic numbers $\mathbb{Q}_p$. Notice that since $\mathbb{Z}_(p)/p^n\cong\mathbb{Z}/p$, this is really the same as taking the inverse limit $\lim_{\leftarrow}\mathbb{Z}/p^n$.
\end{example}

\begin{example}
Let $X$ be a Riemann surface. Let $ x \in X$ be as before, and let $R$ be as
before: the ring of meromorphic functions on $X$ with poles only at $x$. We can
complete $R$ at the ideal $\mathfrak{m}_y \subset R$ corresponding to $y \in X - \left\{x\right\}$. This
is always isomorphic to a power series ring
\[ \mathbb{C}[[t]]  \]
where $t$ is a holomorphic coordinate at $y$.

The reason is that if one considers $R/\mathfrak{m}_y^n$, one always gets
$\mathbb{C}[t]/(t^n)$, where $t$ corresponds to a local coordinate at $y$. Thus
\emph{these} rings don't remember much about the Riemann surface. They're all
isomorphic, for instance.
\end{example}

\begin{remark}
There is always a map $R \to \hat{R}_I$ by taking the limit of the maps $R/I^i$.
\end{remark}

\subsection{Noetherianness and completions}

A priori, one might think this operation of completion gives  a big mess. The amazing thing is that for
noetherian rings, completion is surprisingly well-behaved.


\begin{proposition}
Let $R$ be noetherian, $I \subset R$ an ideal. Then $\hat{R}_I$ is noetherian.
\end{proposition}
\begin{proof}
Choose generators $x_1, \dots, x_n \in I$. This can be done as $I$ is finitely generated
Consider a power series ring
\[ R[[t_1, \dots, t_n]] ; \]
the claim is that there is a map $R[[t_1\dots t_n]] \to \hat{R}_I$ sending each
$t_i$ to $x_i  \in \hat{R}_I$. This is not trivial, since we aren't talking
about a polynomial ring, but a power series ring.

To build this map, we  want a compatible family of maps
\[ R[[t_1, \dots, t_n]] \to R[t_1, \dots, t_n]/(t_1, \dots, t_n)^k  \to R/I^k.  \]
where the second ring is the polynomial ring where homogeneous
polynomials of degree $\geq k$ are killed. There is a map from $R[[t_1, \dots, t_n]]$ to
the second ring that kills monomials of degree $ \geq k$. The second map
$R[t_1, \dots, t_n]/(t_1, \dots, t_n)^k \to R/I^k$ sends $t_i \to x_i$ and is
obviously well-defined.

So we get the map
\[ \phi:  R[[t_1, \dots, t_n]] \to \hat{R}_I ,  \]
which I claim is surjective. Let us prove this. Suppose $a \in \hat{R}_I$. Then $a$ can be thought
of as a collection of elements $(a_k) \in R/I^k$ which are compatible with one
another.  We can lift each $a_k$ to some $\overline{a_k} \in R$ in a
compatible manner, such that
\[ \overline{a_{k+1}} = \overline{a_k} + b_k, \quad b_k \in I^k.  \]
Since $b_k \in I^k$, we can write it as
\[ b_k = f_k(x_1, \dots, x_n)  \]
for $f_k$ a polynomial in $R$ of degree $k$, by definition of the generators in
$I^k$.

I claim now that
\[ a = \phi\left( \sum f_k(t_1, \dots, t_n)  \right).  \]
The proof is just to check modulo $I^k$ for each $k$. This we  do by induction.
When one reduces modulo $I^k$, one gets $a_k$ (as one easily checks).

As we have seen, $\hat{R}_I$ is the quotient of a power series ring. In the
homework, it was seen that $R[[t_1, \dots, t_n]]$ is noetherian; this is a
variant of the Hilbert basis theorem proved in class. So $\hat{R}_I$ is
noetherian.
\end{proof}


In fact, following \cite{Se65}, we shall sometimes find it convenient to note a generalization of the
above argument.

\begin{lemma} \label{grsurjective}
Suppose $A$ is a filtered ring, $M, N$ filtered $A$-modules and $\phi: M \to N$ a
morphism of filtered modules. Suppose $\gr(\phi)$ surjective and $M, N$
complete; then $\phi$ is surjective.
\end{lemma}
\begin{proof} This will be a straightforward ``successive approximation''
argument.
Indeed, let $\left\{M_n\right\}, \left\{N_n\right\}$ be the filtrations on $M,
N$.
Suppose $n \in N$.
We know that there is $m_0 \in M$ such that
\[ n -  \phi(m_0) \in N_1  \]
since $M/M_1 \to N/N_1 $ is surjective.
Similarly, we can choose $m_1 \in M_1$ such that
\[ n - \phi(m_0) -  \phi(m_1)  \in M_2  \]
because $n - \phi(m_0) \in N_1$ and $M_1/M_2 \to N_1/N_2$ is surjective. We
inductively continue the sequence $m_2, m_3, \dots$ such that it tends to zero
rapidly; we then have that $n - \phi\left( \sum m_i \right) \in \bigcap N_i$,
so $n = \phi\left(\sum m_i\right)$ as $N$ is complete.
\end{proof}



\begin{theorem} \label{grnoetherian}
Suppose $A$ is a filtered ring. Let $M$ be a filtered $A$-module, separated
with respect to its topology.
If $\gr(M)$ is noetherian over $\gr(A)$, then $M$ is a noetherian $A$-module.
\end{theorem}
\begin{proof}
If $N \subset M$, then we can obtain an induced filtration on $N$ such that
$\gr(N)$ is a submodule of $\gr(M)$. Since noetherianness equates to the
finite generation of each submodule, it suffices to show that if $\gr(M)$ is
finitely generated, so is $M$.

Suppose $\gr(M)$ is generated by homogeneous elements $\overline{e}_1, \dots,
\overline{e}_n$ of
degrees $d_1, \dots, d_n$, represented by elements $e_1, \dots, e_n \in M$. From this we can define a map
\[ A^n \to M  \]
sending the $i$th basis vector to $e_i$. This will induce a  surjection
$\gr(A^n) \to \gr(M)$. We will have to be careful, though, exactly how we
define the filtration on $A^n$, because the $d_i$ may have large degrees, and
if we are not careful, the map on $\gr$'s will be zero.

We choose the filtration such that at the $m$th level, we get the subgroup of
$A^n$ such that the $i$th coordinate is in $I_{n-d_i}$ (for
$\left\{I_n\right\}$ the filtration of $A$). It is then clear that the
associated map
\[ \gr(A^n ) \to \gr(M)  \]
has image containing each $\overline{e}_i$. Since $A^n$ is complete with
respect to this topology, we find that $A^n \to M$ is surjective by
\cref{grsurjective}.
This shows that $M$ is finitely generated and completes the proof.
\end{proof}


\begin{corollary} \label{completenoetherian}
Suppose $A$ is a ring, complete with respect to the $I$-adic topology. If
$A/I$ is noetherian and $I/I^2$ a finitely generated $A$-module, then $A$ is
noetherian.
\end{corollary}
\begin{proof}
Indeed, we need to show that $\gr(A)$ is a noetherian ring (by
\cref{grnoetherian}). But this is the ring
\[ A/I \oplus I/I^2 \oplus I^2/I^3 \oplus \dots.  \]
It is easy to see that this is generated by $I/I^2$ as an $A/I$-algebra. By
Hilbert's basis theorem, this is noetherian under the conditions of the result.
\end{proof}

\cref{completenoetherian} gives another means of showing that if a ring $A$ is
noetherian, then its completion $\hat{A}$ with respect to an ideal $I \subset A$ is
noetherian. For the algebra $\gr(A)$ (where $A$ is given the $I$-adic
topology) is noetherian because it is finitely generated over $A/I$. Moreover,
$\gr(\hat{A}) = \gr(A)$, so $\hat{A}$ is noetherian.

\section{Exactness properties}

The principal result of this section is:
\begin{theorem} \label{completionisexact}
If $R$ is noetherian and $I \subset R$ an ideal, then the construction $M \to
\hat{M}_I$ is exact when restricted to finitely generated modules.
\end{theorem}


Let's be more precise.  If $M$ is finitely generated, and
\( 0 \to M' \to M \to M'' \to 0  \)
is an exact sequence,\footnote{The ends are finitely generated by noetherianness.} then
\[ 0 \to \hat{M'}_I \to \hat{M}_I \to \hat{M''}_I \to 0  \]
is also exact.

We shall prove this theorem in several pieces.

\subsection{Generalities on inverse limits}
For a moment, let us step back and think about exact sequences of inverse
limits of abelian groups. Say we have a tower of exact sequences of abelian
groups
\[
\xymatrix{
0 \ar[r] &  \vdots \ar[d]  \ar[r] &  \vdots \ar[d]  \ar[r] & \vdots \ar[d]
\ar[r] &  0 \\
0 \ar[r] &  A_2 \ar[d]  \ar[r] &  B_2 \ar[d]  \ar[r] &  C_2 \ar[d]  \ar[r] &  0
\\
0 \ar[r] &  A_1 \ar[d]  \ar[r] &  B_1 \ar[d]  \ar[r] &  C_1 \ar[d]  \ar[r] &  0
\\
0 \ar[r] &  A_0 \ar[r] &  B_0 \ar[r] &  C_0 \ar[r] &  0
}.
\]
Then we get a sequence
\[ 0 \to \varprojlim A_n \to \varprojlim B_n \to \varprojlim C_n \to 0.  \]
In general, it is \emph{not} exact. But it is left-exact.

\begin{proposition}
Hypotheses as above, $ 0 \to \varprojlim A_n \to \varprojlim B_n \to
\varprojlim C_n$ is exact.
\end{proposition}
\begin{proof}
It is obvious that $\phi \circ \psi = 0$.

Let us first show that $\phi: \varprojlim A_n \to \varprojlim B_n$ is
injective. So suppose $a $ is in the projective limit, represented by a
compatible sequence of elements $(a_k )\in A_k$. If $\phi$ maps to zero, all
the $a_k$ go to zero in $B_k$. Injectivity of $A_k \to B_k$ implies that each
$a_k$ is zero. This implies $\phi$ is injective.

Now let us show exactness at the next step. Let $\psi:  \varprojlim B_n \to
\varprojlim C_n$ and let $b = (b_k)$ be in $\ker \psi$. This means that each
$b_k$ gets killed when it maps to $C_k$. This means that each $b_k$ comes from
something in $a_k$. These $a_k$ are unique by injectivity of $A_k \to B_k$. It
follows that the $a_k$ have no choice but to be compatible. Thus $(a_k)$ maps
into $(b_k)$. So $b$ is in the image of $\phi$.
\end{proof}

So far, so good. We get some level of exactness. But the map on the end is not
necessarily surjective. Nonetheless:

\begin{proposition}
$\psi: \varprojlim B_n \to \varprojlim C_n$ is surjective if each $A_{n+1} \to
A_n$ is surjective.
\end{proposition}
\begin{proof}
Say $c \in \varprojlim C_n$, represented by a compatible family $(c_k)$. We
have to show that there is a compatible family $(b_k) \in \varprojlim B_n$
which maps into $c$. It is easy to choose the $b_k$ \emph{individually} since
$B_k \to C_k$ is surjective. The problem is that a priori we may not get
something compatible.

We construct $b_k$ by induction on then, therefore. Assume that $b_k$ which
lifts $c_k$ has been constructed.
We know that $c_k$ receives  a map from $c_{k+1}$.
\[ \xymatrix{
& & c_{k+1 } \ar[d] \\
& b_k \ar[r] &  c_k
}.\]
Choose any $x \in B_{k+1}$ which maps to $c_{k+1}$. However, $x$ might not map
down to $b_k$, which would screw up the compatibility conditions. Next, we try to adjust $x$.
Consider $x' \in B_k$ to be the image of $x$ under $B_{k+1} \to B_k$. We know
that $x' - b_k$ maps to zero in $C_k$, because $c_{k+1}$ maps to $c_k$.
So $x' - b_k$ comes from something in $A_k$, call it $a$.
\[ \xymatrix{
& x \ar[r] &  c_{k+1 } \ar[d] \\
& b_k \ar[r] &  c_k
}.\]
But $a$ comes from some $\overline{a} \in A_{k+1}$. Then we define
\[ b_{k+1} = x - \overline{a},  \]
which adjustment doesn't change the fact that $b_{k+1}$ maps to $c_{k+1}$.
However, this adjustment makes $b_{k+1}$ compatible with $b_k$. Then we
construct the family $b_k$ by induction. We have seen surjectivity.
\end{proof}

Now, let us study the exactness of completions.
\begin{proof}[Proof of \rref{completionisexact}]

Let us try to apply the general remarks above to studying the sequence
\[ 0 \to \hat{M'}_I \to \hat{M}_I \to \hat{M''}_I \to 0.  \]
Now $\hat{M}_I = \varprojlim M/I^n$. We can construct  surjective maps
\[ M/I^n \twoheadrightarrow M''/I^n  \]
whose inverse limits lead to $\hat{M}_I \to \hat{M''}_I$. The image is
$M/(M' + I^n M)$. What is the kernel?
Well, it is $M' + I^n M/ I^n M$.  This is equivalently
\[ M'/M' \cap I^n M.  \]
So we get an exact sequence
\[ 0 \to M'/M' \cap I^n M \to M/I^n M \to M''/I^n M'' \to 0.  \]
By the above analysis of exactness of inverse limits, we get an exact sequence
\[ 0 \to \varprojlim M'/(I^n M \cap M') \to \hat{M}_I \to \hat{M''}_I \to 0.  \]
We of course have surjective maps $M'/I^n M' \to M'/(I^n M \cap M') $ though
these are generally not isomorphisms. Something ``divisible by $I^n$'' in $M$ but
in $M'$ is generally not divisible by $I^n$ in $M'$.
Anyway, we get a map
\[ \varprojlim M'/I^n M' \to \varprojlim M'/I^n M \cap M'  \]
where the individual maps are not necessarily isomorphisms. Nonetheless, I
claim that the map on inverse limits is an isomorphism. This will imply that
completion is indeed an exact functor.

But this follows because the filtrations $\left\{I^n M'\right\},
\left\{I^n M \cap M'\right\}$ are equivalent in view of the Artin-Rees lemma,
\cref{artinrees}.
\end{proof}

Last time, we were talking about completions. We showed that if $R$ is
noetherian and $I \subset R$ an ideal, an exact sequence
\[ 0 \to M' \to M \to M \to 0   \]
of finitely generated $R$-modules leads to a sequence
\[ 0 \to \hat{M'}_I \to \hat{M}_I \to \hat{M;}_I \to 0  \]
which is also exact. We showed this using the Artin-Rees lemma.

\begin{remark}
In particular, for finitely generated modules over a noetherian ring, completion is an \textbf{exact functor}: if $A \to B \to C$ is
exact, so is the sequence of completions. This can be seen by drawing in
kernels and cokernels, and using the fact that completions preserve short
exact sequences.
\end{remark}

\subsection{Completions and flatness}

Suppose that $M$ is a finitely generated $R$-module. Then there is a surjection $R^n
\twoheadrightarrow M$, whose kernel is also finitely generated as $R$ is
noetherian. It follows that
$M$ is finitely presented. In particular, there is a sequence
\[ R^m \to R^n \to M \to 0.  \]
We get an exact sequence
\[ \hat{R}^m \to \hat{R}^n \to \hat{M} \to 0  \]
where the second map is just multiplication by the same $m$-by-$n$ matrix as in
the first case.

\begin{corollary}
If $M$ is finitely generated and $R$ noetherian, there is a canonical isomorphism
\[ \hat{M}_I \simeq M \otimes_R \hat{R}_I.  \]
\end{corollary}

\begin{proof}
We know that there is a map $M \to \hat{M}_I$, so the canonical morphism
$\phi_M: M \otimes_R \hat{R}_{I} \to \hat{M}_I$ exists
(because this induces a map from $M \otimes_R \hat{R}_I$). We
need to check that it is an isomorphism.

If there is an exact sequence $M' \to M \to M'' \to 0$, there is a commutative
diagram
\[ \xymatrix{
M' \otimes_R \hat{R}_I \ar[d]^{\phi_{M'}}  \ar[r] & M \otimes_R \hat{R}_I
\ar[d]^{\phi_M}  \ar[r] &
M'' \otimes_R \hat{R}_I \ar[d] \ar[r] &  0 \\
\hat{M'}_I \ar[r] &  \hat{M}_I \ar[r] &  \hat{M''}_I \ar[r] &  0
}.\]
Exactness of completion and right-exactness of $\otimes$ implies that this
diagram is exact. It follows that if $\phi_M, \phi_{M'}$ are isomorphisms, so
is $\phi_{M''}$.

But any $M''$ appears at the end of such a sequence with $M', M$ are free by
the finite presentation argument above. So it suffices to prove $\phi$ an
isomorphism for finite frees, which reduces to the case of $\phi_R$ an
isomorphism. That is obvious.
\end{proof}

\begin{corollary}
If $R$ is noetherian, then $\hat{R}_I$ is a flat $R$-module.
\end{corollary}
\begin{proof}
Indeed, tensoring with $\hat{R}_I$ is exact (because it is completion, and
completion is exact) on the category of finitely generated $R$-modules.
Exactness on the category of all $R$-modules follows by taking direct limits,
since every module is a direct limit of finitely generated modules, and
direct limits preserve exactness.
\end{proof}


\begin{remark}
Warning: $\hat{M}_I$ is, in general, not $M \otimes_R \hat{R}_I$ when $M$ is
not finitely generated. One example to think about is $M  = \mathbb{Z}[t]$,
$R = \mathbb{Z}$. The
completion of $M$ at $I = (p)$ is the completion of $\mathbb{Z}[t]$ at $p
\mathbb{Z}[t]$, which contains elements like
\[ 1 + pt + p^2 t^2 + \dots,  \]
which belong to the completion but not to $\hat{R}_I \otimes M = \mathbb{Z}_p
[t]$.
\end{remark}

\begin{remark}
By the Krull intersection theorem, if $R$ is a local noetherian ring, then the
map from $R \to \hat{R}$ is an injection.
\end{remark}


\section{Hensel's lemma} One thing that you might be interested in doing is solving
Diophantine equations. Say $R = \mathbb{Z}$; you want to find solutions to a
polynomial $f(X) \in \mathbb{Z}[X]$. Generally, it is very hard to find
solutions. However, there are easy tests you can do that will tell you if there
are no solutions. For instance, reduce mod a prime. One way you can prove that
there are no solutions is to show that there are no solutions mod 2.

But there might be solutions mod 2 and yet you might not be sure about
solutions in $\mathbb{Z}$. So you might try mod 4, mod 8, and so on---you get a
whole tower of problems to consider. If you manage to solve all these equations, you can solve the equations in the 2-adic integers $\mathbb{Z}_2 =
\hat{\mathbb{Z}}_{(2)}$.
But the Krull intersection theorem implies that $\mathbb{Z} \to \mathbb{Z}_2$
is injective. So if you expected that there was a unique solution in
$\mathbb{Z}$, you might try looking at the solutions in $\mathbb{Z}_2$ to be
the solutions in $\mathbb{Z}$.



The moral is that solving an equation over $\mathbb{Z}_2$ is intermediate in
difficulty between $\mathbb{Z}/2$ and $\mathbb{Z}$. Nonetheless, it turns out
that solving an equation mod $\mathbb{Z}/2$ is very close to solving it over
$\mathbb{Z}_2$, thanks to Hensel's lemma.

\subsection{The result}

\begin{theorem}[Hensel's Lemma]
Let $R$ be a noetherian ring, $I \subset R$ an ideal. Let $f(X) \in R[X]$ be a
polynomial such that the equation $f(X)=0$ has a solution $ a \in R/I$.
Suppose, moreover, that $f'(a)$ is invertible in $R/I$.

Then $a$ lifts uniquely to a solution of the equation $f(X) = 0$ in $\hat{R}_I$.
\end{theorem}

\begin{example}
Let $R = \mathbb{Z}, I = (5)$. Consider the equation $f(x) = x^2 + 1 = 0$ in $R$. This
has a solution modulo five, namely $2$. Then $f'(2) = 4$ is invertible in
$\mathbb{Z}/5$. So the equation $x^2 + 1 = 0$ has a solution in $\mathbb{Z}_5$.
In other words, $\sqrt{-1} \in \mathbb{Z}_5$.
\end{example}

Let's prove Hensel's lemma.
\begin{proof}
Now we have $a \in R/I$ such that $f(a) = 0 \in R/I$ and $f'(a)$ is invertible.
The claim is going to be that for each $m \geq 1$, there is a \emph{unique}
element $a_n \in R/I^n$ such that
\[ a_n \to a \ (I), \quad f(a_n)  = 0 \in R/I^n.  \]
Uniqueness implies that this sequence $(a_n)$ is compatible, and thus gives the
required element of the completion.
It will be a solution of $f(X) = 0$ since it is a solution at each element of
the tower.

Let us now prove the claim.
For $n=1$, $a_1 = a$ necessarily.
The proof is induction on $n$. Assume that $a_n$ exists and is unique. We would like to show
that $a_{n+1}$ exists and is unique. Well, if it is going to exist, when we
reduce $a_{n+1}$ modulo $I^n$, we must get $a_n$ or uniqueness at the $n$-th
step would fail.

So let $\overline{a}$ be any lifting of $a_n$ to $R/I^{n+1}$.  Then $a_{n+1}$
is going to be that lifting plus some $\epsilon \in I^n/I^{n+1}$. We want
\[ f(\overline{a} + \epsilon) = 0 \in R/I^{n+1}.  \]
But this is
\[ f(\overline{a}) +  \epsilon f'(\overline{a})  \]
because $\epsilon^2 = 0 \in R/I^{n+1}$. However, this lets us solve for
$\epsilon$, because then necessarily $\epsilon =
\frac{-f(\overline{a})}{f'(\overline{a})} \in I^n$.
Note that $f'(\overline{a}) \in R/I^{n+1}$ is invertible. If you believe this
for a moment, then we have seen that $\epsilon$ exists and is unique; note
that $\epsilon \in I^n$ because $f(\overline{a}) \in I^n$.


\begin{lemma}
$f'(\overline{a}) \in R/I^{n+1}$ is invertible.
\end{lemma}
\begin{proof}
If we reduce this modulo $R/I$, we get the invertible element $f'(a) \in R/I$.
Note also that the $I/I^{n+1}$ is a nilpotent ideal in $R/I^{n+1}$. So we are
reduced to showing, more generally:

\begin{lemma}
Let $A$ be a ring,\footnote{E.g. $R/I^{n+1}$.} $J$ a nilpotent
ideal.\footnote{E.g. $J = I/I^{n+1}$.} Then an element $x \in A$ is invertible
if and only if its reduction in $A/J$ is invertible.
\end{lemma}
\begin{proof}
One direction is obvious. For the converse, say $x \in A$  has an invertible
image. This implies that there is $y \in A$ such that $xy \equiv 1 \mod J$. Say
$$xy = 1+m,$$ where $m \in J$. But $1+m$ is invertible because
\[ \frac{1}{1+m} = 1 - m + m^2 \pm \dots.  \]
The expression makes sense as the high powers of $m$ are zero.
So this means that $y(1+m)^{-1}$ is the inverse to $x$.
\end{proof}
\end{proof}
\end{proof}

This was one of many versions of Hensel's lemma. There are many ways you can
improve on a statement. The above version says something about
``nondegenerate'' cases, where the derivative is invertible. There are better
versions which handle degenerate cases.

\begin{example}
Consider $x^2 - 1$; let's try to solve this in $\mathbb{Z}_2$. Well,
$\mathbb{Z}_2$ is a domain, so the only solutions can be $\pm 1$. But these
have the same reduction in $\mathbb{Z}/2$. The lifting of the solution is
non-unique.

The reason why Hensel's lemma fails is that $f'(\pm 1) = \pm 2$ is not
invertible in $\mathbb{Z}/2$. But it is not far off. If you go to
$\mathbb{Z}/4$, we do get two solutions, and the derivative is at least nonzero
at those places.
\end{example}

One possible extension of Hensel's lemma is to allow the derivative to be
noninvertible, but at least to bound the degree to which it is noninvertible.
From this you can get interesting information.
But then you may have to look at equations $R/I^n$ instead of just $R/I$, where
$n$ depends on the level of noninvertibility.

Let us describe the multivariable Hensel lemma.

\begin{theorem}
Let $f_1, \dots, f_n$ be polynomials in $n$ variables over the ring $R$. Let
$J$ be the Jacobian matrix $( \frac{\partial f_i}{\partial x_j})$. Suppose
$\Delta = \det J \in R[x_1, \dots, x_n]$.

If the system $\left\{f_i(x) = 0\right\}$ has a solution $a \in (R/I)^n$ in $R/I$ for some
ideal $I$ satisfying the condition that $\Delta(a)$ is invertible, then there
is a unique solution of $\left\{f_i(x) =0\right\}$ in $\hat{R}_I^n$ which lifts $a$.
\end{theorem}
The proof is the same idea: successive approximation, using the invertibility
of $\Delta$.

\subsection{The classification of complete DVRs (characteristic zero)}
Let $R$ be a complete DVR with maximal ideal $\mathfrak{m}$ and quotient field
$F$.  We let $k:=R/\mathfrak{m}$; this is the \textbf{residue field} and is,
e.g., the integers mod $p$ for the $p$-adic integers.

The main result that we shall prove is the following:
\begin{theorem} Suppose $k$ is of characteristic zero.  Then $R \simeq k[[X]]$, the power series ring in one variable, with respect to the usual discrete valuation on $k[[X]]$.
\end{theorem}

The ``usual discrete valuation'' on the power series ring is the order at zero.  Incidentally, this applies to the (non-complete) subring of $\mathbb{C}[[X]]$ consisting of power series that converge in some neighborhood of zero, which is the ring of germs of holomorphic functions at zero; the valuation again measures the zero at $z=0$.


To prove it (following \cite{Se79}), we need to introduce another concept.  A \textbf{system of representatives} is a set $S  \subset R$ such that the reduction map $S \to k$ is bijective.  A \textbf{uniformizer} is a generator of the maximal ideal $\mathfrak{m}$.  Then:

\begin{proposition} If $S$ is a system of representatives and $\pi$ a uniformizer, we can write each $x \in R$ uniquely as
\[ x=  \sum_{i=0}^\infty s_i \pi^i, \quad \mathrm{where} \ s_i \in S.\]
\end{proposition}
\begin{proof}
Given $x$, we can find by the definitions $s_0 \in S$ with $x-s_0 \in \pi R$.  Repeating, we can write ${x-s_0}\ {\pi} \in R$ as ${x-s_0}\ {\pi} - s_1 \in \pi R$, or $x - s_0 - s_1 \pi \in \pi^2 R$.  Repeat the process inductively and note that the differences $x - \sum_{i=0}^{n} s_i \pi^i \in \pi^{n+1}R$ tend to zero.

In the $p$-adic numbers, we can take $\{0, \dots, p-1\}$ as a system of representatives, so we find each $p$-adic integer has a unique $p$-adic expansion $x = \sum_{i=0}^\infty x_i p^i$ for $x_i \in \{0, \dots, p-1\}$.
\end{proof}

We now prove the first theorem.

\begin{proof}
Note that $\mathbb{Z}-0 \subset R$ gets sent to nonzero elements in the residue field $k$, which is of characteristic zero.  This means that $\mathbb{Z}-0 \subset R$ consists of units, so $\mathbb{Q} \subset R$.

Let $L \subset R$ be a subfield.  Then $L \simeq \overline{L} \subset k$; if $t \in k - \overline{ L}$, I claim that there is $L' \supset R$ containing $L$ with $t \in \overline{L'}$.

If $t$ is transcendental, lift it to $T \in R$; then $T$ is transcendental over $L$ and is invertible in $R$, so we can take $L' := L(T)$.

If the minimal polynomial of $t$ over $\overline{L}$ is $\overline{f}(X) \in k[X]$, we have $\overline{f}(t) = 0$.  Moreover, $\overline{f}'(t) \neq 0$ because these fields are of characteristic zero and all extensions are separable.
So lift $\overline{f}(X)$ to $f(X) \in R[X]$; by Hensel lift $t$ to $u \in R$ with $f(u) = 0$.  Then $f$ is irreducible in $L[X]$ (otherwise we could reduce a factoring to get one of $\overline{f} \in \overline{L}[X]$), so $L[u] = L[X]/(f(X))$, which is a field $L'$.

So if $K \subset R$ is the maximal subfield (use Zorn's lemma), this is our system of representatives by the above argument.
\end{proof}


\section{Henselian rings}



There is a substitute for completeness that captures the essential
properties: Henselianness. A ring is Henselian if it satisfies
Hensel's lemma, more or less. We mostly follow \cite{Ra70} in the treatment.

\subsection{Semilocal rings}

To start with, we shall need a few preliminaries on semi-local rings.

Fix a local ring $A$ with maximal ideal $\mathfrak{m} \subset A$.
Fix a finite $A$-algebra $B$; by definition, $B $ is a finitely
generated $A$-module.

\begin{proposition}
Hypotheses as above, the maximal ideals of $B$ are in bijection with
the prime ideals of $B $ containing $\mathfrak{m} B$, or equivalently
the prime ideals of $\overline{B} = B \otimes_A A/\mathfrak{m}$.
\end{proposition}

\begin{proof}
We have to show that every maximal ideal of $B$ contains $\mathfrak{m}
B$. Suppose $\mathfrak{n} \subset B$ was maximal and was otherwise.
Then by Nakayama's lemma, $\mathfrak{n} + \mathfrak{m} B \neq B$ is a
proper ideal strictly containing $\mathfrak{n}$; this contradicts
maximality.

It is now clear that the maximal ideals of $B$ are in bijection
naturally with those of $\overline{B}$.
However, $\overline{B}$ is an artinian ring, as it is finite over the
field $A/\mathfrak{m}$, so every prime ideal in it is maximal.
\end{proof}



The next thing to observe is that $\overline{B}$, as an artinian ring,
decomposes  as a product of local artinian rings.
In fact, this decomposition is unique.
However, this does not mean that $B$ itself
is a product of local rings ($B$ is not necessarily artinian).
Nonetheless, if such a splitting exists, it is necessarily unique.

\begin{proposition}
Suppose $R = \prod R_i$ is a finite product of local rings $R_i$. Then
the $R_i$ are unique.
\end{proposition}
\begin{proof}
To give a decomposition $R = \prod R_i$ is equivalent to giving
idempotents $e_i$. If we had another decomposition $R = \prod S_j$,
then we would have new idempotents $f_j$. The image of each $f_j$ in
each $R_i$ is either zero or one as a local ring has no nontrivial
idempotents. From this, one can easily deduce that the $f_j$'s are
sums of the $e_i$'s, and if the $S_j$ are local, one sees that the
$S_j$'s are just the $R_i$'s permuted.
\end{proof}

In fact, there is a canonical way of determining the factors $R_i$.
A finite product of local rings as above is \textit{semi-local};
the maximal ideals $\mathfrak{m_i}$ are finite in number, and, furthermore, the
canonical map
\[ R \to \prod R_{\mathfrak{m_i}} \]
is an isomorphism.


In general, this splitting \textbf{fails} for semi-local rings, and in
particular for rings finite over a local ring.
We have seen that this splitting nonetheless works for rings finite
over a field.


To recapitulate, we can give a criterion for when a semi-local ring splits as
above.
\begin{proposition} \label{whatissplitting}
Let $R$ be a semilocal ring with maximal ideals $\mathfrak{m}_1, \dots,
\mathfrak{m}_k$. Then $R$ splits into local factors if and only if, for each
$i$, there is an idempotent $e_i \in \bigcap_{j \neq i} \mathfrak{m}_j -
\mathfrak{m}_i$. Then the rings $Re_i$ are local and $R = \prod Re_i$.
\end{proposition}
\begin{proof}
If $R$ splits into local factors, then clearly we can find such idempotents.
Conversely, suppose given the $e_i$.
Then for each $i \neq j$, $e_i e_j$ is an idempotent  $e_{ij}$ that belongs to all the
maximal ideals $\mathfrak{m}_k$. So it is in the Jacobson radical. But then $1 -
e_{ij}$ is invertible, so $e_{ij}(1-e_{ij})=0$ implies that $e_{ij} = 0$.

It follows that the $\left\{e_i\right\}$ are \emph{orthogonal} idempotents. To
see that $R = \prod Re_i$ as rings, we now need only to see that the
$\left\{e_i\right\}$ form a \emph{complete} set; that is, $\sum e_i = 1$. But
the sum $\sum e_i$ is an idempotent itself since the $e_i$ are mutually
orthogonal. Moreover, the sum $\sum e_i$ belongs to no $\mathfrak{m}_i$, so it
is invertible, thus equal to $1$. The claim is now clear, since each $Re_i$ is
local by assumption.
\end{proof}

Note that if we can decompose a semilocal ring into a product of local rings,
then we can go no further in a sense---it is easy to check that a local ring has
no nontrivial idempotents.

\subsection{Henselian rings}

\begin{definition}
A local ring $(R, \mathfrak{m})$ is \textbf{henselian} if every finite
$R$-algebra is a product of local $R$-algebras.
\end{definition}


It is clear from the remarks of the previous section that the
decomposition as a product of local algebras is unique.
Furthermore, we have already seen:

\begin{proposition}
A field is henselian.
\end{proposition}
\begin{proof}
Indeed, then any finite algebra over a field is artinian (as a
finite-dimensional vector space).
\end{proof}

This result was essentially a corollary of basic facts about artinian
rings. In general, though, henselian rings are very far from artinian. For
instance, we will see that every \emph{complete} local ring is henselian.

We continue with a couple of further easy claims.
\begin{proposition}  \label{finitehenselian}
A local ring that is finite over a henselian ring is henselian.
\end{proposition}
\begin{proof}
Indeed, if $R$ is a henselian local ring and $S$ a finite $R$-algebra, then
every finite $S$-algebra is a finite $R$-algebra, and thus splits into a product
of local rings.
\end{proof}

We have seen that henselianness of a local ring $(R, \mathfrak{m})$ with residue
field $k$ is equivalent to the condition that every finite $R$-algebra $S$ splits
into a product of local rings. Since $S \otimes_R k$ always splits into a
product of local rings, and this splitting is unique, we see that if a splitting
of $S$ exists, it necessarily lifts the splitting of $S \otimes_R k$.

Since a ``splitting'' is the same thing (by \cref{whatissplitting}) as a
complete collection of idempotents, one for each maximal ideal, we are going to
characterize henselian rings by the property that one can lift idempotents from
the residue ring.

\begin{definition}
A local ring $(R, \mathfrak{m})$ \textbf{satisfies lifting
  idempotents} if for every finite $R$-algebra $S$, the canonical
(reduction) map
between idempotents of $S$ and those of $S/\mathfrak{m}S$ is surjective.
\end{definition}

Recall that there is a functor $\idem$ from rings to sets that sends each ring
to its collection of idempotents. So the claim is that the natural map $\idem(S)
\to \idem(S/\mathfrak{m}S)$ is a surjection.

In fact, in this case, we shall see that the map $\idem(S) \to
\idem(S/\mathfrak{m}S)$ is even injective.
\begin{proposition}
The map from idempotents of $S$ to those of $S/\mathfrak{m} S$ is
always injective.
\end{proposition}
We shall not even use the fact that $S$ is a finite $R$-algebra here.

\begin{proof}
Suppose $e, e' \in S$ are  idempotents whose images in $S/\mathfrak{m}S$ are the
same. Then
\[ (e-e')^3 = e^3 -3e^2 e' + 3e'^2 e- e'^3 = e^3 - e'^3 = e - e. \]
Thus if we let $x = e - e'$, we have $x^3 - x =0$, and $x $ belongs to
$\mathfrak{m}S$. Thus
\[ x(1-x^2) = 0,  \]
and $1-x^2$ is invertible in $S$ (because $x^2$ belongs to the Jacobson radical
of $S$). Thus $x =0 $ and $e = e'$.
\end{proof}


With this, we now want a characterization of henselian rings in terms of the
lifting idempotents property.

\begin{proposition} \label{orthogonallifts}
Suppose $(R, \mathfrak{m})$ satisfies lifting idempotents, and let $S$ be a
finite $R$-algebra. Then given
orthogonal idempotents $\overline{e}_1, \dots, \overline{e}_n$ of $S/\mathfrak{m}S$, there are
mutually orthogonal lifts $\left\{e_i\right\} \in S$.
\end{proposition}

The point is that we can make the lifts mutually orthogonal. (Recall that
idempotents are \emph{orthogonal} if their product is zero.)
\begin{proof}
Indeed, by assumption we can get lifts $\left\{e_i\right\}$ which are
idempotent; we need to show that they are mutually orthogonal. But in any case
$e_i e_j$ for $i \neq j$ is an idempotent, which lies in
$\mathfrak{m}S \subset S$ and thus in the Jacobson radical. It follows that
$e_i e_j = 0$, proving the orthogonality.
\end{proof}

\begin{proposition}
A local ring is henselian if and only if it satisfies lifting idempotents.
\end{proposition}
\begin{proof}
Suppose first $(R, \mathfrak{m} )$ satisfies lifting idempotents.
Let $S$ be any finite $R$-algebra. Then $S/\mathfrak{m}S$ is artinian,
so factors as a product of local artinian rings $\prod \overline{S}_i$. This
factorization corresponds to idempotents $\overline{e}_i \in
S/\mathfrak{m}S$.
We can lift these to orthogonal idempotents $e_i \in S$ by
\cref{orthogonallifts}.
These idempotents correspond to a decomposition
\[ S = \prod S_i  \]
which lifts the decomposition $\overline{S} = \prod \overline{S}_i$. Since the
$\overline{S_i}$ are local, so are the $S_i$.
Thus $R$ is henselian.

Conversely, suppose $R$ henselian.
Let $S$ be a finite $R$-algebra and let $\overline{e} \in \overline{S} =
S/\mathfrak{m}S$ be idempotent. Since $\overline{S}$ is a product of local
rings, $\overline{e}$ is a finite sum of the primitive idempotents in
$\overline{S}$. By henselianness, each of these primitive idempotents lifts to
$S$, so $\overline{e}$ does too.
\end{proof}


\begin{proposition}
Let $R$ be a local ring and $I \subset R$ an ideal consisting of nilpotent
elements. Then $R$ is henselian if and only if
$R/I$ is.
\end{proposition}
\begin{proof} One direction is clear by \cref{finitehenselian}. For the other,
suppose $R/I$ is henselian. Let $\mathfrak{m} \subset R$ be the maximal ideal.
Let $S$ be any finite $R$-algebra; we have to show surjectivity of
\[ \idem(S) \to \idem(S/\mathfrak{m}S).  \]
However, we are given that, by henselianness of $S/I$,
\[ \idem(S/IS ) \to \idem(S/\mathfrak{m}S)  \]
is a surjection. Now we need only observe that $\idem(S) \to \idem(S/IS)$ is a
bijection. This follows because idempotents in $S$ (resp. $S/IS$) correspond
to disconnections of $\spec S$ (resp. $\spec S/IS$) by \cref{}. However, as
$I$ consists of nilpotents, $\spec S$ and $\spec S/IS$ are homeomorphic
naturally.
\end{proof}

\subsection{Hensel's lemma}

We now want to show that Hensel's lemma is essentially what characterizes
henselian rings, which explains the name.
Throughout, we use the $\overline{}$ symbol to denote reduction mod an ideal
(usually $\mathfrak{m}$ or $\mathfrak{m}$ times another ring).

\begin{proposition}  \label{factorcriterion}
Let $(R, \mathfrak{m})$ be a local ring with residue field $k$. Then $R$ is henselian if and only if,
whenever a monic polynomial $P \in R[X]$ satisfies
\[ \overline{P} = \overline{Q}\overline{R} \in k[X], \]
for some relatively prime polynomials $\overline{Q}, \overline{R} \in k[X]$,
then the factorization lifts to a factorization
\[ P = QR \in R[X].  \]
\end{proposition}
\textbf{This notation should be improved.}
\begin{proof}
Suppose $R$ henselian and suppose $P$ is a polynomial whose reduction admits
such a factorization.
Consider the finite $R$-algebra
\( S = R[X]/(P);  \)
since $\overline{S } = S/\mathfrak{m}S $ can be represented as
$k[X]/(\overline{P})$, it admits a splitting into components
\[ \overline{S} = k[X]/(\overline{Q}) \times k[X]/(\overline{R}).  \]
Since $R$ is henselian, this splitting lifts to $S$, and we get a splitting
\[ S = S_1 \times S_2.  \]
Here $S_1 \otimes k \simeq k[X]/(\overline{Q})$ and $S_2 \otimes k \simeq
k[X]/(\overline{R})$.
The image of $X$ in $S_1 \otimes k$ is annihilated by $\overline{Q}$, and the
image of $X$ in $S_2 \otimes k$ is annihilated by $\overline{R}$.

\begin{lemma}
Suppose $R$ is a local ring, $S$ a finite $R$-algebra generated
by an element $x \in S$. Suppose the image $\overline{x} \in \overline{S}=S
\otimes_R
k$ satisfies a monic polynomial equation $u(\overline{x}) = 0$. Then
there is a monic polynomial $U$ lifting $u$ such that $U(x) = 0$ (in $S$). \end{lemma}
\begin{proof}
Let $\overline{x} \in \overline{S}$ be the generating element that satisfies
$u(\overline{x})=0$, and let $x \in S$ be a lift of it.  Suppose $u$ has
rank $n$. Then $1, x, \dots,
x^{n-1}$ spans $S$ by Nakayama's lemma. Thus there is a monic polynomial $U$ of
degree $n$ that annihilates $x$; the reduction must be a multiple of $u$,
hence $u$.\end{proof}


Returning to the proposition, we see that the image of the generator $X$ in $S_1, S_2$
must satisfy polynomial equations $Q, R$ that lift $\overline{Q},
\overline{R}$. Thus $X$ satisfies $QR$ in $S[X]/(P)$; in other words, $QR$ is a
multiple of $P$, hence equal to $P$. Thus we have lifted the factorization
$\overline{P} = \overline{Q} \overline{R}$.
This proves that factorizations can be lifted.

Now, let us suppose that factorizations can always be lifted for finite
$R$-algebras. We are now going
to show that $R$ satisfies lifting idempotents.
Suppose $S$ is a finite $R$-algebra, $\overline{e}$ a primitive idempotent in
$\overline{S}$.
We can lift $\overline{e}$ to some element $e' \in S$. Since $e'$ is contained
in a finite $R$-algebra that contains $R$, we know that $e'$ is \emph{integral} over $R$,
so that we can find a map $R[X]/(P) \to S$ sending the generator $X \mapsto
e'$, for some polynomial $P$.
We are going to use the fact that $R[X]/(P)$ splits to lift the idempotent
$\overline{e}$.

Let $\mathfrak{m}_1, \dots, \mathfrak{m}_k$ be the maximal ideals of $S$.
These equivalently correspond to the points of $\spec \overline{S}$. We know
that $e'$ belongs precisely to one of the $\mathfrak{m_i}$ (because a
primitive idempotent in $\overline{S}$ is one on one maximal ideal and zero
elsewhere). Call this $\mathfrak{m}_1$, say.

We have a map $\spec S \to \spec R[X]/(P)$ coming from the map $\phi:
R[X]/(P) \to S$. We claim that the image of
$\mathfrak{m}_1$ is different from the images of the $\mathfrak{m}_j, j > 1$.
Indeed, $b \in \mathfrak{m}_j$ precisely for $j > 1$, so the image of
$\mathfrak{m}_1$ does not contain $X$. However, the image of $\mathfrak{m}_j,
j> 1$ does contain $X$.

Consider a primitive idempotent for $R[X]/(P)$ corresponding to
$\phi^{-1}(\mathfrak{m}_1)$, say $f$.  Then $f$ belongs to every other maximal
ideal of $R[X]/(P)$ but not to $\phi^{-1}(\mathfrak{m}_1)$. Thus $\phi(f)$,
which is idempotent,
belongs to $\mathfrak{m}_1$ but not to any other maximal ideal of $S$.
It follows that  $\phi(f)$ must lift $\overline{e} $, and we have completed
the proof.
\end{proof}


\begin{corollary}
If every monogenic,\footnote{That is, generated by one element.} finitely
presented and finite $R$-algebra is a product of local rings, then $R$ is
henselian.
\end{corollary}
\begin{proof}
Indeed, the proof of the above result shows that if $R[X]/(P)$ splits for
every monic $P$, then $R$ is henselian.
\end{proof}


From the above result, we can get a quick example of a non-complete henselian
ring:

\begin{example}
The integral closure of the localization $\mathbb{Z}_{(p)}$ in the
ring $\mathbb{Z}_p$ of $p$-adic integers is a henselian ring. Indeed, it is
first of all a discrete valuation ring (as we can restrict the valuation on
$\mathbb{Z}_p$; note that an element of $\mathbb{Q}_p$ which is algebraic over
$\mathbb{Q}$ and has norm at most one is \emph{integral} over
$\mathbb{Z}_{(p)}$). This follows from the criterion of
\cref{factorcriterion}. If a monic polynomial $P$ factors in the residue field, then
it factors in $\mathbb{Z}_p$, and if $P$ has coefficients integral over
$\mathbb{Z}_{(p)}$, so does any factor.
\end{example}


\begin{example}
If $k$ is a complete field with a nontrivial absolute value and $X$ is any
topological space, we can consider for each open subset $U \subset X$ the
ring $\mathcal{A}(U)$ of continuous maps $U \to k$. As $U$ ranges over the open subsets
containing an element $x$, the colimit $\varinjlim \mathcal{A}(U)$ (the
``local ring'' at $x$) is a local henselian ring. See \cite{Ra70}.
\end{example}


\begin{proposition}
Let $(R_i, \mathfrak{m}_i)$ be an inductive system of local rings and local
homomorphisms. If each $R_i$ is henselian, then the colimit $\varinjlim R_i$
is henselian too.
\end{proposition}
\begin{proof}
We already know (\cref{}) that the colimit is a local ring, and that
the maximal ideal of $\varinjlim R_i$ is the colimit $\varinjlim
\mathfrak{m}_i$.
Finally, given any monic polynomial in $\varinjlim R_i$ with a factoring in the residue
field, the polynomial and the factoring come from some finite $R_i$; the
henselianness of $R_i$ allows us to lift the factoring.
\end{proof}


\subsection{Example: Puiseux's theorem}

Using the machinery developed here, we are going to prove:

\begin{theorem}
Let $K$ be an algebraically closed field of characteristic zero. Then any
finite extension of the field of meromorphic power
series\footnote{That is, the quotient field of $K[[T]]$.} $K((T))$ is of the
form $K((T^{1/n}))$ for some $n$.
\end{theorem}
In particular, we see that any finite extension of $K((T))$ is abelian, even
cyclic. The idea is going to be to look at the integral closure of $K[[T]]$ in
the finite extension, argue that it itself is a DVR, and then refine an
``approximate'' root in this DVR of the equation $\alpha^n = T$ to an exact one.

\begin{proof}
Let $R = K[[T]]$ be the power series ring; it is a complete, and thus
henselian, DVR. Let $L$ be a finite extension of $K((T))$ of degree $n$ and $S$ the integral
closure of $R$ in $S$, which we know to be a DVR. This is a finite $R$-algebra (cf. \cref{}), so $S$ is a
product of local domains. Since $S$ is a domain, it is itself local. It is
easy to see that if $\mathfrak{n} \subset S$ is the maximal ideal, then $S$ is
$\mathfrak{n}$-adically complete (for instance because the maximal ideal of
$R$ is a power of $\mathfrak{n}$, and $S$ is a free $R$-module).

Let $\mathfrak{m} \subset R$ be the maximal ideal.
We have the formula $ef = n$, because there is only one prime of $S$ lying
above $\mathfrak{m}$. But $f = 1$ as the residue field of $R$ is algebraically
closed. Hence $e = n$, and the extension is \emph{totally} ramified.

Let $\alpha \in S$ be a uniformizer; we know that $\alpha$ is congruent,
modulo $\mathfrak{n}^2$, to something in $R$ as the residue extension is trivial. Then $\alpha^n $ is congruent to something in $R$, which must be a
uniformizer by looking at the valuation. By rescaling, we may assume
\[ \alpha^n \equiv T \mod \mathfrak{n}^2.  \]
Since the polynomial $X^n - T$ is separable in the residue field, we can
(using Hensel's lemma) refine $\alpha$ to a new $\alpha' \equiv \alpha \mod
\mathfrak{n}^2$ with
\[ \alpha'^n = T.  \]
Then $\alpha'$ is also a uniformizer at $\mathfrak{n}$ (as $\alpha' \equiv
\alpha \mod \mathfrak{n}^2$).
It follows that $R[\alpha']$ must in fact be equal to $S$,\footnote{\cref{};
a citation here is needed.}  and thus $L$ is
equal to $K((T))(\alpha') = K((T^{1/n}))$.
\end{proof}

% ============================ chapters/smoothness.tex}
\chapter{Regularity, differentials, and smoothness}


In this chapter, we shall introduce two notions. First, we shall discuss
\emph{regular} local rings. On varieties over an algebraically closed field,
regularity corresponds to nonsingularity of the variety at that point.
(Over non-algebraically closed fields, the connection is more subtle.) This
will be a continuation of the local algebra done earlier in the chapter
\cref{chdimension}
on dimension theory.

We shall next introduce the module of \emph{K\"ahler differentials} of a
morphism of rings $A \to B$, which itself can measure smoothness (though this
connection will not be fully elucidated until a later chapter).
The module of K\"ahler differentials is the algebraic analog of the
\emph{cotangent bundle} to a manifold, and we will show that for an affine
ring, it can be computed very explicitly. For a
smooth variety, we will see that this module is \emph{projective}, and hence a
good candidate of a vector bundle.

Despite the title, we shall actually wait a few chapters before introducing the
general theory of smooth morphisms.



\section{Regular local rings}
We shall start by introducing the concept of a \emph{regular local} ring, which
is one where the embedding dimension and Krull dimension coincide.
\subsection{Regular local rings}

Let $A$ be a local noetherian ring with maximal ideal $\mathfrak{m} \subset A$
and residue field $k = A/\mathfrak{m}$.
Endow $A$ with the $\mathfrak{m}$-adic topology, so that there is a natural
graded $k$-algebra $\gr(A) = \bigoplus \mathfrak{m}^i/\mathfrak{m}^{i+1}$.
This is a finitely generated $k$-algebra; indeed, a system of generators for
the ideal $\mathfrak{m}$ (considered as elements of
$\mathfrak{m}\mathfrak{m}^2$) generates $\gr(A)$ over $k$.
As a result, we have a natural surjective map of \emph{graded} $k$-algebras.
\begin{equation} \label{reglocringmap} \Sym_k \mathfrak{m}/\mathfrak{m}^2 \to
\gr(A).  \end{equation}
Here $\Sym$ denotes the \emph{symmetric algebra.}
\begin{definition} The local ring $(A, \mathfrak{m})$ is called \textbf{regular} if the above map is
an isomorphism, or equivalently if the embedding dimension of $A$ is equal to
the Krull dimension.
\end{definition}

We want to show the ``equivalently'' in the definition is justified.
One direction is easy: if \eqref{reglocringmap} is an isomorphism, then
$\gr(A)$ is a polynomial ring with $\dim_k \mathfrak{m}/\mathfrak{m}^2$
generators. But the dimension of $A$ was defined in terms of the growth of
$\dim_k \mathfrak{m}^i/\mathfrak{m}^{i+1}  = (\gr A)_i$.
For a polynomial ring on $r$ generators, however, the $i$th graded piece has
dimension a degree-$r$ polynomial in $i$ (easy verification).
As a result, we get the claim in one direction.

However, we still have to show that if the embedding dimension equals the Krull
dimension, then \eqref{reglocringmap} is an isomorphism. This will follow from
the next lemma.

\begin{lemma} If the inequality \[\dim(A) \leq
\dim_{k}(\mathfrak{m}/\mathfrak{m}^2)\]
is an equality, then \eqref{reglocringmap} is an isomorphism.
\end{lemma}
\begin{proof}
Suppose \eqref{reglocringmap} is not an isomorphism.
Then there is an element $f \in \Sym_k \mathfrak{m}/\mathfrak{m}^2$ which is
not zero and which maps to zero in $\gr(A)$; we can assume $f$ homogeneous,
since the map of graded rings is graded.


Now the claim is that if $k[x_1, \dots, x_n]$ is a polynomial ring and $f \neq
0$ a homogeneous element, then the Hilbert polynomial of $k[x_1, \dots,
x_n]/(f)$ is of degree less than $n$. This will easily imply the lemma, since
\eqref{reglocringmap} is always a surjection, and because $\Sym_k
\mathfrak{m}/\mathfrak{m}^2$'s Hilbert polynomial is of degree $\dim_{k}
\mathfrak{m}/\mathfrak{m}^2$.
Now if $\deg f = d$, then the dimension of $(k[x_1, \dots, x_n]/f)_i$ (where
$i$ is a degree) is $\dim (k[x_1, \dots, x_n])_i = \dim (k[x_1, \dots,
x_n])_{i-d}$. It follows that if $P$ is the Hilbert polynomial of the
polynomial ring, that of the quotient is $P(\cdot) - P(\cdot - d)$, which has a
strictly smaller degree.
\end{proof}

We now would like to establish a few  properties of regular local rings.

Let $A$ be a local ring and $\hat{A}$ its completion. Then
$\dim(A)=\dim(\hat{A})$, because
$A/\mathfrak{m}^n=\hat{A}/\hat{\mathfrak{m}}^n$, so the Hilbert functions are
the same. Similarly, $\gr(A)=\gr(\hat{A})$. However, by  $\hat{A}$ is also a
local ring. So applying the above lemma, we see:

\begin{proposition}
A noetherian local ring $A$ is regular if and only if its completion $\hat{A}$ is regular.
\end{proposition}

Regular local rings are well-behaved. We are eventually going to show that any
regular local ring is in fact a unique factorization domain.
Right now, we start with a much simpler claim:

\begin{proposition} A regular local ring is a domain.
\label{reg loc means domain}
\label{regdomain}
\end{proposition}
This is a formal consequence of the fact that $\gr(A)$ is a domain and the
filtration on $A$ is Hausdorff.
\begin{proof} Let $a,b \neq 0$. Note that $\bigcap \mathfrak{m}^n=0$ by the
Krull intersection theorem (\cref{krullint}), so there are $k_1$ and $k_2$ such that
$a \in \mathfrak{m}^{k_1} - \mathfrak{m}^{k_1 + 1}$ and $b \in
\mathfrak{m}^{k_2} - \mathfrak{m}^{k_2 + 1}$.
Let $\overline{a}, \overline{b}$ be the images of $a,b$ in $\gr(A)$ (in
degrees $k_1, k_2$); neither is
zero.
But then $\bar{a}\bar{b} \neq 0 \in \gr(A)$, because $\gr(A)=\Sym(\mathfrak{m}/\mathfrak{m}^2)$ is a domain. So $ab \neq 0$, as desired.
\end{proof}

\begin{exercise}
Prove more generally that if $A$ is a filtered ring with a descending
filtration of ideals $I_1 \supset I_2 \supset \dots$ such that $\bigcap I_k =
0$, and such that the associated graded algebra $\gr(A)$ is a domain, then $A$
is itself a domain.
\end{exercise}

Later we will prove the aforementioned fact that a regular local ring is a factorial
ring. One consequence of
that will be the following algebro-geometric fact. Let $X = \spec
\mathbb{C}[X_1, \dots, X_n]/I$ for some ideal $I$; so $X$ is basically a subset
of $\mathbb{C}^n$ plus some nonclosed points. Then if $X$ is smooth, we find
that $\mathbb{C}[X_1, \dots, X_n]/I$ is locally factorial. Indeed, smoothness
implies regularity, hence local factoriality. The whole apparatus of Weil and
Cartier divisors now kicks in.

\begin{exercise}
Nevertheless, it is possible to prove directly that a regular local ring $(A,
\mathfrak{m})$ is
\emph{integrally closed.}
To do this, we shall use the fact that the associated graded $\gr(A)$ is
integrally closed (as a polynomial ring).
Here is the argument:
\begin{enumerate}[a)]
\item  Let $C$ be a noetherian domain with quotient field $K$. Then $C$ is integrally closed if and
only if for every $x \in K$ such that there exists $d \in A$ with $dx^n \in A$
for all $n$, we have $x \in A$. (In general, this fails for $C$ non-noetherian;
then this condition is called being \emph{completely integrally closed}.)
\item Let $C$ be a noetherian domain. Suppose on $C$ there is an exhaustive
filtration $\left\{C_v\right\}$ (i.e. such that $\bigcap C_v = 0$) and such
that $\gr(C)$ is a \emph{completely} integrally closed domain. Suppose further that
every principal ideal is closed in the topology on $C$ (i.e., for each
principal ideal $I$, we have $I = \bigcap I + C_v$.) Then $C$ is integrally
closed too. Indeed:
\begin{enumerate}
\item  Suppose $b/a, a, b \in C$ is such that $(b/a)^n$ is contained in a finitely
generated submodule of $K$, say $d^{-1}A$ for some $d \in A$. We need to show
that $b \in Ca + C_v$ for all $v$. Write $b  = xa + r$ for $r \in C_{w} -
C_{w+1}$. We
will show that ``$w$'' can be improved to $w+1$ (by changing $x$).
To do this, it suffices to write $r \in Ca + C_{w+1}$.
\item  By hypothesis, $db^n \in Ca^n$ for all $n$. Consequently $dr^n \in Ca^n$
for all $n$.
\item Let $\overline{r}$ be the image of $r$ in $\gr(C)$ (in some possibly
positive homogeneous degree; choose the unique one such that the image of $r$
is defined and not zero). Choosing $\overline{d}, \overline{a}$ similarly, we
get $\overline{d} \overline{r}^n$ lies in the ideal of $\overline{a}^n$ for all
$n$. This implies $\overline{r}$ is a multiple of $\overline{a}$. Deduce that
$r \in Ca + C_{w+1}$.
\end{enumerate}
\item The hypotheses of the previous part apply to a regular local ring, which
is thus integrally closed.
\end{enumerate}
The essential part of this argument is explained in \cite{Bo68}, ch. 5, \S 1.4.
The application to regular local rings is mentioned in \cite{EGA}, vol. IV, \S
16.
\end{exercise}


We now give a couple of easy examples. More interesting examples will come in
the future.
Let $R$ be a noetherian local ring with maximal ideal $\mathfrak{m}$ and
residue field $k$.

\begin{example}
If $\dim(R)=0$, i.e. $R$ is artinian, then $R$ is regular iff the maximal ideal
is zero, i.e. if $R$ is a field.
Indeed, the requirement for regularity is that $\dim_k \mathfrak{m}/\mathfrak{m}^2 = 0$, or
$\mathfrak{m} = 0$ (by Nakayama). This implies that $R$ is a field.
\end{example}

Recall that $\dim_k \mathfrak{m}/\mathfrak{m}^2$ is the size of the minimal set
of generators of the ideal $\mathfrak{m}$, by Nakayama's lemma. As a result, a
local ring is regular if and only if the maximal ideal has a set of generators
of the appropriate size. This is a refinement of the above remarks.

\begin{example}
If $\dim(R) =1$, then $R$ is regular iff the maximal ideal $\mathfrak{m}$ is
principal (by the preceding observation).
The claim is that this happens if and only if $R$ is  a DVR. Certainly a DVR is
regular, so only the other direction is interesting.
But it is easy to see that a local domain whose maximal ideal is principal is a
DVR (i.e. define the valuation of $x$ in terms of the minimal $i$ such that $x
\notin \mathfrak{m}^i$).
\end{example}
We find:
\begin{proposition}
A one-dimensional regular local ring is the same thing as a DVR.
\end{proposition}


Finally, we extend the notion to general noetherian rings:
\begin{definition}
A general noetherian ring is called \textbf{regular} if every localization at a
maximal ideal is a regular local ring.
\end{definition}
In fact, it turns out that if a noetherian ring is regular, then so are
\emph{all} its localizations. This fact relies on a fact, to be proved in the
distant future, that the localization of a regular local ring at a prime ideal is regular.
\subsection{Quotients of regular local rings}

We now study quotients of regular local rings.
In general, if $(A, \mathfrak{m})$ is a regular local ring and $f_1, \dots, f_k \in
\mathfrak{m}$, the quotient $A/(f_1, \dots, f_k)$ is far from being regular.
For instance, if $k$ is a field and $A$ is $k[x]_{(x)}$ (geometrically, this is
the local ring of the affine line at the origin), then $A/x^2 =
k[\epsilon]/\epsilon^2$ is not a regular local ring; it is not even a domain.
In fact, the local ring of \emph{any} variety at a point is a \emph{quotient} of a
regular local ring, and this is because any variety locally sits inside affine
space.\footnote{Incidentally, the condition that a noetherian local ring $(A,
\mathfrak{m})$ is a
quotient of a regular local ring  $(B, \mathfrak{n})$ imposes conditions on
$A$: for instance, it has to be \emph{catenary.} As a result, one can obtain
examples of local rings which cannot be expressed as quotients in this way.}

\begin{proposition}
If $(A, \mathfrak{m}_A)$ is a regular local ring, and $f \in \mathfrak{m}$ is such that $f \in
\mathfrak{m}_A- \mathfrak{m}_A^2$. Then $A'=A/fA$ is also regular of dimension $\dim(A)-1$.
\label{reg loc mod f still reg loc}
\end{proposition}
\begin{proof} First let us show the dimension part of the statement. We know
from \cref{dimdropsbyone} that the dimension has to drop precisely by one (since $f$ is  a
nonzerodivisor on $A$ by \cref{regdomain}).


Now we want to show that $A' = A/fA$ is regular.
Let $\mathfrak{m}_{A'} = \mathfrak{m}/fA$ be the maximal ideal of $A'$.
Then we should show that
$\dim_{A'/\mathfrak{m}_{A'}}(\mathfrak{m}_{A'}/\mathfrak{m}_{A'}^2)=\dim(A')$,
and it suffices to see that  \begin{equation} \label{randombnd}
\dim_{A'/\mathfrak{m}_{A'}}(\mathfrak{m}_{A'}/\mathfrak{m}_{A'}^2) \leq
\dim_{A/\mathfrak{m}_A}(\mathfrak{m}_{A}/\mathfrak{m}_A^2)-1.\end{equation}
In other words, we have to show that the embedding dimension drops by one.


Note that the residue fields $k=A/\mathfrak{m}_A, A'/\mathfrak{m}_{A'}$ are
naturally isomorphic.
To see \eqref{randombnd}, we use the natural surjection of $k$-vector spaces
\[ \mathfrak{m}_A/\mathfrak{m}_A^2 \to \mathfrak{m}_{A'}/\mathfrak{m}_{A'}^2.  \]
Since there is a nontrivial kernel (the class of $f$ is in the kernel), we
obtain the inequality \eqref{randombnd}.
\end{proof}



\begin{corollary} \label{quotientreg44} Consider elements $f_1, \ldots f_m$ in $\mathfrak{m}$ such
that $\bar{f_1}, \ldots \bar{f_m} \in \mathfrak{m}/\mathfrak{m}^2$ are linearly independent. Then $A/(f_1, \ldots f_m)$ is regular with $\dim(A/(f_1, \ldots f_m))=\dim(A)-m$
\label{reg local mod fs still reg loc}
\end{corollary}
\begin{proof} This follows from \cref{reg loc mod f still reg loc} by induction. One just needs to check that in $A_1=A/(f_1)$, $\mathfrak{m}_1=\mathfrak{m}/(f_1)$, we have that $f_2, \ldots f_m$ are still linearly independent in $\mathfrak{m}_1/\mathfrak{m}_1^2$. This is easy to check.
\end{proof}

\begin{remark}
In fact, note in the above result that each $f_i$ is a \emph{nonzerodivisor} on $A/(f_1, \dots,
f_{i-1})$, because a regular local ring is a domain. We will later say that the
$\left\{f_i\right\}$ form a \emph{regular sequence.}
\end{remark}

We can now obtain a full characterization of when a quotient of a regular local
ring is still regular; it essentially states that the above situation is the
only possible case. Geometrically, the intuition is that we are analyzing when
a subvariety of a smooth variety is smooth; the answer is when the subvariety
is cut out by functions with linearly independent images in the maximal ideal
mod its square.

This corresponds to the following fact: if $M$ is a smooth manifold and $f_1,
\dots, f_m$ smooth functions such that the gradients $\left\{df_i\right\}$ are
everywhere independent, then the common zero locus of the $\left\{f_i\right\}$
is a smooth submanifold of $M$, and conversely every smooth submanifold of $M$
locally looks like that.

\begin{theorem} \label{quotientreg} Let $A_0$ be a regular local ring of dimension $n$, and
let $I \subset A_0$ be a proper ideal. Let $A = A_0/I$.
 Then the following are equivalent
\begin{enumerate}
\item $A$ is regular.
\item There are elements $f_1, \ldots f_m \in I$ such that $\bar{f_1}, \ldots \bar{f_m}$ are linearly independent in $\mathfrak{m}_{A_0}/\mathfrak{m}_{A_0}^2$ where $m=n-\dim(A)$ such that $(f_1, \ldots f_m)=I$.
\end{enumerate}
\label{reg loc main thm}
\end{theorem}

\begin{proof} \textbf{(2) $\Rightarrow$ (1)} This is exactly the statement of
\cref{reg local mod fs still reg loc}.

\noindent \textbf{(1) $\Rightarrow$ (2)}
Let $k$ be the residue field of $A$ (or $A_0$, since $I$ is contained in the
maximal ideal).
We see that there is an exact sequence
\[I \otimes_{A_0} k \to \mathfrak{m}_{A_0}/\mathfrak{m}_{A_0}^2 \to \mathfrak{m}_{A}/\mathfrak{m}_{A}^2  \to 0.\]
We can obtain this from the exact sequence $I \to A_0 \to A \to 0$ by tensoring
with $k$.

By assumption $A_0$ and $A$ are regular local, so
\[\dim_{A_0/\mathfrak{m}_{A_0}}(\mathfrak{m}_{A_0}/\mathfrak{m}_{A_0}^2)=\dim(A_0)=n\]
and
\[\dim_{A_0/\mathfrak{m}_{A_0}}(\mathfrak{m}_{A}/\mathfrak{m}_{A}^2)=\dim(A)\]
so the image of $I\otimes_{A_0} k$ in $\mathfrak{m}_{A_0}/\mathfrak{m}_{A_0}^2$
has dimension $m=n-\dim(A)$. Let $\bar{f}_1, \ldots \bar{f}_m$ be a set of
linearly independent generators of the image of $I
\otimes_{A_0} k$ in $\mathfrak{m}_{A_0}/\mathfrak{m}_{A_0}^2$, and let $f_1, \ldots f_m$ be liftings to $I$.
The claim is that the $\left\{f_i\right\}$ generate $I$.

Let $I' \subset A_0$ be the ideal generated by $f_1, \ldots f_m$ and consider
$A'=A_0/I'$. Then by \cref{reg local mod fs still reg loc}, we know that $A'$
is a regular local ring with dimension $n-m=\dim(A)$. Also $I' \subset I$ so we
have an exact sequence
\[0 \to I/I' \to A' \to A \to 0\]
But  \cref{reg loc means domain}, this means that $A'$ is a domain, and we
have just seen that it has the same dimension as $A$.
Now if $I/I' \neq 0$, then $A$ would be a proper quotient of $A'$, and hence of
a \emph{smaller} dimension (because quotienting by a nonzerodivisor drops the
dimension). This contradiction shows that $I = I'$, which means that $I$ is
generated by the sequence $\left\{f_i\right\}$ as claimed.
\end{proof}

So the reason that $k[x]_{(x)}/(x^2)$ was not regular is that $x^2$ vanishes to
too high an order: it lies in the square of the maximal ideal.

We can motivate the results above further with:
\begin{definition}
In a regular local ring $(R, \mathfrak{m})$, a \textbf{regular system of
parameters} is a minimal system of generators for $\mathfrak{m}$, i.e. elements
of $\mathfrak{m}$ that project to a basis of $\mathfrak{m}/\mathfrak{m}^2$.
\end{definition}
So a quotient of a regular local ring is regular if and only if the ideal is
generated by a portion of a system of parameters.

\subsection{Regularity and smoothness}
\newcommand{\maxspec}{\mathrm{MaxSpec}}

We now want to connect the intuition (described in the past) that, in the
algebro-geometric context, regularity of a local ring corresponds to smoothness
of the associated variety (at that point).

Namely, let $R$ be  be the (reduced) coordinate ring $ \mathbb{C}[x_1, \dots, x_n]/I$ of an algebraic
variety. Let $\mathfrak{m}$ be  a maximal ideal corresponding to the origin,
so generated by $(x_1, \dots, x_n)$. Suppose $I \subset \mathfrak{m}$, which is
to say the origin belongs to the corresponding variety.
Then $\maxspec R \subset \spec R$ is the corresponding subvariety of $\mathbb{C}^n$, which is
what we apply the intuition to. Note that $0$ is in this subvariety.

Then we claim:

\begin{proposition}
$R_{\mathfrak{m}}$ is regular iff $\maxspec R$ is a smooth submanifold near $0$.
\end{proposition}
\begin{proof}
We will show that regularity implies smoothness. The other direction is
omitted for now.

Note that $S = \mathbb{C}[x_1, \dots, x_n]_{\mathfrak{m}}$ is clearly a regular
local ring of dimension $n$ ($\mathbb{C}^n$ is smooth, intuitively), and $R_{\mathfrak{m}}$ is the quotient $S/I$. By
\cref{quotientreg}, we have a good criterion for when $R_{\mathfrak{m}}$ is
regular.
Namely, it is regular if and only if $I$ is generated by elements (without loss
of generality, polynomials) $f_1, \dots, f_k$ whose images in
the quotient $\mathfrak{m}_S/\mathfrak{m}_S^2$ (where we write
$\mathfrak{m}_S$ to emphasize that this is the maximal ideal of $S$).

But we
know that this ``cotangent space'' corresponds to cotangent vectors in $\mathbb{C}^n$, and in
particular, we can say the following. There are elements $\epsilon_1, \dots,
\epsilon_n  \in \mathfrak{m}_S/\mathfrak{m}_S^2$ that form a basis for this
space (namely, the images of $x_1, \dots, x_n \in \mathfrak{m}_S$). If $f$ is a
polynomial vanishing at the origin, then the image of $f$ in
$\mathfrak{m}_S/\mathfrak{m}_S^2$ takes only the linear terms---that is, it can
be identified with
\[ \sum \frac{\partial f}{\partial x_i}|_{0} \epsilon_i, \]
which is essentially the gradient of $f$.

It follows that $R_{\mathfrak{m}}$ is regular if and only if $I$ is generated
(in $R_{\mathfrak{m}}$, so we should really say $IR_{\mathfrak{m}}$)
by a family of polynomials vanishing at zero with linearly independent
gradients, or if the variety is cut out by the vanishing of such a family of
polynomials.  However, we know that this implies that the variety is locally a
smooth manifold (by the inverse function theorem).
\end{proof}

The other direction is a bit trickier, and will require a bit of ``descent.''
For now, we omit it. But we have shown \emph{something} in both directions: the
ring $R_{\mathfrak{m}}$ is regular if and only if $I$ is generated
locally (i.e., in $R_{\mathfrak{m}}$ by a family of polynomials with linearly
independent gradients). Hartshorne uses this as the definition of smoothness in
\cite{Ha77}, and thus obtains the result that a variety over an algebraically
closed field (not necessarily $\mathbb{C}$!) is smooth if and only if its local rings are regular.

\begin{remark}[Warning] This argument proves that if $R \simeq K[x_1, \dots,
x_n]/I$ for $K$ algebraically closed, then $R_{\mathfrak{m}}$ is regular local for some maximal ideal
$\mathfrak{m}$ if the corresponding algebraic variety is smooth at the
corresponding point. We proved this in the special case $K  = \mathbb{C}$ and
$\mathfrak{m}$ the ideal of the origin.

If $K$ is not algebraically closed, we \textbf{can't assume} that any maximal
ideal corresponds to a point in the usual sense. Moreover, if $K$ is not
perfect, regularity does \textbf{not} imply smoothness. We have not quite
defined smoothness, but here's a definition: smoothness means that the local
ring you get by base-changing $K$ to the algebraic closure is regular. So what
this means is that
regularity of affine rings over a field $K$ is not preserved under
base-change from $K$ to $\overline{K}$.
\end{remark}

\begin{example} Let $K$ be non-perfect of characteristic $p$. Let $a$ not have
a $p$th root.
Consider $K[x]/(x^p -a)$. This is a regular local ring of dimension zero, i.e.
is a field. If $K$ is replaced by its algebraic closure, then we get
$\overline{K}[x]/(x^p - a)$, which is $\overline{K}[x]/(x- a^{1/p})^p$. This is
still zero-dimensional but is not a field. Over the algebraic closure, the ring
fails to be regular.
\end{example}



\subsection{Regular local rings look alike}
So, as we've seen, regularity corresponds to smoothness. Complex analytically,
all smooth points are the same though---they're locally $\mathbb{C}^n$.
Manifolds have no local invariants.
We'd like
an algebraic version of this. The vague
claim is that all regular local rings of the same dimension ``look alike.''
We have already seen one instance of this phenomenon: a regular local
ring's associated graded is uniquely determined by its dimension (as a
polynomial ring). This was in fact how we defined the notion, in part.
Now we would like to transfer this to statements about things
closer to $R$.

Let $(R, \mathfrak{m})$ be a regular local ring.
\textbf{Assume now for simplicity that the residue field of $k=R/\mathfrak{m}$
maps back into $R$.} In other words, $R$ contains a copy of its residue field,
or there is a section of $R \to k$.  This is always true in the case we
use for geometric intuition---complex algebraic geometry---as the
residue field at any maximal ideal is just $\mathbb{C}$ (by the
Nullstellensatz), and one works with $\mathbb{C}$-algebras.

Choose generators $y_1, \dots, y_n \in
\mathfrak{m}$ where $n = \dim_k \mathfrak{m}/\mathfrak{m}^2$ is the embedding
dimension. We get a map in the other direction
\[ \phi:k[Y_1, \dots, Y_n] \to R, \quad Y_i \mapsto y_i,  \]
thanks to the section $k \to R$. This map from the polynomial ring is not
an isomorphism (the polynomial ring is not local), but if we let $\mathfrak{m} \subset R$ be the maximal ideal
and $\mathfrak{n} = (y_1, \dots, y_n)$,  then the map on associated gradeds is
an isomorphism (by definition). That is, $\phi:
\mathfrak{n}^t/\mathfrak{n}^{t+1} \to \mathfrak{m}^t/\mathfrak{m}^{t+1}$ is an
isomorphism for each $t \in \mathbb{Z}_{\geq 0}$.

Consequently, $\phi$ induces an isomorphism
\[ k[Y_1, \dots,Y_n]/\mathfrak{n}^t \simeq R/\mathfrak{m}^t  \]
for all $t$, because it is an isomorphism on the associated graded level.
So this in turn is equivalent, upon taking inverse limits, to the statement that
$\phi$ induces an isomorphism
\[ k[[Y_1, \dots, Y_n ]] \to \hat{R} \]
at the level of completions.

We can now conclude:
\begin{theorem}
Let $R$ be a regular local ring of dimension $n$. Suppose $R$ contains a copy
of its residue field $k$. Then, as $k$-algebras, $\hat{R} \simeq k[[Y_1, \dots, Y_m]]$.
\end{theorem}

Finally:
\begin{corollary}
A complete noetherian regular local ring that contains a copy of its residue
field $k$ is a power series ring over $k$.
\end{corollary}

It now makes sense to say:
\begin{quote}
\textbf{All \emph{complete} regular local rings of the same dimension look
alike.} (More precisely, this is true when $R$ is assumed to contain a copy of
its residue field, but this is not a strong assumption in practice. One can
show that this will be satisfied if $R$ contains \emph{any}
field.\footnote{This is not always satisfied---take the $p$-adic integers, for instance.})
\end{quote}

We won't get into the precise statement of the general structure theorem, when
the ring is not assumed to contain its residue field, but a safe
intuition to take away from this is the above bolded statement.
Note that ``looking alike'' requires the completeness, because completions are
intuitively like taking analytically local invariants (while localization
corresponds to working \emph{Zariski} locally, which is much weaker).


\section{K\"ahler differentials}
\subsection{Derivations and K\"ahler differentials} Let $R$ be a ring with the maximal ideal
$\mathfrak{m}$. Then there is a $R/\mathfrak{m}$-vector space
$\mathfrak{m}/\mathfrak{m}^2$. This is what we would like to think of as the
``{cotangent space}'' of $\spec R$ at $\mathfrak{m}$. Intuitively, the
cotangent space is what you get by differentiating functions which vanish at
the point, but
differentiating functions that vanish twice should give zero. This is the moral
justification.
(Recall that on a smooth manifold $M$, if $\mathcal{O}_p$ is the local ring of
smooth functions defined in a neighborhood of $p \in M$, and $\mathfrak{m}_p
\subset \mathcal{O}_p$ is the maximal ideal consisting of ``germs'' vanishing
at $p$, then the cotangent space $T_p^* M$ is naturally
$\mathfrak{m}_p/\mathfrak{m}_p^2$.)

A goal might be to generalize this. What if you wanted to think about all
points at once? We'd like to describe the ``cotangent bundle'' to $\spec R$ in
an analogous way. Let's try and describe what would be a section to this
cotangent bundle. A section of $\Omega^*_{\spec R}$ should be the same
thing as a ``1-form'' on $\spec R$. We don't know what a 1-form is yet, but at
least we can give some examples. If $f \in R$, then $f$ is a ``function'' on
$\spec R$, and its ``differential'' should be a 1-form. So there should be a
``$df$'' which should be a 1-form.
This is analogous to the fact that if $g$ is a real-valued function on the
smooth manifold $M$, then there is a 1-form $dg$.

We should expect the rules $d(fg)= df+dg$ and $d(fg) = f(dg) + g(df)$ as the
usual rules of differentiation. For this to make sense, 1-forms should be an
$R$-module.
Before defining the appropriate object, we start with:

\begin{definition}
Let $R$ be a commutative ring, $M$ an $R$-module. A \textbf{derivation} from
$R$ to $M$ is a map $D: R \to M$ such that the two identities below hold:
\begin{gather} D(fg)= Df + Dg  \\
 D(fg) = f(Dg) + g(Df).  \end{gather}
\end{definition}
These equations make sense as $M$ is an $R$-module.

Whatever a 1-form on $\spec R$ might be, there should be a derivation
\[ d: R \to \left\{\text{1--forms}\right\}.  \]
An idea would be to \emph{define} the 1-forms or the ``cotangent bundle''
$\Omega_R$ by a
universal property. It should be universal among $R$-modules with a derivation.

To make this precise:
\begin{proposition}
There is an $R$-module $\Omega_R$ and a derivation $d_{\mathrm{univ}} : R \to
\Omega_R$ satisfying the following universal property. For all $R$-modules
$M$, there is a canonical isomorphism
\[ \hom_{R}(\Omega_R, M) \simeq \mathrm{Der}(R, M)  \]
given by composing the universal $d_{\mathrm{univ}}$ with a map $\Omega_R \to M$.
\end{proposition}

That is, any derivation $d: R \to M$ factors through this universal derivation
in a unique way. Given the derivation $d: R \to M$, we can make the following diagram
commutative in a unique way such that $\Omega_R \to M$ is a morphism of
$R$-modules:
\[
\xymatrix{
R \ar[r]^d \ar[d]  &  M \\
\Omega_R \ar[ru]^{d_{\mathrm{univ}}}
}
\]

\begin{definition}
$\Omega_R$ is called the module of \textbf{K\"ahler differentials} of $R$.
\end{definition}

Let us now verify this proposition.
\begin{proof}
This is like the verification of the tensor product. Namely, build a free
gadget and quotient out to enforce the desired relations.

Let $\Omega_R$ be the quotient of the free $R$-module generated by elements
$da$ for $a \in R$ by enforcing the relations
\begin{enumerate}
\item $d(a+b) =da + db$.
\item $d(ab) = adb + bda$.
\end{enumerate}
By construction, the map $a \to da$ is a derivation $R \to \Omega_R$.
It is easy to see that it is universal. Given a derivation $d': R \to M$, we get a
map $\Omega_R \to M$ sending $da \to d'(a), a \in R$.
\end{proof}

The philosophy of Grothendieck says that we should do this, as with everything,
in a relative context.
Indeed, we are going to need a slight variant, for the case of a \emph{morphism} of
rings.

\subsection{Relative differentials}

On a smooth manifold $M$, the derivation $d$ from smooth functions to 1-forms
satisfies an additional property: it maps the constant functions to zero.
This is the motivation for the next definition:

\begin{definition}
Let $f: R \to R'$ be a ring-homomorphism. Let $M$ be an $R'$-module. A
derivation $d: R' \to M$ is \textbf{$R$-linear if $d(f(a)) = 0, a \in R$.}
This is equivalent to saying that $d$ is an $R$-homomorphism by the Leibnitz
rule.
\end{definition}

Now we want to construct an analog of the ``cotangent bundle'' taking into
account linearity.

\begin{proposition}
Let $R'$ be an $R$-algebra.
Then there is a universal $R$-linear derivation $R'
\stackrel{d_{\mathrm{univ}}}{\to} \Omega_{R'/R}$.
\end{proposition}
\begin{proof}
Use the same construction as in the absolute case. We get a map $R' \to
\Omega_{R'}$ as before. This is not generally $R$-linear, so one has to
quotient out by the images of $d(f(r)), r \in R$.
In other words, $\Omega_{R'/R}$ is the quotient of the free $R'$-module on
symbols $\left\{dr', r' \in R'\right\}$ with the relations:
\begin{enumerate}
\item $d(r_1' r_2') = r'_1 d(r_2') + d(r'_1) r_2'$.
\item $d(r_1' + r_2') = dr_1' + dr_2'$.
\item  $dr = 0$ for $r \in R$ (where we identify $r$ with its image $f(r)$ in
$R'$, by abuse of notation).
\end{enumerate}
\end{proof}

\begin{definition}
$\Omega_{R'/R}$ is called the module of \textbf{relative K\"ahler
differentials,} or simply K\"ahler differentials.
\end{definition}

Here $\Omega_{R'/R}$ also corepresents a simple functor on the category of
$R'$-modules: given an $R'$-module $M$, we have
\[ \hom_{R'}(\Omega_{R'/R}, M) = \mathrm{Der}_R(R', M),  \]
where $\mathrm{Der}_R$ denotes $R$-derivations.
This is a \emph{subfunctor} of the functor $\mathrm{Der}_R(R', \cdot)$, and so
by Yoneda's lemma there is a natural map $\Omega_{R'} \to \Omega_{R'/R}$.
We shall expand on this in the future.

\subsection{The case of a polynomial ring}
Let us do a simple example to make this more concrete.

\begin{example} \label{polynomialringdiff}
Let $R' = \mathbb{C}[x_1, \dots, x_n], R = \mathbb{C}$. In this case, the claim
is that there is an isomorphism
\[ \Omega_{R'/R} \simeq R'^n.  \]
More precisely, $\Omega_{R'/R}$ is free on $dx_1, \dots,dx_n$. So the cotangent
bundle is ``free.'' In general, the module $\Omega_{R'/R}$ will not be free, or
even projective, so the intuition that it is a vector bundle will be rather
loose. (The projectivity will be connected to \emph{smoothness} of $R'/R$.)

\begin{proof}
The construction $f \to \left( \frac{\partial f}{\partial x_i}  \right)$ gives
a map $R' \to R'^n$. By elementary calculus, this is a derivation, even an
$R$-linear derivation.  We get a map
\[ \phi:\Omega_{R'/R} \to R'^n  \]
by the universal property of the K\"ahler differentials. The claim is that this
map is an isomorphism. The map is characterized by sending $df$ to $\left(
\frac{\partial f}{\partial x_i}\right)$. Note that $dx_1, \dots, dx_n$ map to a
basis of $R'^n$ because differentiating $x_i$ gives 1 at $i$ and zero at $j
\neq i$. So we see that $\phi$ is surjective.

There is a map $\psi: R'^n \to \Omega_{R'/R}$ sending $\left(a_i  \right)$ to
$\sum a_i dx_i$. It is easy to check that $\phi \circ \psi = 1$ from the
definition of $\phi$. What we still need to show is that $\psi \circ \phi =1$.
Namely, for any $f$, we want to show that $\psi \circ \phi(df) = df$ for $f \in
R'$. This is precisely the claim that $df = \sum \frac{\partial f}{\partial
x_i} dx_i$. Both sides are additive in $f$, indeed are derivations, and
coincide on monomials of degree one, so they are equal.
\end{proof}

\end{example}

By the same reasoning, one can show more generally:
\begin{proposition}
If $R$ is any ring, then there is a canonical isomorphism
\[ \Omega_{R[x_1, \dots, x_n]/R} \simeq \bigoplus_{i=1}^n R[x_1, \dots, x_n]
dx_i,  \]
i.e. it is $R[x_1, \dots, x_n]$-free on the $dx_i$.
\end{proposition}

This is essentially the claim that, given an $R[x_1, \dots, x_n]$-module $M$
and elements $m_1, \dots, m_n \in M$, there is a \emph{unique} $R$-derivation
from the polynomial ring into $M$ sending $x_i\mapsto m_i$.
\subsection{Exact sequences of K\"ahler differentials}
We now want to prove a few basic properties of K\"ahler differentials, which
can be seen either from the explicit construction or in terms of the functors
they represent, by formal nonsense.
These results will be useful in computation.

 Recall that if
$\phi: A \to B$ is a map of rings, we can define a $B$-module
\( \Omega_{B/A}\)  which is generated by formal symbols $ dx|_{x \in
B}$ and subject to the relations $d(x+y) = dx+dy$, $d(a)=0, a \in A$,
and $d(xy) = xdy + ydx$.
By construction, $\Omega_{B/A}$ is the receptacle from the universal $A$-linear
derivation into a $B$-module.

Let $A \to B \to C$ be a triple of maps of rings. There is an obvious map $dx \to dx$
\[ \Omega_{C/A} \to \Omega_{C/B}  \]
where both sides have the same generators, except with a few additional
relations on $\Omega_{C/B}$. We have to quotient by $db, b \in B$. In
particular, there is a map $\Omega_{B/A} \to \Omega_{C/A}$, $dx \to dx$, whose images
generate the kernel. This induces a map
\[ C \otimes_B \Omega_{B/A} \to \Omega_{C/A}.  \]
The image is the $C$-module generated by $db|_{b \in B}$, and this is the
kernel of the previous map.
We have proved:
\begin{proposition}[First exact sequence] \label{firstexactseq} Given a sequence $A \to B \to C$ of rings, there is an exact sequence
\[  C \otimes_B \Omega_{B/A} \to \Omega_{C/A} \to \Omega_{C/B} \to 0 .\]
\end{proposition}
\begin{proof}[Second proof]
There is, however, a more functorial means of seeing this sequence, which we
now describe.
Namely, let us consider the category of $C$-modules, and the functors
corepresented by these three objects. We have, for a $C$-module $M$:
\begin{gather*}
\hom_C(\Omega_{C/B}, M) = \mathrm{Der}_B(C, M) \\
\hom_C(\Omega_{C/A}, M) = \mathrm{Der}_A(C, M) \\
\hom_C(C \otimes_B \Omega_{B/A}, M) = \hom_B(\Omega_{B/A}, M) = \mathrm{Der}_A(B, M).
\end{gather*}
By Yoneda's lemma, we know that a map of modules is the same thing as a natural
transformation between the corresponding corepresentable functors, in the
reverse direction.
It is easy to see that there are natural transformations
\[ \mathrm{Der}_B(C, M) \to \mathrm{Der}_A(C, M), \quad \mathrm{Der}_A(C, M) \to \mathrm{Der}_A(B, M)  \]
obtained by restriction in the second case, and by doing nothing in the first
case (a $B$-derivation is automatically an $A$-derivation).
The induced maps on the modules of differentials are precisely those described
before; this is easy to check (and we could have defined the maps by these
functors if we wished). Now to say that the sequence is right exact is to say
that for each $M$, there is an exact sequence of abelian groups
\[ 0 \to \mathrm{Der}_B(C, M) \to \mathrm{Der}_A(C, M) \to \mathrm{Der}_A(B, M).  \]
But this is obvious from the definitions: an $A$-derivation is a $B$-derivation
if and only if the restriction to $B$ is trivial.
This establishes the claim.
\end{proof}



Next, we are interested in a second exact sequence. In the past
(\cref{polynomialringdiff}), we computed the module of K\"ahler differentials
of a \emph{polynomial} algebra. While this was a special case, any algebra is a
quotient of a polynomial algebra. As a result, it will be useful to know how
$\Omega_{B/A}$ behaves with respect to quotienting $B$.

 Let $A
\to  B$ be a  homomorphism of rings and $I \subset B $ an ideal. We would like
to describe $\Omega_{B/I/A}$. There is a map
\[ \Omega_{B/A} \to \Omega_{B/I/A}  \]
sending $dx$ to $d \overline{x}$ for $\overline{x}$ the reduction of $x$ in
$B/I$. This is surjective on generators, so it is surjective. It is not
injective, though. In $\Omega_{B/I/A}$, the generators $dx, dx'$ are identified
if $x \equiv x' \mod I$.  Moreover, $\Omega_{B/I/A}$ is a
$B/I$-module.
This means that there will be additional relations for that. To remedy this, we
can tensor and consider the morphism
\[ \Omega_{B/A} \otimes_B B/I \to \Omega_{B/I/A} \to 0.  \]

Let us now define a map
\[ \phi: I /I^2 \to \Omega_{B/A} \otimes_B B/I,  \]
which we claim will generate the kernel. Given $x \in I$, we define $\phi(x) =
dx$. If $x \in I^2$, then $dx \in I \Omega_{B/A}$ so $\phi$ is indeed a map of
abelian groups
$I/I^2 \to \Omega_{B/A} \otimes_B B/I$. Let us check that this is a
$B/I$-module homorphism. We would like to check that $\phi(xy) = y \phi(x)$
for $x \in I$ in
$\Omega_{B/A}/I \Omega_{B/A}$. This follows from the Leibnitz rule, $\phi(xy) =
y \phi(x) + xdy \equiv x \phi(x) \mod I \Omega_{B/A}$. So $\phi$ is also
defined. Its image is the submodule of $\Omega_{B/A}/I \Omega_{B/A}$ generated
by $dx, x \in I$. This is precisely what one has to quotient out by to get
$\Omega_{B/I/A}$. In particular:

\begin{proposition}[Second exact sequence] Let $B$ be an $A$-algebra and $I \subset B$ an ideal.
There is an exact sequence
\[ I/I^2 \to \Omega_{B/A} \otimes_B B/I \to \Omega_{B/I/A} \to 0.  \]
\end{proposition}

These results will let us compute the module of K\"ahler differentials in cases
we want.

\begin{example}
Let $B = A[x_1, \dots, x_n]/I$ for $I$ an ideal. We will compute $\Omega_{B/A}$.

First, $\Omega_{A[x_1, \dots, x_n]/A} \otimes B \simeq B^n$ generated by
symbols $dx_i$. There is a surjection of
\[ B^n \to \Omega_{B/A} \to 0  \]
whose kernel is generated by $dx, x \in I$, by the second exact sequence above.
If $I = (f_1, \dots, f_m)$, then the kernel is generated by
$\left\{df_i\right\}$.
It follows that $\Omega_{B/A}$ is the cokernel of the map
\[ B^m \to B^n  \]
that sends the $i$th generator of $B^m$ to $df_i$ thought of as an element in
the free $B$-module $B^n$ on generators $dx_1, \dots, dx_n$. Here, thanks to
the Leibnitz rule, $df_i$ is
given by formally differentiating the polynomial, i.e.
\[ df_i = \sum_j \frac{\partial f_i}{\partial x_j} dx_j. \] We have thus
explicitly represented $\Omega_{B/A}$ as the cokernel of the matrix $\left(
\frac{\partial f_i}{\partial x_j}\right)$.
\end{example}

In particular, the above example shows:
\begin{proposition}
If $B$ is a finitely generated $A$-algebra, then $\Omega_{B/A}$ is a finitely
generated $B$-module.
\end{proposition}
Given how $\Omega$ behaves with respect to localization, we can extend this to
the case where $B$ is \emph{essentially} of finite type over $A$ (recall that
this means $B$ is a localization of a finitely generated $A$-algebra).

Let $R = \mathbb{C}[x_1, \dots, x_n]/I$ be the coordinate ring of an algebraic
variety. Let $\mathfrak{m} \subset R$ be the maximal ideal. Then
$\Omega_{R/\mathbb{C}}$ is what one should think of as containing information
of the cotangent bundle of $\spec R$. One might ask what the \emph{fibe}r over a point
$\mathfrak{m} \in \spec R$ is, though. That is, we might ask what
\( \Omega_{R/\mathbb{C}} \otimes_R R/\mathfrak{m}  \)
is. To see this, we note that there are maps
\[ \mathbb{C} \to R \to R/\mathfrak{m} \simeq \mathbb{C}.  \]
There is now an exact sequence by
\cref{firstexactseq}
\[ \mathfrak{m}/\mathfrak{m}^2 \to \Omega_{R/\mathbb{C}} \otimes_R
R/\mathfrak{m} \to \Omega_{\mathbb{R}/\mathfrak{m}/\mathbb{C}} \to 0,  \]
where the last thing is zero as $R/\mathfrak{m} \simeq \mathbb{C} $ by the
Nullstellensatz.
The upshot is that $\Omega_{R/\mathbb{C}} \otimes_R R/\mathfrak{m}$ is a
quotient of $\mathfrak{m}/\mathfrak{m}^2$.

In fact, the natural map $\mathfrak{m}/\mathfrak{m}^2 \to \Omega_{R/\mathbb{C}}
\otimes_R \mathbb{C}$ (given by $d$) is an \emph{isomorphism} of
$\mathbb{C}$-vector spaces. We have seen
that it is surjective, so we need to see that it is injective.
That is, if $V$ is a $\mathbb{C}$-vector space, then we need to show that the
map
\[ \hom_{\mathbb{C}}(\Omega_{R/\mathbb{C}}\otimes_R \mathbb{C}, V) \to
\hom_{\mathbb{C}}(\mathfrak{m}/\mathfrak{m}^2, V)   \]
is surjective. This means that given any $\mathbb{C}$-linear map
$\lambda: \mathfrak{m}/\mathfrak{m}^2 \to V$, we can extend this to a derivation $R \to
V$ (where $V$ becomes an $R$-module by $R/\mathfrak{m} \simeq \mathbb{C}$, as
usual).
But this is easy: given $f \in R$, we write $f = f_0 + c$ for $c \in
\mathbb{C}$ and $f_0 \in \mathfrak{m}$, and have the derivation send  $f$ to
$\lambda(f_0)$.
(Checking that this is a well-defined derivation is straightforward.)

This goes through if $\mathbb{C}$ is replaced by any algebraically closed field.
We have found:
\begin{proposition}
Let $(R, \mathfrak{m}) $ be the localization of a finitely generated algebra
over an algebraically closed field $k$ at a maximal ideal $\mathfrak{m}$.  Then
there is a natural isomorphism:
\[  \Omega_{R/k} \otimes_R k \simeq \mathfrak{m}/\mathfrak{m}^2. \]
\end{proposition}

This result connects the K\"ahler differentials to the cotangent bundle: the
fiber of the cotangent bundle at a point in a manifold is, similarly, the maximal ideal
modulo its square (where the ``maximal ideal'' is the maximal ideal in the ring
of germs of functions at that point).
\subsection{K\"ahler differentials and base change}

We now want to show that the formation of $\Omega$ is compatible with base
change. Namely, let $B$ be an $A$-algebra, visualized by a morphism $ A \to B$.
If $A \to A'$ is any morphism of rings, we can think of the \emph{base-change}
$A' \to A' \otimes_A B$; we often write $B' =  A' \otimes_A B$.

\begin{proposition} \label{basechangediff} With the above notation, there is a canonical isomorphism
of $B'$-modules:
\[ \Omega_{B/A} \otimes_A A' \simeq \Omega_{B'/A'}.  \]
\end{proposition}
Note that, for a $B$-module, the functors $\otimes_A A'$ and $\otimes_B B'$ are
the same. So we could have as well written $\Omega_{B/A} \otimes_B B' \simeq
\Omega_{B'/A'}$.
\begin{proof}
We will use the functorial approach. Namely, for a $B'$-module $M$, we will
show that there is a canonical isomorphism
\[ \hom_{B'}( \Omega_{B/A} \otimes_A A', M) \simeq
\hom_{B'}( \Omega_{B'/A'}, M) .
\]
The right side represents $A'$-derivations $B' \to M$, or $\mathrm{Der}_{A'}(B', M)$.
The left side represents $\hom_B(\Omega_{B/A}, M)$, or $\mathrm{Der}_A(B, M)$.
Here the natural map of modules corresponds by Yoneda's lemma to the restriction
\[ \mathrm{Der}_{A'}(B', M) \to \mathrm{Der}_A(B, M).  \]
We need to see that this restriction map is an isomorphism. But given an
$A$-derivation $B \to M$, this is to say that extends in a \emph{unique} way to
an $A'$-linear derivation $B' \to M$. This is easy to verify directly.
\end{proof}

We next describe how $\Omega$ behaves with respect to forming tensor products.
\begin{proposition}
Let $B, B'$ be $A$-algebras. Then there is a natural isomorphism
\[ \Omega_{B \otimes_A B'/A} \simeq \Omega_{B/A} \otimes_A B' \oplus B
\otimes_A \Omega_{B'/A} .  \]
\end{proposition}
Since $\Omega$ is a linearization process, it is somewhat natural that it
should turn tensor products into direct sums.
\begin{proof}
The ``natural map'' can be described in the leftward direction. For instance,
there is a natural map $\Omega_{B/A} \otimes_A B' \to \Omega_{B \otimes_A
B'/A}$. We just need to show that it is an isomorphism.
For this, we essentially have to show that to give an $A$-derivation of $B
\otimes_A B'$ is the same as giving a derivation of $B$ and one of $B'$. This
is easy to check.
\end{proof}

\subsection{Differentials and localization}
We now show that localization behaves \emph{extremely} nicely with respect to
the formation of K\"ahler differentials. This is important in algebraic
geometry for knowing that the ``cotangent bundle'' can be defined locally.

\begin{proposition} \label{localizationdiff}
Let $f: A \to B$ be a map of rings. Let $S \subset  B$ be multiplicatively
closed. Then the natural map
\[ S^{-1}\Omega_{B/A} \to \Omega_{S^{-1}B/A}  \]
is an isomorphism.
\end{proposition}
So the formation of K\"ahler differentials commutes with localization.

\begin{proof}
We could prove this by the calculational definition, but perhaps it is better
to prove it via the universal property. If $M$ is any $S^{-1}B$-module, then
we can look at
\[ \hom_{S^{-1}B}( \Omega_{S^{-1}B/A}, M)  \]
which is given by the group of $A$-linear derivations $S^{-1}B \to M$, by the
universal property.

On the other hand,
\[ \hom_{S^{-1}B}( S^{-1} \Omega_{B/A}, M)  \]
is the same thing as the set of $B$-linear maps $\Omega_{B/A} \to M$, i.e. the
set of $A$-linear derivations $B \to M$.

We want to show that these two are the same thing. Given an $A$-derivation
$S^{-1}B \to M$, we get an $A$-derivation $B \to M$ by pulling back. We want to
show that any $A$-linear derivation $B \to M$ arises in this way. So we need to
show that any $A$-linear derivation $d: B \to M$ extends uniquely to an $A$-linear
$\overline{d}: S^{-1}B \to M$.
Here are two proofs:
\begin{enumerate}
\item (Lowbrow proof.) For $x/s \in S^{-1}B$, with $x \in B, s \in S$, we
define $\overline{d}(x/s) = dx/s - xds/s^2$ as in calculus. The claim is that
this works, and is the only thing that works. One should check
this---\textbf{exercise}.
\item (Highbrow proof.) We start with a digression. Let $B$ be a commutative
ring, $M$ a $B$-module. Consider $B \oplus M$, which is a  $B$-module. We can
make it into a ring (via \textbf{square zero multiplication}) by multiplying
\[ (b,x)(b',x') = (bb', bx'+b'x).  \]
This is compatible with the $B$-module structure on $M \subset B \oplus
M$. Note that $M$ is an ideal in this ring with square zero.  Then the
projection $\pi: B \oplus M \to B$ is a ring-homomorphism as well.
There is also a ring-homomorphism in the other direction $b \to (b,0)$, which
is a section of $\pi$. There may be other homomorphisms $B \to B \oplus M$.

You might ask what all the right inverses to $\pi$ are, i.e. ring-homomorphisms
$\phi:  B \to B \oplus M $ such that $\pi \circ \phi = 1_{B}$. This must be of
the form $\phi: b \to (b, db)$ where $d: B \to M$ is some map. It is easy to check
that $\phi$ is a homomorphism precisely when $d$ is a derivation.

Suppose now $A \to B$ is a morphism of rings making $B$ an $A$-algebra. Then
$B \oplus M$ is an $A$-algebra via the inclusion $a \to (a, 0)$. Then
you might ask when $\phi: b \to (b, db), B \to B \oplus M$ is an
$A$-homomorphism. The answer is clear: when $d$ is an $A$-derivation.

Recall that we were in the situation of $f: A \to B$  a morphism of rings, $S
\subset B$ a multiplicatively closed subset, and $M$ an $S^{-1}B$-module. The
claim was that any $A$-linear derivation $d: B \to M$ extends uniquely to
$\overline{d}: S^{-1} B \to M$.
We can draw a diagram
\[ \xymatrix{
& B \oplus M \ar[d] \ar[r] &  S^{-1}B \oplus M \ar[d] \\
A \ar[r] &  B \ar[r] &  S^{-1}B
}.\]
This is a cartesian diagram. So given a section of $A$-algebras $B \to B \oplus M$, we have to
construct a section of $A$-algebras $S^{-1}B \to S^{-1}B \oplus M$. We can do this by the
universal property of localization, since $S$ acts by invertible elements on
$S^{-1}B \oplus M$. (To see this, note that $S$ acts by invertible elements on
$S^{-1}B$, and $M$ is a nilpotent ideal.)
\end{enumerate}
\end{proof}

Finally, we note that there is an even slicker argument. (We learned this from
\cite{Qu}.)
Namely, it suffices to show that $\Omega_{S^{-1}B/B} =0 $, by the exact
sequences.
But this is a $S^{-1}B$-module, so we have
\[  \Omega_{S^{-1}B/B} = \Omega_{S^{-1}B/B} \otimes_B S^{-1}B, \]
because tensoring with $S^{-1}B$ localizes at $S$, but this does nothing to a
$S^{-1}B$-module! By the base change formula (\cref{basechangediff}), we have
\[ \Omega_{S^{-1}B/B} \otimes_B S^{-1}B = \Omega_{S^{-1}B/S^{-1}B} = 0,  \]
where we again use the fact that $S^{-1} B \otimes_B S^{-1} B \simeq S^{-1}B$.

\subsection{Another construction of $\Omega_{B/A}$}

Let $B$ be an $A$-algebra. We have constructed $\Omega_{B/A}$ by quotienting
generators by relations.
There is also a simple and elegant ``global'' construction one sometimes finds
useful in generalizing the procedure to schemes.

Consider the algebra $B \otimes_A B$ and the map $B \otimes_A B \to B$ given by
multiplication.
Note that $B$ acts on $B \otimes_A B$ by multiplication on
the first factor: this is how the latter is a $B$-module, and then the
multiplication map is a $B$-homomorphism. Let $I \subset B \otimes_A B$ be the
kernel.

\begin{proposition} \label{alternateOmega}
There is an isomorphism of $B$-modules
\[ \Omega_{B/A} \simeq I/I^2  \]
given by the derivation $b \mapsto 1 \otimes b - b \otimes 1$, from $B$ to
$I/I^2$.
\end{proposition}
\begin{proof}
It is clear that the maps
\[ b \to 1 \otimes b, b \to b \otimes 1: \quad B \to B \otimes_A B   \]
are $A$-linear, so their difference is too. The quotient $d:B \to I/I^2$ is thus
$A$-linear too.

First, note that if $c,c' \in B$, then $1 \otimes c - c \otimes 1, 1 \otimes c'
- c' \otimes 1 \in I$. Their product is thus zero in $I/I^2$:
\[  (1 \otimes c - c \otimes 1)(1 \otimes c'
- c' \otimes 1) = 1 \otimes cc' + cc' \otimes 1  - c \otimes c' - c' \otimes c
  \in I^2.\]
Next
we must check that $d: B \to I/I^2$ is a derivation. So fix $b, b' \in B$; we
have
\[ d(bb') =   1 \otimes bb'- bb' \otimes 1\]
and
\[ bdb' = b (   1 \otimes b'-b' \otimes 1), \quad b' db = b'(1
\otimes b - b \otimes 1  ).  \]
The second relation shows that
\[ bdb' + b' db =   b \otimes b' -  bb' \otimes 1+ b' \otimes b - bb' \otimes
1 . \]
Modulo $I^2$, we have as above $b \otimes b' + b' \otimes b \equiv 1 \otimes
bb' + bb' \otimes 1$, so
\[   bdb' + b' db \equiv 1 \otimes bb' - bb' \otimes 1 \mod I^2,  \]
and this last is equal to $d(bb')$ by definition. So we have an $A$-linear
derivation $d: B \to I/I^2$. It remains to be checked that this is
\emph{universal}. In particular, we must check that the induced
\[ \phi: \Omega_{B/A} \to I/I^2  \]
sending $db \to 1 \otimes b - b \otimes 1$.
is an isomorphism. We can define the inverse $\psi: I/I^2 \to \Omega_{B/A}$ by sending $\sum b_i \otimes b_i'
\in I$
to $\sum b_i db_i'$. This is clearly a $B$-module homomorphism, and it
 is well-defined mod $I^2$.

It is clear that $\psi (\phi(db)) = db$ from the definitions, since this
is
\[ \psi( 1 \otimes b - b \otimes 1) = 1 (db) - b d1 = db,  \]
as $d1 = 0$. So $\psi \circ \phi = 1_{\Omega_{B/A}}$.
It follows that $\phi$ is injective.
We will check now that it is surjective.
Then we will be done.

\begin{lemma}
Any element in $I$ is a $B$-linear combination of elements of the form $1
\otimes b - b \otimes 1$.
\end{lemma}

Every such element is the image of $db$ under $\phi$ by definition of the
derivation $B \to I/I^2$. So this lemma will complete the proof.

\begin{proof}
Let $Q = \sum c_i \otimes d_i \in I$. By assumption, $\sum c_i d_i = 0 \in B$.
We have by this last identity
\[Q =  \sum \left( ( c_i \otimes d_i ) - (c_i d_i \otimes 1)\right)
= \sum c_i (1 \otimes d_i - d_i \otimes 1).
\]
So $Q$ is in the submodule spanned by the $\left\{1 \otimes b - b \otimes
1\right\}_{b \in B}$.
\end{proof}
\end{proof}

\section{Introduction to smoothness}
\subsection{K\"ahler differentials for fields}

Let us start with the simplest examples---fields.

\begin{example}
Let $k$ be a field, $k'/k$ an extension.
\begin{question}
What does $\Omega_{k'/k}$ look like? When does it vanish?
\end{question}
$\Omega_{k'/k}$ is a $k'$-vector space.

\begin{proposition}
Let $k'/k$ be a separable algebraic extension of fields. Then $\Omega_{k'/k} = 0$.
\end{proposition}
\begin{proof}
We will need a formal property of K\"ahler differentials that is easy to check,
namely that they are compatible with filtered colimits. If $B = \varinjlim
B_\alpha$ for $A$-algebras $B_\alpha$, then there is a canonical isomorphism
\[ \Omega_{B/A} \simeq \varinjlim \Omega_{B_{\alpha}/A}.  \]
One can check this on generators and relations, for instance.

Given this, we can reduce to the case of $k'/k$ finite and separable.
\begin{remark}
Given a sequence of fields and morphisms $k \to k' \to k''$, then there is an
exact sequence
\[ \Omega_{k'/k} \otimes k'' \to \Omega_{k''/k} \to \Omega_{k''/k'} \to 0.  \]
In particular, if $\Omega_{k'/k} = \Omega_{k''/k'} =0 $, then $\Omega_{k''/k} =
0$. This is a kind of d\'evissage argument.
\end{remark}

Anyway, recall that we have a finite separable extension $k'/k$ where $k' =
k(x_1, \dots, x_n)$.\footnote{We can take $n=1$ by the primitive element
theorem, but shall not need this.} We will show that
\[ \Omega_{k(x_1, \dots, x_i)/k(x_1, \dots, x_{i-1})} =0 \quad \forall i,  \]
which will imply by the devissage argument that $\Omega_{k'/k} = 0$.
In particular, we are reduced to showing the proposition when $k'$ is generated
over $k$ by a \emph{single element} $x$. Then we have that
\[ k' \simeq k[X]/(f(X))  \]
for $f(X)$ an irreducible polynomial. Set $I = (f(X))$. We have an exact sequence
\[ I/I^2 \to \Omega_{k[X]/k} \otimes_{k[X]} k' \to \Omega_{k'/k} \to 0 \]
The middle term is a copy of $k'$ and the first term is isomorphic to $k[X]/I
\simeq k'$. So there is an exact sequence
\[ k' \to k' \to \Omega_{k'/k} \to 0.  \]
The first term is, as we have computed, multiplication by $f'(x)$; however
this is nonzero by separability. Thus we find that $\Omega_{k'/k} =0$.
\end{proof}
\end{example}

\begin{remark}
The above result is \textbf{not true} for inseparable extensions in general.
\end{remark}
\begin{example}
Let $k$ be an imperfect field of characteristic $p>0$. There is $x \in k$ such
that $x^{1/p} \notin k$, by definition. Let $k' = k(x^{1/p})$. As a ring, this
looks like
$k[t]/(t^p - x)$. In writing the exact sequence, we find that $\Omega_{k'/k} =
k'$ as this is the cokernel of the map $k' \to k'$ given by multiplication
$\frac{d}{dt}|_{x^{1/p}} (t^p - x)$. That polynomial has identically vanishing
derivative, though. We find that a generator of $\Omega_{k'/k}$ is $dt$ where
$t$ is a $p$th root of $x$, and $\Omega_{k'/k } \simeq k$.
\end{example}

Now let us consider transcendental extensions. Let $k' = k(x_1, \dots, x_n)$ be
a purely transcendental extension, i.e. the field of rational functions of
$x_1, \dots, x_n$.

\begin{proposition}
If $k' = k(x_1, \dots, x_n)$, then $\Omega_{k'/k}$ is a free $k'$-module on the
generators $dx_i$.
\end{proposition}
This extends to an \emph{infinitely generated} purely transcendental extension,
because K\"ahler differentials commute with filtered colimits.
\begin{proof}
We already know this for the polynomial ring $k[x_1, \dots, x_n]$. However, the
rational function field is just a localization of the polynomial ring at the
zero ideal.  So the result will follow from \cref{localizationdiff}.
\end{proof}

We have shown that separable algebraic extensions have no K\"ahler
differentials, but that purely transcendental extensions have a free module of
rank equal to the transcendence degree.

We can deduce from this:
\begin{corollary}
Let $L/K$ be a field extension of fields of char 0. Then
\[ \dim_L \Omega_{L/K} = \mathrm{trdeg}(L/K).  \]
\end{corollary}
\begin{proof}[Partial proof]
Put the above two facts together. Choose a transcendence basis $\{x_\alpha\}$
for $L/K$. This means that $L$ is algebraic over $K(\left\{x_\alpha\right\})$
and the $\left\{x_\alpha\right\}$ are algebraically independent.
Moreover $L/K(\left\{x_\alpha\right\})$ is \emph{separable} algebraic.  Now let
us use a few things about these cotangent complexes. There is an exact sequence:
\[ \Omega_{K(\left\{x_\alpha\right\})}
\otimes_{K(\left\{x_\alpha\right\})} L \to \Omega_{L/K} \to \Omega_{L/K(\left\{x_\alpha\right\})}  \to 0 \]
The last thing is zero, and we know what the first thing is; it's free on the
$dx_\alpha$. So we find that $\Omega_{L/K}$ is generated by
the elements $dx_\alpha$. If we knew that the $dx_\alpha$ were linearly
independent, then we would be done. But we don't, yet.
\end{proof}

This is \textbf{not true} in characteristic $p$. If $L = K(\alpha^{1/p})$ for
$\alpha \in K$ and $\alpha^{1/p} \notin K$, then $\Omega_{L/K} \neq 0$.

\subsection{Regularity, smoothness, and K\"ahler differentials}
From this, let us revisit a statement made last time.
Let $K$ be an algebraically closed field, let $R = k[x_1, \dots, x_n]/I$ and
let $\mathfrak{m} \subset R$ be a maximal ideal. Recall that the
Nullstellensatz implies that $R/\mathfrak{m} \simeq k$. We were studying
\[ \Omega_{R/k}.  \]
This is an $R$-module, so $\Omega_{R/k} \otimes_R k$ makes sense. There is a
surjection
\[ \mathfrak{m}/\mathfrak{m}^2 \to \Omega_{R/k} \otimes_R k \to 0,  \]
that sends $x \to dx$.
\begin{proposition}
This map is an isomorphism.
\end{proposition}
\begin{proof}
We construct a map going the other way. Call the map $\mathfrak{m}/\mathfrak{m}^2 \to
\Omega_{R/k} \otimes_R k$ as $\phi$. We want to construct
\[ \psi: \Omega_{R/k} \otimes_R k \to \mathfrak{m}/\mathfrak{m}^2.  \]
This is equivalent to giving an $R$-module map
\[ \Omega_{R/k} \to \mathfrak{m}/\mathfrak{m}^2,  \]
that is a derivation $\partial: R \to \mathfrak{m}/\mathfrak{m}^2$. This acts
via $\partial(\lambda + x) = x$ for $\lambda \in k, x \in \mathfrak{m}$. Since
$k+\mathfrak{m} = R$, this is indeed well-defined. We must check that
$\partial$ is a derivation. That is, we have to compute
$\partial((\lambda+x)(\lambda' + x'))$.
But this is
\[ \partial(\lambda\lambda' + (\lambda x' + \lambda' x) + xx').  \]
The definition of $\partial$ is to ignore the constant term and look at the
nonconstant term mod $\mathfrak{m}^2$. So this becomes
\[ \lambda x' + \lambda' x = (\partial (\lambda+x)) (x'+\lambda') + (\partial (\lambda'+
x')) (x+\lambda)  \]
because $xx' \in \mathfrak{m}^2$, and because $\mathfrak{m}$ acts trivially on
$\mathfrak{m}/\mathfrak{m}^2$. Thus we get the map $\psi$ in the inverse
direction, and one checks that $\phi, \psi$ are inverses. This is because
$\phi$ sends $x \to dx$ and $\psi$ sends $dx \to x$.
\end{proof}

\begin{corollary}
Let $R$ be as before. Then $R_{\mathfrak{m}}$ is regular iff $\dim
R_{\mathfrak{m}} = \dim_k \Omega_{R/k} \otimes_R R/\mathfrak{m}$.
\end{corollary}
In particular, the modules of K\"ahler differentials detect regularity for
certain rings.

\begin{definition}
Let $R$ be a noetherian ring. We say that $R$ is \textbf{regular} if
$R_{\mathfrak{m}}$ is regular for every maximal ideal $\mathfrak{m}$. (This
actually implies that $R_{\mathfrak{p}}$ is regular for all primes
$\mathfrak{p}$, though we are not ready to see this. It will follow from the
fact that the localization of a regular local ring at a prime ideal is regular.)
\end{definition}

Let $R = k[x_1, \dots, x_n]/I$ be an affine ring over an algebraically closed
field $k$.
Then:

\begin{proposition}
TFAE:
\begin{enumerate}
\item $R$ is regular.
\item ``$R$ is smooth over $k$'' (to be defined)
\item  $\Omega_{R/k}$ is  a projective module over $R$ of rank $\dim R$.
\end{enumerate}
\end{proposition}
A finitely generated projective module is locally free. So the last statement is that
$(\Omega_{R/k})_{\mathfrak{p}}$ is free of rank $\dim R$ for each prime
$\mathfrak{p}$.

\begin{remark}
A projective module does not necessarily have a well-defined rank as an integer. For
instance, if $R = R_1 \times R_2$ and $M = R_1 \times 0$, then $M$ is a summand
of $R$, hence is projective. But there are two candidates for what the rank
should be. The problem is that $\spec R$ is disconnected into two pieces, and
$M$ is of rank one on one piece, and of rank zero on the other.
But in this case, it does not happen.
\end{remark}

\begin{remark}
The smoothness condition states that locally on $\spec R$, we have an isomorphism with
$k[y_1, \dots, y_n]/(f_1, \dots, f_m)$ with the gradients $\nabla f_i$ linearly
independent. Equivalently, if $R_{\mathfrak{m}}$ is the localization of $R$ at
a maximal ideal  $\mathfrak{m}$, then $R_{\mathfrak{m}}$ is a regular local
ring, as we have seen.
\end{remark}

\begin{proof}
We have already seen that 1 and 2 are equivalent. The new thing is that they
are equivalent to 3. First, assume 1 (or 2).
First, note that $\Omega_{R/k}$ is a finitely generated $R$-module; that's a general
observation:

\begin{proposition}
\label{finitelygeneratedOmega}
If $f: A \to B$ is a map of rings that makes $B$ a finitely generated $A$-algebra, then
$\Omega_{B/A}$ is a finitely generated $B$-module.
\end{proposition}
\begin{proof}
We've seen this is true for polynomial rings, and we can use the exact
sequence. If $B$ is a quotient of a polynomial ring, then $\Omega_{B/A}$ is a
quotient of the K\"ahler differentials of the polynomial ring.
\end{proof}
Return to the main proof. In particular, $\Omega_{R/k}$ is projective if and
only if $(\Omega_{R/k})_{\mathfrak{m}}$ is projective for every maximal ideal
$\mathfrak{m}$.  According to the second assertion, we have that
$R_{\mathfrak{m}}$ looks like $(k[y_1, \dots, y_n]/(f_1, \dots,
f_m))_{\mathfrak{n}}$ for some maximal ideal $\mathfrak{n}$, with the
gradients $\nabla f_i$ linearly independent. Thus
$(\Omega_{R/k})_{\mathfrak{m}} = \Omega_{R_{\mathfrak{m}}/k}$ looks like the cokernel of
\[ R_{\mathfrak{m}}^m \to R_{\mathfrak{m}}^n  \]
where the map is multiplication by the Jacobian matrix $\left(\frac{\partial
f_i}{\partial y_j}  \right)$. By assumption this matrix has full rank. We see
that there is a left inverse of the reduced  map $k^m \to k^n$.
We can lift this to a map $R_{\mathfrak{m}}^n \to R_{\mathfrak{m}}^m$. Since
this is a left inverse mod $\mathfrak{m}$, the composite is at least an
isomorphism (looking at determinants). Anyway, we see that $\Omega_{R/k}$ is
given by the cokernel of a map of free module that splits, hence is projective.
The rank is $n-m = \dim R_{\mathfrak{m}}$.

Finally, let us prove that 3 implies 1. Suppose $\Omega_{R/k}$ is projective of
rank $\dim R$. So this means that $\Omega_{R_{\mathfrak{m}}/k}$ is free of
dimension $\dim R_{\mathfrak{m}}$. But this implies that $(\Omega_{R/k})
\otimes_R R/\mathfrak{m}$ is free of the appropriate rank, and that is---as we
have seen already---the embedding dimension $\mathfrak{m}/\mathfrak{m}^2$. So
if 3 holds, the embedding dimension equals the usual dimension, and we get
regularity.
\end{proof}

\begin{corollary}
Let $R = \mathbb{C}[x_1, \dots, x_n]/\mathfrak{p}$ for $\mathfrak{p}$ a prime.
Then there is a nonzero $f \in R$ such that $R[f^{-1}]$ is regular.
\end{corollary}
Geometrically, this says the following. $\spec R$ is some algebraic variety,
and $\spec R[f^{-1}]$ is a Zariski open subset. What we are saying is that, in
characteristic zero, any algebraic variety has a nonempty open smooth locus.
The singular locus is always smaller than the entire variety.

\begin{proof}
$\Omega_{R/\mathbb{C}}$ is a finitely generated $R$-module. Let $K(R) $ be the fraction field of $R$.
Now
\[ \Omega_{R/\mathbb{C}} \otimes_R K(R) = \Omega_{K(R)/\mathbb{C}}  \]
is a finite $K(R)$-vector space. The dimension is
$\mathrm{trdeg}(K(R)/\mathbb{C})$. That is also $d=\dim R$, as we have seen.
Choose elements $x_1, \dots, x_d \in \Omega_{R/\mathbb{C}}$ which form a basis
for $\Omega_{K(R)/\mathbb{C}}$. There is a map
\[ R^d \to \Omega_{R/\mathbb{C}}  \]
which is an isomorphism after localization at $(0)$. This implies that there is
$f \in R$ such that the map is an isomorphism after localization at
$f$.\footnote{There is an inverse defined over the fraction field, so it is
defined over some localization.} We find that $\Omega_{R[f^{-1}]/\mathbb{C}}$
is free of rank $d$ for some $f$, which is what we wanted.
\end{proof}

This argument works over any algebraically closed field of characteristic
zero, or really any field of characteristic zero.
\begin{remark}[Warning] Over imperfect fields in characteristic $p$, two things can happen:
\begin{enumerate}
\item Varieties need not be generically smooth
\item $\Omega_{R/k}$ can be projective with the wrong rank
\end{enumerate}
(Nothing goes wrong for \textbf{algebraically closed fields} of characteristic
$p$.)
\begin{example}
Here is a silly example. Say $R = k[y]/(y^p-x)$ where $x \in K$ has no $p$th
root. We know that $\Omega_{R/k}$ is free of rank one. However, the rank is
wrong: the variety has dimension zero.
\end{example}
\end{remark}

Last time, were trying to show that $\Omega_{L/K}$ is free on a transcendence
basis if $L/K$ is an extension in characteristic zero. So we had a tower of fields
\[ K \to K' \to L,  \]
where $L/K'$ was separable algebraic.
We claim in this case that
\[ \Omega_{L/K} \simeq \Omega_{K'/K} \otimes_{K'} L.  \]
This will prove the result. But we had not done this yesterday.
\begin{proof}
This doesn't follow directly from the previous calculations. Without loss of generality, $L$ is
finite over $K'$, and in particular, $L = K'[x]/(f(x))$ for $f$ separable. The claim is that
\[ \Omega_{L/K} \simeq (\Omega_{K'/K}\otimes_{K'}L \oplus K' dx)/f'(x)dx + \dots  \]
When we kill the vector $f'(x) dx + \dots$, we kill the second component.
\end{proof}




\part{Topics}
% ============================ chapters/various.tex}
\chapter{Various topics}

This chapter is currently a repository for various topics that may or may not
reach a status worthy of their own chapters in the future, but in any event
should be included.

\section{Linear algebra over rings}

\subsection{The determinant trick}
We want to understand what $IN=N$ means.

 Let $I\subset R$ and ${}_R M$ finitely generated. Let
 $E=\End_R (M)$, which is not commutative in general. We may view $M$ as an $E$-module
 ${}_E M$. Since every element in $R$ commutes with all of $E$, $E$ is an $R$-algebra (i.e.\
 There is a homomorphism $R\to E$ sending $R$ into the center of $E$).
 \begin{lemma}[Determinant Trick]
  \begin{enumerate}\item[]
    \item Every $\phi\in E$ such that $\phi(M)\subset IM$ satisfies a monic equation
    of the form $\phi^n+a_1\phi^{n-1} +\cdots + a_n=0$, where each $a_i\in I$, i.e.\
    $\phi$ is ``integral over $I$''.

    \item $IM=M$ if and only if $(1-a)M=0$ for some $a\in I$.
  \end{enumerate}
 \end{lemma}
 \begin{proof}
   (1) Fix a finite set of generators, $M=Rm_1+\cdots + Rm_n$. Then we have
   $\phi(m_i)=\sum_j a_{ij} m_j$, with $a_{ij}\in I$ by assumption. Let $A=(a_{ij})$.
   Then these equations tell us that $(I\phi-A)\vec{m}=0$. Multiplying by the adjoint of
   the matrix $I\phi-A$, we get that $\det(I\phi-A)m_i=0$ for each $i$. It follows that
   $\det(I\phi-A)=0\in E$. But $\det(I\phi-A)=\phi^n+a_1\phi^{n-1}+\cdots +a_n$ for some
   $a_i\in I$.

   (2) The ``if'' part is clear. The ``only if'' part follows from (1), applied to
   $\phi=\id_M$.
 \end{proof}
 \begin{remark}
   Determinant trick (part 2) actually includes Nakayama's Lemma, because if $I$ is in
   $\rad R$, $(1-a)$ is a unit, so $M=(1-a)M=0$.
 \end{remark}
 \begin{corollary}
   For a finitely generated ideal $I\subset R$, $I=I^2$ if and only if $I=eR$ for some
   $e=e^2$.
 \end{corollary}
 \begin{proof}
   ($\Leftarrow$) clear.

   ($\Rightarrow$) Apply determinant trick (part 2) to the case $M={}_R I$. We get
   $(1-e)I=0$ for some $e\in I$, so $(1-e)a=0$ for each $a\in I$, so $a=ea$, so $I$ is
   generated by $e$. Letting $a=e$, we see that $e$ is idempotent.
 \end{proof}
 \begin{corollary}[Vasconcelos-Strooker Theorem]
   For any finitely generated module $M$ over \emph{any} commutative $R$. If $\phi\in
   \End_R(M)$ is onto, then it is injective.
 \end{corollary}
 \begin{proof}
   We can view $M$ as a module over $R[t]$, where $t$ acts by $\phi$. Apply the
   determinant trick (part 2) to $I=t\cdot R[t]\subset R[t]$. We have that $IM=M$
   because $\phi$ is surjective, so $m =\phi(m_0)=t\cdot m_0\in IM$. It follows that
   there is some $th(t)$ such that $(1-th(t))M=0$. In particular, if $m\in  \ker \phi$,
   we have that $0=(1-h(t)t)m=1\cdot m=m$, so $\phi$ is injective.
 \end{proof}

\subsection{Determinantal ideals}
\begin{definition}
   An ideal $I\subset R$ is called \emph{dense}\index{dense ideal} if $rI=0$ implies $r=0$.
   This is denoted $I\subset_d R$. This is the same as saying that ${}_RI$ is a
   faithful module over $R$.
 \end{definition}
 If $I$ is a principal ideal, say $Rb$, then $I$ is dense exactly when $b\in \mathcal{C}(R)$. The
 easiest case is when $R$ is a domain, in which case an ideal is dense exactly when it is
 non-zero.

 If $R$ is an integral domain, then by working over the quotient field, one can define
 the rank of a matrix with entries in $R$. But if $R$ is not a domain, rank becomes
 tricky. Let $\mathcal{D}_i(A)$ be the $i$-th \emph{determinantal ideal} in $R$, generated by all
 the determinants of $i\times i$ minors of $A$. We define $\mathcal{D}_0(A)=R$. If $i\ge
 \min\{n,m\}$, define $\mathcal{D}_i(A)=(0)$.

 Note that $\mathcal{D}_{i+1}(A)\supset \mathcal{D}_i(A)$ because you can expand by minors, so we have a
 chain
 \[
    R=\mathcal{D}_0(A)\supset \mathcal{D}_1(A)\supset \cdots \supset (0).
 \]
 \begin{definition}
   Over a non-zero ring $R$, the \emph{McCoy rank} (or just \emph{rank}) of $A$ to be
   the maximum $i$ such that $\mathcal{D}_i(A)$ is dense in $R$. The rank of $A$ is denoted
   $rk(A)$.
 \end{definition}
 If $R$ is an integral domain, then $rk(A)$ is just the usual rank. Note that over any
 ring, $rk(A)\le \min\{n,m\}$.

 If $rk(A)=0$, then $\mathcal{D}_1(A)$ fails to be dense, so there is some non-zero element $r$
 such that $rA=0$. That is, $r$ zero-divides all of the entries of $A$.

 If $A\in \mathbb{M}_{n,n}(R)$, then $A$ has rank $n$ (full rank) if and only if $\det A$ is a
 regular element.

 \begin{exercise}
   Let $R=\mathbb{Z}/6\mathbb{Z} $, and let $A=diag(0,2,4)$, $diag(1,2,4)$, $diag(1,2,3)$, $diag(1,5,5)$
   ($3\times 3$ matrices). Compute the rank of $A$ in each case.
 \end{exercise}
 \begin{solution}\raisebox{-2\baselineskip}{
   $\begin{array}{c|cccc}
   A & \mathcal{D}_1(A) & \mathcal{D}_2(A) & \mathcal{D}_3(A) & \\ \hline
   diag(0,2,4) & (2) & (2) & (0) & 3\cdot (2)=0\text{, so }rk=0 \\
   diag(1,2,4) & R & (2) & (2) & 3\cdot (2)=0\text{, so }rk=1 \\
   diag(1,2,3) & R & R & (2) & 3\cdot (2)=0\text{, so }rk=2 \\
   diag(1,5,5) & R & R & R & \text{so }rk=3
  \end{array}$}
 \end{solution}
 \subsection{Lecture 2}

 Let $A\in \mathbb{M}_{n,m}(R)$. If $R$ is a field, the rank of $A$ is the dimension of the
 image of $A:R^m\to R^n$, and $m-rk(A)$ is the dimension of the null space. That
 is, whenever $rk(A)< m$, there is a solution to the system of linear equations
 \begin{equation}
 0 = A\cdot x \label{lec02ast}
 \end{equation}
 which says that the columns $\alpha_i\in R^n$ of $A$ satisfy the dependence $\sum
 x_i\alpha_i=0$. The following theorem of McCoy generalizes this so that $R$ can be any
 non-zero commutative ring.
 \begin{theorem}[McCoy]\label{lec02T:McCoy3}
   If $R$ is not the zero ring, the following are equivalent:
   \begin{enumerate}
     \item The columns $\alpha_1$, \dots, $\alpha_m$ are linearly dependent.
     \item Equation \ref{lec02ast} has a nontrivial solution.
     \item $rk(A)<m$.
   \end{enumerate}
 \end{theorem}
 \begin{corollary}
   If $R\ne 0$, the following hold
   \begin{enumerate}
     \item[(a)] If $n<m$ (i.e.\ if there are ``more variables than equations''), then
      Equation \ref{lec02ast} has a nontrivial solution.
     \item[(b)] $R$ has the ``strong rank property'':
        $R^m\hookrightarrow R^n \Longrightarrow m\le n$.
     \item[(c)] $R$ has the ``rank property'':
        $R^n\twoheadrightarrow R^m \Longrightarrow m\le n$.
     \item[(d)] $R$ has the ``invariant basis property'':
        $R^m\cong R^n \Longrightarrow m=n$.
   \end{enumerate}
 \end{corollary}
 \begin{proof}[Proof of Corollary]
   $(a)$ If $n<m$, then $rk(A)\le \min\{n,m\} =n< m$, so by Theorem \ref{lec02T:McCoy3},
   Equation \ref{lec02ast} has a non-trivial solution.

   $(a\Rightarrow b)$ If $m>n$, then by $(a)$, any $R$-linear map $R^m\to R^n$
   has a kernel. Thus, $R^m\hookrightarrow R^n$ implies $m\le n$.

   $(b\Rightarrow c)$ If $R^n\twoheadrightarrow R^m$, then since $R^m$ is free,
   there is a section $R^m\hookrightarrow R^n$ (which must be injective), so $m\le n$.

   $(c\Rightarrow d)$ If $R^m\cong R^n$, then we have surjections both ways, so
   $m\le n\le m$, so $m=n$.
 \end{proof}
 \begin{corollary}
   Let $R\ne 0$, and $A$ some $n\times n$ matrix. Then the following are equivalent
   (1) $\det A\in \mathcal{C}(R)$; (2) the columns of $A$ are linearly independent; (3) the rows of
   $A$ are linearly independent.
 \end{corollary}
 \begin{proof}
   The columns are linearly independent if and only if Equation \ref{lec02ast} has no
   non-trivial solutions, which occurs if and only if the rank of $A$ is equal to $n$,
   which occurs if and only if $\det A$ is a non-zero-divisor.

   The transpose argument shows that $\det A\in \mathcal{C}(R)$ if and only if the rows are
   independent.
 \end{proof}
 \begin{proof}[Proof of the Theorem]
   $0=Ax = \sum \alpha_i x_i$ if and only if the $\alpha_i$ are dependent, so $(1)$ and
   $(2)$ are equivalent.

   $(2\Rightarrow 3)$ Let $x\in R^m$ be a non-zero solution to $A\cdot x=0$. If $n<m$,
   then $rk(A)\le n <m$ and we're done. Otherwise, let $B$ be any $m\times m$ minor of
   $A$ (so $B$ has as many columns as $A$, but perhaps is missing some rows). Then
   $Bx=0$; multiplying by the adjoint of $B$, we get $(\det B)x=0$, so each $x_i$
   annihilates $\det B$. Since $x\neq 0$, some $x_i$ is non-zero, and we have shown that
   $x_i\cdot \mathcal{D}_m(A)=0$, so $rk(A)<m$.

   $(3\Rightarrow 2)$ Assume $r=rk(A)<m$. We may assume $r< n$ (adding a row of
   zeros to $A$ if needed). Fix a nonzero element $a$ such that $a\cdot \mathcal{D}_{r+1}(A)=0$.
   If $r=0$, then take $x$ to be the vector with an $a$ in each place. Otherwise, there
   is some $r\times r$ minor not annihilated by $a$. We may assume it is the upper left
   $r\times r$ minor. Let $B$ be the upper left $(r+1)\times (r+1)$ minor, and let $d_1$,
   \dots, $d_{r+1}$ be the cofactors along the $(r+1)$-th row. We claim that the column
   vector $x = (ad_1,\dots, ad_{r+1},0,\dots, 0)$ is a solution to Equation
   \ref{lec02ast} (note that it is non-zero because $ad_{r+1}\neq 0$ by assumption). To
   check this, consider the product of $x$ with the $i$-th row, $(a_{i1},\dots, a_{im})$.
   This will be equal to $a$ times the determinant of $B'$, the matrix $B$ with the
   $(r+1)$-th row replaced by the $i$-th row of $A$. If $i\le r$, the determinant of $B'$
   is zero because it has two repeated rows. If $i> r$, then $B'$ is an $(r+1)\times
   (r+1)$ minor of $A$, so its determinant is annihilated by $a$.
 \end{proof}
 \begin{corollary}
   Suppose a module ${}_RM$ over a non-zero ring $R$ is generated by $\beta_1,\dots,
   \beta_n\in M$. If $M$ contains $n$ linearly independent vectors, $\gamma_1,\dots,
   \gamma_n$, then the $\beta_i$ form a free basis.
 \end{corollary}
 \begin{proof}
   Since the $\beta_i$ generate, we have $\gamma = \beta\cdot A$ for some $n\times n$
   matrix $A$. If $Ax=0$ for some non-zero $x$, then $\gamma \cdot x = \beta Ax = 0$,
   contradicting independence of the $\gamma_i$. By Theorem \ref{lec02T:McCoy3},
   $rk(A)=n$, so $d=\det(A)$ is a regular element.

   Over $R[d^{-1}]$, there is an inverse $B$ to $A$. If $\beta\cdot
   y=0$ for some $y\in R^n$, then $\gamma By = \beta y=0$. But the $\gamma_i$ remain
   independent over $R[d^{-1}]$ since we can clear the denominators of any linear
   dependence to get a dependence over $R$ (this is where we use that $d\in \mathcal{C}(R)$), so
   $By=0$. But then $y=A\cdot 0 = 0$. Therefore, the $\beta_i$ are linearly independent,
   so they are a free basis for $M$.
\end{proof}

\section{Finite presentation}

\label{noetheriandescent}
\subsection{Compact objects in a category}

Let $\mathcal{C}$ be a category.
In general, colimits tell one how to map \emph{out of} them, not into them,
and there is no a priori reason to assume that if $F: I \to \mathcal{C}$ is a
functor, that
\begin{equation} \label{filtcolimhom} \varinjlim_i \hom(X, Fi) \to \hom(X,
\varinjlim Fi)  \end{equation}
is an isomorphism.
In practice, though, it often happens that when $I$ is
\emph{filtered}, the above map is an isomorphism. For simplicity, we shall
restrict to the case when $I$ is a \emph{directed }set
(which is naturally a category); in this case, we call the limits
\textbf{inductive.}

\begin{definition}
The object $X$ is called \textbf{compact} if \eqref{filtcolimhom} is an
isomorphism whenever $I$ is inductive.
\end{definition}
The following example motivates the term ``compact.''
\begin{example}
Let $\mathcal{C}$ be the category of Hausdorff topological spaces and
\emph{closed inclusions} (so that we do not obtain a full subcategory of the
category of topological spaces), and let $X$
be a compact space. Then $X$ is a compact object in $\mathcal{C}$.

Indeed, suppose $\left\{X_i\right\}_{i \in I}$ is an inductive system of
Hausdorff spaces and closed inclusions. Suppose given a map $f:X \to \varinjlim
X_i$. Then each $X_i$ is a closed subspace of the colimit, so we need to show that
$f(X)$ lands inside one of the $X_i$. This will easily imply compactness.

Suppose not. Then $f(X)$ contains, for each $i$, a point $x_i$ that belongs to
no $X_j, j < i$. Choose a countable subset $T \subset I$ (if $I$ is finite,
then this is automatic!). For each $t \in T$, we get an element $x_t \in
f(X)$ that belongs to no $X_i$ for $i < t$. Note that if $t' \in T$, then it
follows that $X_{t'} \cap \left\{x_t\right\}$ is finite.


In particular, if $F \subset \left\{x_t\right\}$ is \emph{any} subset, then
$X_{t'} \cap F$ is closed  for each $t' \in T$.
Thus $\varinjlim_T X_{t'}$ contains the set $F$ as a closed
subset, and since this embeds as a closed subset of $\varinjlim X_i$,  $F$ is
thus closed in there too.
The induced topology on $\left\{x_t\right\}$ is thus the discrete one.

We have thus seen that the set $\left\{x_t\right\}$ is an infinite, discrete
closed subset of $\varinjlim X_i$. However, it is a subset of $f(X)$ as well,
which is compact, so it is itself compact; this is a contradiction.

This example allows one to run the ``small object argument'' of Quillen for
the category of topological spaces, and in particular to construct the
\emph{Quillen model structure} on it. See \cite{Ho07}. As an simple example,
we may note that if we have a sequence of closed subspaces (such as the
skeleton filtration of a CW complex)
\[ X_1 \subset X_2 \subset \dots  \]
it then follows easily from this that  (where $[K, -]$ denotes homotopy
classes of maps)
\[ [K, \varinjlim X_i]  = \varinjlim [K, X_i]  \]
for any compact space $K$. Taking $K$ to be a sphere, one finds that the
homotopy group functors commute with inductive limits of closed inclusions.
\end{example}



This notion is closely related to that of ``smallness'' introduced in
\cref{smallness} to prove an object can be imbedded in an injective module.
For instance, smallness with respect to any limit ordinal and the class of all
maps is basically equivalent to compactness in this sense.

\add{this should be clarified. Can we replace any inductive limit by an
ordinal one, assuming there's no largest element?}



\subsection{Finitely presented modules}


Let us recall that a module $M$ over a ring $R$ is said to be \emph{finitely
presented} if there is an exact sequence
\[ R^m \to R^n \to M \to 0.  \]
In particular, $M$ can be described by a ``finite amount of data:'' $M$ is
uniquely determined by the matrix describing the map $R^m \to R^n$.
Thus, to hom out of $M$  into an $R$-module $N$ is to specify the images of the $n$ generators
(that are the images of the standard basis elements in $R^n$), that is to
pick $n$ elements of $N$, and these
images are required to satisfy $m$ relations (that come from the map $R^m \to
R^n$).


Note that the theory of finitely presented modules is only special and new
when one works with a non-noetherian rings; over a noetherian ring, every
finitely generated module is finitely presented. Nonetheless, the techniques
described here are useful even if one restricts one's attention to noetherian
rings.

\begin{exercise}
Show that a finitely generated \emph{projective} module is finitely presented.
\end{exercise}


\begin{proposition} \label{fpcompact}
In the category of $R$-modules, the compact objects are the finitely presented
ones.
\end{proposition}
\begin{proof}
First, let us show that a finitely presented module is in fact finite.
Suppose $M$ is finitely presented and $\left\{N_i, i \in I\right\}$ is an
inductive system of modules. Suppose given $M \to \varinjlim N_i$; we show
that it factors through one of the $N_i$.

There are finitely many generators $m_1, \dots,
m_n$, and in the colimit
\[ N = \varinjlim N_i , \]
they must all lie in the image of some $N_j, j \in I$. Thus we can choose
$r^{(j)}_1, \dots, r^{(j)}_n$ such that $r^{(j)}_k$ and $m_k$ both map to the
same thing in $\varinjlim N_i$.
This alone does not enable us to conclude that $M \to \varinjlim N_i$
factors through $N_j$, since the relations between the $m_1, \dots, m_n$ may not be
satisfied between the putative liftings $r^{(j)}_k$ to $N_j$.

However, we know that the relations \emph{are} satisfied when we push down to
the colimit. Since there are  only finitely many relations that we need to
have satisfied, we can choose $j' > j$
such that the relations all do become satisfied by the images of the
$r^{(j)}_k$ in $N_{j'}$. We thus get a lifting $M \to N_{j'}$.

We see from this that the map
\[ \varinjlim \hom_R(M, N_i) \to \varinjlim \hom_R( M, \varinjlim N_i)  \]
is in fact surjective. To see that it is injective, note that if two maps $f,g:M
\to N_j$ become the same map $M \to \varinjlim N_i$, then the finite set of
generators $m_1, \dots, m_n$ must both be mapped to the same thing in some
$N_{j'}, j' > j$.

Now suppose $M$ is a compact object in the category of $R$-modules.
First, we claim that $M$ is finitely generated. Indeed, we know that $M$ is
the \emph{inductive} limit of its finitely generated submodules.
Thus we get a map
\[ M \to \varinjlim_{M_F \subset M, \text{f. gen}} M_F ,\]
and by hypothesis it factors as $M \to M_F$ for some $M_F$. This
implies that $M \to M_F \to M $ is the identity, and so $M = M_F$ and $M$ is
finitely generated.

Finally, we need to see that $M$ is finitely presented. Choose a surjection
\[ R^n \twoheadrightarrow M  \]
and let the kernel be $K$. We would like to show that $K$ is finitely
generated. Now $M \simeq R^n/K$, and consequently $M$ is the inductive limit
$\varinjlim R^n/ K_F$ for $K_F$ ranging over the finitely generated submodules
of $K$. It follows that the natural isomorphism $M \simeq \varinjlim R^n/K_F$
factors as $M \to R^n/K_F$ for some $K_F$, which is thus an isomorphism. Hence
$M$ is finitely presented.
\end{proof}

The above argument shows, incidentally, that if $M$ is finitely
\emph{generated}, then
$\varinjlim \hom_R(M, N_i) \to \varinjlim \hom_R( M, \varinjlim N_i)  $ is
always \emph{injective.}

\add{any module is an inductive limit of finitely presented modules}
\add{Lazard's theorem on flat modules}

\subsection{Finitely presented algebras}

Let $R$ be a commutative ring.
\begin{definition}
An $R$-algebra $A$ is called \textbf{finitely presented} if $A$ is isomorphic
to an $R$-algebra of the form $R[x_1, \dots, x_n]/I$, where $I \subset R[x_1,
\dots, x_n]$ is a finitely generated ideal in the polynomial ring.
A morphism of rings $\phi: R \to R'$ is called \textbf{finitely presented} if
it makes $R'$ into a finitely presented $R$-algebra.
\end{definition}

For instance, a quotient of $R$ by a finitely generated ideal is a finitely
presented $R$-algebra. If $R$ is noetherian, then by the Hilbert basis
theorem, an $R$-algebra is finitely presented if and only if it is finitely
generated.

\begin{proposition}
The finitely presented $R$-algebras are the compact objects in the category of
$R$-algebras.
\end{proposition}
We leave the proof to the reader, as it is analogous to \cref{fpcompact}.

The notion of a finitely presented algebra is analogous to that of a finitely
presented module, insofar as a finitely presented algebra can be specified by a
finite amount of ``data.''
Namely, this data consists of the generators $x_1, \dots, x_n$ and the
finitely many relations that they are required to satisfy (these finitely
many relations can be taken to be generators of $I$).
Thus, to hom out of $A$ is ``easy:'' to map into an $R$-algebra $B$, we need
to specify $n$ elements of $B$, which have to satisfy the finitely many
relations that generate the ideal $I$.


Like most nice types of morphisms, finitely presented morphisms have a
``sorite.''
\begin{proposition}[Le sorite for finitely presented morphisms] \label{soritefp}
Finitely presented morphisms are preserved under composite and base-change.
That is, if $\phi: A \to B$ is a finitely presented morphism, then:
\begin{enumerate}
\item If $A'$ is any $A$-algebra, then $\phi \otimes A': A' \to B \otimes_A
A'$ is finitely presented.
\item If $\psi: B \to C$ is finitely presented, then $C$ is a finitely
presented over $A$ (that is, $\psi \circ \phi$ is finitely presented).
\end{enumerate}
\end{proposition}
\begin{proof}
First, we show that finitely presented morphisms are preserved under base-change.
Suppose $B$ is finitely presented over $A$, thus isomorphic to a quotient $A[x_1, \dots,
x_n]/I$, where $I$ is a finitely generated ideal in the polynomial ring. Then
for any $A$-algebra $A'$, we have that
\[ B \otimes_A A' = A'[x_1, \dots, x_n]/ I'  \]
where $I'$ is the ideal in $A'[x_1, \dots, x_n]$ generated by $I$. (This
follows by right-exactness of the tensor product.) Thus $I'$ is finitely
presented and $B \otimes_A A'$ is finitely presented over $A'$.

Next, we show that finitely presented morphisms are closed under composition.
Suppose $A \to B$ and $B \to C$ are finitely presented morphisms. Then $B$ is isomorphic as
$A$-algebra to $A[x_1, \dots, x_n/I$ and $C$ is isomorphic as $B$-algebra to
$B[y_1, \dots, y_m]/J$, where $I, J$ are finitely generated ideals.
Thus $C \simeq A[x_1, \dots, x_n, y_1, \dots, y_m]/(I+J)$ for $I+J$ the ideal
generated by $I, J$ in $A[x_1, \dots, x_n, y_1, \dots, y_m]$.  This is clearly a
finitely generated ideal.
\end{proof}

Finitely presented morphisms have a curious cancellation property that we
tackle next. In algebraic geometry, one often finds properties $\mathcal{P}$ of morphisms
of schemes such that if a composite
\[ X \stackrel{f}{\to} Y \stackrel{g}{\to} Z \]
has $\mathcal{P}$, then so does $f$ (possibly with weak conditions on $g$).
One example of this (in any category) is the class of monomorphisms.  A more
interesting example (for schemes) is the property of separatedness; the
interested reader
may consult \cite{EGA}.

In our case, we shall illustrate this cancellation phenomenon in the category
of commutative rings. Since arrows for schemes go in the opposite direction as
arrows of rings, this will look slightly different.

\begin{proposition}
Suppose we have a composite
\[ A \stackrel{f}{\to} B \stackrel{g}{\to} C \]
such that $g \circ f: A \to C$ is finitely presented, and $f$ is of finite
type (that is, $B$ is a finitely generated $A$-algebra). Then  $g: B \to C$
is finitely presented.
\end{proposition}
\begin{proof}
We shall prove this using the fact that the \emph{codiagonal} map in the
category of commutative rings is finitely presented if the initial map is finitely generated:

\begin{lemma}
Let $S$ be a finitely generated $R$-algebra. Then the map $S \otimes_R S \to
S$ is finitely presented.
\end{lemma}
\begin{proof}
We shall show that the kernel $I$ of $S \otimes_R S \to S$ is a \emph{finitely generated} ideal. This will
clearly imply the claim, as $S \otimes_R S \to S$ is obviously a surjection.

To see this, let $\alpha_1, \dots, \alpha_n \in S$ be generators for $S$ as an
$R$-algebra. The claim is that the elements $1 \otimes \alpha_i - \alpha_i
\otimes 1$ generate $I$ as an $S \otimes_R S$-module.
Clearly these live in $I$. Conversely, it is clear $I$ is generated by
elements of the form $ x \otimes 1 - 1 \otimes x$ (because if $z=\sum x_k
\otimes y_k \in I$, then $z = \sum (x_k \otimes 1) \left(  1 \otimes y_k -  y_k
\otimes y_k \right) + \sum x_k y_k \otimes 1$ and the last term vanishes by
definition of $I$).

In other words, if we define $d(\alpha) = \alpha \otimes 1 - 1 \otimes
\alpha$ for $\alpha \in S$, then $I$ is generated by elements $d(\alpha)$.
Now $d$ is clearly $R$-linear, and  we have the identity
\begin{align*} d(\alpha \beta) & =  \alpha \beta \otimes 1 - 1 \otimes \alpha
\beta \\
&  =
 \alpha \beta \otimes 1 - \alpha \otimes \beta + \alpha \otimes \beta -  1 \otimes \alpha
\beta \\
& = (\alpha \otimes 1) d(\beta) + (1 \otimes \beta) d(\alpha).
\end{align*}
Thus $d(\alpha \beta)$ is in the $S \otimes_R S$-module spanned by $d(\alpha)$
and $d(\beta)$.
From this, it is clear that $d(\alpha_1), d(\alpha_2), \dots, d(\alpha_n)$
generate $I$ as a $S \otimes_R S $-module.
\end{proof}

From this lemma, we will be able to prove the theorem as follows.
We can write $g: B \to C$ as the composite
\[ B \to B \otimes_A C  \to C  \]
where the first map is the base-change of the finitely presented morphism $A
\to C$ and the second morphism is the base-change of the finitely presented
morphism $B \otimes_A B \to B$. Thus the composite $B \to C$ is finitely
presented.
\end{proof}
\section{Inductive limits of rings}

We shall now find ourselves in the following situation. We shall have an
inductive system $\left\{A_\alpha\right\}_{\alpha \in I}$ of rings, indexed by a
directed set $I$. With $A = \varinjlim A_\alpha$, we will be interested in relating
categories of modules and algebras over $A$ to the categories over $A_\alpha$.

The basic idea will be as follows. Given an object (e.g. module) $M$ of finite presentation of
$A$, we will be able to find an object $M_\alpha$ of finite presentation over some
$A_\alpha$ such that $M$ is obtained from $M_\alpha$ by base-change $A_\alpha
\to A$.
Moreover, given a morphism $M \to N$ of objects over $A$, we will be able to
``descend'' this to a morphism $M_\alpha \to N_\alpha$ of objects of finite
presentation over some $A_\alpha$, which will induce $M \to N$ by base-change.
In other words, the \emph{category} of objects over $A$ of finite presentation
will be the inductive limit of the \emph{categories} of such objects over the
$A_\alpha$.

\subsection{Prologue: fixed points of polynomial involutions over $\mathbb{C}$}

Following \cite{Se09}, we give an application of these ideas to a simple
concrete problem. This will help illustrate some of them, even though we have
not formally developed the machinery yet.


If $k$ is an algebraically closed field, a map $k^n \to k^n$ is called \emph{polynomial} if each of
the components is a polynomial function in the input coordinates.
So if we identify $k^n $ with the closed points of $\spec
k[x_1, \dots, x_n]$, then a polynomial function is just the
restriction to to the closed points of an endomorphism of $\spec
k[x_1, \dots, x_n]$ induced by an algebra endomorphism.

\begin{theorem}
Let $F: \mathbb{C}^n \to \mathbb{C}^n$ be a polynomial map with $F \circ F =
1_{\mathbb{C}^n}$. Then $F$ has a fixed point.
\end{theorem}

We can phrase this alternatively as follows. Let $\sigma: \mathbb{C}[x_1,
\dots, x_n] \to \mathbb{C}[x_1, \dots, x_n]$ be a $\mathbb{C}$-involution.
Then the map on the $\spec$'s has a fixed point (which is a closed
point\footnote{One can show that if there is a fixed point, there is a fixed
point that is a closed point.}).


\begin{proof}
It is clear that the presentation of $\sigma$ involves only a finite amount of
data, so as in \cref{} we can construct a finitely generated
$\mathbb{Z}$-algebra $R \subset \mathbb{C}$ and an involution
\[ \overline{\sigma}: R[x_1, \dots, x_n] \to R[x_1, \dots, x_n] \] such that $\sigma$ is obtained from
$\overline{\sigma}$ by base-changing $R \to \mathbb{C}$.
We can assume that $\frac{1}{2} \in R$ as well.
To see this explicitly, we simply need only add to $R$ the coefficients of the
polynomials $\sigma(x_1), \dots, \sigma(x_n)$, and $\frac{1}{2}$, and
consider the $\mathbb{Z}$-algebra they generate.

Suppose now the system of equations $\sigma(x_1, \dots, x_n) - (x_1, \dots,
x_n)$ has no solution in $\mathbb{C}^n$. This is equivalent to stating that a
finite
system of polynomials (namely, the $\sigma(x_i) - x_i$) generate the unit ideal in $\mathbb{C}[x_1, \dots,
x_n]$, so that there are polynomials $P_i \in \mathbb{C}[x_1, \dots, x_n]$
such that $\sum P_i \left( \sigma(x_i) - x_i \right)  = 1$.

Let us now enlarge $R$ so that the coefficients of the $P_i$ lie in $R$.
Since the coefficients of the $\sigma(x_i)$ are already in $R$, we find
that the polynomials $\sigma(x_i) - x_i$ will generate the unit ideal in
$R[x_1, \dots, x_n]$.
If $R'$ is a homomorphic image of $R$, then this will be true in $R'[x_1,
\dots, x_n]$.

Choose a maximal ideal $\mathfrak{m} \subset R$. Then $R/\mathfrak{m}$ is a
finite field, and $\sigma$ becomes an involution
\[ (R/\mathfrak{m})[x_1, \dots, x_n] \to (R/\mathfrak{m})[x_1, \dots, x_n].  \]
If we let $\overline{k}$ be the algebraic closure of $R/\mathfrak{m}$, then we
have an involution
\[ \widetilde{\sigma}: k[x_1, \dots, x_n] \to k[x_1, \dots, x_n].  \]
But the induced map by $\widetilde{\sigma}$ on $k^n$ has \emph{no fixed points.}  This follows because the
$\widetilde{\sigma(x_i)} - x_i$ generate the unit ideal in $k[x_1, \dots,
x_n]$ (because we can consider the images of the $P_i$ in $k[x_1, \dots, x_n]$).
Moreover, $\mathrm{char} k \neq 2$ as $\frac{1}{2} \in R$, so $2$ is
invertible in $k$ as well.

So from the initial fixed-point-free involution $F$ (or $\sigma$), we have
induced a
polynomial map $k^n \to k^n$ with no fixed points. We need only now prove:

\begin{lemma} \label{easycaseoffptheorem}
If $k$ is the algebraic closure of $\mathbb{F}_p$ for $p \neq 2$, then any
involution $F: k^n \to k^n$ which is a polynomial map has  a fixed point.
\end{lemma}
\begin{proof}
This is very simple. There is a finite field $\mathbb{F}_q$ in which the
coefficients of $F$ all lie; thus $F$ induces a map
\[ \mathbb{F}_q^n \to \mathbb{F}_q^n  \]
which is necessarily an involution. But an involution on a finite set of odd
cardinality necessarily has a fixed point (or all orbits would be even).
\end{proof}

\end{proof}


\begin{remark}
An alternative approach to the above proof is to use a little bit of model
theory. There is a general principle due to Abraham Robinson, that can be
stated roughly as follows. If a sentence  $P$ in the first-order logic of fields
(that is, one is allowed to refer to the elements $0,1$ and to addition and
multiplication; in addition, one is allowed to make existential and universal
quantifications, negations, disjunctions, and conjunctions) has the property
that $P$ is true for an algebraically closed field of characteristic $p$ for
each $p \gg 0$, then $P$ holds in \emph{every} algebraically closed field of
characteristic zero.
This principle follows from a combination of the compactness theorem and the
fact that the theory of algebraically closed fields of a fixed characteristic
is \emph{complete}: any statement is true in all of them, or in none of them.

Consider the statement $S_{n,d}$ that for any polynomial map $F: k^n \to k^n$
consisting of polynomials of degree $\leq d$ such that $F \circ F$, there is
$(x_1, \dots, x_n) \in k^n$ with $F(x_1, \dots, x_n) = (x_1, \dots, x_n)$.
Then $S_{n,d}$ is clearly a statement of first-order logic.
\cref{easycaseoffptheorem} shows that $S_{n,d}$ holds in
$\overline{\mathbb{F}_p}$ whenever $p > 2$. Thus, $S_{n,d}$ holds in
$\mathbb{C}$ by Robinson's principle.

These types of model-theoretic arguments can be used to prove the \textbf{Ax-Grothendieck
theorem}: an injective polynomial map $\mathbb{C}^n \to \mathbb{C}^n$ is
surjective. See \cite{Ma02}.
\end{remark}

\subsection{The inductive limit of categories}

\add{general formalism to clarify all this}



\subsection{The category of finitely presented modules}

Throughout, we let $\left\{A_{\alpha}\right\}_{\alpha \in I}$ be an inductive
system of rings, and $A = \varinjlim A_\alpha$.
We are going to relate the category of finitely presented modules over $A$ to
the categories of finitely presented modules over the $A_\alpha$.

We start by showing that any module over $A$ ``descends'' to one of the
$A_\alpha$.
\begin{proposition} \label{descentfpmodule}
Suppose $M$ is a finitely presented module over $A$. Then there is $\alpha \in
I$ and a finitely presented $A_\alpha$-module $M_\alpha$ such that $M \simeq
M_\alpha \otimes_{A_\alpha} A$.
\end{proposition}
\begin{proof}
Indeed, $M$ is the cokernel of a morphism
\[ f: A^m \to A^n   \]
by definition. This morphism is described by a $m$-by-$n$ (or $n$-by-$m$,
depending on conventions) matrix with coefficients in $A$. Each of these
finitely many coefficients must come from various $A_\alpha$ in the image (by
definition of the inductive limit), and choosing $\alpha$ ``large'' we can
assume that every coefficient in the matrix is in the image of $A_\alpha \to A$.
Then we have a morphism
\[ f_\alpha:  A_\alpha^m \to A_\alpha^n  \]
that induces $f$ by base-change to $A$. Then we may let $M_\alpha$ be the
cokernel of $f_\alpha$ since the tensor product is right-exact.
\end{proof}

Now, we want to show that if the base-change of two finitely presented modules
over $A_\alpha$ to $A$ become isomorphic, then they ``become isomorphic'' at some
$A_\beta $ (for $\beta > \alpha$).
We shall actually prove a more general result.
Namely, we shall see that
a morphism at the colimit ``descends'' to one of the steps.

\begin{proposition} \label{colimfpmodules} We keep the same notation as above.
Suppose $M_\alpha, N_\alpha$ are finitely presented modules over $A_\alpha$.
Write $M_\beta = M_\alpha \otimes_{A_\alpha} A_\beta, N_\beta = N_\alpha
\otimes_{A_\alpha} A_\beta$ for each $\beta > \alpha$ and $M, N$ for the
base-changes to $N$.

Suppose there is a morphism $f: M \to N$. Then there is $\beta \geq \alpha$ such
that $f$ is obtained by base-changing a morphism $f_\beta: M_\beta \to N_\beta$.
If $f_\beta, f_\gamma$ are any two morphisms that do this, then there is
$\delta \geq \beta, \gamma$ such that $f_\beta, f_\gamma$ become equal when
base-changed to $A_\delta$.
\end{proposition}
The conclusion of this result is then
\[ \hom_A(M, N) = \varinjlim_{\beta} \hom_{A_\beta}(M_\beta, N_\beta).  \]
The last part is essentially the ``uniqueness'' that we were discussing previously.
\begin{proof} Suppose the transition maps $A_\alpha \to A_\beta$ are denoted
$\phi_{\alpha \beta}$, and the natural maps $A_\alpha \to A$ are denoted
$\phi_\alpha$.

We know that there are exact sequences
\[ A_\alpha^m \stackrel{\textbf{M}}{\to} A_\alpha^n \to M_\alpha \to 0,  \]
and
\[ A_\alpha^p \to N_\alpha \to 0.  \]
These are preserved by tensoring with $A$. Here $\textbf{M}$ is a suitable matrix.
So we get exact sequences
\begin{gather*}
A^m \stackrel{\phi_\alpha(\textbf{M})}{\to} A^n \to M \to 0 \\
A^p \to N \to 0
\end{gather*}
and the projectivity of $A^p$ shows that the map $A^n \to M \to N$ can be
lifted to  a map $A^n \to A^p$ given by some matrix $\textbf{M}'$ with coefficients
in $A$. We know that there is $\textbf{M}'  \circ \phi_\alpha(\textbf{M}) = 0$
because the map factors through $M$.

Now $\textbf{M}'$ can be written as $\phi_\beta(\textbf{M}'')$ for some matrix
with coefficients in $A_\beta$, or in other words a map $A_\beta^n \to
A_\beta^p$. We would like to use this to get a map $M_\beta \to A_\beta^p \to
N_\beta$, but for this we need to check that $A_\beta^n \to A_\beta^p$ pulls
back to zero in $A_\beta^m$. In other words, we need that
$\textbf{M}'' \phi_{\alpha \beta}( \textbf{M}) = 0$. This need not be true, but we know
that it is true if base-change to a bigger $\beta$ (since this matrix product
is zero in the colimit). This allows us to get the map $M_\beta \to N_\beta$.

Finally, we need uniqueness. Suppose $f_\beta: M_\beta \to N_\beta$ and
$f_\gamma: M_\gamma \to N_\gamma$ both are such that the base-changes to $A$
are the same morphism $M \to N$. We need to find a $\delta$ as in the
proposition. By replacing $\beta, \gamma$ with a mutual upper bound, we may
suppose that $\beta = \gamma$; we shall write the two morphisms as $f_\beta,
g_\beta$ then.

Consider the pull-backs $A_\beta^n \stackrel{f_\beta, g_\beta}{\to } N_\beta$.
These uniquely determine $f_\beta, g_\beta$ (since the map $A_\beta^n \to
M_\beta$ is a surjection). These pull-backs are specified by $n$ elements of
$N_\beta$. If the base-changes of $f_\beta, g_\beta$ via $\phi_{\beta}:
A_\beta \to A$ are the same, then these $n$ elements of $N_\beta$ become the
same in $N = \varinjlim_{\beta'} N \otimes_{A_\beta} A_{\beta'}$; thus they
become equal at some finite stage, so there is $\beta' > \beta$ such that the
base changes $f_{\beta'} = g_{\beta'}$.

\end{proof}

\begin{remark}
The idea of the above proof was to exploit the idea that the homomorphism
carries a finite amount of data, that is the images of the generators and the
condition that these images satisfy finitely many relations. In essence, it is
analogous to the argument that finitely presented modules over a \emph{fixed}
ring are compact objects in that category.
\end{remark}


\begin{remark}
In fact, we can give an alternative (and slightly simpler) argument for \cref{colimfpmodules}.
We know that
\[ \hom_{A_\beta}(M_\beta, N_\beta) = \hom_{A_\alpha}(M_\alpha, N_\beta)  \]
by the adjoint property of the tensor product, and similarly
\[ \hom_{A}(M,N) = \hom_{A_\alpha}(M_\alpha, N).  \]
So the assertion we are trying to prove is
\[ \hom_{A_\alpha}(M_\alpha, N) = \varinjlim_{\beta} \hom_{A_\alpha}(M_\alpha,
N_\beta) , \]
which follows from \cref{fpcompact}.
\end{remark}

\begin{exercise}
Give a proof of the following claim. If $M$ is a finitely generated module
over a noetherian ring $R$, $\mathfrak{p} \in \spec R$ is such that
$M_{\mathfrak{p}}$ is free over $R_{\mathfrak{p}}$, then there is $f \in R - \mathfrak{p}$ such that
$M_f$ is free over $R_f$.
\end{exercise}

\subsection{The category of finitely presented algebras}

We can treat the category of finitely presented algebras over such an
inductive limit in a similar manner.
As before, let $\left\{A_\alpha\right\}_{\alpha \in I}$ be an inductive system
of rings with $A = \varinjlim A_\alpha$.
For each $\alpha$, there is a  functor from the category of finitely presented $A_\alpha$-algebras
to the category of finitely presented $A$-algebras sending $C \mapsto C
\otimes_{A_\alpha} A$.
(Note that morphisms of finite presentation are preserved under base-change by
\cref{soritefp}.)

\begin{proposition}
Suppose $B$ is a finitely presented $A$-algebra. Then there is $\alpha \in I$
and a finitely presented $A_\alpha$-algebra $B_\alpha$ such that $B \simeq
B_\alpha \otimes_{A_\alpha} A$.
\end{proposition}
\begin{proof}
This is analogous to the proof of \cref{descentfpmodule}.
\end{proof}

\add{analog of the next result}

\subsection{$\spec$ and inductive limits}

Suppose $\left\{A_\alpha\right\}_{\alpha\in I}$ is an inductive system of
commutative rings, as before; we let $A = \varinjlim A_\alpha$.
Since $\spec$ is a contravariant functor, we thus find that $\spec A_\alpha$
is a \emph{projective} system of topological spaces.\footnote{Or schemes.}
We are now interested in relating $\spec A$ to the individual $\spec A_\alpha$.

\begin{proposition}
$\spec A$ is the projective limit $\varprojlim \spec A_\alpha$ in the category
of topological spaces.
\end{proposition}

Recall that if $\left\{X_\alpha\right\}$ is a projective system of topological
spaces with transition maps $\phi_{\beta \alpha}: X_\beta \to X_\alpha$ whenever $\alpha \leq
\beta$, then the projective limit $\varprojlim X_\alpha$ can be constructed as
follows. One considers the subset of $\prod X_\alpha$ consisting of sequences
$(x_\alpha)$ such that $\phi_{\beta \alpha}(x_\alpha) = x_\beta$ for every
$\alpha \leq \beta$. One can easily check that this has the universal property
of the projective limit.

\begin{proof}
Let us first verify that the assertion is true as \emph{sets.} There are maps
\[ \spec A \to \spec A_\alpha  \]
for each $\alpha \in I$, which are obviously compatible (since the
$\left\{A_\alpha\right\}$ form an inductive system) so that they lead to a
(continuous) map of topological spaces
\[ \spec A \to \varprojlim \spec A_\alpha.  \]
We first verify injectivity. Suppose two primes $\mathfrak{p}, \mathfrak{p}'$ were sent to the same element
of $\varprojlim \spec A_\alpha$. This means that if $\phi_\alpha: A_\alpha \to
A$ is the natural morphism for each $\alpha$, we have
$\phi_\alpha^{-1}(\mathfrak{p}) = \phi_\alpha^{-1}(\mathfrak{p}')$ for all
$\alpha$. It follows that the intersections of $\mathfrak{p}, \mathfrak{p}'$
with the image of $A_\alpha$ are identical; since $A$ is the union of
$\phi_\alpha(A_\alpha)$ over all $\alpha$, this implies $\mathfrak{p} =
\mathfrak{p}'$.

Now let us verify surjectivity. Suppose given a sequence $\mathfrak{p}_\alpha$
of primes in $A_\alpha$, for each $\alpha$, such that $\mathfrak{p}_\alpha$ is
the pre-image of $\mathfrak{p}_\beta$ under $A_\alpha \to A_\beta$ whenever
$\alpha \leq \beta$. We want to form a prime ideal $\mathfrak{p} \in \spec A$
pulling back to all these. To do this, we decide that $x \in \mathfrak{p}$ if
and only if there exists $\alpha \in I$ such that $x \in
\phi_\alpha(\mathfrak{p}_\alpha)$ (recall that $\phi_\alpha: A_\alpha \to A$
is the natural map). This does not depend on the choice of $\alpha$, and one
verifies easily that this is a prime ideal with the appropriate properties.

We now have to show that the map $\spec A \to \varprojlim \spec A_\alpha$ is
in fact a homeomorphism. We have seen that it is continuous and bijective, so
we must prove that it is open. If $a \in A$, we will be done if we can show
that the image of the basic open set $D(a) \subset \spec A$ is open in
$\varprojlim \spec A_\alpha$.

Suppose $a = \phi_\beta(a_\beta)$ for some $a_\beta \in A_\beta$. Then the
claim is that the image of $D(a)$ is precisely the subset of $\varprojlim
\spec A_\beta$ such that the $\beta$th coordinate (which is in $\spec A_\beta$!)
lies in $D(a_\beta)$. This is clearly an open set, so if we prove this, then
we are done. Indeed, if $\mathfrak{p} \in D(\alpha) \subset \spec A$,
then clearly the preimage in $A_\beta$ cannot contain $a_\beta$ (since
$a_\beta$ maps to $a$). Conversely, if we have a compatible sequence
$\left\{\mathfrak{p}_\alpha\right\}$ of primes  such that $\mathfrak{p}_\beta
\in D(a_\beta)$, then the above construction of a prime $\mathfrak{p} \in
\spec A$ from this shows that $a \notin \mathfrak{p}$.
\end{proof}

% ============================ chapters/homological.tex}
\chapter{Homological Algebra}
\label{homological}


Homological algebra begins with the notion of a \emph{differential object,}
that is, an object with an endomorphism $A \stackrel{d}{\to} A$ such that $d^2 =
0$. This equation leads to the obvious inclusion $\im(d) \subset \ker(d)$, but
the inclusion generally is not equality. We will find that the difference
between $\ker(d)$ and $\im(d)$, called the \emph{homology}, is a highly useful
variant of a differential object: its first basic property is that if an exact
sequence
\[ 0 \to A' \to A \to A'' \to 0  \]
of differential objects is given, the homology of $A$ is related to that of
$A', A''$ through a long exact sequence. The basic example, and the one we
shall focus on, is where $A$ is a
chain complex, and $d$ the usual differential.
In this case, homology simply measures the failure of a complex to be exact.

After introducing these preliminaries, we develop the theory of \emph{derived
functors}. Given a functor that is only left or right-exact, derived functors
allow for an extension of a partially exact sequence to a long exact sequence.
The most important examples to us, $\mathrm{Tor}$ and $\mathrm{Ext}$, provide
characterizations of flatness, projectivity, and injectivity.

\section{Complexes}


\subsection{Chain complexes}
The chain complex is the most fundamental construction in
homological algebra.

\begin{definition} Let $R$ be a ring. A \textbf{chain complex} is a collection
of $R$-modules
$\{C_i\}$ (for $i \in \mathbb{Z}$)
together with boundary
operators
$\partial_i:C_i\rightarrow C_{i-1}$ such that
$\partial_{i-1}\partial_i=0$. The boundary map is also
called the
\textbf{differential.} Often, notation is abused and the indices for
the boundary map are dropped.

A chain complex is often simply denoted $C_*$.
\end{definition}

In practice, one often has that $C_i = 0$ for $i<0$.


\begin{example} All exact sequences are chain complexes.
\end{example}

\begin{example} Any sequence of abelian groups $\left\{C_i\right\}_{i \in
\mathbb{Z}}$ with the boundary operators
identically zero forms a chain complex.
\end{example}

We will see plenty of more examples in due time.

At each stage, elements in the image of the boundary $C_{i+1} \to C_i$ lie in
the kernel of $\partial_i: C_i \to C_{i-1}$. 	Let us recall that a chain
complex is \emph{exact} if the kernel and the image coincide. In general, a
chain complex need not be exact, and this failure of exactness is measured by
its homology.

\begin{definition}
Let $C_*$
The submodule of cycles $Z_i\subset C_i$ is
the kernel $\ker(\partial_i)$. The submodule of boundaries
$B_i\subset C_i$ is the image $Im(\partial_{i+1})$. Thus
homology is said to be ``cycles mod boundaries,'' i.e.
$Z_i/B_i$.
\end{definition}

To further simplify notation, often all differentials regardless
of what chain complex they are part of are denoted $\partial$,
thus the commutativity relation on chain maps is
$f\partial=\partial f$ with indices and distinction between the
boundary operators dropped.


\begin{definition} Let $C_*$ be a chain complex with boundary
map $\partial_i$.
We define the \textbf{homology} of the complex $C_*$ via
$H_i(C_*)=\ker(\partial_i)/Im(\partial_{i+1})$.
\end{definition}

\begin{example} In a chain complex $C_*$ where all the boundary
maps are
trivial, $H_i(C_*)=C_i$.
\end{example}

Often we will bundle all the modules $C_i$ of a chain complex
together to form a graded module $C_*=\bigoplus_i C_i$. In this
case, the boundary operator is a
endomorphism that takes elements from degree $i$ to degree
$i-1$. Similarly, we
often bundle together all the homology modules to give a graded
homology module
$H_*(C_*)=\bigoplus_i H_i(C_*)$.

\begin{definition}
A \textbf{differential module} is a module $M$ together with a morphism $d:
M\to M$ such that $d^2 =0$.
\end{definition}

Thus, given a chain complex $C_*$, the module $\bigoplus C_i$ is a
differential module with the direct sum of all the differentials $\partial_i$.
A chain complex is just a special kind of differential module, one where the
objects are graded and the differential drops the grading by one.

\subsection{Functoriality}
We have defined chain complexes now, but we have no notion of a morphism
between chain complexes.
We do this next; it turns out that chain complexes form a category when morphisms
are appropriately defined.

\begin{definition} A \textbf{morphism} of chain complexes $f:C_*\rightarrow
D_*$, or a \textbf{chain map}, is a sequence of maps $f_i:C_i\rightarrow
D_i$ such that $f\partial = \partial' f$ where $\partial$ is the
boundary map of $C_*$ and $\partial'$ of $D_*$ (again we are
abusing notation and dropping indices).
\end{definition}

There is thus a \emph{category} of chain complexes where the morphisms are
chain maps.

One can make a similar definition for differential modules. If $(M, d)$ and
$(N,d')$ are differential modules, then a \emph{morphism of differential
modules} $(M,d) \to (N,d')$ is a morphism of modules $M \to N$ such that the diagram
\[
\xymatrix{
M \ar[d] \ar[r]^d &  M \ar[d] \\
N \ar[r]^{d'} &  N
}
\]
commutes.
There is therefore a category of differential modules, and the map $C_* \to
\bigoplus C_i$ gives a functor from the category of chain complexes to that of
differential modules.


\begin{proposition} A chain map $C_* \to D_*$ induces a map in homology $H_i(C)
\to H_i(D)$ for each $i$; thus homology is a covariant functor from
the category of chain complexes to the category of graded
modules.
\end{proposition}

More precisely, each $H_i$ is a functor from chain complexes to modules.
\begin{proof}
Let $f:C_*\rightarrow D_*$ be a chain map. Let $\partial$ and
$\partial'$ be the differentials for $C_*$ and $D_*$
respectively. Then we have a commutative diagram:

\begin{equation}
\begin{CD}
C_{i+1} @>\partial_{i+1}>> C_i @>>\partial_i> C_{i-1}\\
@VV f_{i+1} V          @VV f_i V             @VVf_{i-1} V\\
D_{i+1} @>\partial'_{i+1}>> D_i @>>\partial'_i> D_{i-1}
\end{CD}
\end{equation}

Now, in order to check that a chain map $f$ induces a map $f_*$
on homology, we need to check that $f_*(Im(\partial))\subset
Im(\partial')$ and $f_*(\ker(\partial))\subset
\ker(\partial)$. We first check the condition on images: we want
to look at $f_i(Im(\partial_{i+1}))$. By commutativity of $f$
and the boundary maps, this is equal to
$\partial'_{i+1}(Im(f_{i+1})$. Hence we have
$f_i(Im(\partial_{i+1}))\subset Im(\partial_{i+1}')$. For the
condition on kernels, let $x\in \ker(\partial_i)$. Then by
commutativity, $\partial'_i(f_i(x))=f_{i-1}\partial_i(x)=0$.
Thus we have that $f$ induces for each $i$ a homomorphism
$f_i:H_i(C_*)\rightarrow H_i(D_*)$ and hence it induces a
homomorphism on homology as a graded module. \end{proof}

\begin{exercise}
Define the \emph{homology} $H(M)$ of a differential module $(M, d)$ via $\ker d / \im
d$. Show that $M \mapsto H(M)$ is  a functor from differential modules to
modules.
\end{exercise}


\subsection{Long exact sequences}
\add{OMG! We have all this and not the most basic theorem of them all.}

\begin{definition} If $M$ is a complex then for any integer $k$, we define a new complex $M[k]$ by shifting indices, i.e. $(M[k])^i:=M^{i+k}$.\end{definition}

\begin{definition} If $f:M\rightarrow N$ is a map of complexes, we define a complex $\mathrm{Cone}(f):=\{N^i\oplus M^{i+1}\}$ with differential
$$d(n^i,m^{i+1}):= (d_N^i(n_i)+(-1)^i\cdot f(m^{i+1}, d_M^{i+1}(m^{i+1}))$$
\end{definition}

Remark:  This is a special case of the total complex construction to be seen later.

\begin{proposition} A map $f:M\rightarrow N$ is a quasi-isomorphism if and only if $\mathrm{Cone}(f)$ is acyclic.\end{proposition}

\begin{proposition}  Note that by definition we have a short exact sequence of complexes
$$0\rightarrow N\rightarrow \mathrm{Cone}(f)\rightarrow M[1]\rightarrow 0$$
so by Proposition 2.1, we have a long exact sequence
$$\dots \rightarrow H^{i-1}(\mathrm{Cone}(f))\rightarrow H^{i}(M)\rightarrow H^{i}(N)\rightarrow H^{i}(\mathrm{Cone}(f))\rightarrow\dots$$
so by exactness, we see that $H^i(M)\simeq H^i(N)$ if and only if $H^{i-1}(\mathrm{Cone}(f))=0$ and $H^i(\mathrm{Cone}(f))=0$.  Since this is the case for all $i$, the claim follows. $\blacksquare$
\end{proposition}



\subsection{Cochain complexes}
Cochain complexes are much like chain complexes except the
arrows point in the
opposite direction.

\begin{definition} A \textbf{cochain complex} is a sequence of modules
$C^i$ for $i \in \mathbb{Z}$ with \textbf{coboundary operators}, also
called
\textbf{differentials}, $\partial^i:C^i\rightarrow C^{i+1}$ such that
$\partial^{i+1}\partial^i=0$. \end{definition}

The theory of cochain complexes is entirely dual to that of chain complexes,
and we shall not spell it out in detail.
For instance, we can form a category of cochain complexes and
\textbf{chain maps} (families of morphisms commuting with the
differential). Moreover, given a cochain complex $C^*$, we
define the
\textbf{cohomology objects} to be
$h^i(C^*)=\ker(\partial^i)/Im(\partial^{i-1})$; one obtains cohomology
functors.

It should be noted that the long exact sequence in cohomology runs in the
opposite direction.
If $0 \to C_*' \to C_* \to C_*'' \to 0$ is a short exact sequence of cochain
complexes, we get a long exact sequence
\[ \dots \to H^i(C' ) \to H^i(C) \to H^{i}(C'') \to H^{i+1}(C' ) \to H^{i+1}(C) \to
\dots.  \]

Similarly, we can also turn cochain complexes and cohomology
modules into a
graded module.

Let us now give a standard example of a cochain complex.
\begin{example}[The de Rham complex] Readers unfamiliar with differential
forms may omit this example. Let $M$ be a smooth manifold. For each $p$, let
$C^p(M)$ be the $\mathbb{R}$-vector space of smooth $p$-forms on $M$.
We can make the $\left\{C^p(M)\right\}$ into a complex by defining the maps
\[ C^p(M) \to C^{p+1}(M)  \]
via $\omega \to d \omega$, for $d$ the exterior derivative.
(Note that $d^2 = 0$.)  This complex is called the \textbf{de Rham complex} of
$M$, and its cohomology is called the \textbf{de Rham cohomology.} It is known
that the de Rham cohomology is isomorphic to singular cohomology with real
coefficients.

It is a theorem, which we do not prove, that the de Rham cohomology is
isomorphic to the singular cohomology of $M$ with coefficients in $\mathbb{R}$.
\end{example}

\subsection{Long exact sequence}

\subsection{Chain Homotopies}

In general, two maps of complexes $C_* \rightrightarrows D_*$ need not be
equal to induce the same morphisms in homology. It is thus of interest to
determine conditions when they do. One important condition is given by chain
homotopy: chain homotopic maps are indistinguishable in homology. In algebraic
topology, this fact is used to show that singular homology is a homotopy
invariant.
We will find it useful in showing that the construction (to be given later) of a
projective resolution is essentially unique.

\begin{definition} Let $C_*, D_*$ be chain complexes with differentials $d_i$. A chain homotopy between two chain maps
$f,g:C_*\rightarrow D_*$ is a series of homomorphisms
$h^i:C^i\rightarrow D^{i-1}$ satisfying $f^i-g^i=d h^i+
h^{n+1}d$. Again often notation is abused and the
condition is written $f-g=d h +
hd$.
\end{definition}

\begin{proposition} If two morphisms of complexes $f,g: C_* \to D_*$ are chain homotopic, they are taken
to the same induced map after applying the homology functor.
\end{proposition}

\begin{proof}
Write $\left\{d_i\right\}$ for the various differentials (in both complexes).
Let $m\in Z_i(C)$, the group of $i$-cycles.
Suppose there is a chain homotopy $h$ between $f,g$ (that is, a set of
morphisms $C_i \to D_{i-1}$).
Then
$$f^i(m)-g^i(m)= h^{i+1}\circ d^i(m) + d^{i-1}\circ h^i(m)= d^{i-1}\circ H^i(m) \in \Im(d^{i-1})$$
which is zero in the cohomology $H^i(D)$.
\end{proof}


\begin{corollary} If two chain complexes are chain homotopically equivalent
(there are maps $f: C_*\rightarrow D_*$ and $g:D_*\rightarrow
C_*$ such that both $fg$ and $gf$ are chain homotopic to the
identity), they have isomorphic homology.
\end{corollary}
\begin{proof}
Clear.
\end{proof}

\begin{example}  Not every quasi-isomorphism is a homotopy equivalence.  Consider the complex
$$\dots \rightarrow 0\rightarrow\mathbb{Z}/{\cdot 2}\rightarrow \mathbb{Z}\rightarrow 0\rightarrow 0\rightarrow\dots$$
so $H^0=\mathbb{Z}/2\mathbb{Z}$ and all cohomologies are 0.  We have a quasi-isomorphism from the above complex to the complex
$$\dots \rightarrow 0\rightarrow 0 \rightarrow \mathbb{Z}/2\mathbb{Z}\rightarrow 0\rightarrow 0\rightarrow\dots$$
but no inverse can be defined (no map from $\mathbb{Z}/2\mathbb{Z}\rightarrow \mathbb{Z}$).
\end{example}


\begin{proposition} Additive functors preserve chain homotopies
\end{proposition}
\begin{proof} Since an additive functor $F$ is a homomorphism on $Hom(-,-)$,
the chain homotopy condition will be preserved; in
particular, if $t$ is a chain homotopy, then $F(t)$ is a chain
homotopy.
\end{proof}

In more sophisticated homological theory, one often makes the
definition of the ``homotopy category of chain complexes.''
\begin{definition} The homotopy category of chain complexes is
the category $hKom(R)$ where objects are chain complexes of
$R$-modules and morphisms are chain maps modulo chain homotopy.
\end{definition}


\subsection{Topological remarks}

\add{add more detail}
The first homology theory
to be developed was simplicial homology - the study of homology
of simplicial
complexes. To be simple, we will not develop the general theory
and instead
motivate our definitions with a few basic examples.

\begin{example} Suppose
our simplicial complex has one line segment with both ends
identified at
one point $p$. Call the line segment $a$. The $n$-th homology
group of this
space roughly counts how many ``different ways'' there are of
finding $n$
dimensional sub-simplices that have no boundary that aren't the
boundary of
any $n+1$ dimensional simplex. For the circle, notice that for
each integer,
we can find such a way (namely the simplex that wraps counter
clockwise that
integer number of times). The way we compute this is we look at
the free abelian group generated by $0$ simplices, and $1$
simplices (there are no simplices of
dimension $2$ or higher so we can ignore that). We call these
groups $C_0$ and
$C_1$ respectively. There is a boundary map $\partial_1:
C_1\rightarrow C_0$.
This boundary map takes a $1$-simplex and associates to it its
end vertex minus
its starting vertex (considered as an element in the free
abelian group on
vertices of our simplex). In the case of the circle, since there
is only one
$1$-simplex and one $0$-simplex, this map is trivial. We then
get our homology
group by looking at $\ker(\partial_1)$. In the case that there
is a nontrivial
boundary map $\partial_2: C_2\rightarrow C_1$ (which can only
happen when our
simplex is at least $2$-dimensional), we have to take the
quotient
$\ker(\partial_1)/\ker(\partial_2)$. This motivates us to define
homology in a
general setting.
\end{example}

Originally homology was
intended to be a homotopy invariant meaning that space with the
same homotopy type would have isomorphic homology modules. In fact, any
homotopy induces what is now known as a chain homotopy on the simplicial chain
complexes.

\begin{exercise}[Singular homology] Let $X$ be a topological
space and let $S^n$ be the set of all continuous maps
$\Delta^n\rightarrow X$ where $\Delta^n$ is the convex hull of
$n$ distinct points and the origin with orientation given by an
ordering of the $n$ vertices. Define $C_n$ to be the free
abelian group generated by elements of $S^n$. Define
$\Delta^n_{\hat{i}}$ to be the face of $\Delta^n$ obtained by
omitting the $i$-th vertex from the simplex. We can then
construct a boundary map $\partial_n:C_n\rightarrow C_{n-1}$ to
take a map $\sigma^n:\Delta^n\rightarrow X$ to
$\sum_{i=0}^n(-1)^i\sigma^n|_{\Delta^n_{\hat{i}}}$. Verify that
$\partial^2=0$ (hence making $C_*$ into a chain complex known as
the ``singular chain complex of $X$''. Its homology groups are
the ``singular homology groups''. \end{exercise}

\begin{exercise} Compute the singular homology groups of a
point. \end{exercise}

\section{Derived functors}
\subsection{Projective resolutions}

Fix a ring $R$.
Let us recall (\rref{projectives}) that an $R$-module $P$ is called
\emph{projective} if the functor $N \to \hom_R(P,N)$ (which is always
left-exact) is exact.

Projective objects are useful in defining chain exact sequences
known as ``projective resolutions.'' In the theory of derived functors, the
projective resolution of a module $M$ is in some sense a replacement for $M$:
thus, we want it to satisfy some uniqueness and existence properties. The
uniqueness is not quite true, but it is true modulo chain equivalence.

\begin{definition} Let $M$ be an arbitrary module, a projective
resolution of
$M$ is an exact sequence
\begin{equation} \cdots\rightarrow P_i\rightarrow
P_{i-1}\rightarrow
P_{i-2}\cdots\rightarrow P_1\rightarrow P_0\rightarrow M
\end{equation} where
the $P_i$ are projective modules. \end{definition}


\begin{proposition} Any module admits a projective resolution. \end{proposition}
The proof will even show that we can take a \emph{free} resolution.
\begin{proof}
We construct the resolution inductively.
First, we take a projective module $P_0$ with $P_0 \twoheadrightarrow N$
surjective by the previous part.  Given a portion of the resolution
\[ P_n \to P_{n-1} \to \dots \to P_0 \twoheadrightarrow N \to 0  \]
for $n \geq 0$, which is exact at each step, we consider $K = \ker(P_n \to
P_{n-1})$. The sequence
\[ 0 \to K \to P_n \to P_{n-1} \to \dots \to P_0 \twoheadrightarrow N \to 0  \]
is exact. So if $P_{n+1}$ is chosen such that it is projective and there is an
epimorphism
\( P_{n+1} \twoheadrightarrow K,  \)
(which we can construct by \rref{freesurjection}), then
\[ P_{n+1} \to P_n \to \dots  \]
is exact at every new step by construction. We can repeat this inductively and
get a full projective resolution.
\end{proof}

Here is a useful observation:
\begin{proposition}
If $R$ is noetherian, and $M$ is finitely generated, then we can
choose a
projective resolution where each $P_i$ is finitely generated.
\end{proposition}
We can even take a resolution consisting of finitely generated free modules.
\begin{proof}
To say that $M$ is finitely generated is to say that it is a
quotient of a free module on
finitely many generators, so we can take $P_0$ free and finitely generated. The kernel
of $P_0 \to M$
is finitely generated by noetherianness, and we can proceed as
before, at each step
choosing a finitely generated object.
\end{proof}

\begin{example} The abelian group $\mathbb{Z}/2$ has the free
resolution $0\rightarrow\cdots
0\rightarrow\mathbb{Z}\rightarrow\mathbb{Z}\rightarrow\mathbb{Z}/2$.
Similarly, since any finitely generated abelian group can be
decomposed into the direct sum of torsion subgroups and free
subgroups, all finitely generated abelian groups admit
a free resolution of length two.

Actually, over a principal ideal domain $R$ (e.g. $R=\mathbb{Z}$),
\emph{every} module admits a free resolution of length two. The reason is that
if $F \twoheadrightarrow M$ is a surjection with $F$ free, then the kernel $F'
\subset F$ is free by a general fact (\add{citation needed}) that a submodule
of a free module is free (if one works over a PID). So we get a free
resolution of the type
\[ 0 \to F' \to F \to M \to 0.  \]
\end{example}


In general, projective resolutions are not at all unique.
Nonetheless, they \emph{are} unique up to chain homotopy. Thus a projective
resolution is a rather good ``replacement'' for the initial module.

\begin{proposition}
Let $M, N$ be modules and let $P_* \to M, P'_* \to N$ be projective
resolutions. Let $f: M \to N$ be a morphism. Then there is a morphism
\[ P_* \to P'_*  \]
such that the following diagram commutes:
\[
\xymatrix{
\dots \ar[r] &  P_1 \ar[r] \ar[d]  &  P_0 \ar[r] \ar[d]  &  M \ar[d]^f  \\
\dots \ar[r] &  P'_1 \ar[r] &  P'_0 \ar[r] &  N
}
\]
This morphism is unique up to chain homotopy.
\end{proposition}

\begin{proof}
Let $P_* \to M$ and $P'_* \to N$ be projective resolutions. We will define a
morphism of complexes $P_* \to P'_* $ such that the diagram commutes.
Let the boundary maps in $P_*, P'_*$ be denoted $d$  (by abuse of notation).
We have an exact diagram
\[
\xymatrix{
\dots \ar[r] &  P_n \ar[r]^d &  P_{n-1} \ar[r]^d &  \dots \ar[r]^d & P_0
\ar[r]&  M \ar[d]^{f} \ar[r] &  0 \\
\dots \ar[r] &  P'_n \ar[r]^d &  P'_{n-1} \ar[r] &  \dots \ar[r]^d & P'_0 \ar[r] &  N \ar[r] &  0
}
\]
Since $P'_0 \twoheadrightarrow N$ is an epimorphism, the map $P_0 \to M \to N$ lifts
to a map $P_0 \to P'_0$ making the diagram
\[ \xymatrix{
P_0 \ar[d] \ar[r] &  M \ar[d]^{f} \\
P'_0 \ar[r] &  N
}\]
commute.
Suppose we have defined maps $P_i \to P'_i$ for $i \leq n$ such that the
following diagram commutes:
\[
\xymatrix{
P_n \ar[r]^d \ar[d]  &  P_{n-1} \ar[r]^d \ar[d] &  \dots \ar[r]^d & P_0
\ar[d]  \ar[r]&  M \ar[d]^{f} \ar[r] &  0 \\
P'_n \ar[r]^d &  P'_{n-1} \ar[r] &  \dots \ar[r]^d & P'_0 \ar[r] &  N \ar[r] &  0
}
\]
Then we will define $P_{n+1} \to P'_{n+1}$, after which induction will prove
the existence of a map. To do this, note that
the map
\[ P_{n+1} \to P_n \to P'_n \to P'_{n-1}  \]
is zero, because this is the same as $P_{n+1} \to P_n \to P_{n-1} \to P'_{n-1}$
(by induction, the diagrams before $n$ commute), and this is zero because two
$P$-differentials were composed one after another. In particular, in the diagram
\[
\xymatrix{
P_{n+1}   \ar[r] &  P_n \ar[d]  \\
P'_{n+1} \ar[r] & P'_n
},
\]
the image in $P'_n$ of $P_{n+1}$ lies in the kernel of $P'_n \to P'_{n-1}$,
i.e. in the image $I$ of $P'_{n+1}$.  The exact diagram
\[
\xymatrix{
& P_{n+1} \ar[d]  \\
P'_{n+1} \ar[r] & I \ar[r] &  0
}
\]
shows that we can lift $P_{n+1} \to I$ to $P_{n+1} \to P'_{n+1}$ (by
projectivity). This implies that we can continue the diagram further and get a
morphism $P_* \to P'_* $ of complexes. 	



Suppose $f, g: P_* \to P'_*$ are two morphisms of the projective resolutions
making $$\xymatrix{
P_0 \ar[r] \ar[d] &  M \ar[d] \\
P'_0 \ar[r] &  N
}$$ commute. We will show that $f,g$ are chain homotopic.

For this,
we start by defining $D_0: P_0 \to P'_1$ such that $dD_0 = f-g: P_0 \to P'_0$.
This we can do because $f-g$ sends $P_0$ into $\ker(P'_0 \to N)$, i.e. into the
image of $P'_1 \to P'_0$, and $P_0$ is projective.
Suppose we have defined chain-homotopies $D_i: P_{i} \to P_{i+1}$ for $i \leq
n$ such that $dD_i + D_{i-1}d = f-g$ for $i \leq n$. We will define $D_{n+1}$.
There is a diagram
\[
\xymatrix{
 & P_{n+1} \ar[d]  \ar[r] &  P_n \ar[ld]^{D_n}\ar[d] \ar[r] & P_{n-1}
 \ar[ld]^{D_{n-1}} \ar[d]  \\
P'_{n+2} \ar[r] & P'_{n+1}   \ar[r] &  P'_n  \ar[r] & P'_{n-1}  \\
}\]
where the squares commute regardless of whether you take the vertical maps to
be $f$ or $g$ (provided that the choice is consistent). 	

We would like to define $D_{n+1}: P_n \to P'_{n+1}$.
The key condition we need satisfied is that
\[ d D_{n+1} = f - g - D_n d.  \]
However, we know that, by the inductive hypothesis on the $D$'s
\[ d( f- g - D_{n}d) = fd  - gd - dD_n d = fd - gd - (f-g)d + D_n dd = 0.  \]
In particular, $f-g - D_n d$ lies in the image of $P'_{n+1} \to P'_n$.
The projectivity of $P_n$ ensures that we can define $D_{n+1}$ satisfying the
necessary condition.

\end{proof}


\begin{corollary}
Let $P_* \to M, P'_* \to M$ be projective resolutions of $M$. Then there are
maps $P_* \to P'_*, P'_* \to P_* $ under $M$ such that the compositions are
chain homotopic to the identity.
\end{corollary}
\begin{proof}
Immediate.
\end{proof}

\subsection{Injective resolutions}

One can dualize all this to injective resolutions. \add{do this}

\subsection{Definition}
Often in homological algebra, we see that ``short exact
sequences induce long exact sequences.'' Using the theory of
derived functors, we can make this formal.

Let us work in the category of modules over a ring $R$. Fix two such categories.
Recall that a right-exact functor $F$ (from the category of modules over a
ring to the category of modules over another ring) is an additive functor
 such that for every short
exact sequence $0\rightarrow A\rightarrow B\rightarrow
C\rightarrow 0$, we get a exact sequence $F(A)\rightarrow
F(B)\rightarrow F(C)\rightarrow 0$.

We want a natural way to continue this exact sequence to the
left; one way of doing this is to define the left derived
functors.
\begin{definition} Let $F$ be a right-exact functor and
$P_*\rightarrow M$ are projective resolution. We can form a
chain complex $F(P_*)$ whose object in degree $i$ is $F(P_i)$
with boundary maps $F(\partial)$. The homology of this chain
complex denoted $L_iF$ are the left derived functors.
\end{definition}

For this definition to be useful, it is important to verify that
deriving a functor yields functors independent on choice of
resolution. This is clear by \rref{}.

\begin{theorem} The following properties characterize derived
functors: \begin{enumerate}
\item{ $L_0F(-)=F(-)$ }
\item{ Suppose $0\rightarrow A\rightarrow B\rightarrow
C\rightarrow 0$ is an exact sequence and $F$ a right-exact
functor; the left derived functors fit into the following exact
sequence:

\begin{equation} \cdots L_iF(A)\rightarrow L_iF(B)\rightarrow
L_iF(C)\rightarrow L_{i-1}F(A)\cdots\rightarrow
L_1(C)\rightarrow L_0F(A)\rightarrow L_0F(B)\rightarrow
L_0F(C)\rightarrow 0 \end{equation}}
\end{enumerate}
\end{theorem}
\begin{proof} The second property is the hardest to prove, but
it is by far the most useful; it is essentially an application
of the snake lemma. \end{proof}
One can define right derived functors analogously; if one has a
left exact functor (an additive functor that takes an exact
sequence $0\rightarrow A\rightarrow B\rightarrow C\rightarrow 0$ to
$0\rightarrow F(A)\rightarrow F(B)\rightarrow F(C)$), we can
pick an injective resolution instead (the injective criterion is simply the
projective criterion with arrows reversed). If
$M\rightarrow I^*$ is a injective resolution then the cohomology of the chain
complex $F(I^*)$ gives the right derived functors.
However, variance must also be taken into consideration so the
choice of whether or not to use a projective or injective
resolution is of importance (in all of the above, functors were
assumed to be covariant). In the following, we see an example of when right
derived functors can be computed using projective
resolutions.

\subsection{$\ext$ functors}

\begin{definition} The right derived functors of $Hom(-,N)$ are
called the $Ext$-modules denoted $Ext^i_R(-,N)$.
\end{definition}
We now look at the specific construction:

Let $M, M'$ be $R$-modules. Choose a projective resolution
\[ \dots \to P_2 \to P_1 \to P_0 \to M \to 0  \]
and consider what happens when you hom this resolution into $N$.
Namely, we can
consider $\hom_R(M,N)$, which is the kernel of $\hom(P_0, M)
\to\hom(P_1, M) $
by exactness of the sequence
\[ 0 \to \hom_R(M,N) \to \hom_R(P_0, N) \to \hom_R(P_1, N) . \]
You might try to continue this with the sequence
\[ 0 \to \hom_R(M,N) \to \hom_R(P_0, N) \to \hom_R(P_1, N) \to
\hom_R(P_2, N)
\to \dots. \]
In general, it won't be exact, because $\hom_R$ is only
left-exact. But it is a
chain complex. You can thus consider the homologies.

\begin{definition}
The homology of the complex $\{\hom_R(P_i, N)\}$ is denoted
$\ext^i_R(M,N)$. By
definition, this is $\ker(\hom(P_i,N) \to \hom(P_{i+1},
N))/\im(\hom(P_{i-1},
N) \to \hom(P_i,N))$. This is an $R$-module, and is called the
$i$th ext group.
\end{definition}



Let us list some properties (some of these properties are just
case-specific examples of general properties of derived
functors)

\begin{proposition}
$\ext_R^0(M,N) = \hom_R(M,N)$.
\end{proposition}
\begin{proof}
This is obvious from the left-exactness of $\hom(-,N)$. (We
discussed this.)
\end{proof}

\begin{proposition}
$\ext^i(M,N)$ is a functor of $N$.
\end{proposition}
\begin{proof}
Obvious from the definition.
\end{proof}

Here is a harder statement.
\begin{proposition}
$\ext^i(M,N)$ is well-defined, independent of the projective
resolution $P_*
\to M$, and is in fact a contravariant additive functor of
$M$.\footnote{I.e. a map $M
\to M'$ induces $\ext^i(M', N) \to \ext^i(M,N)$.}
\end{proposition}
\begin{proof}
Omitted. We won't really need this, though; it requires more
theory about
chain complexes.
\end{proof}


\begin{proposition}
If $M$ is annihilated by some ideal $I \subset R$, then so is
$\ext^i(M,N)$ for
each $i$.
\end{proposition}
\begin{proof}
This is a consequence of the functoriality in $M$. If $x \in
I$,then $x: M \to
M$ is the zero map, so it induces the zero map on
$\ext^i(M,N)$.\end{proof}

\begin{proposition}
$\ext^i(M,N) = 0$ if $M$ projective and $i>0$.
\end{proposition}
\begin{proof}
In that case, one can use the projective resolution
\[ 0 \to M \to M \to 0.  \]
Computing $\ext$ via this gives the result.
\end{proof}




\begin{proposition}
If there is an exact sequence
\[ 0 \to N' \to N \to N'' \to 0,  \]
there is a long exact sequence of $\ext$ groups
\[ 0 \to \hom(M,N') \to \hom(M,N) \to \hom(M,N'') \to
\ext^1(M,N') \to
\ext^1(M,N) \to \dots  \]
\end{proposition}
\begin{proof}
This proof will assume a little homological algebra. Choose a
projective
resolution $P_* \to M$. (The notation $P_*$ means the chain
complex $\dots \to
P_2 \to P_1 \to P_0$.) In general, homming out of $M$ is not
exact, but homming
out of a projective module is exact. For each $i$, we get an
exact sequence
\[ 0 \to \hom_R(P_i, N') \to \hom_R(P_i, N) \to \hom_R(P_i,
N'')\to 0, \]
which leads to an exact sequence of \emph{chain complexes}
\[ 0 \to \hom_R(P_*,N') \to \hom_R(P_*,N) \to \hom_R(P_*,N'')
\to 0 . \]
Taking the long exact sequence in homology gives the result.
\end{proof}


Much less obvious is:

\begin{proposition}
There is a long exact sequence in the $M$ variable. That is, a
short exact
sequence
\[ 0 \to M' \to M \to M'' \to 0  \]
leads a long exact sequence
\[ 0 \to \hom_R(M'', N) \to \hom_R(M,N) \to \hom_R(M', N) \to
\ext^1(M'', N)
\to \ext^1(M, N) \to \dots.  \]
\end{proposition}
\begin{proof}
Omitted.
\end{proof}

We now can characterize projectivity:
\begin{corollary}
TFAE:
\begin{enumerate}
\item $M$ is projective.
\item $\ext^i(M,N) = 0$ for all $R$-modules $N$ and $i>0$.
\item  $\ext^1(M,N)=0$ for all $N$.
\end{enumerate}
\end{corollary}
\begin{proof}
We have seen that 1 implies 2 because projective modules have
simple projective
resolutions. 2 obviously implies 3. Let's show that 3 implies
1.Choose a
projective module $P$ and a surjection $P \twoheadrightarrow M$
with kernel
$K$. There is a short exact sequence $0 \to K \to P \to M \to
0$. The sequence
\[ 0 \to \hom(M,K) \to \hom(P,K) \to \hom(K,K) \to
\ext^1(M,K)=0\]
shows that there is a map $P \to K$ which restricts to the
identity $K \to K$.
The sequence $0 \to K \to P \to M \to 0$ thus splits, so $M$ is
a direct
summand in a projective module, so is projective.
\end{proof}


Finally, we note that there is another way of constructing
$\ext$. We
constructed them by choosing a projective resolution of $M$. But
you can also
do this by resolving $N$ by \emph{injective} modules.
\begin{definition}
An $R$-module $Q$ is \textbf{injective} if $\hom_R(-,Q)$ is an
exact (or,
equivalently, right-exact) functor. That is, if $M_0 \subset M$
is an inclusion
of $R$-modules, then any map $M_0 \to Q$ can be extended to $M
\to Q$.
\end{definition}

If we are given $M,N$, and an injective resolution $N \to Q_*$,
we can look at
the chain complex $\left\{\hom(M,Q_i)\right\}$, i.e. the chain
complex
\[ 0 \to \hom(M, Q^0) \to \hom(M, Q^1) \to \dots  \]
and we can consider the cohomologies.

\begin{definition}
We call these cohomologies
\[ \ext^i_R(M,N)' = \ker(\hom(M, Q^i) \to \hom(M,
Q^{i+1}))/\im(\hom(M,
Q^{i-1}) \to \hom(M, Q^i)).  \]
\end{definition}

This is dual to the previous definitions, and it is easy to
check that the
properties that we couldn't verify for the previous $\ext$s are
true for the
$\ext'$'s.

Nonetheless:

\begin{theorem}
There are canonical isomorphisms:
\[ \ext^i(M,N)' \simeq \ext^i(M,N).  \]
\end{theorem}

In particular, to compute $\ext$ groups, you are free either to
take a
projective resolution of $M$, or an injective resolution of
$N$.\begin{proof}[Idea of proof]
In general, it might be a good idea to construct a third more
complex
construction that resembles both. Given $M,N$ construct a
projective resolution
$P_* \to M$ and an injective resolution $N \to Q^*$. Having made
these choices,
we get a \emph{double complex}
\[ \hom_R(P_i, Q^j)  \]
of a whole lot of $R$-modules. The claim is that in such a
situation, where
you have a double complex $C_{ij}$, you can
form an ordinary chain complex $C'$
by adding along the diagonals. Namely, the $n$th term
is $C'_n = \bigoplus_{i+j=n} C_{ij}$. This \emph{total complex}
will receive a
map from the chain complex used to compute the $\ext$ groups
and a chain
complex used to compute the $\ext'$ groups. There are maps on
cohomology,
\[ \ext^i(M,N) \to H^i(C'_*), \quad \ext^i(M,N)' \to H^i(C'_*).
\]
The claim is that isomorphisms on
cohomology will be induced in each case. That will prove the
result, but we
shall not prove the claim.
\end{proof}

Last time we were talking about $\ext$ groups over commutative
rings. For $R$ a
commutative ring and $M,N$ $R$-modules, we defined an $R$-module
$\ext^i(M,N)$ for
each $i$, and proved various properties. We forgot to mention
one.

\begin{proposition}
If $R$ noetherian, and $M,N$ are finitely generated,
$\ext^i(M,N)$ is also finitely generated.
\end{proposition}
\begin{proof}
We can take a projective resolution $P_*$ of $M$ by finitely
generated free modules, $R$ being
noetherian. Consequently the complex $\hom(P_*, N)$ consists of
finitely
generated modules. Thus the cohomology is finitely generated,
and this cohomology
consists of the $\ext$ groups.
\end{proof}

\subsection{Application: Modules over DVRs}


\begin{definition} Let $M$ be a module over a domain $A$. We say that $M$ is \underline{torsion-free}, if for any nonzero $a \in A$, $a:M \to M$ is injective. We say that $M$ is \underline{torsion} if for any $m \in M$, there is nonzero $a \in A$ such that $am=0$.
\end{definition}

\begin{lemma} For any module finitely generated module $M$ over a Noetherian domain $A$, there is a short exact sequence
\[0 \to M_{tors} \to M \to M_{tors-free} \to 0\]
where $M_{tors}$ is killed by an element of $A$ and $M_{tors-free}$ is torsion-free.
\label{tors tors-free ses}
\end{lemma}
\begin{proof} This is because we may take $M_{tors}$ to be all the elements which are killed by a non-zero element of $A$. Then this is clearly a sub-module. Since $A$ is Noetherian, it is finitely generated, which means that it can be killed by one element of $A$ (take the product of the elements that kill the generators). Then it is easy to check that the quotient $M/M_{tors}$ is torsion-free.
\end{proof}

\begin{lemma} For $R$ a PID, a module $M$ over $R$ is flat if and only if it is torsion-free.
\label{PID means flat=tors free}
\end{lemma}
\begin{proof} This is the content of Problem 2 on the Midterm.
\end{proof}

Using this, we will classify modules over DVRs.

\begin{proposition} let $M$ be a finitely generated module over a DVR $R$. Then
\[M=M_{tors}\oplus R^{\oplus n},\] i.e, where $M_{tors}$ can be annihilated by $\pi^n$ for some $n$.
\end{proposition}
\begin{proof}
Set $M_{tors} \subset M$ be as in Lemma \ref{tors tors-free ses} so that $M/M_{tors}$ is torsion-free. Therefore, by Corollary \ref{DVR is PID} and Lemma \ref{PID means flat=tors free} we see that it is flat. But it is over a local ring, so that means that it is free. So we have $M/M_{tors}=R^{\oplus n}$ for some $n$. Furthermore, since $R^{\oplus n}$ is free, it is additionally projective, so the above sequence splits, so
\[M=M_{tors} \oplus R^{\oplus n}\]
as desired.
\end{proof}

There is nothing more to say about the free part, so let us discuss the torsion part in more detail.

\begin{lemma} Any finitely generated torsion module over a DVR is
\[\bigoplus R/\pi^nR.\]
\label{dvr fin gen tor module struct}
\end{lemma}
Before we prove this, let us give two examples:
\begin{enumerate}
\item Take $R=k[[t]]$, which is a DVR with maximal ideal (t). Thus, by the lemma, for a finitely generated torsion module $M$, $t:M \to M$ is a nilpotent operator. However, $k[[t]]/t^n$ is a Jordan block so we are exactly saying that linear transformations can be written in Jordan block form.
\item Let $R=\mathbb{Z}_p$. Here the lemma implies that finitely generated torsion modules over $\mathbb{Z}_p$ can be written as a direct sum of $p$-groups.
\end{enumerate}
Now let us proceed with the proof of the lemma.
\begin{proof}[Proof of Lemma \ref{dvr fin gen tor module struct}] Let $n$ be the minimal integer such that $\pi^n$ kills $M$. This means that $M$ is a module over $R_n=R/\pi^nR$, and also there is an element $m \in M$, and an injective map $R_n \hookrightarrow M$, because we may choose $m$ to be an element which is not annihilated by $\pi^{n-1}$, and then take the map to be $1 \mapsto m$.

Proceeding by induction, it suffices to show that the above map $R_n \hookrightarrow M$ splits. But for this it suffices that $R_n$ is an injective module over itself. This property of rings is called the Frobenius property, and it is very rare. We will write this as a lemma.
\begin{lemma} $R_n$ is injective as a module over itself.
\label{Rn Frobenius}
\end{lemma}
\begin{proof}[Proof of Lemma \ref{Rn Frobenius}] Note that a module $M$ over a ring $R$ is injective if and only if for any ideal $I \subset R$, $\Ext^1(R/I,M)=0$. This was shown on  Problem Set 8, Problem 2a.

Thus we wish to show that for any ideal $I$, $\Ext^1_{R_n}(R_n/I,R_n)=0$. Note that since $R$ is a DVR, we know that it is a PID, and also any element has the form $r=\pi^kr_0$ for some $k \geq 0$ and some $r_0$ invertible. Then all ideals in $R$ are of the form $(\pi^k)$ for some $k$, so all ideals in $R_n$ are also of this form. Therefore, $R_n/I=R_m$ for some $m \leq n$, so it suffices to show that for $m \leq n$, $\Ext^1_{R_n}(R_m,R_n)=0$.

But note that we have short exact sequence
\[ 0 \to R_{n-m} \to^{\pi^m \cdot} R_n \to R_m \to 0\]
which gives a corresponding long exact sequence of $\Ext$s
\[0 \to \Hom_{R_n}(R_m,R_n) \to \Hom_{R_n}(R_n,R_n) \to^\hearts \Hom_{R_n}(R_{n-m},R_n)\]
\[\to \Ext^1_{R_n}(R_m,R_n) \to \Ext^1_{R_n}(R_n,R_n) \to \cdots\]
But note that any map of $R_n$ modules, $R_{n-m} \to R_n$, must map $1 \in R_{n-m}$ to an element which is killed by $\pi^{n-m}$, which means it must be a multiple of $\pi^m$, so say is is $\pi^ma$. Then the map is
\[r \mapsto \pi^mar,\]
which is the image of the map
\[[r \mapsto ar] \in \Hom_{R_n}(R_n,R_n).\]
Thus, $\hearts$ is surjective.
Also note that $R_n$ is projective over itself, so $\Ext^1_{R_n}(R_n,R_n)=0$. This, along with the surjectivity of $\hearts$ shows that
\[\Ext^1_{R_n}(R_m,R_n)=0\]
as desired.
\end{proof}
As mentioned earlier, this lemma concludes our proof of Lemma \ref{dvr fin gen tor module struct} as well.
\end{proof}




% ============================ chapters/flat.tex}
\chapter{Flatness revisited}

In the past, we have already encountered the notion of \emph{flatness}. We
shall now study it in more detail.
We shall start by introducing the notion of \emph{faithful} flatness and
introduce the idea of ``descent.'' Later, we shall consider other criteria for
(normal) flatness that we have not yet explored.

We recall (\cref{flatdefn}) that a module $M$ over a commutative ring $R$ is
\emph{flat} if the functor $N \mapsto N \otimes_R M$ is an exact functor. An
$R$-algebra is flat if it is flat as a module. For instance, we have seen that
any localization of $R$ is a flat algebra, because localization is an exact
functor.


\textbf{All this has not been added yet!}

\section{Faithful flatness}



\subsection{Faithfully flat modules}
Let $R$ be a commutative ring.

\begin{definition}
The $R$-module $M$ is \textbf{faithfully flat} if  any complex $N' \to N
\to N''$ of $R$-modules is exact if and only if the tensored sequence $N'
\otimes_R M \to N \otimes_R M \to N'' \otimes_R M$ is exact.
\end{definition}

Clearly, a faithfully flat module is flat.


\begin{example}
The direct sum of faithfully flat modules is faithfully flat.
\end{example}
\begin{example}
A (nonzero)  free module is faithfully flat, because $R$ itself is flat
(tensoring with $R$ is the identity functor).
\end{example}

We shall now prove several useful criteria about faithfully flat modules.

\begin{proposition}  \label{easyffcriterion}
An $R$-module $M$ is faithfully flat if and only if it is flat and if $M
\otimes_R N = 0$ implies $N=0$ for any $N$.
\end{proposition}
\begin{proof} Suppose $M$ faithfully flat
Then $M$ is flat, clearly. In addition, if $N$ is any $R$-module, consider the
sequence
\[ 0 \to N \to 0;  \]
it is exact if and only if
\[ 0 \to M \otimes_R N \to 0  \]
is exact. Thus $N=0$ if and only if $M \otimes_R N = 0$.

Conversely, suppose $M$ is flat and satisfies the additional condition. We
need to show that if $N'
\otimes_R M \to N \otimes_R M \to N'' \otimes_R M$ is exact, so is $N' \to N
\to N''$. Since $M$ is flat, taking homology commutes with tensoring with $M$.
In particular, if $H$ is the homology of $N' \to N \to N''$, then $H \otimes_R
M$ is the homology of
$N'
\otimes_R M \to N \otimes_R M \to N'' \otimes_R M$. It follows that $H
\otimes_R M = 0$, so $H=0$, and the initial complex is exact.
\end{proof}

\begin{example}
Another illustration of the above technique is the following observation: if
$M$ is faithfully flat and $N \to N'$ is any morphism, then $N \to N'$ is an
isomorphism if and only if $M \otimes N' \to M \otimes N$ is an isomorphism.
This follows because the condition that a map be an isomorphism can be phrased
as the exactness of a certain (uninteresting) complex.
\end{example}
\begin{exercise}
The direct sum of a flat module and a faithfully flat module is faithfully flat.
\end{exercise}


From the above result, we can get an important example of a faithfully flat
algebra over a ring.
\begin{example}
Let $R$ be a commutative ring, and $\left\{f_i\right\}$ a finite set of
elements that generate the unit ideal in $R$ (or equivalently, the basic open
sets $D(f_i) = \spec R_{f_i}$ form a covering of $\spec R$).
Then the algebra $\prod R_{f_i}$ is faithfully flat over $R$ (i.e., is so as a
module). Indeed, as a
product of localizations, it is certainly flat.

So by \cref{easyffcriterion}, we are left with showing that if $M$ is any
$R$-module and $M_{f_i} =0 $ for all $i$, then $M = 0$.
Fix $m \in M$, and consider the ideal $\ann(m)$ of elements annihilating $m$.
Since $m$ maps to zero in each localization $M_{f_i}$, there is a power of
$f_i$ in $\ann(m)$ for each $i$.
This easily implies that $\ann(m) = R$, so $m=0$. (We used the fact that if the
$\left\{f_i\right\}$ generate the unit ideal, so do $\left\{f_i^N\right\}$ for
any $N \in \mathbb{Z}_{\geq 0}$.)
\end{example}

A functor $F$ between two categories is said to be \textbf{faithful} if the
induced map on the hom-sets $\hom(x,y) \to \hom(Fx, Fy)$ is always injective.
The following result explains the use of the term ``faithful.''

\begin{proposition}
A module $M$ is faithfully flat if and only if it is flat and the functor $N \to N
\otimes_R M$ is faithful.
\end{proposition}
\begin{proof} Let $M$ be flat.
We need to check that $M$ is faithfully flat if and only if the natural map
\[ \hom_R(N, N') \to \hom_R(N \otimes_R M, N' \otimes_R M)  \]
is injective.
Suppose first $M$ is faithfully flat and $f: N \to N'$ goes to zero $f \otimes
1_M: N \otimes_R M \to  N' \otimes_R M$. We know by flatness that
\[ \im(f) \otimes_R M = \im(f \otimes 1_M)  \]
so that if $f \otimes 1_M = 0$, then $\im(f) \otimes M = 0$. Thus by faithful
flatness, $\im(f) = 0$ by \rref{easyffcriterion}.

Conversely, let us suppose $M$ flat and the functor $N \to N \otimes_R M$
faithful. Let $N \neq 0$; then $1_N \neq 0$ as maps $N \to N$.
It follows that $1_N \otimes 1_M$ and $0 \otimes 1_M = 0$ are different as
endomorphisms of $M \otimes_R N$. Thus $M \otimes_R N \neq 0$. By
\rref{easyffcriterion}, we are done again.
\end{proof}

\begin{example}
Note, however, that $\mathbb{Z} \oplus \mathbb{Z}/2$ is a $\mathbb{Z}$-module
such that tensoring by it is a faithful but not exact functor.
\end{example}

Finally, we prove one last criterion:

\begin{proposition} \label{ffmaximal}
$M$ is faithfully flat if and only if $M$ is flat and $\mathfrak{m}M \neq M$ for all
maximal ideals $\mathfrak{m} \subset R$.
\end{proposition}
\begin{proof}
If $M$ is faithfully flat, then $M$ is flat, and $M \otimes_R R/\mathfrak{m} =
M/\mathfrak{m}M \neq 0$ for all $\mathfrak{m}$ as $R/\mathfrak{m} \neq 0$, by
\rref{easyffcriterion}. So we get one direction.

Alternatively, suppose $M$ is flat and $M \otimes_R R/\mathfrak{m} \neq 0$ for
all maximal $\mathfrak{m}$. Since every proper ideal is contained in a maximal
ideal, it follows that $M \otimes_R R/I \neq 0$ for all proper ideals $I$. We
shall use this and \rref{easyffcriterion} to prove that $M$ is faithfully flat

Let $N$ now be any nonzero module. Then $N$ contains a \emph{cyclic} submodule, i.e.
one isomorphic to $R/I$ for some proper $I$. The injection
\[ R/I \hookrightarrow N  \]
becomes an injection
\[ R/I \otimes_R M \hookrightarrow N \otimes_R M,  \]
and since $R/I \otimes_R M \neq 0$, we find that $N \otimes_R M \neq 0$. By
\rref{easyffcriterion}, it follows that $M$ is faithfully flat
\end{proof}

\begin{corollary}
A nonzero finitely generated flat module over a \emph{local} ring is faithfully flat.
\end{corollary}
\begin{proof}
This follows from \cref{ffmaximal} and Nakayama's lemma.
\end{proof}

A \emph{finitely presented} flat module over a local ring is in fact free, but we do not prove
this (except when the ring is noetherian, see \cref{}).
\begin{proof}
Indeed, let $R$ be a local ring with maximal ideal $\mathfrak{m}$, and $M$ a
finitely generated flat $R$-module. Then by Nakayama's lemma, $M/\mathfrak{m}M
\neq 0$, so that $M$ must be faithfully flat.
\end{proof}

\begin{proposition}
Faithfully flat modules are closed under direct sums and tensor products.
\end{proposition}

\begin{proof}
Exercise.
\end{proof}




\subsection{Faithfully flat algebras}

Let $\phi: R \to S$ be a morphism of rings, making $S$ into an $R$-algebra.

\begin{definition}
$S$ is a \textbf{faithfully flat $R$-algebra} if it is faithfully flat as an
$R$-module.
\end{definition}

\begin{example}
The map $R \to R[x]$ from a ring into its polynomial ring is always faithfully
flat. This is clear.
\end{example}

Next, we indicate the usual ``sorite'' for faithfully flat morphisms:
\begin{proposition} \label{ffsorite}
Faithfully flat morphisms are closed under composition and base change.
\end{proposition}
That is, if $R \to S$, $S \to T$ are faithfully flat, so is $R \to T$.
Similarly, if $R \to S$ is faithfully flat and $R'$ any $R$-algebra, then $R'
\to S \otimes_R R'$ is faithfully flat.

The reader may wish to try this proof as an exercise.
\begin{proof}
The first result follows because the composite of the two faithful and exact
functors (tensoring  $ \otimes_R S$ and tensoring  $ \otimes_S T$ gives the
composite $\otimes_R T$) yields a faithful and exact functor.

In the second case, let $M$ be an $R'$-module. Then $M \otimes_{R'} (R'
\otimes_R S)$ is canonically isomorphic to $M \otimes_R S$. From this it is
clear if the functor $M \mapsto M \otimes_R S$ is faithful and
exact, so is
$M \mapsto M \otimes_{R'} (R'
\otimes_R S)$.
\end{proof}

Flat maps are usually injective, but they need not be. For instance, if $R$ is a
product $R_1 \times R_2$, then the projection map $R \to R_1$ is flat.
This never happens for faithfully flat maps.
In particular, a quotient can never be faithfully flat.

\begin{proposition}  \label{ffinjective}
If $S$ is a faithfully flat $R$-algebra, then the structure map $R \to S$ is injective.
\end{proposition}
\begin{proof}
Indeed, let us tensor the map $R \to S $ with $S$, over $R$. We get a morphism
of $S$-modules
\[ S \to S \otimes_R S ,  \]
sending $s \mapsto  1 \otimes s$.
This morphism has an obvious section $S \otimes_R S \to S$ sending $a \otimes b
\mapsto ab$. Since it has a section, it is injective. But faithful flatness says
that the original map $R \to S$ must be injective itself.
\end{proof}

\begin{example}
The converse of \cref{ffinjective} definitely fails. Consider the localization $\mathbb{Z}_{(2)}$;
it is a flat $\mathbb{Z}$-algebra, but not faithfully flat (for instance,
tensoring with $\mathbb{Z}/3$ yields zero).
\end{example}

\begin{exercise}
Suppose $\phi: R \to S$ is a flat, injective morphism of rings such that $S/\phi(R)$ is a
flat $R$-module. Then show that $\phi$ is faithfully flat.
\end{exercise}

Flat morphisms need not be injective, but they are locally injective. We shall see this using:
\begin{proposition}  \label{flatlocal}
A flat local homomorphism of local rings is faithfully flat. In particular, it
is injective.
\end{proposition}
\begin{proof}
Let $\phi: R \to S$ be a local homomorphism of local rings with maximal ideals
$\mathfrak{m}, \mathfrak{n}$. Then by definition $\phi(\mathfrak{m}) \subset
\mathfrak{n}$. It follows that $S \neq \phi(\mathfrak{m})S$, so by
\rref{ffmaximal} we win.
\end{proof}
The point of the above proof was, of course, the fact that the
ring-homomorphism was \emph{local}. If we just had that $\phi( \mathfrak{m})S
\subsetneq S$ for every maximal ideal $\mathfrak{m} \subset R$, that would be
sufficient for the argument.

\begin{corollary}
Let $\phi: R \to S$ be a flat morphism. Let $\mathfrak{q} \in \spec S$,
$\mathfrak{p} = \phi^{-1}(\mathfrak{q})$ the image in $\spec R$. Then
$R_{\mathfrak{p}} \to S_{\mathfrak{q}}$ is faithfully flat, hence injective.
\end{corollary}
\begin{proof}
We only need to show that the map is flat by \cref{flatlocal}.
Let $M' \hookrightarrow M$ be an injection of $R_{\mathfrak{p}} \to
S_{\mathfrak{q}}$-modules. Note that $M', M$ are then $R$-modules as well.
Then
$$M' \otimes_{R_{\mathfrak{p}}} S_{\mathfrak{q}} = (M' \otimes_R
R_{\mathfrak{p}}) \otimes_{R_{\mathfrak{p}}} S_{\mathfrak{q}} = M' \otimes_R
S_{\mathfrak{q}}.$$
Similarly for $M$.
This shows that tensoring over $R_{\mathfrak{p}}$ with $S_{\mathfrak{q}}$ is
the same as tensoring over $R$ with $S_{\mathfrak{q}}$. But $S_{\mathfrak{q}}$
is flat over $S$, and $S$ is flat over $R$, so by \cref{ffsorite},
$S_{\mathfrak{q}}$ is flat over $R$. Thus the result is clear.
\end{proof}

\subsection{Descent of properties under faithfully flat base change}

Let $S$ be an $R$-algebra. Often, things that are true about objects over $R$
(for instance, $R$-modules) will remain true after base-change to $S$.
For instance, if $M$ is a finitely generated $R$-module, then $M \otimes_R S$
is a finitely generated $S$-module.
In this section, we will show that we can conclude the \emph{reverse}
implication when $S$ is \emph{faithfully flat} over $R$.

\begin{exercise}
Let $R \to S$ be a faithfully flat morphism of rings. If $S$ is noetherian, so
is $R$. The converse is false!
\end{exercise}


\begin{exercise} Many properties of morphisms of rings are such that if they hold after
one makes a faithfully flat base change, then they hold for the original
morphism.
Here is a simple example.
Suppose $S$ is a faithfully flat $R$-algebra. Let $R'$ be any $R$-algebra.
Suppose $S'  =S \otimes_R R'$ is finitely generated over $R'$. Then $S$ is
finitely generated over $R$.

To see that, note that $R'$ is the colimit of its finitely generated
$R$-subalgebras $R_\alpha$. Thus $S'$ is the colimit of the $R_\alpha
\otimes_R S$, which inject into $S'$; finite generation implies that one of
the $R_\alpha \otimes_R S \to S'$ is an isomorphism. Now use the fact that
isomorphisms ``descend'' under faithfully flat morphisms.

In algebraic geometry, one can show that many properties of morphisms of
\emph{schemes} allow for descent under faithfully flat base-change. See
\cite{EGA}, volume IV-2.
\end{exercise}


\subsection{Topological consequences}

There are many topological consequences of faithful flatness on the $\spec$'s.
These are
explored in detail in volume 4-2 of \cite{EGA}. We shall only scratch the
surface.
The reader
should bear in mind the usual intuition that flatness means that the fibers
``look similar'' to one other.

\begin{proposition}
Let $R \to S$ be a faithfully flat morphism of rings. Then the map $\spec S
\to \spec R$ is surjective.
\end{proposition}

\begin{proof} Since $R \to S$ is injective, we may regard $R$ as a subring of $S$.
We shall first show that:

\begin{lemma} \label{intideal}
If $I \subset R$ is any ideal, then $R \cap IS = I$.
\end{lemma}
\begin{proof}
To see this, note that the morphism
\[ R/I \to S/IS  \]
is faithfully flat, since faithful flatness is preserved by base-change, and
this is the base-change of $R \to S$ via $R \to R/I$.
In particular, it is injective. Thus $IS \cap R = I$.
\end{proof}


Now to see surjectivity, we use a general criterion:

\begin{lemma} \label{imagespec}
Let $\phi: R \to S$ be a morphism of rings and suppose $\mathfrak{p} \in \spec
R$. Then $\mathfrak{p}$ is in the image of $\spec S \to \spec R$ if and only if
$\phi^{-1}( \phi(\mathfrak{p}) S) = \mathfrak{p}$.
\end{lemma}

This lemma will prove the proposition.
\begin{proof}
Suppose first that $\mathfrak{p}$ is in the image of $\spec S \to \spec R$. In
this case, there is $\mathfrak{q} \in \spec S$ such that
$ \mathfrak{p}$ is the preimage of $\mathfrak{q}$.
In particular, $\mathfrak{q} \supset \phi(\mathfrak{p})S$, so that, if we take
pre-images,
\[ \mathfrak{p} \supset \phi^{-1}(\phi(\mathfrak{p}) S),  \]
while the other inclusion is obviously true.

Conversely, suppose that $\mathfrak{p} \subset \phi^{-1}(\phi(\mathfrak{p})
S)$. In this case, we know that
\[ \phi(R  - \mathfrak{p}) \cap \phi(\mathfrak{p})S = \emptyset.  \]
Now $T = \phi(R - \mathfrak{p})$ is a multiplicatively closed subset.
There is a morphism
\begin{equation} \label{randomequationwhichidonthaveanamefor}
R_{\mathfrak{p}} \to T^{-1}S
\end{equation}
which sends elements of $\mathfrak{p}$ into non-units, by
\eqref{randomequationwhichidonthaveanamefor} so it is a \emph{local}
homomorphism. The maximal ideal of $T^{-1} S$ pulls back to that of
$R_{\mathfrak{p}}$. By the usual commutative diagrams, it follows that
$\mathfrak{p}$ is the preimage of something in $\spec S$.
\end{proof}
\end{proof}

\begin{remark}
The converse also holds. If $\phi: R \to S$ is a flat morphism of rings such
that $\spec S \to \spec R$ is surjective, then $\phi$ is faithfully flat.
Indeed, \cref{imagespec} shows then that for any prime ideal $\mathfrak{p}
\subset R$, $\phi(\mathfrak{p})$ fails to generate $S$.
This is sufficient to imply that $S$ is faithfully flat by \cref{ffmaximal}.
\end{remark}

\begin{remark}
A ``slicker'' argument that faithful flatness implies surjectiveness on spectra
can be given as follows. Let $R \to S$ be faithfully flat. Let $\mathfrak{p}
\in \spec R$; we want to show that $\mathfrak{p}$ is in the image of $\spec S$.
Now \emph{base change preserves faithful flatness.} So we can replace $R$ by
$R/\mathfrak{p}$, $S$ by $S/\mathfrak{p}S$, and assume that $R$ is a domain and
$\mathfrak{p}  = 0$.
Indeed, the commutative diagram
\[ \xymatrix{
\spec S/\mathfrak{p}S \ar[d] \ar[r] &  \spec R/\mathfrak{p} \ar[d]  \\
\spec S \ar[r] &  \spec R
}\]
shows that $\mathfrak{p}$ is in the image of $\spec S \to \spec R$ if and only
if $\left\{0\right\}$ is in the image of $\spec S/\mathfrak{p}S \to \spec
R/\mathfrak{p}$.

We can make another reduction: by localizing at $\mathfrak{p}$ (that is,
$\left\{0\right\}$), we may assume that $R$ is local and thus a field.
So we have to show that if $R$ is a field and $S$ a faithfully flat
$R$-algebra, then $\spec S \to \spec R$ is surjective. But since $S$ is not the
zero ring (by \emph{faithful} flatness!), it is clear that $S$ has a prime
ideal and $\spec S \to \spec R$ is thus surjective.
\end{remark}

In fact, one can show that the morphism $\spec S \to \spec R$ is actually an
\emph{identification,} that is, a quotient map. This is true more generally
for faithfully flat and quasi-compact morphisms of schemes; see \cite{EGA},
volume 4-2.

\begin{theorem}
Let $\phi: R \to S$ be a faithfully flat morphism of rings. Then $\spec S \to
\spec R$ is a quotient map of topological spaces.
\end{theorem}

In other words, a subset of $\spec R$ is closed if and only if its pre-image
in $\spec S$ is closed.

\begin{proof}
We need to show that if $F \subset \spec R$ is such that its pre-image in
$\spec S$ is closed, then $F$ itself is closed.  \textbf{ADD THIS PROOF}
\end{proof}


\section{Faithfully flat descent}

Fix a ring $R$, and let $S$ be an $R$-algebra. Then there is a natural functor
from $R$-modules to $S$-modules sending $N \mapsto S \otimes_R N$.
In this section, we shall be interested in going in the opposite direction,
or in characterizing the image of this functor.
Namely, given an $S$-module, we want to ``descend'' to an $R$-module when
possible; given a morphism of $S$-modules, we want to know when it comes from a
morphism of $R$-modules by base change.

\add{this entire section!}


\subsection{The Amitsur complex}
\add{citation needed}

Suppose $B$ is an $A$-algebra.
Then we can construct a complex of $A$-modules
\[ 0 \to A \to B \to B \otimes_A B \to B \otimes_A B \otimes_A B \to \dots  \]
as follows.
For each $n$, we denote by $B^{\otimes n}$ the tensor product of $B$ with
itself $n$ times (over $A$).
There are morphisms of $A$-algebras
\[ d_i: B^{\otimes n} \to B^{\otimes n+1} , \quad 0 \leq i \leq n+1 \]
where the map sends
\[ b_1 \otimes \dots \otimes b_n \mapsto b_1 \otimes \dots \otimes b_{i-1}
\otimes  1 \otimes  b_i \otimes \dots \otimes b_n,  \]
so that the $1$ is placed in the $i$th spot.
Then the coboundary
$\partial: B^{\otimes n} \to B^{\otimes n+1}$ is defined as $\sum (-1)^i d_i$.
It is easy to check that this forms a complex of $A$-modules.

\begin{definition}
The above complex of $B$-modules is called the \textbf{Amitsur complex} of $B$
over $A$, and we denote it $\mathcal{A}_{B/A}$. It is clearly functorial in
$B$; a map of $A$-algebras $B \to C$ induces a morphism of complexes
$\mathcal{A}_{B/A} \to \mathcal{A}_{C/A}$.
\end{definition}

Note that the Amitsur complex behaves very nicely with respect to base-change.
If $A'$ is an $A$-algebra and $B' = B \otimes_A A'$ is the base extension, then
$\mathcal{A}_{B'/A'}  = \mathcal{A}_{B/A} \otimes_A A'$, which follows easily
from the fact that base-change commutes with tensor products.

In general, the Amitsur complex is not even exact.
For instance, if it is exact in degree one, then the map $A \to B$ is necessarily injective.
If, however, the morphism is \emph{faithfully flat}, then we do get exactness:

\begin{theorem}
If $B$ is a faithfully flat $A$-algebra, then the Amitsur complex of $B/A$ is
exact.  In fact, if $M$ is any $A$-module, then $\mathcal{A}_{B/A} \otimes_A
M$ is exact.
\end{theorem}
\begin{proof}
We prove this first under the assumption that $A \to B$ has a section.
In this case, we will even have:

\begin{lemma}
Suppose $A \to B$ is a morphism of rings with a section $B \to A$. Then the
Amitsur complex $\mathcal{A}_{B/A}$ is homotopically trivial. (In particular,
$\mathcal{A}_{B/A} \otimes_A M$ is acyclic for all $M$.)
\end{lemma}
\begin{proof}
Let $s: B \to A$ be the section; by assumption, this is a morphism of
$A$-algebras. We shall define a chain contraction of $\mathcal{A}_{B/A}$.
To do this, we must define a collection of morphisms of $A$-modules
\( h_{n+1} : B^{\otimes n+1} \to B^{\otimes n},  \)
and this we do by sending
\[ b_1 \otimes \dots \otimes b_{n+1} \mapsto s(b_{n+1}) \left( b_1 \otimes
\dots \otimes b_n \right).  \]
It is still necessary to check that the $\left\{h_{n+1}\right\}$ form a chain
contraction; in other words, that $\partial h_{n} + h_{n+1} \partial =
1_{B^{\otimes n}}$.
By linearity, we need only check this on elements of the form $b_1 \otimes
\dots \otimes b_n$. Then we find
\[ \partial h_n (b_1 \otimes b_n) = s(b_1) \sum (-1)^i b_2 \otimes \dots \otimes 1
\otimes \dots \otimes b_n  \]
where the $1$ is in the $i$th place,
while
\[ h_{n+1} \partial ( b_1 \otimes \dots \otimes  b_n) = b_1 \otimes \dots \otimes b_n +
\sum_{i>0} s(b_1) (-1)^{i-1}b_2 \otimes \dots \otimes 1 \otimes \dots \otimes b_n  \]
where again the $1$ is in the $i$th place. The assertion is from this clear.
Note that if $\mathcal{A}_{B/A}$ is contractible, we can tensor the chain
homotopy with $M$ to see that $\mathcal{A}_{B/A} \otimes_A M$ is chain contractible
for any $M$.
\end{proof}

With this lemma proved, we see that the Amitsur complex $\mathcal{A}_{B/A}$
(or even $\mathcal{A}_{B/A} \otimes_A M$) is acyclic whenever $B/A$ admits a
section. Now if we make the base-change by the morphism $A \to B$, we get the
morphism $B \to B \otimes_A B$. That is,
\[  B \otimes_A \left( \mathcal{A}_{B/A} \otimes_A M \right)= \mathcal{A}_{B
\otimes_A B/B} \otimes_B (M \otimes_A B). \]
The latter is acyclic because $B \to B \otimes_A B$ admits a section (namely,
$b_1 \otimes b_2 \mapsto b_1 b_2$). So the complex $\mathcal{A}_{B/A}
\otimes_A M$ becomes acyclic after base-changing to $B$; this, however, is a
faithfully flat base-extension, so the original complex was itself exact.
\end{proof}

\begin{remark}
A powerful use of the Amitsur complex in algebraic geometry is to show that
the cohomology of a quasi-coherent sheaf on an affine scheme is trivial. In
this case, the Cech complex (of a suitable covering) turns out to be precisely
the Amitsur complex (with the faithfully flat morphism $A \to \prod A_{f_i}$
for the $\left\{f_i\right\}$ a family generating the unit ideal). This
argument generalizes to showing that the \emph{{\'e}tale}
cohomology of a quasi-coherent sheaf on an affine is trivial; cf. \cite{Ta94}.
\end{remark}

\subsection{Descent for modules}
Let $A \to B$ be a faithfully flat morphism of rings.
Given an $A$-module $M$, we have a natural way of getting a $B$-module $M_B = M
\otimes_A B$. We want to describe the image of this functor; alternatively,
given a $B$-module, we want to describe the image of this functor.

Given an $A$-module $M$ and the associated $B$-module $M_B = M \otimes_A B$,
there are two ways of getting $B \otimes_A B$-modules from $M_B$, namely
the two tensor products $M_B \otimes_B (B \otimes_A B)$ according as we pick
the first map $b \mapsto b \otimes 1$ from $B \to B \otimes_A B$ or the
second $b \mapsto 1 \otimes b$.
We shall denote these by $M_B \otimes_A B$ and $B \otimes_A M_B$ with the
action clear.
But these are naturally isomorphic because both are obtained from $M$ by
base-extension $A \rightrightarrows B \otimes_A B$, and the two maps are the
same. Alternatively, these two tensor products are
$M \otimes_A B \otimes_A B$ and $B \otimes_A M \otimes_A B$ and these are
clearly isomorphic by the braiding isomorphism\footnote{It is \emph{not} the
braiding isomorphism $M_B \otimes_A B \simeq B \otimes_A M_B$, which is not an
isomorphism of $B \otimes_A B$-modules.
This is the isomorphism that sends $m \otimes b \otimes b'$ to $b \otimes m
\otimes b'$.
} of the first two factors as $B \otimes_A B$-modules (with the $B \otimes_A B$ part
acting on the $B$'s in the above tensor product!).

\begin{definition}
The \textbf{category of descent data} for the faithfully flat extension $A \to
B$ is defined as follows. An object in this category consists of the following
data:
\begin{enumerate}
\item A $B$-module $N$.
\item An isomorphism of $B \otimes_A B$-modules $\phi: N \otimes_A B \simeq B \otimes_A N$.
This isomorphism is required to make the following diagram\footnote{This is
the cocycle condition.} of $B \otimes_A B
\otimes_A B$-modules commutative:
\begin{equation} \label{dc} \xymatrix{
B \otimes_A B \otimes_A N \ar[rr]^{\phi_{23}} \ar[rd]^{\phi_{13}} & &  B \otimes_A N \otimes_A B
\ar[ld]^{\phi_{12}} \\
&  N \otimes_A B \otimes_A B
}\end{equation}
Here $\phi_{ij}$ means that the permutation of the $i$th and $j$th factors of
the tensor product is done using the isomorphism $\phi$.
\end{enumerate}
A morphism between objects $(N, \phi), (N', \psi)$ is a morphism of
$B$-modules $f: N \to N'$ that makes the diagram
\begin{equation} \label{dc2}  \xymatrix{
N \otimes_A B \ar[d]^{f \otimes 1}  \ar[r]^{\phi} &  B \otimes_A N
\ar[d]^{1 \otimes f} \\
N' \otimes_A B \ar[r]^{\psi} &  B \otimes_A N' \\
}\end{equation}
\end{definition}

As we have seen, there is a functor  $F$ from $A$-modules
to descent data.
Strictly speaking, we should check the commutativity of \eqref{dc}, but this
is clear: for $N= M\otimes_A B$,  \eqref{dc} looks like
$$
\xymatrix{
B \otimes_A B \otimes_A M \otimes_A B  \ar[rr]^{\phi_{23}} \ar[rd]^{\phi_{13}} &
&  B \otimes_A M \otimes_A B  \otimes_A B
\ar[ld]^{\phi_{12}} \\
&  M \otimes_A B \otimes_A B \otimes_A B
}$$
Here all the maps are just permutations of the factors (that is, the braiding
isomorphisms in the structure of symmetric tensor category on the category of
$A$-modules), so it clearly commutes.

The main theorem is:

\begin{theorem}[Descent for modules]
The above functor from $A$-modules to descent data for $A \to B$ is an
equivalence of categories.
\end{theorem}

We follow \cite{Vi08} in the proof.
\begin{proof}
We start by describing the inverse functor from descent data to $A$-modules.
Recall that if $M$ is an $A$-module, then $M$ can be characterized as the
submodule of $M_B$ consisting of $m \in M_B$ such that $1
\otimes m$ and $m \otimes 1$ corresponded to the same thing in $M_B \otimes_A B
\simeq B \otimes_A M_B$.
(The case $M = A$ was particularly transparent: elements of $A$ were elements
$x \in B$ such that $x \otimes 1 = 1 \otimes x$ in $B \otimes_A B$.)
In other words, we had the exact sequence
\[ 0 \to M \to M_B \to M_B \otimes_A B . \]

We want to imitate this for descent data.
Namely, we want to construct a functor $G$ from descent data to $A$-modules.
Given descent data $(N, \phi)$ where $\phi: N \otimes_A B \simeq B \otimes_A
N$ is an isomorphism of $B \otimes_A B$-modules, we define $GN$ to be
\[ GN = \ker ( N \stackrel{n \mapsto 1 \otimes n - \psi(n \otimes 1) }{\to} B
\otimes_A N).  \]
It is clear that this is an $A$-module, and that it is functorial in the
descent data.
We have also shown that $GF (M)$ is naturally isomorphic to $M$ for any
$A$-module $M$.

We need to show the analog for $FG(N, \phi)$; in other words, we need to show
that any descent data arises via the $F$-construction. Even before that, we
need to describe a natural transformation from $FG(N, \phi)$ to the identity.
Fix a  descent data $(N, \phi)$.
Then $G(N, \phi)$ gives an $A$-submodule $M \subset N$.
We get a morphism
\[ f:  M_B = M \otimes_A B \to N  \]
by the universal property. This sends $m \otimes b \mapsto bm$.
The claim is that
this is a map of descent data.
In other words, we have to show that \eqref{dc2} commutes.
The diagram looks like
\[ \xymatrix{
M_B \otimes_A B \ar[d]^{f \otimes 1} \ar[r] &  B \otimes_A M_B \ar[d]^{1
\otimes f}  \\
N \otimes_A B \ar[r]^{\phi} &  B \otimes_A N
}.\]
In other words, if $m\otimes b \in M_B$ and $b' \in B$, we have to show that
$\phi(  bm  \otimes b' ) =  (1 \otimes f)( b \otimes m \otimes b') = b \otimes
b' m$.

However,
\[ \phi(bm \otimes b') = (b \otimes b') \phi(m \otimes 1) = (b \otimes b')(1
\otimes m) = b \otimes b'm  \]
in view of the definition of $M = GN$ as the set of elements such that $\phi(m
\otimes 1) = 1 \otimes m$, and the fact that $\phi$ is an isomorphism of $B
\otimes_A B$-modules. The equality we wanted to prove is thus clear.

So we have the two natural transformations between $FG, GF$ and the respective
identity functors. We have already shown that one of them is an isomorphism.
Now we need to show that if $(N, \phi)$ is descent data as above, and $M =
G(N, \phi)$, the map $F(M) \to (N, \phi)$ is an \emph{isomorphism}.
In other words, we have to show that the map
\[ M \otimes_A B \to N  \]
is an isomorphism.


Here we shall draw a commutative diagram. Namely, we shall essentially use the Amitsur
complex for the faithfully flat map $B \to B \otimes_A B$. We shall obtain a
commutative an exact diagram:
\[ \xymatrix{
0 \ar[r] &  M \otimes_A B \ar[d]   \ar[r] &  N  \otimes_A B
\ar[d]^{\phi}  \ar[r] &  N \otimes_A B \otimes_A B  \ar[d]^{\phi_{13}^{-1}}  \\
0 \ar[r] &  N   \ar[r] &  B \otimes_A N
  \ar[r] &  B \otimes_A B \otimes_A N
}.\]
Here the map $$N \otimes_A B \to N \otimes_A B \otimes_A B$$ sends $n \otimes b
\mapsto n \otimes 1 \otimes b - \phi(1 \otimes n) \otimes b$.
Consequently the first row is exact, $B$ being flat over $A$.
The bottom map
$$B \otimes_A N \to B \otimes_A N \otimes_A N$$
sends $b \otimes n \mapsto b \otimes 1 \otimes n - 1 \otimes b \otimes n$.
It follows by the Amitsur complex that the bottom row is exact too.
We need to check that the diagram commutes. Since the two vertical maps on the
right are isomorphisms, it will follow that $M \otimes_A B \to N$ is an
isomorphism, and we shall be done.

Fix $n \otimes b \in N \otimes_A B$. We need to figure out where it goes in $B
\otimes_A B \otimes_A N$ under the two maps.  Going right gives $n \otimes 1 \otimes b - \phi_{12}( 1 \otimes n \otimes
b)$.
Going down then gives
$\phi_{13}^{-1}(n \otimes 1 \otimes b) - \phi_{13}^{-1}\phi_{12}( 1 \otimes n \otimes
b) =
\phi_{13}^{-1}(n \otimes 1 \otimes b) - \phi_{23}^{-1}(1 \otimes n \otimes
b)$, where we have used the cocycle condition.
So this is one of the maps $N \otimes_A B \to B \otimes_A B \otimes_A N$.

Now we consider the other way $n \otimes b$ can map to $B \otimes_A B \otimes_A N$.

Going down gives $\phi(n \otimes
b)$, and then going right gives the difference of two maps $N \otimes_A B \to B
\otimes_A B \otimes_A N$, which are the same as above.
\end{proof}

\subsection{Example: Galois descent}
\add{this section}


\section{The $\tor$ functor}


\subsection{Introduction}
Fix $M$. The functor $N \mapsto N \otimes_R M$ is a right-exact functor on the
category of $R$-modules. We can thus consider its \emph{left-derived functors}
as in \cref{homological}.
Recall:

\begin{definition}
The derived functors of the tensor product functor $N \mapsto N \otimes_R M$ are denoted by
$\mathrm{Tor} _R^i( N, M), i \geq 0$.  We shall sometimes denote omit the
subscript $R$.
\end{definition}

So in particular, $\mathrm{Tor} _R^0(M,N) = M \otimes N$.
A priori, $\tor$ is only a functor of the first variable, but in fact, it is
not hard to see that $\tor$ is a covariant functor of two variables $M, N$.
In fact, $\tor_R^i(M, N) \simeq \tor_R^i(N, M)$ for any two $R$-modules $M, N$.
For proofs, we refer to \cref{homological}. \textbf{ADD: THEY ARE NOT IN THAT
CHAPTER YET.}

Let us recall the basic properties of $\tor$ that follow from general facts
about derived functors. Given an exact sequence
\[ 0 \to N' \to N \to N'' \to 0 \]
we have a long exact sequence
\[ \mathrm{Tor} ^i(N',M) \to \mathrm{Tor} ^i(N,M) \to \mathrm{Tor} ^i(N'',M ) \to \mathrm{Tor} ^{i-1}(N',M) \to \dots \]
Since $\tor$ is symmetric, we can similarly get a long exact sequence if we
are given a short exact sequence of $M$'s.

Recall, moreover, that $\tor$ can be  computed explicitly (in theory).
If we have modules $M, N$, and a projective resolution $P_* \to N$, then
$\tor_R^i(M,N)$ is the $i$th homology of the complex $M \otimes P_*$.
We can use this to compute $\tor$ in the case of abelian groups.

\begin{example} We compute $\tor_{\mathbb{Z}}^*(A, B)$ whenever $A, B $ are abelian groups
and $B$ is finitely generated. This immediately reduces to the case of $B$
either $\mathbb{Z}$ or $\mathbb{Z}/d\mathbb{Z}$ for some $d$ by the
structure theorem. When $B= \mathbb{Z}$, there is nothing to
compute (derived functors are not very interesting on projective objects!).
Let us compute $\tor_{\mathbb{Z}}^*(A, \mathbb{Z}/d\mathbb{Z})$ for an abelian group $A$.


Actually, let us be more general and consider the case where the ring is
replaced by $\mathbb{Z}/m$ for some $m$ such that $d \mid m$. Then we will
compute $\tor_{\mathbb{Z}/m}^*(A, \mathbb{Z}/d)$ for any
$\mathbb{Z}/m$-module $A$.  The case $m = 0$
will handle the ring $\mathbb{Z}$.
Consider the projective resolution
\[
\xymatrix{
\cdots \ar[r]^{m/d} & \mathbb{Z}/m\mathbb{Z} \ar[r]^d & \mathbb{Z}/m\mathbb{Z} \ar[r]^{m/d}
	%& \mathbb{Z}/m\mathbb{Z} \ar[r]^d & \mathbb{Z}/m\mathbb{Z} \ar[r]^{m/d}
	& \mathbb{Z}/m\mathbb{Z} \ar[r]^{d} & \mathbb{Z}/m\mathbb{Z} \ar[r] & \mathbb{Z}/d\mathbb{Z} \ar[r] & 0.
}
\]
We apply $A \otimes_{\mathbb{Z}/m\mathbb{Z}} \cdot$. Since tensoring (over
$\mathbb{Z}/m$!) with $\mathbb{Z}/m\mathbb{Z}$ does nothing, we  obtain the complex
\[
\xymatrix{
\cdots \ar[r]^{m/d} & A \ar[r]^d & A \ar[r]^{m/d}
	& A \ar[r]^{d} & A \ar[r] & 0.
}
\]
The groups $\Tor_n^{\mathbb{Z}/m\mathbb{Z}} (A, \mathbb{Z}/d\mathbb{Z})$ are simply the homology groups
(ker/im) of
the complex, which are simply
\begin{align*}
\Tor_0^{\mathbb{Z} / m\mathbb{Z}} (A, \mathbb{Z}/d\mathbb{Z}) &\cong A / dA \\
\Tor_n^{\mathbb{Z} / m\mathbb{Z}} (A, \mathbb{Z}/d\mathbb{Z}) &\cong {}_dA/(m/d)A
			\quad \text{$n$ odd, $n \ge 1$} \\
\Tor_n^{\mathbb{Z} / m\mathbb{Z}} (A, \mathbb{Z}/d\mathbb{Z}) &\cong {}_{m/d}A/dA
			\quad \text{$n$ even, $n \ge 2$},
\end{align*}
where ${}_kA = \{ a \in A \mid ka = 0 \}$ denotes the set of elements of $A$
killed by $k$.
\end{example}


The symmetry of the tensor product also provides with a simple proof that
$\tor$ commutes with filtered colimits.
\begin{proposition} \label{torfilteredcolim}
Let $M$ be an $R$-module, $\left\{N_i\right\}$ a filtered system of
$R$-modules. Then the natural morphism
\[  \varinjlim_i \tor_R^i(M, N_i) \to \tor^i_R(M, \varinjlim_i N_i)   \]
is an isomorphism.
\end{proposition}
\begin{proof}
We can see this explicitly. Let us compute the $\tor$ functors by choosing a
projective resolution $P_* \to M$ of $M$ (note that which factor we use is irrelevant, by
symmetry!). Then the left side is the colimit
\( \varinjlim H(P_* \otimes N_i)  \), while the right side is $H(P_* \otimes
\varinjlim N_i)$. But tensor products commute with filtered (or arbitrary)
colimits, since the tensor product admits a right adjoint. Moreover, we know
that homology commutes with filtered colimits. Thus the natural map is an
isomorphism.
\end{proof}


\subsection{$\tor$ and flatness}

$\tor$ provides a simple way of detecting flatness. Indeed, one of the basic applications of this is that for a flat module $M$, the tor-functors vanish for $i \geq 1$ (whatever be $N$).
Indeed, recall that $\mathrm{Tor} (M,N)$ is computed by taking a projective resolution of $N$,
\[ \dots \to P_2 \to P_1 \to P_0 \to M \to 0 \]
tensoring with $M$, and taking the homology.  But tensoring with $M$ is exact if we have flatness, so the higher $\mathrm{Tor} $ modules vanish.

The converse is also true. In fact, something even stronger holds:
\begin{proposition} $M$ is flat iff $\mathrm{Tor} ^1(M,R/I)=0$ for all finitely generated ideals $I \subset R$.
\end{proposition}
\begin{proof}
We have just seen one direction.
Conversely, suppose $\mathrm{Tor} ^i(M,R/I) = 0$ for all finitely generated
ideals $I$ and $i>0$.
Then the result holds, first of all, for all ideals $I$, because of
\cref{torfilteredcolim} and the fact that $R/I$ is always the colimit of $R/J$
as $J$ ranges over finitely generated ideals $J \subset I$.

We now show that $\tor^i(M, N) = 0$ whenever $N$ is finitely generated. To do
this, we induct on the number of generators of $N$. When $N$ has one
generator, it is cyclic and we are done. Suppose we have proved the result
whenever for modules that have $n-1$ generators or less, and suppose $N$ has
$n$ generators.
Then we can consider an exact sequence of the form
\[ 0 \to N' \hookrightarrow N \twoheadrightarrow N'' \to 0  \]
where $N'$ has $n-1$ generators and $N''$ is cyclic. Then the long exact
sequence shows that $\tor^i(M, N) = 0$ for all $i \geq 1$.

Thus we see that $\tor^i(M, N)  = 0$ whenever $N$ is finitely generated. Since
any module is a filtered colimit of finitely generated ones, we are done by
\cref{torfilteredcolim}.
\end{proof}


Note that there is an exact sequence $0 \to I \to R \to R/I \to 0$ and
so
\[ \mathrm{Tor} _1(M,R)=0 \to \mathrm{Tor} _1(M,R/I) \to I \otimes M \to M \]
is exact, and by this:

\begin{corollary}
If the map
\[ I \otimes M \to M \]
is injective for all ideals $I$, then $M$ is flat.
\end{corollary}


\section{Flatness over noetherian rings}

We shall be able to obtain simpler criterion for flatness when the ring in
question is noetherian local. For instance, we have already seen:

\begin{theorem}
If $M$ is a finitely generated module over a noetherian local ring $R$ (with
residue field $k$), then $M$ is free if and only if
$\tor_1(k, M) = 0$.
\end{theorem}

In particular, flatness is the same thing as the vanishing of \emph{one}
$\tor$ module, and it equates to freeness. Now, we want to generalize this
result to the case where $M$ is not necessarily finitely generated over $R$,
but finitely generated over an $R$-algebra that is also noetherian local. In
particular, we shall get useful criteria for when an extension of
noetherian local \emph{rings}
(which in general is not finite, or even finitely generated)
is flat.

We shall prove two main criteria. The \emph{local criterion} is a direct
generalization of the above result (the vanishing of one $\tor$ group). The
\emph{infinitesimal criterion} reduces checking flatness of $M$ to checking
flatness of $M \otimes_R R/\mathfrak{m}^t$ over $R/\mathfrak{m}^t$; in
particular, it reduces to the case where the base ring is \emph{artinian.}
Armed with these, we will be able to prove a rather difficult theorem that
states that we can always find lots of flat extensions of noetherian local
rings.

\subsection{Flatness over a noetherian local ring}

We shall place ourselves in the following situation. $R, S$ are noetherian
local rings with maximal ideals $\mathfrak{m} \subset R, \mathfrak{n} \subset
S$, and $S$ is an $R$-algebra (and the morphism $R \to S$ is \emph{local}, so
$\mathfrak{m}S \subset \mathfrak{n}$).
We will want to know when a $S$-module is flat over $R$. In particular, we
want a criterion for when $S$ is flat over $R$.

\begin{theorem} \label{localcrit} The finitely generated $S$-module $M$ is flat over $R$ iff
\[ \mathrm{Tor} ^1_R( k, M) = 0.\]
In this case, $M$ is even free.
\end{theorem}

It is actually striking how little the condition that $M$ is a finitely
generated $S$-module enters, or how irrelevant it seems in the statement. The
argument will, however, use the fact that $M$ is \emph{separated} with respect
to the $\mathfrak{m}$-adic topology, which relies on Krull's intersection
theorem (note that since $\mathfrak{m} S \subset \mathfrak{n}$, the
$\mathfrak{m}$-adic topology on $M$ is separated).

\begin{proof}
Necessity is immediate.  What we have to prove is sufficiency.

First, we claim that if $N$ is an $R$-module of finite length, then
\begin{equation} \label{vanishingtorlocal} \mathrm{Tor} ^1_R( N,
M)=0.\end{equation}
This is because $N$ has by d{\'e}vissage (\cref{filtrationlemma}) a finite  filtration
$N_i$ whose quotients are of the form $R/\mathfrak{p}$ for $\mathfrak{p}$
prime and (by finite length hypothesis) $\mathfrak{p}= \mathfrak{m}$. So we
have a filtration on $M$ whose successive quotients are isomorphic to $k$.
We can then climb up the filtration to argue that $\tor^1(N_i, M) = 0$ for
each $i$.

Indeed, the claim \eqref{vanishingtorlocal} is true $N_0=0 \subset N$ trivially.  We climb up the filtration piece by piece inductively; if $\mathrm{Tor} ^1_R(N_i, M)=0$, then the exact sequence
\[ 0 \to N_i \to N_{i+1} \to k \to 0 \]
yields an exact sequence
\[ \mathrm{Tor} ^1_R(N_i, M) \to \mathrm{Tor} ^1_R(N_{i+1}, M) \to 0 \]
from the long exact sequence of $\mathrm{Tor} $ and the hypothesis on $M$.
The claim is proved.


Now we want to prove that $M$ is flat. The idea is to show that $I \otimes_RM
\to M$ is injective for any ideal $I \subset R$.  We will use some diagram chasing and the Krull intersection theorem on the kernel $K$ of this map, to interpolate between it and various quotients by powers of $\mathfrak{m}$.
First we write some exact sequences.

We have an exact sequence
\[ 0 \to \mathfrak{m}^t \cap I \to I \to I/I \cap \mathfrak{m}^t \to 0\]
which we tensor with $M$:
\[   \mathfrak{m}^t \cap I \otimes M \to I \otimes M \to I/I \cap \mathfrak{m}^t \otimes M \to 0.\]

The sequence
\[ 0 \to  I/I  \cap \mathfrak{m}^t \to R/\mathfrak{m}^t \to R/(I+\mathfrak{m}^t) \to 0\]
is also exact, and tensoring with $M$ yields an exact sequence:
\[ 0 \to  I/I  \cap \mathfrak{m}^t \otimes M  \to M/\mathfrak{m}^tM  \to M/(\mathfrak{m}^t  + I) M \to 0\]
because $\mathrm{Tor} ^1_R(M,   R/(I+\mathfrak{m}^t))=0$ by
\eqref{vanishingtorlocal}, as $R/(I + \mathfrak{m}^t)$ is of finite length.

Let us draw the following commutative diagram:
\begin{equation} \label{keyflatnessdiag}
\xymatrix{
& & 0 \ar[d] \\
\mathfrak{m}^t \cap I \otimes M \ar[r] & I \otimes M \ar[r] & I/I \cap \mathfrak{m}^t \otimes M \ar[d] \\
& & M/\mathfrak{m}^t M
} \end{equation}

Here the column and the row are exact.
As a result, if an element in $I \otimes M$ goes to zero in $M$ (a fortiori
in  $M/\mathfrak{m}^tM$) it must come from $\mathfrak{m}^t \cap I \otimes M$
for all $t$.  Thus, by the Artin-Rees lemma, it belongs to $\mathfrak{m}^t(I \otimes M)$ for all $t$, and the Krull intersection theorem (applied to $S$, since $\mathfrak{m}S \subset \mathfrak{n}$) implies it is zero.

\end{proof}

\subsection{The infinitesimal criterion for flatness}

\begin{theorem} \label{infcriterion} Let $R$ be a noetherian local ring, $S$ a noetherian local
$R$-algebra. Let $M$ be a finitely generated module over $S$.  Then $M$ is
flat over $R$ iff $M/\mathfrak{m}^tM$ is flat over $R/\mathfrak{m}^t$ for all $t>0$.
\end{theorem}
\begin{proof}
One direction is easy, because flatness is preserved under base-change $R \to
R/\mathfrak{m}^t$.
For the other direction, suppose $M/\mathfrak{m}^t M$ is flat over
$R/\mathfrak{m}^t$ for all $t$. Then, we need to show that if $I \subset R$ is any ideal,
then the map $I \otimes_R M \to M$ is injective. We shall argue that the
kernel is zero using the Krull intersection theorem.

Fix $t \in \mathbb{N}$. As before, the short exact sequence of
$R/\mathfrak{m}^t$-modules  $0 \to
I/(\mathfrak{m}^t \cap I) \cap R/\mathfrak{m}^t  \to R/(\mathfrak{m}^t \cap I) \to 0$ gives an exact
sequence (because $M/\mathfrak{m}^t M$ is $R/\mathfrak{m}^t$-flat)
\[ 0 \to  I/I  \cap \mathfrak{m}^t \otimes M  \to M/\mathfrak{m}^tM  \to M/(\mathfrak{m}^t  + I) M \to 0\]
which we can fit into a diagram, as in \eqref{keyflatnessdiag}
$$\xymatrix{
& & 0 \ar[d] \\
\mathfrak{m}^t \cap I \otimes M \ar[r] & I \otimes M \ar[r] & I/I \cap \mathfrak{m}^t \otimes M \ar[d] \\
& & M/\mathfrak{m}^t M
}.$$

The horizontal sequence was always exact, as before.  The vertical sequence can be argued to be exact by tensoring the exact sequence
\[ 0 \to  I/I  \cap \mathfrak{m}^t \to R/\mathfrak{m}^t \to R/(I+\mathfrak{m}^t) \to 0\]
of $R/\mathfrak{m}^t$-modules with $M/\mathfrak{m}^tM$, and using flatness of
$M/\mathfrak{m}^t M$ over $R/\mathfrak{m}^t$ (and \cref{}).
Thus we get flatness of $M$ as before.
\end{proof}

Incidentally, if we combine the local and infinitesimal criteria for flatness, we get a little more.

\begin{comment}
%% THIS IS NOT ADDED YEt
\subsection{The $\gr$ criterion for flatness}

Suppose $(R, \mathfrak{m})$ is a noetherian local ring and $(S, \mathfrak{n})$
a local $R$-algebra.
As usual, we are interested in criteria for when a finitely generated
$S$-module $M$ is flat over $R$.

We can, of course, endow $M$ with the $\mathfrak{m}$-adic topology.
Then $M$ is a filtered module over the filtered ring $R$ (with the
$\mathfrak{m}$-adic topology).
We have morphisms for each $i$,
\[ \mathfrak{m}^i/\mathfrak{m}^{i +1} \otimes_{R/\mathfrak{m}}
M/\mathfrak{m}M \to \mathfrak{m}^i M/\mathfrak{m}^{i+1} M  \]
that induce map
\[ \gr(R) \otimes_{R/\mathfrak{m}}  M/\mathfrak{m}M \to \gr(M). \]

If $M$ is flat over
\end{comment}

\subsection{Generalizations of the local and infinitesimal criteria}
In the previous subsections, we obtained results that gave criteria for when,
given a local homomorphism of noetherian local rings $(R, \mathfrak{m}) \to
(S, \mathfrak{n})$, a finitely generated $S$-module was $R$-flat.
These criteria generally were related to the $\tor$ groups of the module with
respect to $R/\mathfrak{m}$.
We are now interested in generalizing the above results to the setting where
$\mathfrak{m}$ is replaced by an ideal that \emph{maps into the Jacobson radical of $S$.}
In other words,
\[ \phi: R \to S  \]
will be a homomorphism of noetherian rings, and $J \subset R$ will be an ideal
such that $\phi(J)$ is contained in every maximal ideal of $S$.

Ideally, we are aiming for results of the following type:
\begin{theorem}[Generalized local criterion for flatness] \label{localcritg}
Let $\phi: R \to S$ be a morphism of noetherian rings, $J \subset R$ an ideal
with $\phi(J) $ contained in the Jacobson radical of $S$.
Let $M$ be a finitely generated $S$-module. Then $M$ is $R$-flat if and only if
$M /JM$ is $R/J$-flat and $\tor_1^R(R/J, M) = 0$.
\end{theorem}

Note that this is a generalization of \cref{localcrit}. In that case, $R/J$ was
a field and the $R/J$-flatness of $M/JM$ was automatic.
One key step in the proof of \cref{localcrit} was to go from the hypothesis
that $\tor_1(M, k) = 0$ to $\tor_1(M, N) =0 $ whenever $N$ was an $R$-module of
\emph{finite length.}
We now want to do the same in this generalized case; the analogy would be
that, under the hypotheses of \cref{localcritg}, we would like to conclude
that $\tor_1^R(M, N) = 0$ whenever $N$ is a finitely generated $R$-module
\emph{annihilated by $I$}.
This is not quite as obvious because we cannot generally find a filtration on
$N$ whose successive quotients are $R/J$ (unlike in the case where $J$ was
maximal).
Therefore we shall need two lemmas.

\begin{remark}
One situation where the strong form of the local criterion, \cref{localcritg},
is used is in Grothendieck's proof (cf. EGA IV-11, \cite{EGA}) that the locus of points where a coherent
sheaf is flat is open (in commutative algebra language, if $A$ is noetherian
and $M$ finitely generated over a finitely generated $A$-algebra $B$, then the
set of primes $\mathfrak{q} \in \spec B$ such that $M_{\mathfrak{q}}$ is
$A$-flat is open in $\spec  B$).
\end{remark}

\begin{lemma}[Serre] \label{serrelemma}
Suppose $R$ is a ring, $S$ an $R$-algebra, and $M$ an $S$-module.
Then the following are equivalent:
\begin{enumerate}
\item $M \otimes_R S$ is $S$-flat and $\tor_1^R(M, S) = 0$.
\item $\tor_1^R(M, N) = 0$ whenever $N$ is any  $S$-module.
\end{enumerate}
\end{lemma}
We follow \cite{SGA1}.
\begin{proof}
Let $P$ be an $S$-module (considered as fixed), and $Q$ any (variable) $R$-module.
Recall that there is a homology spectral sequence
\[ \tor_p^S(\tor_q^R(Q, S), P) \implies \tor_{p+q}^R(Q,P).  \]
Recall that this is the Grothendieck spectral sequence of the composite functors
\[ Q \mapsto Q \otimes_R S, \quad Q' \mapsto Q' \otimes_S P  \]
because
\[ (Q \otimes_R S) \otimes_S P \simeq Q \otimes_R P.  \]
\add{This, and generalities on spectral sequences, need to be added!}
From this spectral sequence, it will be relatively easy to deduce
the result.
\begin{enumerate}
\item Suppose $M \otimes_R S$ is $S$-flat and $\tor_1^R(M, S) = 0$.
We want to show that 2 holds, so let $N$ be any $S$-module.
Consider the $E_2$ page of the above spectral sequence
 $\tor_p^S(\tor_q^R(M, S), N) \implies \tor_{p+q}^R(M, N)$.
 In the terms such that $p+q = 1$, we have the two terms
$\tor_0^S(\tor_1^R(M, S), N), \tor_1^S(\tor_0^R(M, S),N)$.
But by hypotheses these are both zero. It follows that $\tor_1^R(M, N) = 0$.
\item Suppose $\tor_1^R(M, N) = 0$ for each $S$-module $N$.
Since this is a {homology} spectral sequence, this implies that the
$E_2^{10}$ term vanishes (since nothing will be able to hit this term).
In particular $\tor_1^S(M \otimes_R  S, N) = 0$ for each $S$-module $N$.
It follows that $M \otimes_R S$ is $S$-flat.
Hence the higher terms $\tor_p^S(M \otimes_R S, N) = 0$ as well, so the botton row of
the $E_2$ page (except $(0,0)$) is thus entirely zero. It follows that the
$E_{01}^2$ term vanishes if $E_{\infty}^{01}$ is trivial.
This gives that $\tor_1^R(M, S) \otimes_S N = 0$ for every $S$-module $N$,
which clearly implies $\tor_1^R(M, S) = 0$.
\end{enumerate}
\end{proof}

As a result, we shall be able to deduce the result alluded to in the motivation
following the statement of \cref{localcritg}.

\begin{lemma}
Let $R$ be a noetherian ring, $J \subset R$ an ideal, $M$ an $R$-module. Then TFAE:
\begin{enumerate}
\item $\tor_1^R(M, R/J) = 0$ and $M/JM$ is $R/J$-flat.
\item $\tor_1^R(M, N) = 0$ for any finitely generated $R$-module $N$
annihilated by a power of $J$.
\end{enumerate}
\end{lemma}
\begin{proof}
This is immediate from \cref{serrelemma}, once one notes that any $N$ as in the
statement admits a finite filtration whose successive quotients are annihilated
by $J$.
\end{proof}
\begin{proof}[Proof of \cref{localcritg}]
Only one direction is nontrivial, so suppose $M$ is a finitely generated
$S$-module, with $M/JM$ flat over $R/J$ and $\tor_1^R(M, R/J) = 0$.
We know by the lemma that $\tor_1^R(M, N) = 0$ whenever $N$ is finitely
generated and annihilated by a power of $J$.


So as to avoid repeating the same argument over and over, we encapsulate it in
the following lemma.
\begin{lemma} \label{flatlemma} Let the hypotheses be as in \cref{localcritg}
Suppose for every ideal $I \subset R$, and every $t \in \mathbb{N}$, the map
\[ I/I \cap J^t \otimes M \to M/J^t M  \]
is an injection. Then $M$ is $R$-flat.
\end{lemma}
\begin{proof}
Indeed, then as before, the kernel of $I \otimes_R M \to M$ lives inside the image of $(I \cap J^t)
\otimes M \to I \otimes_R M$ for \emph{every} $t$; by the Artin-Rees lemma, and the Krull
intersection theorem (since $\bigcap J^t(I \otimes_R M) = \{0\}$), it follows that this kernel is zero.
\end{proof}

It is now easy to finish the proof. Indeed, we can verify the hypotheses of the
lemma by noting that
\[ I /I \cap J^t \otimes M \to I \otimes M  \]
is obtained by tensoring with $M$ the sequence
\[ 0 \to I/I \cap J^t \to R/(I \cap J^t) \to R/(I + J^t) \to 0.  \]
Since $\tor_1^R(M, R/(I + J^t)) = 0$, we find that the map as in the lemma is
an injection, and so we are done.
\end{proof}

The reader can similarly formulate a version of the infinitesimal criterion in
this more general case using \cref{flatlemma} and the argument in
\cref{infcriterion}. (In fact, the spectral sequence argument of this section
is not necessary.) We shall not state it here, as it will appear as a
component of \cref{bigflatcriterion}. We leave the details of the proof to the reader.

\subsection{The final statement of the flatness criterion}

We shall now bundle the various criteria for flatness into one big result,
following \cite{SGA1}:

\begin{theorem} \label{bigflatcriterion}
Let $A, B$ be noetherian rings, $\phi: A \to B$ a morphism making $B$ into an
$A$-algebra. Let $I$ be an ideal of $A$ such that $\phi(I)$ is contained in the
Jacobson radical of $B$.
Let $M$ be a finitely generated $B$-module.
Then the following are equivalent:
\begin{enumerate}
\item $M$ is $A$-flat.
\item (Local criterion) $M/IM$ is $A/I$-flat and $\tor_1^A(M, A/I) = 0$.
\item (Infinitesimal criterion)  $M/I^n M$ is $A/I^n$-flat for each $n$.
\item (Associated graded criterion)  $M/IM$ is $A/I$-flat and $M/IM \otimes_{A/I} I^n/I^{n+1} \to I^n
M/I^{n+1}M$ is an isomorphism for each $n$.
\end{enumerate}
\end{theorem}

The last criterion can be phrased as saying that the $I$-adic \emph{associated
graded} of $M$ is determined by $M/IM$.
\begin{proof}
We have already proved that the first three are equivalent. It is easy to see
that flatness of $M$ implies that
\begin{equation} \label{flatwantiso} M/IM \otimes_{A/I} I^n/I^{n+1} \to I^n
M/I^{n+1}M  \end{equation}
is an isomorphism for each $n$.
Indeed, this easily comes out to be the quotient of $M \otimes_A I^n$ by the
image of $M \otimes_A I^{n+1}$, which is $I^n M/I^{n+1}M$ since the map $M
\otimes_A I^n \to I^n M$ is an isomorphism.
Now we need to show that this last condition implies flatness.
To do this, we may (in view of the infinitesimal criterion) assume that $I$ is
\emph{nilpotent}, by base-changing to $A/I^n$.
We are then reduced to showing that $\tor_1^A(M, A/I) = 0$ (by the local
criterion).
Then we are, finally, reduced to showing:

\begin{lemma}
Let $A$ be a ring, $I \subset A$ be a nilpotent ideal, and $M$ any $A$-module.
If \eqref{flatwantiso} is an isomorphism for each $n$, then
$\tor_1^A(M, A/I) = 0$.
\end{lemma}
\begin{proof}
This is equivalent to the assertion, by a diagram chase, that
\[ I \otimes_A M \to M  \]
is an injection.
We shall show more generally that $I^n \otimes_A M \to M$ is an injection for
each $n$. When $n \gg 0$, this is immediate, $I$ being nilpotent. So we can use
descending induction on $n$.

Suppose $I^{n+1} \otimes_A M \to I^{n+1}M$ is an isomorphism.
Consider the diagram
\[ \xymatrix{
& I^{n+1} \otimes_A M \ar[r] \ar[d]  &  I^n \otimes_A M \ar[r]  \ar[d]  &
I^n/I^{n+1}  \otimes_A M \ar[d] \to
0 \\
0 \ar[r] &  I^{n+1}M \ar[r] & I^n M \ar[r] & I^nM/I^{n+1}M \ar[r] &  0.
}\]
By hypothesis, the outer two vertical arrows are isomorphisms. Thus the middle
vertical arrow is an isomorphism as well. This completes the induction
hypothesis.
\end{proof}
\end{proof}

Here is an example of the above techniques:
\begin{proposition}
\label{fiberwiseflat}
Let $(A, \mathfrak{m}), (B, \mathfrak{n}), (C, \mathfrak{n}')$ be noetherian
local rings. Suppose given a commutative diagram of local homomorphisms
\[ \xymatrix{
B \ar[rr]  & & C \\
& A \ar[ru] \ar[lu].
}\]
Suppose $B, C$ are flat $A$-algebras, and $B/\mathfrak{m}B \to C/\mathfrak{m}C$
is a flat morphism. Then $B \to C$ is flat.
\end{proposition}
Geometrically, this means that flatness can be checked fiberwise if both
objects are flat over the base.
This will be  a useful technical fact.
\begin{proof}
We will use the associated graded criterion for flatness with the ideal
$I = \mathfrak{m}B \subset B$. (Note that we are \emph{not} using the criterion
with the maximal ideal here!) Namely, we shall show
that
\begin{equation} \label{monkey}  I^n/I^{n+1} \otimes_{B/I} C/IC \to I^n
C/I^{n+1}C \end{equation}
is an isomorphism. By \cref{bigflatcriterion}, this will do it. Now we have:
\begin{align*}
 I^n/I^{n+1} \otimes_{B/I} C/IC & \simeq
\mathfrak{m}^nB/\mathfrak{m}^{n+1}B \otimes_{B/\mathfrak{m}B}
C/\mathfrak{m}C  \\ & \simeq
(\mathfrak{m}^n/\mathfrak{m}^{n+1})\otimes_{A} B/\mathfrak{m}B \otimes_B
C/\mathfrak{m}C  \\
& \simeq (\mathfrak{m}^n/\mathfrak{m}^{n+1})\otimes_{A} B \otimes_B
C/\mathfrak{m}C \\
& \simeq (\mathfrak{m}^n/\mathfrak{m}^{n+1})\otimes_{A} C/\mathfrak{m}C \\
& \simeq \mathfrak{m}^nC/\mathfrak{m}^{n+1} C \simeq I^n C/I^{n+1}C.
\end{align*}
In this chain of equalities, we have used the fact that $B, C$ were flat over
$A$, so their associated gradeds with respect to $\mathfrak{m} \subset A$
behave nicely. It follows that \eqref{monkey} is an isomorphism, completing the
proof.
\end{proof}

\subsection{Flatness over regular local rings}

Here we shall prove a result that implies geometrically, for instance, that a
finite morphism between smooth varieties is always flat.

\begin{theorem}[``Miracle'' flatness theorem]
Let $(A, \mathfrak{m})$  be a regular local (noetherian) ring. Let $(B,
\mathfrak{n})$ be a Cohen-Macaulay, local $A$-algebra such that
\[ \dim B = \dim A + \dim B/\mathfrak{m}B . \]
Then $B$ is flat over $A$.
\end{theorem}
Recall that \emph{inequality} $\leq$ always holds in the above for any
morphism of noetherian local rings (\cref{}), and
equality always holds with flatness supposed.
We get a partial converse.

\begin{proof}
We shall work by induction on $\dim A$.
Let $x \in \mathfrak{m}$ be a non-zero divisor, so the first element in a
regular sequence of parameters.
We are going to show that $(A/(x), B/(x))$ satisfies the same hypotheses.
Indeed, note that
\[ \dim B/(x) \leq \dim A/(x) + \dim B/\mathfrak{m}B  \]
by the usual inequality. Since $\dim A/(x) = \dim A - 1$,
we find that quotienting by $x$ drops the dimension of $B$ by at least one: that is,
$\dim B/(x) \leq \dim B - 1$. By the principal ideal theorem, we have equality,
\[ \dim B/(x) = \dim B - 1.  \]

The claim is that $x$ is a non-zero divisor in $B$, and consequently we can
argue by induction.
Indeed, but $B$ is \emph{Cohen-Macaulay}. Thus, any zero-divisor in $B$ lies in a
\emph{minimal} prime (since all associated primes of $B$ are minimal); thus
quotienting by a zero-divisor would not bring down the degree. So $x$ is a
nonzerodivisor in $B$.

In other words, we have found $x \in A$ which is both $A$-regular and
$B$-regular (i.e. nonzerodivisors on both), and such that the hypotheses of the theorem apply to the pair
$(A/(x), B/(x))$. It follows that $B/(x)$ is flat over $A/(x)$ by the
inductive hypothesis. The next lemma will complete the proof.
\end{proof}


\begin{lemma}
Suppose $(A, \mathfrak{m})$ is a noetherian local ring, $(B, \mathfrak{n})$ a
noetherian local $A$-algebra, and $M$ a finite $B$-module. Suppose $x \in A$ is
a regular element of $A$ which is also regular on $M$.
Suppose moreover $M/xM$ is $A/(x)$-flat. Then $M$ is flat over $A$.
\end{lemma}
\begin{proof}
This follows from the associated graded criterion for flatness (see the
omnibus result \cref{bigflatcriterion}).
Indeed, if we use the notation of that result, we take $I = (x)$.
We are given that $M/xM$ is $A/(x)$-flat. So we need to show that
\[ M/xM \otimes_{A/(x)}  (x^n)/(x^{n+1}) \to x^n M/x^{n+1}M \]
is an isomorphism for each $n$. This, however, is implied because
$(x^n)/(x^{n+1})$ is isomorphic to $A/(x)$ by regularity, and multiplication
\[ M \stackrel{x^n}{\to} x^n M, \quad xM \stackrel{x^n}{\to} x^{n+1}M \]
are isomorphisms by $M$-regularity.
\end{proof}
\subsection{Example: construction of flat extensions}

As an illustration of several of the techniques in this chapter and previous
ones, we shall show, following \cite{EGA} (volume III, chapter 0) that, given a
local ring and an extension of its residue field, one may find a flat
extension of this local ring with the bigger field as \emph{its} residue
field. One application of this is in showing (in the context of Zariski's
Main Theorem) that the fibers of a birational
projective morphism of noetherian schemes (where the target is normal) are
\emph{geometrically} connected.
We shall later give another application in the theory of \'etale morphisms.

\begin{theorem}
Let $(R, \mathfrak{m})$ be a noetherian local ring with residue field $k$.
Suppose $K$ is an extension of $k$. Then there is a noetherian local
$R$-algebra $(S,
\mathfrak{n})$ with residue field $K$ such that $S$ is flat over $R$ and $\mathfrak{n} =
\mathfrak{m}S$.
\end{theorem}

\begin{proof}
Let us start by motivating the theorem when $K$ is generated over $k$ by
\emph{one} element.
This case can be handled directly, but the general case will require a
somewhat tricky passage to the limit.
There are two cases.

\begin{enumerate}
\item
First, suppose $K = k(t)$ for $t \in K$ \emph{transcendental} over $k$. In
this case, we will take $S$ to be a suitable localization of $R[t]$. Namely,
we consider the prime\footnote{It is prime because the quotient is the domain
$k[t]$.} ideal $\mathfrak{m} R[t] \subset R[t]$, and let
$S = (R[t])_{\mathfrak{m} R[t]}$.
Then $S$ is clearly noetherian and local, and moreover $\mathfrak{m}S$ is the
maximal ideal of $S$. The residue field of $S$ is $S/\mathfrak{m}S $, which is
easily seen to be the quotient field of $R[t]/\mathfrak{m}R[t] = k[t]$, and is
thus isomorphic to $K$. Moreover, as a localization of a polynomial ring, $S$
is flat over $R$.
Thus we have handled the case of a purely transcendental extension generated
by one element.

\item
Let us now suppose $K = k(a)$ for $a \in K$ \emph{algebraic} over $k$. Then
$a$ satisfies a monic irreducible polynomial $\overline{p}(T)$ with coefficients in $k$.
We lift $\overline{p}$ to a monic polynomial $p(T) \in R[T]$. The claim is
that then, $S = R[T]/(p(T))$ will suffice.

Indeed, $S$ is clearly flat over $R$ (in fact, it is free of rank $\deg p$).
As it is finite over $R$, $S$ is noetherian. Moreover, $S/\mathfrak{m}S = k[T]/
(p(T)) \simeq K$. It follows that $\mathfrak{m}S \subset S$ is a maximal ideal
and that the residue field is $K$. Since any maximal ideal of $S$ contains
$\mathfrak{m}S$ by Nakayama,\footnote{\add{citation needed}} we see that $S$
is local as well. Thus we have showed that $S$ satisfies all the conditions we
want.
\end{enumerate}

So we have proved the theorem when $K$ is generated by one element over $k$.
In general, we can iterate this procedure finitely many times, so that the
assertion is clear when $K$ is a finitely generated extension of $k$.
Extending to infinitely generated extensions is trickier.

Let us first argue that we can write $K/k$ as a ``transfinite limit'' of
monogenic extensions. Consider the set of   well-ordered collections
$\mathcal{C}'$ of subfields between $k$ and $K$ (containing $k$) such that if $L \in
\mathcal{C}'$ has an immediate predecessor $L'$, then $L/L'$ is generated by
one element. First, such collections $\mathcal{C}'$ clearly exist; we can take
the one consisting only of $k$. The set of such collections is clearly a
partially ordered set such that every chain has an upper bound.
By Zorn's lemma, there is a \emph{maximal} such collection of subfields, which
we now call $\mathcal{C}$.

The claim is that $\mathcal{C}$ has a maximal field, which is $K$. Indeed, if
it had no maximal element, we could adjoin the union $\bigcup_{F \in
\mathcal{C}} F$ to $\mathcal{C}$ and make $\mathcal{C}$ bigger, contradicting
maximality. If this maximal field of $\mathcal{C}$ were not $K$, then we could add another
element to this maximal subfield and get a bigger collection than
$\mathcal{C}$, contradiction.

So thus we have a  set of fields $K_\alpha$ (with $\alpha$, the
index, ranging over a well-ordered set) between $k$ and $K$,
such that if $\alpha$ has a successor $\alpha'$, then
$K_\alpha'$ is generated by one element over $K_\alpha$. Moreover $K$ is the
largest of the $K_\alpha$, and $k$ is the smallest.

We are now going to define a collection of rings $R_\alpha$ by transfinite
induction on $\alpha$. We start the induction with $R_0 = R$ (where $0$ is the
smallest allowed $\alpha$). The inductive hypothesis that we will want to
maintain is that $R_\alpha$ is a noetherian local ring with maximal ideal
$\mathfrak{m}_\alpha$, flat over $R$ and
satisfying $\mathfrak{m} R_\alpha = \mathfrak{m}_\alpha$; we require,
moreover, that the residue field of $R_\alpha$ be $K_\alpha$. Thus if we can
do this at each step, we will be able to work up to $K$ and get the ring $S$
that we want.
We are, moreover, going to construct the $R_\alpha$ such that whenever $\beta <
\alpha$, $R_\alpha$ is a $R_\beta$-algebra.

Let us assume that $R_\beta$ has been defined for all $\beta < \alpha$ and
satisfies the conditions. Then
we want to define $R_\alpha$ in an appropriate way. If we can do this, then we
will have proved the result.
There are two cases:
\begin{enumerate}
\item $\alpha$ has an immediate predecessor $\alpha_{pre} $. In this case, we
can define $R_\alpha$ from $R_{\alpha_{pre}}$ as above (because
$K_\alpha/K_{\alpha_{pre}}$ is monogenic).
\item $\alpha$ has no immediate predecessor. Then we define $R_\alpha =
\varinjlim_{\beta < \alpha} R_\beta$. The following lemma will show that
$R_\alpha$ satisfies the appropriate hypotheses.
\end{enumerate}
This completes the proof, modulo \cref{indlimnoetherianlocal}.
\end{proof}

We shall need the following lemma to see that we preserve noetherianness when
we pass to the limit.
\begin{lemma}\label{indlimnoetherianlocal}
Suppose given an inductive system $\left\{(A_\alpha,
\mathfrak{m}_{\alpha})\right\}$ of noetherian
rings and flat local homomorphisms, starting with $A_0$.
Suppose moreover that $\mathfrak{m}_{\alpha} A_{\beta} = \mathfrak{m}_{\beta}$
whenever $\alpha < \beta$.

Then $A = \varinjlim A_\alpha$ is a
noetherian local ring, flat over each $A_\alpha$. Moreover, if $\mathfrak{m} \subset A$
is the maximal ideal, then $\mathfrak{m}_\alpha A = \mathfrak{m}$. The residue
field of $A$ is $\varinjlim A_\alpha/\mathfrak{m}_\alpha$.
\end{lemma}
\begin{proof}
First, it is clear that $A$ is a local ring (\cref{} \add{reference!}) with
maximal ideal equal to $\mathfrak{m}_\alpha A$ for any $\alpha $ in the
indexing set, and that $A$ has the appropriate residue field. Since filtered colimits preserve flatness, flatness of $A$ is
also clear.
We need to show that $A$ is noetherian; this is the crux of the lemma.

To prove that $A$ is noetherian, we are going to show that its
$\mathfrak{m}$-adic completion $\hat{A}$ is noetherian. Fortunately, we have a
convenient criterion for this. If $\hat{\mathfrak{m}}=
\mathfrak{m}\hat{A}$, then $\hat{A}$ is complete with respect to the
$\hat{\mathfrak{m}}$-adic topology. So if we show that
$\hat{A}/\hat{\mathfrak{m}}$ is noetherian and
$\hat{\mathfrak{m}}/\hat{\mathfrak{m}^2}$ is a finitely generated
$\hat{A}$-module, we will have shown that $\hat{A}$ is noetherian by
\cref{completenoetherian}.

But $\hat{A}/\hat{\mathfrak{m}}$ is a field, so obviously noetherian.
Also, $\hat{\mathfrak{m}}/\hat{\mathfrak{m}}^2 = \mathfrak{m}/\mathfrak{m}^2$,
and by flatness of $A$, this is
\[ A \otimes_{A_\alpha} \mathfrak{m}_\alpha/\mathfrak{m}_\alpha^2  \]
for any $\alpha$. Since $A_\alpha$ is noetherian, we see that this is finitely
generated. The criterion \cref{completenoetherian} now shows that the completion $\hat{A}$ is
noetherian.

Finally, we need to deduce that $A$ is itself noetherian.
To do this,
we shall show that $\hat{A}$ is faithfully flat over $A$. Since noetherianness
``descends'' under faithfully flat extensions (\add{citation needed}), this
will be enough. It suffices to show that $\hat{A}$ is \emph{flat} over each
$A_\alpha$. For this, we use the infinitesimal criterion; we have that
\[ \hat{A} \otimes_{A_\alpha} A_\alpha/\mathfrak{m}_\alpha^t =
\hat{A}/\hat{\mathfrak{m}^t} = A/\mathfrak{m}^t = A/A\mathfrak{m}_\alpha^t,  \]
which is flat over $A_\alpha/\mathfrak{m}_\alpha^t$ since $A$ is flat over
$A_\alpha$.

It follows that $\hat{A}$ is flat over each $A_\alpha$.
If we want to see that $A \to \hat{A}$ is flat, we let $I \subset A$ be a
finitely generated
ideal; we shall prove that $I \otimes_A \hat{A} \to \hat{A}$ is injective
(which will establish flatness). We know that there is an ideal $I_\alpha \subset A_\alpha$ for some
$A_\alpha$ such that
\[ I = I_\alpha A = I_\alpha \otimes_{A_\alpha} A.  \]
Then
\[ I \otimes_A \hat{A} = I_\alpha \otimes_{A_\alpha} \hat{A}  \]
which injects into $\hat{A}$ as $A_\alpha \to \hat{A}$ is flat.

\begin{comment}
Let us first show that $A$ is \emph{separated} with respect to the
$\mathfrak{m}$-adic topology. Fix $x \in A$. Then $x$ lies in the subring
$A_\alpha$ for some fixed $\alpha$ depending on $\alpha$ (note that $A_\alpha
\to A$ is injective since a flat morphism of local rings is \emph{faithfully
flat}). If $x \in \mathfrak{m}^n = A \mathfrak{m}_\alpha^n$, then $x \in
\mathfrak{m}_\alpha^n$ by faithful flatness and \cref{intideal}.
So if $x \in \mathfrak{m}^n$ for all $n$, then $x \in \mathfrak{m}_\alpha^n$
for all $n$; the separatedness of $A_\alpha$ with respect to the
$\mathfrak{m}_\alpha$-adic topology now shows $x=0$.
\end{comment}


\end{proof}


\subsection{Generic flatness}

Suppose given a module $M$ over a noetherian \emph{domain} $R$. Then $M
\otimes_R K(R)$ is a finitely generated free module over the field $K(R)$.
Since $K(R)$ is the inductive limit $\varinjlim R_f$ as $f$ ranges over $(R -
\left\{0\right\})/R^*$ and $K(R) \otimes_R M \simeq \varinjlim_{f \in (R -
\left\{0\right\})/R^*} M_f$, it follows by the general theory of \cref{} that
there exists $f \in R - \left\{0\right\}$ such that $M_f$ is free over $R_f$.

Here $\spec R_f = D(f) \subset \spec R$ should be thought of as a ``big''
subset of $\spec R$ (in fact, as one can check, it is \emph{dense} and open).
So the moral of this argument is that $M$ is ``generically free.'' If we had
the language of schemes, we could make this more precise.
But the idea is that localizing at $M$ corresponds to restricting the
\emph{sheaf} associated to $M$ to $D(f) \subset \spec R$; on this dense open subset, we
get a free sheaf.
(The reader not comfortable with such ``finitely presented'' arguments will
find another one below, that also works more generally.)

Now we want to generalize this to the case where $M$ is finitely generated not
over $R$, but over a finitely generated $R$-algebra. In particular, $M$ could
itself be a finitely generated $R$-algebra!

\begin{theorem}[Generic freeness]
Let $S$ be a finitely generated algebra over the noetherian domain $R$, and
let $M$ be a finitely generated $S$-module. Then there is $f \in R -
\left\{0\right\}$ such that $M_f$ is a free (in particular, flat) $R$-module.
\end{theorem}
\begin{proof} We shall first reduce the result to one about rings instead of
modules. By Hilbert's basis theorem, we know that $S$ is noetherian.
By d\'evissage (\cref{devissage}), there is a finite filtration of $M$ by
$S$-submodules,
\[ 0 = M_0 \subset M_1 \subset \dots \subset M_k = M  \]
such that the quotients $M_{i+1}/M_i$ are isomorphic to quotients
$S/\mathfrak{p}_i$ for the $\mathfrak{p}_i \in \spec S$.

Since localization is an exact functor, it will suffice to show that there
exists an $f$ such that $(S/\mathfrak{p}_i)_f$ is a free $R$-module for each
$f$. Indeed, it is clear that if a module admits a finite filtration all of
whose successive quotients are free, then the module itself is free.
We may thus even reduce to the case where $M = S/\mathfrak{p}$.

So we are reduced to showing that if we have a finitely generated
\emph{domain} $T$ over $R$, then there exists $f \in R - \left\{0\right\}$
such that $T_f$ is a free $R$-module.
If $R \to T$ is not injective, then the result is obvious (localize at
something nonzero in the kernel), so we need only handle the case where $R \to
T$ is a monomorphism.


By the Noether normalization theorem, there are $d$  elements of $T \otimes_R K(R)$, which we
denote by $t_1, \dots, t_d$, which are algebraically independent over $K(R)$
and such that $T \otimes_R K(R)$ is integral over $K(R)[t_1, \dots, t_d]$.
(Here $d$ is the transcendence degree of $K(T)/
K(R)$.)
If we localize at some highly divisible element, we can assume that $t_1,
\dots, t_d$ all lie in $T$ itself. \emph{Let us assume that the result for
domains is true whenever the transcendence degree is $< d$, so that we can
induct.}

Then we know that $R[t_1, \dots, t_d] \subset T$ is  a polynomial ring.
Moreover, each of the finitely many generators of $T/R$ satisfies a monic polynomial
equation over $K(R)[t_1, \dots, t_d]$ (by the integrality part of Noether
normalization). If we localize $R$ at a highly divisible element, we may
assume that the coefficients of these polynomials belong to $R[t_1, \dots,
t_d]$.
We have thus reduced to the following case. $T$ is a finitely generated domain
over $R$, \emph{integral} over the polynomial ring $R[t_1, \dots, t_d]$. In
particular, it is a finitely generated module over the polynomial ring $R[t_1,
\dots, t_d]$.
Thus we have some $r$ and an exact sequence
\[ 0 \to R[t_1, \dots, t_d]^r \to T \to Q \to 0,  \]
where $Q$ is a torsion $R[t_1, \dots, t_d]^r$-module. Since the polynomial
ring is free, we are reduced to showing that by localizing at a suitable
element of $R$, we can make  $Q$ free.

But now we can do an inductive argument. $Q$ has a  finite filtration by
$T$-modules whose
quotients are isomorphic to $T/\mathfrak{p}$ for nonzero primes
$\mathfrak{p}$ with $\mathfrak{p} \neq 0$ as $T$ is torsion; these are still domains finitely generated over $R$, but such
that the associated transcendence degree is \emph{less} than $d$. We have
already assumed the statement proven for domains where the transcendence
degree is $< d$. Thus we can
find a suitable localization that makes all these  free, and thus $Q$ free; it
follows that with this localization, $T$ becomes free too.
\end{proof}




% ============================ chapters/homologicallocal.tex}
\chapter{Homological theory of local rings}

We will then apply the general theory to commutative algebra proper. The use
of homological machinery provides a new and elegant characterization of regular local
rings (among noetherian local rings, they are the ones with finite global
dimension) and leads to proofs of several difficult results about them.
For instance, we will be able to prove the rather important result (which one
repeatedly uses in algebraic geometry) that a
regular local ring is a UFD.
As another example, the aforementioned criterion leads to a direct proof of
the otherwise non-obvious that a localization of a regular local ring at a
prime ideal is still a regular local ring.

\textbf{Note: right now, the material on regular local rings is still missing!
It should be added.}

\section{Depth}

In this section, we first introduce the notion of \emph{depth} for local rings
via the $\ext$ functor, and then show that depth can be measured as the length
of a maximal \emph{regular sequence}. After this, we study the theory of
regular sequences in general (on not-necessarily-local rings), and show that
the depth of a module can be bounded in terms of both its dimension and its
associated primes.
\subsection{Depth over local rings}

Throughout, let $(R, \mathfrak{m})$ be  a noetherian
local ring. Let $k = R/\mathfrak{m}$ be the residue field.

Let $M \neq 0$ be a finitely generated $R$-module. We are going to define an
arithmetic invariant of $M$, called the \emph{depth}, that will measure in
some sense the torsion of $M$.

\begin{definition}
The \textbf{depth} of $M$ is equal to the smallest integer $i$
such that
$\ext^i(k,M) \neq 0$. If there is no such integer, we set $\depth M = \infty$.
\end{definition}

We shall give another characterization of this shortly that makes no reference
to $\ext$ functors, and is purely elementary.
We will eventually see that there is always such an $i$ (at least if $M \neq
0$), so $\depth M < \infty$.

\begin{example}[Depth zero] Let us characterize when a module $M$ has depth zero.
Depth zero is equivalent to saying that $\ext^0(k,M) = \hom_R(k, M) \neq 0$,
i.e. that there is a
nontrivial morphism
\[ k \to M.  \]
As $k = R/\mathfrak{m}$, the existence of such a map is
equivalent to the existence of a nonzero $x$
such that $\ann(x) = \mathfrak{m}$, i.e. $\mathfrak{m} \in
\ass(M)$. So depth
zero is equivalent to having $\mathfrak{m} \in \ass(M)$.
\end{example}

Suppose now that $\depth(M) \neq 0$. In particular,
$\mathfrak{m} \notin
\ass(M)$. Since $\ass(M)$ is finite, prime avoidance implies that
$\mathfrak{m}
\not\subset \bigcup_{\mathfrak{p} \in \ass(M)} \mathfrak{p}$.
Thus
$\mathfrak{m}$ contains an element which is a nonzerodivisor on
$M$ (see \cref{assmdichotomy}). So we find:

\begin{proposition} \label{depthzero}
$M$ has depth zero iff every element in $\mathfrak{m}$ is a
zerodivisor on $M$.
\end{proposition}

Now suppose $\depth M \neq 0$. There is $a \in \mathfrak{m}$
which is a
nonzerodivisor on $M$, i.e.  such that there is
an exact sequence
\[ 0 \to M \stackrel{a}{\to} M \to M/aM \to 0.  \]
For each $i$, there is an  exact sequence in $\ext$ groups:
\begin{equation} \label{extlongextdepth}\ext^{i-1}(k,M/aM) \to \ext^i(k,M) \stackrel{a}{\to} \ext^i(k,M)
\to \ext^i(k,
M/aM) \to \ext^{i+1}(k,M)  .\end{equation}
However, the map $a: \ext^i(k,M) \to \ext^i(k,M)$ is zero as
multiplication by $a$
kills $k$. (If $a$ kills a module $N$,
then it kills
$\ext^*(N,M)$ for all $M$.) We see from this that
\[ \ext^i(k,M) \hookrightarrow \ext^i(k,M/aM)  \]
is injective, and
\[ \ext^{i-1}(k, M/aM) \twoheadrightarrow \ext^i(k,M)  \]
is surjective.

\begin{corollary} \label{depthdropsbyone}
If $a \in \mathfrak{m}$ is a nonzerodivisor on $M$, then
\[ \depth(M/aM) = \depth M -1.  \]
\end{corollary}
\begin{proof}
When $\depth M = \infty$, this is easy (left to the reader) from
the exact
sequence. Suppose $\depth(M) = n$. We would like to see that
$\depth M/aM =
n-1$. That is, we want to see that $\ext^{n-1}(k,M/aM) \neq 0$,
but
$\ext^i(k,M/aM) =
0$ for $i < n-1$. This is direct from the sequence \eqref{extlongextdepth} above.
In fact, surjectivity of $\ext^{n-1}(k,M/aM) \to \ext^n(k,M)$
shows that
$\ext^{n-1}(k,M/aM) \neq 0$. Now let $i < n-1$.
Then in \eqref{extlongextdepth}, $\ext^i(k, M/aM)$ is sandwiched between two
zeros, so it is zero.
\end{proof}

The moral of the above discussion is that one quotients out by a nonzerodivisor, the depth drops by one.
In fact, we have described a recursive algorithm for computing
$\depth(M)$.
\begin{enumerate}
\item If $\mathfrak{m}  \in \ass(M)$, output zero.
\item If $\mathfrak{m} \notin \ass(M)$, choose an element $a
\in\mathfrak{m}$
which is a nonzerodivisor on $M$. Output $\depth(M/aM) +1$.
\end{enumerate}


If one wished to apply this in practice, one would probably start by
looking for a
nonzerodivisor $a_1 \in \mathfrak{m}$ on $M$, and then looking for
one on $M/a_1
M$, etc.
From this we make:

\begin{definition}
Let $(R, \mathfrak{m})$ be a local noetherian ring, $M$ a finite
$R$-module. A
sequence $a_1, \dots, a_n \in \mathfrak{m}$ is said to be
\textbf{$M$-regular} iff:
\begin{enumerate}
\item $a_1$ is a nonzerodivisor on $M$
\item $a_2$ is a nonzerodivisor on $M/a_1 M$
\item  $\dots$
\item $a_i$ is a nonzerodivisor on $M/(a_1, \dots, a_{i-1})M$
for all $i$.
\end{enumerate}
A regular sequence $a_1, \dots, a_n$ is \textbf{maximal } if it
can be extended
no further, i.e. there is no $a_{n+1}$ such that $a_1, \dots,
a_{n+1}$ is
$M$-regular.
\end{definition}

We now get the promised ``elementary'' characterization of depth.
\begin{corollary} \label{depthregular}
$\depth(M)$ is the length of every maximal $M$-regular
sequence. In particular,
all $M$-regular sequences have the same length.
\end{corollary}

\begin{proof}
If $a_1, \dots, a_n$ is $M$-regular, then
\[ \depth M/(a_1, \dots, a_i)M = \depth M -i  \]
for each $i$, by an easy induction on $i$ and the \cref{depthdropsbyone}.
From this the result is clear, because depth zero occurs precisely when
$\mathfrak{m}$ is an associated prime (\cref{depthzero}). But it is also clear
that a regular sequence $a_1, \dots, a_n$ is maximal precisely when every
element of $\mathfrak{m}$ acts as a zerodivisor on $M/(a_1, \dots, a_n) M$,
that is, $\mathfrak{m} \in \ass(M/(a_1, \dots, a_n)M)$.
\end{proof}

\begin{remark}
We could \emph{define} the depth via the length of a maximal
$M$-regular sequence.
\end{remark}

Finally, we can bound the depth in terms of the dimension.

\begin{corollary}\label{depthboundlocal} Let $M \neq 0$. Then the depth of $M$ is finite. In fact,
\begin{equation} \label{depthbound} \depth M \leq \dim M.  \end{equation}
\end{corollary}
\begin{proof}
When $\depth M = 0$, the assertion is obvious.
Otherwise,
there is $ a \in \mathfrak{m}$ which is a nonzerodivisor on $M$.
We know that
\[ \depth M/aM = \depth M -1  \]
and (by \cref{dimdropsbyone})
\[ \dim  M/aM = \dim  M -1.  \]
By induction on $\dim M$, we have that $\depth M/aM \leq \dim M/aM$.
From this the
induction step is clear, because $\depth$ and $\dim$ both drop by one after
quotienting.
\end{proof}

Generally, the depth is not the dimension.
\begin{example}
Given any $M$, adding $k$ makes the depth zero: $M \oplus k$
has $\mathfrak{m}$ as an associated prime. But the dimension
 does not
jump to zero just by adding a copy of $k$. If $M$ is a direct sum of pieces of
differing dimensions, then the bound \eqref{depthbound} does not exhibit
equality.
In fact, if $M, M'$ are finitely generated modules, then we have
\[ \depth M \oplus M' = \min \left(\depth M, \depth M' \right),  \]
which follows at once from the definition of depth in terms of
vanishing $\ext$ groups.
\end{example}

\begin{exercise}
Suppose $R$ is a noetherian local ring whose depth (as a module over itself)
is zero. If $R$ is reduced, then $R$ is a field.
\end{exercise}

Finally, we include a result that states that the depth does not depend
on the ring so much as the module.
\begin{proposition}[Depth and change of rings]
Let $(R, \mathfrak{m}) \to (S, \mathfrak{n})$ be a morphism of
noetherian local rings. Suppose $M$ is a finitely generated $S$-module,
which is also finitely generated as an $R$-module. Then
$\depth_R M = \depth_S M$.
\end{proposition}
\begin{proof}
It is clear that we have the inequality $\depth_R M \leq \depth_S M$, by the
interpretation of depth via regular sequences. Let $x_1, \dots, x_n \in R$
be a maximal $M$-sequence. We need to show that it is a maximal $M$-sequence
in $S$ as well. By quotienting, we may replace $M$ with $M/(x_1,\dots, x_n)M$;
we then have to show that if $M$ has depth zero as an $R$-module, it has
depth zero as an $S$-module.

But then $\hom_R(R/\mathfrak{m}, M) \neq 0$. This is a $R$-submodule of
$M$, consisting of elements killed by $\mathfrak{m}$,
and in fact it is a $S$-submodule. We are going to show that $\mathfrak{n}$
annihilates some element of it, which will imply that $\depth_S M = 0$.

To see this, note that $\hom_R(R/\mathfrak{m}, M)$ is artinian as an
$R$-module (as it is killed by $\mathfrak{m}$). As a result, it is an
artinian $S$-module, which means it contains $\mathfrak{n}$ as an
associated prime, proving the claim and the result.
\end{proof}
\subsection{Regular sequences}

In the previous subsection, we defined the notion of \emph{depth} of a
finitely generated module over a noetherian local ring using the $\ext$
functors. We then showed that the depth was the length of a maximal regular
sequence.

Now, although it will not be necessary for the main results in this chapter, we want to generalize this to the case of a non-local ring. Most of the
same arguments go through, though there are some subtle differences. For
instance, regular sequences remain regular under permutation in the local
case, but not in general. Since there will be some repetition, we shall try to
be brief.

We start by generalizing the idea of a regular sequence which is not required
to be contained in the maximal ideal of a local ring.
Let $R$ be a noetherian ring, and $M$ a finitely generated $R$-module.
\begin{definition}
A sequence $x_1, \dots, x_n \in R$ is \textbf{$M$-regular} (or is an
\textbf{$M$-sequence}) if for each $k \leq n$, $x_k$ is a nonzerodivisor on the
$R$-module $M/(x_1, \dots, x_{k-1}) M$ and also $(x_1, \dots, x_n) M \neq M$. 	\end{definition}

So $x_1$ is a nonzerodivisor on $M$, by the first part. That is, the homothety
$M \stackrel{x_1}{\to} M$ is injective.
The last condition is also going to turn out to be necessary for us. In the
previous subsection, it was automatic as $\mathfrak{m}M \neq M$ (unless $M =
0$) by Nakayama's lemma as $M$ was assumed finitely generated.	


The property of being a regular sequence is inherently an inductive one. Note
that $x_1, \dots, x_n$ is a regular sequence on $M$ if and only if $x_1$ is a
zerodivisor on $M$ and $x_2, \dots, x_n$ is an $M/x_1 M$-sequence.


\begin{definition}
If $M$ is an $R$-module and $I \subset R$ an ideal, then we write $\depth_I M$
for the length of the length-maximizing $M$-sequence contained in $I$.
When $R$ is local and $I \subset R$ the maximal ideal, then we just write
$\depth M$ as before.
\end{definition}

While we will in fact have a similar characterization of $\depth$ in terms of
$\ext$, in this section we \emph{define} it via regular sequences.

\begin{example}
The basic example one is supposed to keep in mind is the polynomial ring $R =
R_0[x_1, \dots, x_n]$ and $M = R$. Then the sequence $x_1, \dots, x_n$ is
regular in $R$.
\end{example}

\begin{example}
Let $(R, \mathfrak{m})$ be a regular local ring, and let $x_1, \dots, x_n$ be a
regular system of parameters in $R$ (i.e. a system of generators for
$\mathfrak{m}$ of minimal size). Then we have seen that the
$\left\{x_i\right\}$ form a regular sequence on $R$, in any order. This is
because each quotient $R/(x_1, \dots, x_i)$ is itself regular, hence a domain.
\end{example}

As before, we have a simple characterization of depth zero:
\begin{proposition} Let $R$ be noetherian, $M$ finitely generated.
If $M$ is an $R$-module with $IM \neq M$, then $M$ has depth zero if and only
if $I $ is contained in an element of $\ass(M)$.
\end{proposition}
\begin{proof}
This is analogous to \cref{depthzero}. Note than an ideal consists of
zerodivisors on $M$ if and only if it is contained in an associated prime
(\cref{assmdichotomy}).
\end{proof}

The above proof used \cref{assmdichotomy}, a key fact which will be used
repeatedly in the sequel.
This is one reason the theory of depth works best for finitely generated
modules over noetherian rings.

The first observation to make is that regular sequences are \textit{not}
preserved by permutation. This is one nice characteristic that we would like
but is not satisfied.

\begin{example} Let $k $ be a field.
Consider $R=k[x,y]/((x-1)y, yz)$. Then $x,z$ is a regular sequence on $R$. Indeed,
$x$ is a nonzerodivisor and $R/(x) = k[z]$.  However, $z,
x$ is not a regular sequence because $z$ is a zerodivisor in $R$.
\end{example}

Nonetheless, regular sequences \emph{are} preserved by permutation for local rings under
suitable noetherian hypotheses:
\begin{proposition}
Let $R$ be a noetherian local ring and $M$ a finite $R$-module. Then if $x_1,
\dots, x_n$ is a $M$-sequence contained in the maximal ideal, so is any permutation $x_{\sigma(1)}, \dots,
x_{\sigma(n)}$.
\end{proposition}
\begin{proof}
It is clearly enough to check this for a transposition. Namely, if we have an
$M$-sequence
\[ x_1, \dots, x_i, x_{i+1}, \dots x_n  \]
we would like to check that so is
\[ x_1, \dots, x_{i+1}, x_i, \dots, x_n.  \]
It is here that we use the inductive nature. Namely, all we need to do is check
that
\[ x_{i+1}, x_i, \dots,x_n  \]
is regular on $M/(x_1, \dots,x_{i-1}) M$, since the first part of the sequence
will automatically be regular. Now $x_{i+2}, \dots, x_n$ will automatically be
regular on $M/(x_1, \dots, x_{i+1})M$. So all we need to show is that
$x_{i+1}, x_i$ is regular on $M/(x_1, \dots, x_{i-1})M$.

The moral of the story is that we have reduced to the following lemma.

\begin{lemma}
Let $R$ be a noetherian local ring. Let $N$
be a finite $R$-module and
$a,b \in R$ an $N$-sequence contained in the maximal ideal. Then so is $b,a$.
\end{lemma}
\begin{proof}
We can prove this as follows. First, $a$ will be a nonzerodivisor on $N/bN$.
Indeed, if not then we can write
\[ an = bn'  \]
for some $n,n' \in N$ with $n \notin bN$. But $b$ is a nonzerodivisor on
$N/aN$, which means that $bn' \in aN$ implies $n' \in aN$. Say $n' = an''$. So
$an = ba n''$. As $a$ is a nonzerodivisor on $N$, we see that $n = bn''$. Thus
$n \in bN$, contradiction.
This part has not used the fact that $R$ is local.

Now we claim that $b$ is a nonzerodivisor on $N$. Suppose $n \in N$ and $bn =
0$. Since $b$ is a nonzerodivisor on $N/aN$, we have that $n \in aN$, say $n =
an'$. Thus
\[ b(an') = a(bn') = 0.  \]
The fact that $N \stackrel{a}{\to} N$ is injective implies that $bn' = 0$. So
we can do the same and get $n' = an''$, $n'' = a n^{(3)}, n^{(3)} =a n^{(4)}$, and
so on. It follows that $n$ is a multiple of $a, a^2,a^3, \dots$, and hence in
$\mathfrak{m}^j N$ for each $j$ where $\mathfrak{m} \subset R$ is the maximal
ideal. The Krull intersection theorem now implies that $n = 0$.

Together, these arguments imply that $b,a$ is an $N$-sequence, proving the
lemma.
\end{proof}
The proof of the result is now complete.
\end{proof}


One might wonder what goes wrong, and why permutations do not preserve
regular sequences in general; after all, oftentimes we can reduce results
to their analogs for local rings. Yet the fact that regularity is preserved by
permutations for local rings does not extend to arbitrary rings.
The problem is that regular sequences do \emph{not} localize. Well, they almost
do, but the final condition that $(x_1, \dots, x_n) M \neq M$ doesn't get
preserved.
We can state:

\begin{proposition}
Suppose $x_1, \dots, x_n$ is an $M$-sequence. Let $N$ be a flat $R$-module.
Then if $(x_1, \dots, x_n)M \otimes_R N \neq M \otimes N$, then $x_1, \dots, x_n$
is an $M \otimes_R N$-sequence.
\end{proposition}
\begin{proof}
This is actually very easy now. The fact that $x_i: M/(x_1, \dots, x_{i-1})M
\to M/(x_1, \dots, x_{i-1})M$ is injective is preserved when $M$ is replaced by
$M \otimes_R N$ because the functor $- \otimes_R N$ is exact.
\end{proof}

In particular, it follows that if we have a good reason for supposing that
$(x_1,\dots, x_n) M \otimes N \neq M \otimes N$, then we'll already be
done. For instance, if $N$ is the localization of $R$ at a prime ideal
containing the $x_i$. Then we see that automatically $x_1, \dots, x_n$ is an
$M_{\mathfrak{p}} = M \otimes_R R_{\mathfrak{p}}$-sequence.

Finally, we have an analog of the previous correspondence between depth and
the vanishing of $\ext$. Since the argument is analogous to
\cref{depthregular}, we omit it.
\begin{theorem}
\label{depthextI}
Let $R$ be a ring. Suppose $M$ is an $R$-module and $IM \neq M$.
All maximal $M$-sequences in $I$ have the same length. This length is the
smallest value of $r$ such that $\mathrm{Ext}^r(R/I, M) \neq 0$.
\end{theorem}

\begin{exercise}
Suppose $I$ is an ideal in $R$. Let $M$ be an $R$-module such that $IM \neq
M$. Show that $\depth_I M \geq 2$ if and only if the natural map
\[ M \simeq \hom(R, M) \to \hom(I, M)  \]
is an isomorphism.
\end{exercise}


\subsection{Powers of regular sequences}

Regular sequences don't necessarily behave well with respect to permutation or
localization without additional hypotheses. However, in all cases they behave
well with respect to taking powers. The upshot of this is that the invariant
called \textit{depth} that we will soon introduce is invariant under passing to
the radical.

We shall deduce this from the following easy fact.
\begin{lemma}
Suppose we have an exact sequence of $R$-modules
\[  0 \to M' \to M \to M'' \to 0.  \]
Suppose the sequence $x_1, \dots, x_n \in R$ is $M'$-regular and $M''$-regular.
Then it is $M$-regular.
\end{lemma}
The converse is not true, of course.
\begin{proof}
Morally, this is the snake lemma. For instance, the fact that multiplication by
$x_1$ is injective on $M', M''$ implies by the snake diagram that $M
\stackrel{x_1}{\to} M$ is injective. However, we don't a priori know that a
simple inductive argument on $n$ will work to prove this. The reason is that it needs
to be seen that quotienting each term by $(x_1, \dots, x_{n-1})$ will preserve
exactness. However, a general fact will tell us that this is indeed the case.
See below.

Anyway, this general fact now lets us induct on $n$. If we assume
that $x_1, \dots, x_{n-1}$ is $M$-regular, we need only prove that $x_{n}:
M/(x_1, \dots, x_{n-1})M
\to M/(x_1, \dots, x_{n-1})$ is injective. (It is not surjective or the
sequence would not be $M''$-regular.) But we have the exact sequence by the
next lemma,
\[ 0 \to M'/(x_1 \dots x_{n-1})M' \to M/(x_1 \dots x_{n-1})M \to  M''/(x_1
\dots x_{n-1})M'' \to 0 \]
and the injectivity of $x_n$ on the two ends implies it at the middle by the
snake lemma.
\end{proof}

So we need to prove:
\begin{lemma}
Suppose $0 \to M' \to M \to M'' \to 0$ is a short exact sequence. Let $x_1,
\dots, x_m$ be an $M''$-sequence. Then the sequence
\[ 0 \to M'/(x_1 \dots x_m)M' \to M/(x_1 \dots x_m)M \to   M''/(x_1 \dots
x_m)M'' \to 0\]
is exact as well.
\end{lemma}
One argument here uses the fact that the Tor functors vanish when one has a
regular sequence like this. We can give a direct argument.
\begin{proof}
By induction, this needs only be proved when $m=1$, since we have the recursive
description of regular sequences: in general, $x_2 \dots x_m$ will be regular
on $M''/x_1 M''$.
In any case, we have exactness except possibly at the left as the tensor
product is right-exact. So let $m' \in M'$; suppose $m'$ maps to a multiple of
$x_1$ in $M$. We need to show that $m'$ is a multiple of $x_1$ in $M'$.

Suppose $m'$ maps to $x_1 m$. Then $x_1m$ maps to zero in $M''$, so by regularity $m$
maps to zero in $M''$. Thus $m$ comes from something, $\overline{m}'$, in $M'$. In particular
$m' - x_1 \overline{m}'$ maps to zero in $M$, so it is zero in $M'$. Thus
indeed $m'$ is a multiple of $x_1$ in $M'$.
\end{proof}

With this lemma proved, we can state:
\begin{proposition}
\label{powregseq}
Let $M$ be an $R$-module and $x_1, \dots, x_n$ an $M$-sequence. Then $x_1^{a_1}
,\dots, x_n^{a_n}$ is an $M$-sequence for any $a_1, \dots, a_n \in
\mathbb{Z}_{>0}$.
\end{proposition}

\begin{proof}
We will use:
\begin{lemma}
Suppose $x_1, \dots, x_i, \dots, x_n$ and $x_1, \dots, x_i', \dots, x_n$ are
$M$-sequences for some $M$. Then so is $x_1, \dots, x_i x_i', \dots, x_n$.
\end{lemma}

\begin{proof}
As usual, we can mod out by $(x_1 \dots x_{i-1})$ and thus assume that $i=1$.
We have to show that if $x_1, \dots, x_n$ and $x_1', \dots, x_n$ are
$M$-sequences, then so is $x_1 x_1', \dots, x_n$.

We have an exact sequence
\[ 0 \to x_1 M/x_1 x_1' M \to M/x_1 x_1' M \to  M/x_1  M \to 0.  \]
Now $x_2, \dots, x_n$ is regular  on the last term by assumption, and also on
the first term, which is isomorphic to $M/x_1' M$ as $x_1$ acts as a
nonzerodivisor on $M$. So $x_2, \dots, x_n$ is regular on both ends, and thus
in the middle. This means that
\[ x_1 x_1', \dots, x_n  \]
is $M$-regular. That proves the lemma.
\end{proof}

So we now can prove the proposition. It is trivial if $\sum a_i = n$ (i.e. if
all are $1$) it is clear. In general, we can use complete induction on $\sum
a_i$. Suppose we know the result for smaller values of $\sum a_i$. We can
assume that some $a_j >1$.
Then  the sequence
\[ x_1^{a_1}, \dots x_j^{a_j} , \dots x_n^{a_n} \]
is obtained from the sequences
\[  x_1^{a_1}, \dots,x_j^{a_j - 1}, \dots, x_n^{a_n} \]
and
\[  x_1^{a_1}, \dots,x_j^{1}, \dots, x_n^{a_n} \]
by multiplying the middle terms. But the complete induction hypothesis implies
that both those two sequences are $M$-regular, so we can apply the lemma.
\end{proof}

In general, the product of two regular sequences is not a regular sequence. For
instance, consider a regular sequence $x,y$ in some finitely generated module $M$ over a
noetherian local ring. Then $y,x$ is regular, but the product sequence $xy, xy$
is \emph{never} regular.


\subsection{Depth}

We make the following definition slightly differently than in the local case:

\begin{definition}
Suppose $I$ is an ideal such that $IM \neq M$. Then we define the
\textbf{$I$-depth of $M$} to be the maximum length of a maximal $M$-sequence contained
in $I$. When $R$ is a local ring and $I$ the maximal ideal, then that number is
simply called the \textbf{depth} of $M$.

The \textbf{depth} of a proper ideal $I \subset R$ is its depth on $R$.
\end{definition}


The definition is slightly awkward, but it turns out that all maximal
$M$-sequences in $I$ have the same length, as we saw in \cref{depthextI}. So we can use any of them to compute
the depth.

The first thing we can prove using the above machinery is that depth is really
a ``geometric'' invariant, in that it depends only on the radical of $I$.

\begin{proposition}
Let $R$ be a ring, $I \subset R$ an ideal, and $M$ an $R$-module
with $IM \neq M$. Then $\mathrm{depth}_I M = \mathrm{depth}_{\mathrm{Rad}(I)} M$.
\end{proposition}
\begin{proof}
The inequality $\mathrm{depth}_I M \leq \mathrm{depth}_{\mathrm{Rad} I} M$ is trivial, so we need only
show that if $x_1, \dots, x_n$ is an $M$-sequence in $\mathrm{Rad}(I)$, then there is
an $M$-sequence of length $n$ in $I$. For this we just take a high power
\[ x_1^N, \dots, x_n^{N}  \]
where $N$ is large enough such that everything is in $I$. We can do this as
powers of $M$-sequences are $M$-sequences (\cref{powregseq}).
\end{proof}

This was a fairly easy consequence of the above result on powers of regular
sequences. On the other hand, we want to give another proof, because it will
let us do more. Namely, we will show that depth is really a function of prime
ideals.

For convenience, we set the following condition: if $IM = M$, we define
\[ \mathrm{depth}_I (M) = \infty.  \]

\begin{proposition} \label{depthlocal}
Let $R$ be a noetherian ring, $I \subset R$ an ideal, and $M$ a finitely generated $R$-module.
Then
\[ \mathrm{depth}_I M = \min_{\mathfrak{p} \in V(I)} \mathrm{depth}_{\mathfrak{p}} M .  \]
\end{proposition}

So the depth of $I$ on $M$ can be calculated  from the depths at each
prime containing $I$. In this sense, it is clear that $\mathrm{depth}_I (M)$ depends
only on $V(I)$ (and the depths on those primes), so clearly it depends only on
$I$ \emph{up to radical}.

\begin{proof}
In this proof, we shall {use the fact that the length of every maximal
$M$-sequence is the same} (\cref{depthextI}).

It is obvious that we have an inequality
\[ \mathrm{depth}_I \leq  \min_{\mathfrak{p} \in V(I)} \mathrm{depth}_{\mathfrak{p}} M \]
as each of those primes contains $I$.
We are to prove that there is
a prime $\mathfrak{p}$ containing $I$ with
\[ \mathrm{depth}_I M = \mathrm{depth}_{\mathfrak{p}} M . \]
But we shall actually prove the stronger statement that there is $\mathfrak{p}
\supset I$ with $\mathrm{depth}_{\mathfrak{p}} M_{\mathfrak{p}} = \mathrm{depth}_I M$. Note
that localization at a prime can only increase depth because an $M$-sequence in
$\mathfrak{p}$ leads to an $M$-sequence in $M_{\mathfrak{p}}$ thanks to
Nakayama's lemma and the flatness of localization.

So let $x_1, \dots, x_n \in I$ be a $M$-sequence of maximum length. Then $I$
acts by zerodivisors on
$M/(x_1 , \dots, x_n) M$ or we could extend the sequence further.
In particular, $I$ is contained in an associated prime of $M/(x_1, \dots, x_n)
M$ by elementary commutative algebra (basically, prime avoidance).

Call this associated prime $\mathfrak{p} \in V(I)$. Then $\mathfrak{p}$ is an
associated prime of $M_{\mathfrak{p}}/(x_1, \dots, x_n) M_{\mathfrak{p}}$,
and in particular acts only by zerodivisors on this module.
Thus the $M_{\mathfrak{p}}$-sequence $x_1, \dots, x_n$ can be extended no
further in $\mathfrak{p}$. In particular, since  the depth
can be computed as the length of \emph{any} maximal $M_{\mathfrak{p}}$-sequence,
\[ \mathrm{depth}_{\mathfrak{p}} M_{\mathfrak{p}} = \mathrm{depth}_I M. \]
\end{proof}

Perhaps we should note a corollary of the argument above:
\begin{corollary} \label{depthlocal2}
Hypotheses as above, we have $\mathrm{depth}_I M  \leq \mathrm{depth}_\mathfrak{p} M_{\mathfrak{p}}$ for
any prime $\mathfrak{p} \supset I$. However, there is at least one $\mathfrak{p}
\supset I$ where equality holds. \end{corollary}

We are thus reduced to analyzing depth in the local case.

\begin{exercise}
\label{exer:depthcompletion}
If $(R, \mathfrak{m})$ is a local noetherian ring and $M$ a finitely
generated $R$-module, then show that $\depth M = \depth_{\hat{R}} \hat{M}$,
where $\hat{M}$ is the $\mathfrak{m}$-adic completion. (Hint: use $\hat{M}= M
\otimes_R \hat{R}$, and the fact that $\hat{R}$ is flat over $R$.)
\end{exercise}
\subsection{Depth and dimension}

Consider an $R$-module $M$, which is always assumed to be finitely generated.
Let $I \subset R$ be an ideal with $IM \neq M$.
We deduce from the previous subsections:
\begin{proposition}
Let $M$ be a finitely generated module over the noetherian ring $R$. Then
\[ \mathrm{depth}_I M \leq \dim M  \]
for any ideal $I \subset R$ with $IM \neq M$.
\end{proposition}
\begin{proof}
We have proved this when $R$ is a \emph{local}  ring
(\cref{depthboundlocal}). Now we just use \cref{depthlocal2} to reduce to the
local case.
\end{proof}

This does not tell us much about how $\mathrm{depth}_I M$ depends on $I$, though; it
just says something about how it depends on $M$. In particular, it is not very
helpful when trying to estimate $\mathrm{depth} I = \mathrm{depth}_I R$.
Nonetheless, there is a somewhat stronger result, which we will need in the
future.
We start by stating the version in the local case.

\begin{proposition} \label{localdepthassbound}
Let $(R,\mathfrak{m})$ be a noetherian local ring. Let $M$ be a finite
$R$-module. Then the depth of $\mathfrak{m}$ on $M$ is at most the dimension of
$R/\mathfrak{p}$ for $\mathfrak{p}$ an associated prime of $M$:
\[ \depth M \leq \min_{\mathfrak{p} \in \ass(M)}\dim R/\mathfrak{p}.  \]
\end{proposition}

This is sharper than the bound $\depth M \leq \dim M$, because each $\dim
R/\mathfrak{p}$ is at most $\dim M$ (by definition).
\begin{proof}
To prove this, first assume that the depth is zero. In that case, the result is
immediate. We shall now argue inductively.
Assume that that this is true for modules of smaller depth.
We will quotient out appropriately to shrink the
support and change the associated
primes. Namely, choose a $M$-regular (nonzerodivisor on $M$) $x \in R$.
Then $\mathrm{depth} M/xM = \mathrm{depth} M -1$.

Let $\mathfrak{p}_0$ be an associated prime of $M$.
We  claim that $\mathfrak{p}_0$ is \emph{properly} contained in an associated prime of
$M/xM$.
We will prove this below.
Thus $\mathfrak{p}_0$ is properly contained in some $\mathfrak{q}_0 \in
\ass(M/xM)$.

Now we know that $\mathrm{depth} M/xM = \mathrm{depth} M -1$. Also, by the inductive
hypothesis, we know that $\dim R/\mathfrak{q}_0 \geq \mathrm{depth} M/xM = \mathrm{depth} M
-1$. But the dimension of $R/\mathfrak{q}_0$ is strictly smaller than that of
$R/\mathfrak{p}_0$, so at least $\dim R/\mathfrak{p}_0 +1 \geq \mathrm{depth} M$. This
proves the lemma, modulo the result:

\begin{lemma} \label{screwylemmaonquotientassprime}
Let $(R, \mathfrak{m})$ be a noetherian local ring. Let $M$ be a finitely
generated $R$-module, $x \in \mathfrak{m}$ an $M$-regular element.
Then each element of $\ass(M)$ is properly contained in an element of
$\ass(M/xM)$.
\end{lemma}
So if we quotient by a regular element, we can make the associated primes jump
up.
\begin{proof} Let $\mathfrak{p}_0 \in \ass(M)$; we want to show
$\mathfrak{p}_0$ is properly contained in something in $\ass(M/xM)$.

Indeed, $x \notin \mathfrak{p}_0$, so $\mathfrak{p}_0$ cannot itself be
an associated prime.
However, $\mathfrak{p}_0$ annihilates a nonzero element of $M/xM$. To see this,
consider a maximal principal submodule of $M$ annihilated by $\mathfrak{p}_0$.
Let this submodule be $Rz$ for some $z \in M$. Then if $z$ is a multiple of
$x$, say $z = xz'$, then $Rz'$ would be a larger
submodule of $M$ annihilated by $\mathfrak{p}_0$---here we are using the fact
that $x$ is a nonzerodivisor on $M$. So the image of this $z$ in $M/xM$ is
nonzero and is clearly annihilated by $\mathfrak{p}_0$.
It follows $\mathfrak{p}_0$ is contained in an element of
$\ass(M/xM)$, necessarily properly.
\end{proof}

\end{proof}
\begin{exercise}
Another argument  for \cref{screwylemmaonquotientassprime} is given in \S 16 of \cite{EGA}, vol. IV, by reducing to
the coprimary case. Here is a sketch.

The strategy is to use the existence of an exact sequence
\[ 0 \to M' \to M \to M'' \to 0  \]
with $\ass(M'') = \ass(M) - \left\{\mathfrak{p}_0\right\}$ and
$\ass(M') = \left\{\mathfrak{p}_0\right\}$.
Quotienting by $x$ preserves exactness, and we get
\[ 0 \to M'/xM' \to M/xM \to M''/xM'' \to 0.  \]
Now $\mathfrak{p}_0$ is properly contained in every associated prime of
$M'/xM'$ (as it acts nilpotently on $M'$). It follows that any element of
$\ass(M'/xM') \subset \ass(M/xM)$ will do the job.

In essence, the point is that the result is \emph{trivial} when $\ass(M)
= \left\{\mathfrak{p}_0\right\}$.
\end{exercise}

\begin{exercise}
Here is a simpler argument for \cref{screwylemmaonquotientassprime},
following \cite{Se65}.
Let $\mathfrak{p}_0 \in \ass(M)$, as before. Again as before, we want  to show that
$\hom_R(R/\mathfrak{p}_0, M/xM) \neq 0$.
But we have an exact sequence
\[ 0 \to \hom_R(R/\mathfrak{p}_0, M)
\stackrel{x}{\to} \hom_R(R/\mathfrak{p}_0, M) \to
\hom_R(R/\mathfrak{p}_0, M/xM) ,
\]
and since the first map is not surjective (by Nakayama), the last
object is nonzero.
\end{exercise}

Finally, we can globalize the results:

\begin{proposition}
Let $R$ be a noetherian ring, $I \subset R$ an ideal, and $M$ a finitely
generated module. Then $\mathrm{depth}_I M$ is at most the length of every  chain
of primes in $\mathrm{Spec} R$ that starts at an associated prime of $M$ and
ends at a prime containing $I$.
\end{proposition}

\begin{proof} Currently omitted.
\begin{comment}
Consider a chain of primes $\mathfrak{p}_0 \subset \dots \subset
\mathfrak{p}_k$ where $\mathfrak{p}_0$ is an associated prime and
$\mathfrak{p}_k$ contains $I$.
The goal is to show that
\[  \mathrm{depth}_I M \leq k .  \]
By localization, we can assume that $\mathfrak{p}_k$ is the maximal ideal of
$R$; recall that localization can only increase the depth.
We can also assume $I$ is this maximal ideal, by increasing it.

In this case, the result follows from the local version
(\cref{localdepthassbound}).
\end{comment}
\end{proof}


\section{Cohen-Macaulayness}

\subsection{Cohen-Macaualay modules over a local ring}
For a local noetherian ring, we have discussed two invariants of a module:
dimension and depth. They generally do not coincide, and Cohen-Macaulay
modules will be those where they do.

Let $(R, \mathfrak{m})$ be a noetherian local ring.
\begin{definition}
A finitely generated $R$-module $M$ is \textbf{Cohen-Macaulay} if $\depth M =
\dim M$. The ring $R$ is called \textbf{Cohen-Macaulay} if it is
Cohen-Macaulay as a module over itself.
\end{definition}

We already know that the inequality $\leq$ always holds.
If there is a system of parameters for $M$ (i.e., a sequence $x_1, \dots, x_r
\in \mathfrak{m}$ such that $M/(x_1, \dots, x_r) M$ is artinian) which is a
regular sequence on $M$, then $M$ is Cohen-Macaulay: we see in fact that
$\dim M  = \depth M = r$.
This is the distinguishing trait of Cohen-Macaulay rings.

Let us now give a few examples:

\begin{example}[Regular local rings are Cohen-Macaulay]
If $R$ is regular, then $\depth R = \dim R$, so $R$ is Cohen-Macaulay.

Indeed, we have seen that if $x_1, \dots, x_n$ is a regular system of parameters
for $R$ (i.e. a minimal set of generators for $\mathfrak{m}$), then $n
= \dim R$ and the $\left\{x_i\right\}$ form a regular sequence. See the remark
after \cref{quotientreg44}; the point is that $R/(x_1, \dots, x_{i-1})$ is
regular for each $i$ (by the aforementioned corollary), and hence a
domain, so $x_i$
acts on it by a nonzerodivisor.
\end{example}

The next example easily shows that a Cohen-Macaulay ring need not be
regular, or even a domain:
\begin{example}[Local artinian rings are Cohen-Macaulay]
Any local
artinian ring, because the dimension is zero for an artinian
ring.
\end{example}


\begin{example}[Cohen-Macaulayness and completion]
A finitely generated module $M$ is Cohen-Macaulay if and only if its
completion $\hat{M}$ is; this follows from \cref{exer:depthcompletion}.
\end{example}

Here is a slightly harder example.
\begin{example}
A normal local domain $(R, \mathfrak{m})$ of dimension 2 is Cohen-Macaulay. This is a special case
of Serre's criterion for normality.

Here is an argument. If $x \in \mathfrak{m}$ is nonzero, we want to
show that $\depth R/(x) = 1$.
To do this, we need to show that $\mathfrak{m} \notin \ass(R/(x))$ for
each such $x$, because then $\depth R/(x) \geq 1$ (which is all we need).
However, suppose the contrary; then there is $y$ not divisible by $x$ such
that $\mathfrak{m}y \subset (x)$.
So $y/x \notin R$, but $\mathfrak{m} (y/x) \subset R$.

This, however, implies $\mathfrak{m}$ is principal. Indeed, we either have
$\mathfrak{m}(y/x) = R$, in which case  $\mathfrak{m}$ is generated by $x/y$,
or $\mathfrak{m}(y/x) \subset \mathfrak{m}$. The latter would imply
that $y/x$ is integral over $R$ (as multiplication by it stabilizes a
finitely generated $R$-module), and by normality $y/x \in R$. We have seen
much of this argument before.
\end{example}

\begin{example}
Consider $\mathbb{C}[x,y]/(xy)$, the coordinate ring of the
union of two axes
intersecting at the origin. This is not
regular, as its localization at the origin
is not a domain.
We will later show that this is a Cohen-Macaulay ring, though.
\begin{comment}
Indeed, we can project the associated variety
$X = V(xy)$
onto the affine line by adding the coordinates. This corresponds
to the map
\[ \mathbb{C}[z] \to \mathbb{C}[x,y]/(xy)  \]
sending $z \to x+y$. This makes $\mathbb{C}[x,y]/(xy)$ into a
free
$\mathbb{C}[z]$-module of rank two (with generators $1, x$), as
one can check.
So by the previous result (strictly speaking, its extension to
non-domains),
the ring in question is Cohen-Macaulay.
\end{comment}
\end{example}

\begin{example}
$R=\mathbb{C}[x,y,z]/(xy, xz)$ is not Cohen-Macaulay (at the
origin). The associated variety looks
geometrically like the union of the plane $x=0$ and the line
$y=z=0$ in affine
3-space. Here there are two components of different dimensions
intersecting.
Let's choose a regular sequence (that is, regular after
localization at the
origin). The dimension at the origin is clearly two because of
the plane.
First, we need a nonzerodivisor in this ring, which vanishes at
the origin, say
$ x+y+z$. (Check this.) When we quotient by
this, we get
\[ S=\mathbb{C}[x,y,z]/(xy,xz, x+y+z) = \mathbb{C}[y,z]/(
(y+z)y, (y+z)z). \]

The claim is that $S$ localized at the ideal corresponding to
$(0,0)$ has depth
zero. We have $y+z \neq 0$, which is killed by both $y,z$, and
hence by the
maximal ideal at zero. In particular the maximal ideal at zero
is an associated
prime, which implies the claim about the depth.
\end{example}

As it happens, a Cohen-Macaulay variety is always
equidimensional. The rough
reason is that each irreducible piece puts an upper bound on the
depth given by
the dimension of the piece. If any piece is too small, the total
depth will be
too small.


Here is the deeper statement:

\begin{proposition} \label{dimthing}
Let $(R, \mathfrak{m})$ be a noetherian local ring, $M$ a finitely generated,
Cohen-Macaulay $R$-module.
Then:
\begin{enumerate}
\item For each $\mathfrak{p}  \in \ass(M)$, we have $\dim M = \dim
R/\mathfrak{p}$.
\item Every associated prime of $M$ is minimal (i.e. minimal in $\supp M$).
\item  $\supp M$ is equidimensional.
\end{enumerate}
\end{proposition}
In general, there may be nontrivial inclusion relations among the
associated primes of a general module. However, this cannot happen for a Cohen-Macaulay
module.
\begin{proof}
The first statement implies all the others. (Recall that
\emph{equidimensional} means that all the irreducible components of $\supp
M$, i.e. the $\spec R/\mathfrak{p}$, have the same dimension.)
But this in turn follows from the bound of  \cref{localdepthassbound}.
\end{proof}

Next, we would like to obtain a criterion for when a quotient of a
Cohen-Macaulay module is still Cohen-Macaulay.
The answer will be similar to \cref{quotientreg} for regular local rings.

\begin{proposition} \label{quotientCM}
Let $M$ be a Cohen-Macaulay module over the local noetherian ring $(R,
\mathfrak{m})$. If $x_1, \dots, x_n \in \mathfrak{m}$ is a $M$-regular
sequence, then $M/(x_1, \dots, x_n)M$ is Cohen-Macaulay of dimension (and
depth) $\dim M - n$.
\end{proposition}
\begin{proof}
Indeed, we reduce to the case $n=1$ by induction.
But then, because $x_1$ is a nonzerodivisor on $M$, we have $\dim
M/x_1 M = \dim M -1$ and $\depth M/x_1 M = \depth M -1$. Thus
\[ \dim M/x_1 M = \depth M/x_1M.  \]
\end{proof}

So, if we are given a Cohen-Macaulay module $M$ and want one of a smaller
dimension, we just have to find $x \in \mathfrak{m}$ not contained in any of
the minimal primes of $\supp M$ (these are the only associated primes). Then,
$M/xM$ will do the job.

\subsection{The non-local case}

More generally, we would like to make the definition:
\begin{definition} \label{generalCM}
 A general noetherian ring $R$ is
\textbf{Cohen-Macaulay} if
$R_{\mathfrak{p}}$ is Cohen-Macaulay for all $\mathfrak{p} \in
\spec R$.
\end{definition}

We should check that these definitions coincide for a local noetherian ring.
This, however, is not entirely obvious; we have to show that localization
preserves Cohen-Macaulayness.
In this subsection, we shall do that, and we shall furthermore show that Cohen-Macaulay rings are \emph{catenary}, or
more generally that Cohen-Macaulay modules are catenary. (So far we have
seen that they are equidimensional, in the local case.)


We shall deduce this from the following result, which states that for a
Cohen-Macaulay module, we can choose partial systems of parameters in any
given prime ideal in the support.

\begin{proposition} \label{CMintermediatep}
Let $M$ be a Cohen-Macaulay module over the local noetherian ring $(R,
\mathfrak{m})$, and let $\mathfrak{p} \in \supp M$.
Let $x_1, \dots, x_r \in \mathfrak{p}$ be a maximal $M$-sequence contained in
$\mathfrak{p}$. Then:
\begin{enumerate}
\item $\mathfrak{p}$ is an associated and minimal prime of $M/(x_1, \dots, x_r)M$.
\item $\dim R/\mathfrak{p} = \dim M -r$
\end{enumerate}
\end{proposition}
\begin{proof}
We know (\cref{quotientCM}) that $M/(x_1, \dots, x_r)M$ is a Cohen-Macaulay module too.
Clearly $\mathfrak{p}$ is in its support, since all the $x_i \in
\mathfrak{p}$.
The claim is that $\mathfrak{p}$ is an associated prime---or minimal prime, it
is the same thing---of $M/(x_1, \dots, x_r)M$. If not, there is $x \in
\mathfrak{p}$ that is a nonzerodivisor on this quotient, which means that
$\left\{x_1, \dots, x_r\right\}$ was not maximal as claimed.

Now we need to verify the assertion on the dimension. Clearly $\dim M/(x_1,
\dots, x_r)M = \dim M - r$, and moreover $\dim R/\mathfrak{p} =
\dim M/(x_1, \dots, x_r)$ by \cref{dimthing}. Combining these gives
the second assertion.
\end{proof}

\begin{corollary} \label{CMloc}
Hypotheses as above,
 $\dim M_{\mathfrak{p}}  = r = \dim M - \dim R/\mathfrak{p} $.
Moreover, $M_{\mathfrak{p}}$ is a Cohen-Macaulay module over
$R_{\mathfrak{p}}$.
\end{corollary}
This result shows that \cref{generalCM} is a reasonable definition.
\begin{proof}
Indeed, if we consider the conclusions of \cref{intermediatep}, we find that
$x_1, \dots, x_r$ becomes a system of parameters for $M_{\mathfrak{p}}$: we
have that $M_{\mathfrak{p}}/(x_1, \dots, x_r)M_{\mathfrak{p}}$ is an
artinian $R_{\mathfrak{p}}$-module, while the sequence is also regular. The
first claim follows, as does the second: any module with a system of
parameters that is a regular sequence is Cohen-Macaulay.
\end{proof}

As a result, we can get the promised result that a Cohen-Macaulay ring is
catenary.
\begin{proposition}
If $M$ is Cohen-Macaulay over the local noetherian ring $R$, then $\supp M$ is a catenary space.
\end{proposition}

In other words, if $\mathfrak{p} \subset \mathfrak{q}$ are elements of
$\supp M$, then every maximal chain of prime ideals from $\mathfrak{p}$ to
$\mathfrak{q}$ has the same length.
\begin{proof}
We will show that
\( \dim R/\mathfrak{p} = \dim R/\mathfrak{q} + \dim
R_{\mathfrak{q}}/\mathfrak{p} R_{\mathfrak{q}}, \) a claim that
suffices to establish catenariness.
We will do this by using the dimension formulas computed earlier.

Namely, we know that
$M$ is catenary over $R$, so  by \cref{CMloc}
\[ \dim_{R_{\mathfrak{q}}} M_{\mathfrak{q}} = \dim M - \dim
R/\mathfrak{q}, \quad
\dim_{ R_{\mathfrak{p}}} M_{\mathfrak{p}} = \dim M - \dim R/\mathfrak{p}.
\]
Moreover, $M_{\mathfrak{q}} $ is Cohen-Macaulay over
$R_{\mathfrak{q}}$. As a result, we have (in view of the previous equation)
\[ \dim_{R_{\mathfrak{p}}}
M_{\mathfrak{p}} = \dim_{R_{\mathfrak{q}}} M_{\mathfrak{q}} - \dim
R_{\mathfrak{q}}/\mathfrak{p}R_{\mathfrak{q}} =
\dim M - \dim R/\mathfrak{q} - \dim
R_{\mathfrak{q}}/\mathfrak{p}R_{\mathfrak{q}}
.  \]
Combining, we find
\[ \dim M - \dim R/\mathfrak{p} =  \dim M - \dim R/\mathfrak{q} - \dim
R_{\mathfrak{q}}/\mathfrak{p}R_{\mathfrak{q}} ,
 \]
which is what we wanted.
\end{proof}

It thus follows that any Cohen-Macaulay ring, and thus any \emph{quotient} of a
Cohen-Macaualay ring, is catenary. In particular, it follows any non-catenary
local noetherian ring cannot be expressed as a quotient of a
Cohen-Macaulay (e.g. regular) local ring.

It also follows immediately that if $R$ is any regular (not necessarily local)
ring, then $R$ is catenary, and the same goes for any quotient of $R$.
In particular, since a polynomial ring over a field is regular, we find:
\begin{proposition}
Any affine ring is catenary.
\end{proposition}

\subsection{Reformulation of Serre's criterion}

Much earlier, we proved criteria for a noetherian ring to be reduced and (more
interestingly) normal.
We can state them more cleanly using the theory of depth developed.

\begin{definition}
Let $R$ be a noetherian ring, and let $k \in \mathbb{Z}_{\geq 0}$.
\begin{enumerate}
\item We say that $R$ satisfies \textbf{condition $R_k$} if, for every
prime ideal $\mathfrak{p} \in \spec R$ with $\dim R_{\mathfrak{p}} \leq k$,
the local ring $R_{\mathfrak{p}}$ is regular.
\item $R$ satisfies \textbf{condition $S_k$} if $\depth R_{\mathfrak{p}} \geq
\inf(k, \dim R_{\mathfrak{p}})$ for all $\mathfrak{p} \in \spec R$.
\end{enumerate}
\end{definition}

A Cohen-Macaulay ring satisfies all the conditions $S_k$, and conversely. The
condition $R_k$ means geometrically that the associated variety
is regular (i.e., smooth, at least if one works over an algebraically closed
field) outside a subvariety of codimension $\geq k$.



Recall that, according to \cref{reducedcrit1}, a noetherian ring is \textit{reduced} iff:
\begin{enumerate}
\item For any minimal prime $\mathfrak{p} \subset R$,
$R_{\mathfrak{p}}$ is a
field.
\item Every associated prime of $R$ is minimal.
\end{enumerate}

Condition 1 can be restated as follows. The ideal
$\mathfrak{p}\subset R$ is
minimal if and only if it is zero-dimensional, and $R_{\mathfrak{p}}$  is
regular if and only if it is a
field. So the first condition is that \emph{for every height
zero prime,
$R_{\mathfrak{p}}$ is regular.}
In other words, it is the condition $R_0$.

For the second condition,
$\mathfrak{p} \in
\ass(R)$ iff $\mathfrak{p} \in \ass(R_{\mathfrak{p}})$, which is
equivalent to
$\depth R_{\mathfrak{p}} = 0$. So the second condition states that for primes
$\mathfrak{p} \in \spec R$ of height at least 1, $\mathfrak{p} \notin
\ass(R_{\mathfrak{p}})$, or $\depth(R_{\mathfrak{p}}) \geq 1$. This
is the condition $S_1$.

We find:
\begin{proposition}
A noetherian ring is reduced if and only if it satisfies $R_0$ and $S_1$.
\end{proposition}

In particular, for a Cohen-Macaulay ring, checking if it is reduced is
easy; one just has to check $R_0$ (if the localizations at minimal primes are
reduced).


Serre's criterion for normality is in the same spirit, but harder.
Recall that
a noetherian ring is \textit{normal} if it is a finite direct
product of
integrally closed domains.

The earlier form of Serre's criterion (see \cref{serrecrit1}) was:
\begin{proposition}
Let $R$ be a local ring.
Then $R$ is normal iff
\begin{enumerate}
\item  $R$ is reduced.
\item For every height one prime $\mathfrak{p}  \in \spec R$,
$R_{\mathfrak{p}}$ is a DVR (i.e. regular).
\item For every nonzerodivisor $x \in R$, every associated prime
of $R/(x)$ is
minimal.
\end{enumerate}
\end{proposition}
In view of the criterion for reducedness, these conditions are equivalent to:
\begin{enumerate}
\item For every prime $\mathfrak{p}$ of height $\leq 1$,
$R_{\mathfrak{p}} $ is regular.
\item For every prime $\mathfrak{p}$ of height $\geq 1$,
$\depth R_{\mathfrak{p}} \geq 1$ (necessary for reducedness)
\item $\depth R_{\mathfrak{p}} \geq 2$ for $\mathfrak{p}$ containing but not
minimal over any
principal ideal $(x)$ for $x$ a nonzerodivisor. This
is the last
condition of the proposition; to say $\depth R_{\mathfrak{p}} \geq 2$ is to
say that $\depth R_{\mathfrak{p}}/(x)R_{\mathfrak{p}} \geq 1$, or
$\mathfrak{p} \notin
\ass(R_{\mathfrak{p}}/(x)R_{\mathfrak{p}})$.
\end{enumerate}

Combining all this, we find:
\begin{theorem}[Serre's criterion] A noetherian ring is normal
if and only if it satisfies the conditions $R_1$ and $S_2$.
\end{theorem}

Again, for a Cohen-Macaulay ring, the last condition is automatic, as
the depth is the
codimension.

\section{Projective dimension and free resolutions}

We shall introduce the notion of \emph{projective dimension} of a module; this
will be the smallest projective resolution it admits (if there is none such,
the dimension is $\infty$). We can think of it as measuring how far a module is
from being projective. Over a noetherian \emph{local} ring, we will show that
the projective dimension can be calculated very simply using the $\tor$ functor
(which is an elaboration of the story that a projective module over a local
ring is free).

Ultimately we want to show that a noetherian local ring is regular if and only
if every finitely generated module admits a finite free resolution. Although we
shall not get to that result until the next section, we will at least relate
projective dimension to a more familiar invariant of a module: \emph{depth.}

\subsection{Introduction}
\newcommand{\pr}{\mathrm{pd}}
Let $R$ be a commutative ring, $M$ an $R$-module.

\begin{definition}
The \textbf{projective dimension} of $M$ is the largest integer
$n$ such that
there exists  a module $N$ with
\[ \ext^n(M,N) \neq 0.  \]
We allow $\infty$, if arbitrarily large such $n$ exist.
We write $\pr(M)$ for the projective dimension. For convenience, we set $\pr(0)
= - \infty$.
\end{definition}

So, if $m> n = \pr(M)$, then we have $\ext^m(M, N) = 0$ for \emph{all} modules $N$, and
$n$ is the smallest integer with this property.
As an example, note that $\pr(M) = 0$ if and only if $M$ is projective and
nonzero. Indeed, we have seen that
the $\ext$ groups
$\ext^i(M,N), i >0$
vanish always for $M$ projective, and conversely.

To compute $\pr(M)$ in general, one can proceed as follows.
Take any $M$. Choose a surjection $P \twoheadrightarrow M$ with
$P$ projective;
call the kernel $K$ and draw a short exact sequence
\[ 0 \to K \to P \to M \to 0.  \]
For any $R$-module $N$, we have a long exact sequence
\[ \ext^{i-1}(P,N) \to \ext^{i-1}(K,N) \to \ext^i(M,N) \to
\ext^i(P, N). \]
If $i >0$, the right end vanishes; if $i >1$, the left end
vanishes. So if $i
>1$, this map $\ext^{i-1}(K,N) \to \ext^i(M,N)$ is an
\emph{isomorphism}.

Suppose that $\pr(K) = d \geq 0$. We find that
$\ext^{i-1}(K,N)=0$ for $i-1
> d$.
This implies that $\ext^i(M,N) = 0$ for such $i > d+1$. In
particular, $\pr(M)
\leq d+1$.
This argument is completely reversible if $d >0$.
Then we see from these isomorphisms that
\begin{equation} \label{pdeq} \boxed{\pr(M) = \pr(K)+1}, \quad \mathrm{unless} \ \pr(M)=0
\end{equation}
If $M$ is projective, the sequence $0 \to K \to P \to M \to 0$
splits, and
$\pr(K)=0$ too.

The upshot is that {we can compute projective dimension
by choosing a
projective resolution.}
\begin{proposition}\label{pdprojectiveresolution}
Let $M$ be an $R$-module. Then $\pr(M) \leq n$ iff there exists
a finite
projective resolution of $M$ having $n+1$ terms,
\[ 0 \to P_n \to \dots \to P_1 \to P_0 \to M \to 0.  \]
\end{proposition}
\begin{proof}
Induction on $n$. When $n = 0$, $M$ is projective, and we can
use the
resolution $0 \to M \to M \to 0$.

Suppose $\pr(M) \leq n$, where $n >0$. We can get a short exact
sequence
\[ 0 \to K \to P_0 \to M \to 0  \]
with $P_0$ projective, so $\pr(K) \leq n-1$ by \eqref{pdeq}. The inductive
hypothesis implies
that there is a projective resolution of $K$ of length $\leq
n-1$. We can
splice this in with the short exact sequence to get a projective
resolution of
$M$ of length $n$.

The argument is reversible. Choose any projective resolution
\[  0 \to P_n \to \dots \to P_1 \to P_0 \to M \to 0 \]
and split into short exact sequences, and then one argue inductively to show
that $\pr(M) \leq n$.
\end{proof}

Let $\pr(M) = n$. Choose any projective resolution $\dots \to P_2 \to P_1 \to P_0 \to M$. Choose $K_i = \ker(P_i \to P_{i-1})$ for each $i$.  Then there is a short exact sequence $0 \to K_0 \to P_0 \to M
\to 0$. Moreover,
there are exact sequences
\[ 0 \to K_i \to P_i \to K_{i-1} \to 0  \]
for each $i$. From these, and from \eqref{pdeq}, we see that the projective dimensions
of the $K_i$
drop by one as $i$ increments. So $K_{n-1}$ is projective if
$\pr(M) = n$ as
$\pr(K_{n-1})=0$. In particular, we can get a projective
resolution
\[ 0 \to K_{n-1} \to P_{n-1} \to \dots \to P_0 \to M \to 0  \]
which is of length $n$.
In particular, if one has a (possibly infinite) projective resolution $M$, one can stop after going out $n$ terms, because the kernels
will become
projective. In other words, the projective resolution can be made to
\emph{break off} at the $n$th term.
This applies to \emph{any} projective resolution.
Conversely, since any module has a (possibly infinite) projective resolution,
we find:

\begin{proposition}
We have $\pr(M) \leq n$ if any projective resolution
\[ \dots \to P_1 \to P_0 \to M \to 0  \]
breaks off at the $n$th stage: that is, the kernel of $P_{n-1} \to P_{n-2}$ is
projective.
\end{proposition}


If $\pr(M) \leq n$, then by definition we have $\ext^{n+1}(M, N) = 0$ for
\emph{any} module $N$. By itself, this does not say anything about the $\tor$
functors.
However, the criterion for projective dimension enables us to show:

\begin{proposition} \label{pdfd}
If $\pr(M) \leq n$, then $\tor_m(M, N) = 0$ for $m > n$.
\end{proposition}
One can define an analog of projective dimension with the $\tor$ functors,
called \emph{flat dimension}, and it follows that the flat dimension is at most
the projective dimension.

In fact, we have more generally:
\begin{proposition}
Let $F$ be a right-exact functor on the category of $R$-modules, and let $\{L_i
F\}$ be its left derived functors.
If $\pr(M) \leq n$, then $L_i F(M) = 0$ for $i > n$.
\end{proposition}

Clearly this implies the claim about $\tor$ functors.
\begin{proof}
Recall how $L_i F(M)$ can be computed. Namely, one chooses a projective
resolution $P_\bullet \to M$ (any will do), and compute the homology of the
complex
$F(P_\bullet)$. However, we can choose $P_\bullet \to M$ such that $P_i = 0$
for $i > n$ by \cref{pdprojectiveresolution}. Thus $F(P_\bullet)$ is
concentrated in degrees between $0$ and $n$, and the result becomes clear when
one takes the homology.
\end{proof}

In general, flat modules are not projective (e.g. $\mathbb{Q}$ is flat, but not
projective, over $\mathbb{Z}$), and while one can use projective dimension to
bound ``flat dimension'' (the analog for $\tor$-vanishing), one cannot use the
flat dimension to bound the projective dimension. For a local ring, we will see
that it is possible in the next subsection.

\subsection{$\tor$ and projective dimension}

Over  a noetherian \emph{local} ring, there is a much simpler way to test whether a
finitely generated module is projective. This is a special case of the very
general flatness criterion \cref{bigflatcriterion}, but we can give a simple
direct proof. So we prefer to keep things self-contained.

\begin{theorem} \label{localflateasy}
Let $M$ be a finitely generated module over the noetherian local ring $(R,
\mathfrak{m})$, with residue field $k = R/\mathfrak{m}$. Then, if $\tor_1(M, k)
= 0$, $M$ is free.
\end{theorem}
In particular, projective---or even flat---modules which are of finite type
over $R$ are automatically free.
This is a strengthening of the earlier theorem (\cref{}) that a finitely
generated projective
module over a local ring is free.
\begin{proof}
Indeed, we can find a free module $F$ and a surjection $F \to M$ such that $F
\otimes_R k \to M \otimes_R k$ is an isomorphism. To do this, choose elements
of $M$ that form a basis of $M \otimes_R k$, and then define a map $F \to M$
via these elements; it is a surjection by Nakayama's lemma.

Let $K$ be the kernel of $F \twoheadrightarrow M$, so there is an exact sequence
\[ 0 \to K \to F \to M \to 0.  \]
We want to show that $K = 0$, which will imply that $M = 0$. By Nakayama's
lemma, it suffices to show that $K \otimes_R k = 0$. But we have an exact
sequence
\[ \tor_1(M, k) \to K \otimes_R k \to F \otimes_R k \to M \otimes_R k \to 0.  \]
The last map is an isomorphism, and $\tor_1(M, k) = 0$, which implies that $K
\otimes_R k = 0$. The result is now proved.
\end{proof}

As a result, we can compute the projective dimension of a module in terms of
$\tor$.
\begin{corollary}
Let $M$ be a finitely generated module over the noetherian local ring $R$ with
residue field $k$. Then $\pr(M)$ is the largest integer $n$
such that
$\tor_n(M, k) \neq 0$.
It is also the smallest integer $n$ such that $\tor_{n+1}(M, k) = 0$.
\end{corollary}
There is a certain symmetry: if $\ext$ replaces $\tor$, then one has the
definition of depth. We will show later that there is indeed a useful connection
between projective dimension and depth.
\begin{proof}
We will show that if
$\tor_{n+1}(M, k) = 0$, then $\pr(M) \leq n$.
This implies the claim, in view of \cref{pdfd}. Choose a (possibly infinite)
projective resolution
\[ \dots \to P_1 \to P_0 \to M \to 0.  \]
Since $R$ is noetherian, we can assume that each $P_i$ is \emph{finitely
generated.}

Write $K_i = \ker(P_i \to P_{i-1})$, as before; these are finitely generated
$R$-modules. We want to show that $K_{n-1}$
is projective, which will establish the claim, as then the projective
resolution will ``break off.''
But we have an exact sequence
\[ 0 \to K_0 \to P_0 \to M \to 0,  \]
which shows that $\tor_n(K_0, k) = \tor_{n+1}(M, k)= 0$.
Using the exact sequencese $0 \to K_{i} \to P_i \to K_{i-1} \to 0$, we
inductively work downwards to get that $\tor_1(K_{n-1}, k) =0$. So $K_{n-1}$ is
projective by \cref{localflateasy}.
\end{proof}

In particular, we find that if $\pr(k) \leq n$, then $\pr(M) \leq n$ for all
$M$. This is because if $\pr(k) \leq n$, then $\tor_{n+1}(M, k) = 0$ by using
the relevant resolution of $k$ (see \cref{pdfd}, but for $k$).
\begin{corollary}
Suppose there exists $n$ such that $\tor_{n+1}(k, k) = 0$.
Then every finitely generated $R$-module has a finite free resolution of length
at most $n$.
\end{corollary}

We have thus seen that $k$ is in some sense the ``worst'' $R$-module, in that it is
as far from being projective, or that it has the largest projective dimension.
We can describe this worst-case behavior with the next concept:

\begin{definition}
Given a ring $R$, the \textbf{global dimension} is the $\sup$ of the projective
dimensions of all finitely generated $R$-modules.
\end{definition}

So, to recapitulate: the global dimension of a noetherian local ring $R$ is the
projective dimension of its residue field $k$, or even the \emph{flat}
dimension of the residue field.
\subsection{Minimal projective resolutions}
Usually projective resolutions are non-unique; they are only unique up to
chain homotopy. We will introduce a certain restriction that enforces
uniqueness. These ``minimal'' projective resolutions will make it extremely
easy to compute the groups $\tor_{\bullet}(\cdot, k)$.

Let $(R, \mathfrak{m})$ be a local noetherian ring with residue field $k$, $M$ a
finitely generated $R$-module.
All tensor products will be over $R$.

\begin{definition}
A projective resolution $P_\bullet \to M$ of finitely generated
modules is \textbf{minimal} if for each $i$, the
induced map $P_i \otimes k \to P_{i-1} \otimes
k$ is
zero, and the map $P_0 \otimes k \to
M/\mathfrak{m}M$ is an isomorphism.
\end{definition}

In other words, the complex $P_\bullet \otimes k$ is isomorphic to $M \otimes
k$.
This is equivalent to saying that for each $i$, the map $P_i
\to\ker(P_{i-1}
\to P_{i-2})$ is an isomorphism modulo $\mathfrak{m}$.

\begin{proposition}
Every $M$ (over a local noetherian ring) has a minimal
projective resolution.
\end{proposition}
\begin{proof}
Start with a module $M$. Then $M/\mathfrak{m}M$ is a
finite-dimensional vector
space over $k$, of dimension say $d_0$. We can
choose a basis for that vector space, which
we can lift to $M$. That determines a map of free modules
\[ R^{d_0} \to M,  \]
which is a surjection by Nakayama's lemma. It is by construction
an
isomorphism modulo $\mathfrak{m}$. Then define $K =
\ker(R^{d_0}\to M)$; this
is finitely generated by noetherianness, and we
can do the same thing for $K$, and repeat to get a map $R^{d_1}
\twoheadrightarrow K$ which is an isomorphism modulo
$\mathfrak{m}$. Then
\[ R^{d_1} \to R^{d_0} \to M \to 0  \]
is exact, and minimal; we can continue this by the same
procedure.
\end{proof}


\begin{proposition}
Minimal projective resolutions are unique up to isomorphism.
\end{proposition}
\begin{proof}
Suppose we have one minimal projective resolution:
\[ \dots \to P_2 \to P_1 \to P_0 \to M \to 0  \]
and another:
\[ \dots \to Q_2 \to Q _1 \to Q_0 \to M \to 0  .\]
There is always a map of projective resolutions $P_* \to Q_*$ by
general
homological algebra. There is, equivalently, a commutative
diagram
\[\xymatrix{ \dots \ar[d] \ar[r] & P_2\ar[d] \ar[r] & P_1
\ar[d]\ar[r]
& P_0 \ar[d] \ar[r] & M \ar[d]^{\mathrm{id}} \ar[r] & 0 \\
 \dots  \ar[r] &   Q_2  \ar[r] &  Q_1   \ar[r]
&  Q_0   \ar[r] &   M  \ar[r] &   0 } \]
If both resolutions are minimal, the claim is that this map is
an isomorphism.
That is, $\phi_i: P_i \to Q_i$ is an isomorphism, for each $i$.

To see this, note that $P_i, Q_i$ are finite free
$R$-modules.\footnote{We are
using the fact that a finite projective module over a local ring
is
\emph{free}.} So $\phi_i$ is an isomorphism iff $\phi_i$ is an
isomorphism
modulo the maximal ideal, i.e. if
\[ P_i/\mathfrak{m}P_i \to Q_i/\mathfrak{m}Q_i  \]
is an isomorphism. Indeed, if $\phi_i$ is an isomorphism, then
its tensor
product with $R/\mathfrak{m}$ obviously is an isomorphism.
Conversely suppose
that the reductions mod $\mathfrak{m}$ make an isomorphism. Then
the ranks of
$P_i, Q_i$ are the same, and $\phi_i$ is an $n$-by-$n$ matrix
whose determinant
is not in the maximal ideal, so is invertible. This means that
$\phi_i$ is invertible by the
usual formula for the inverse matrix.

So we are to check that $P_i / \mathfrak{m}P_i \to Q_i /
\mathfrak{m}Q_i$ is an
isomorphism for each $i$. This is equivalent to the assertion
that
\[ (Q_i/\mathfrak{m}Q_i)^{\vee} \to
(P_i/\mathfrak{m}P_i)^{\vee}\]
is an isomorphism. But this is the map
\[ \hom_R(Q_i, R/\mathfrak{m}) \to \hom_R(P_i, R/\mathfrak{m}).
\]
If we look at the chain complexes $\hom(P_*, R/\mathfrak{m}),
\hom(Q_*,
R/\mathfrak{m})$, the cohomologies
compute the $\ext$ groups of $(M, R/\mathfrak{m})$. But all the
maps in this
chain complex are zero because the resolution is minimal, and we
have that the
image of $P_i$ is contained in $\mathfrak{m}P_{i-1}$ (ditto for
$Q_i$). So the
cohomologies are just the individual terms, and the maps
$ \hom_R(Q_i, R/\mathfrak{m}) \to \hom_R(P_i, R/\mathfrak{m})$
correspond to
the identities on $\ext^i(M, R/\mathfrak{m})$. So these are
isomorphisms.\footnote{We are sweeping under the rug the
statement that $\ext$
can be computed via \emph{any} projective resolution. More
precisely, if you
take any two projective resolutions, and take the induced maps
between the
projective resolutions, hom them into $R/\mathfrak{m}$, then the
maps on
cohomology are isomorphisms.}
\end{proof}


\begin{corollary}
If $\dots \to P_2 \to P_1 \to P_0 \to M$ is a minimal projective
resolution of
$M$, then the ranks $\mathrm{rank}(P_i)$ are well-defined (i.e.
don't depend
on the choice of the minimal resolution).
\end{corollary}
\begin{proof}
Immediate from the proposition. In fact, the ranks are the
dimensions (as
$R/\mathfrak{m}$-vector spaces) of $\ext^i(M, R/\mathfrak{m})$.
\end{proof}

\subsection{The Auslander-Buchsbaum formula}



\begin{theorem}[Auslander-Buschsbaum formula]
Let $R$ be a local noetherian ring, $M$ a finitely generated $R$-module of
finite
projective dimension. If $\pr(R) <
\infty$, then $\pr(M) = \depth(R) - \depth(M)$.
\end{theorem}

\begin{proof}
Induction on $\pr(M)$. When $\pr(M)=0$, then $M$ is projective,
so isomorphic
to $R^n$ for some $n$. Thus $\depth(M) = \depth(R)$.

Assume $\pr(M) > 0$.
Choose a surjection $P \twoheadrightarrow M$ and write an exact
sequence
\[ 0 \to K \to P \to M \to 0,  \]
where $\pr(K) = \pr(M)-1$. We also know by induction that
\[ \pr(K) = \depth R - \depth(K).  \]
What we want to prove is that
\[ \depth R - \depth M = \pr(M) = \pr(K)+1.  \]
This is equivalent to wanting know that $\depth(K) = \depth (M)
+1$.
In general, this may not be true, though, but we will prove it
under
minimality hypotheses.

Without loss of generality, we can choose that $P$ is
\emph{minimal}, i.e.
becomes an isomorphism modulo the maximal ideal $\mathfrak{m}$.
This means
that the rank of $P$ is $\dim M/\mathfrak{m}M$.
So $K = 0$ iff $P \to M$ is an isomorphism; we've assumed that
$M$ is not
free, so $K \neq 0$.

Recall that the depth of $M$ is the smallest value $i$ such
that$\ext^i(R/\mathfrak{m}, M) \neq 0$. So we should look at the long exact
sequence from the above short exact sequence:
\[ \ext^i(R/\mathfrak{m}, P) \to  \ext^i(R/\mathfrak{m},M)  \to
\ext^{i+1}(R/\mathfrak{m}, K) \to \ext^{i+1}(R/\mathfrak{m},
P).\]
Now $P$ is just a direct sum of copies of $R$, so
$\ext^i(R/\mathfrak{m}, P)$
and $\ext^{i+1}(R/\mathfrak{m}, P)$ are zero if $i+1< \depth R$.
In
particular, if $i+1< \depth R$, then the map $
\ext^i(R/\mathfrak{m},M) \to
\ext^{i+1}(R/\mathfrak{m}, K) $ is an isomorphism.
So we find that $\depth M + 1 = \depth K$ in this case.

We have seen that \emph{if $\depth K < \depth R$, then } by
taking $i$ over
all integers $< \depth K$, we find that
\[ \ext^{i}(R/\mathfrak{m}, M) = \begin{cases}
0 & \mathrm{if \ } i+1 < \depth K \\
\ext^{i+1}(R/\mathfrak{m},K) & \mathrm{if \ } i+1 = \depth K
\end{cases}. \]
In particular, we are \textbf{done} unless $\depth K \geq \depth
R$.
By the inductive hypothesis, this is equivalent to saying that
$K$ is
projective.

So let us consider the case where $K$ is projective, i.e.
$\pr(M)=1$.
We want to show that $\depth M = d-1$ if $d = \depth R$.
We need a
slightly different argument in this case. Let $d = \depth(R) =
\depth (P) =
\depth(K)$ since $P,K$ are free. We have a short exact sequence
\[ 0 \to K \to P \to M \to 0  \]
and a long exact sequence of $\ext$ groups:
\[ 0 \to \ext^{d-1}(R/\mathfrak{m}, M) \to
\ext^d(R/\mathfrak{m}, K) \to \ext^d(R/\mathfrak{m}, P) .\]
We know that $\ext^d(R/\mathfrak{m}, K)$ is nonzero as $K$ is
free and $R$ has
depth $d$. However, $\ext^i(R/\mathfrak{m}, K) =
\ext^i(R/\mathfrak{m}, P)=0$
for $i<d$. This implies that $\ext^{i-1}(R/\mathfrak{m}, M)=0$
for $i<d$.

We will show:
\begin{quote}
The map $\ext^d(R/\mathfrak{m}, K) \to \ext^{d}(R/\mathfrak{m},
P)$ is zero.
\end{quote}
This will imply that the depth of $M$ is \emph{precisely} $d-1$.
This is because the matrix $K \to P$ is given by multiplication
by a matrix
with coefficients in $\mathfrak{m}$ as $K/\mathfrak{m}K \to
P/\mathfrak{m}P$
is zero. In particular, the map on the $\ext$ groups is zero,
because it is
annihilated by $\mathfrak{m}$.
\end{proof}

\begin{example} \label{abregularloc}
Consider the case of a \emph{regular} local ring $R$ of dimension $n$. Then
$\depth(R) = n$, so we have
\[ \pr(M) + \depth(M) = n,  \]
for every finitely generated $R$-module $M$.
In particular, $\depth(M) = n$ if and only if $M$ is free.
\end{example}

\begin{example}[The Cohen-Macaulay locus is open]
Let $R$ be a regular noetherian ring (i.e. one all of whose localizations are
regular). Let $M$ be a finitely generated $R$-module.
We consider the locus $Z \subset \spec R$ consisting of prime ideals
$\mathfrak{p} \in \spec R$ such that $M_{\mathfrak{p}}$ is a Cohen-Macaulay
$R$-module.
We want to show that this is an \emph{open} subset.

\newcommand{\codp}{\mathrm{codepth}}
Namely, over a local ring $(A, \mathfrak{m})$, define the \emph{codepth} of a
finitely generated $A$-module $N$ as $\codp N = \dim N - \depth N \geq 0$; we
have that $\codp N = 0$ if and only if $N$ is Cohen-Macaulay.
We are going to show that the function $\mathfrak{p} \mapsto
\codp_{R_{\mathfrak{p}}}
M_{\mathfrak{p}}$ is  upper semicontinuous on $\spec R$.
To do this, we use  the Auslander-Buchsbaum formula $\depth_{R_{\mathfrak{p}}} M_{\mathfrak{p}} = \dim
R_{\mathfrak{p}} - \pr_{R_{\mathfrak{p}}} M_{\mathfrak{p}}$ (see
\cref{abregularloc}). We will show below
that $\mathfrak{p} \mapsto \pr_{R_{\mathfrak{p}}} M_{\mathfrak{p}}$ is upper
semi-continuous on $\spec R$.
Thus, we have
\[ \codp_{R_{\mathfrak{p}}} M_{\mathfrak{p}} =  -\left( \dim R_{\mathfrak{p}} -
\dim_{R_{\mathfrak{p}}} M_{\mathfrak{p}}\right) + \pr_{R_{\mathfrak{p}}}
M_{\mathfrak{p}},   \]
where the second term is upper semi-continuous.
The claim is that the first term is upper semi-continuous. If we consider
$\supp M \subset \spec R$, then the bracketed difference measures the
\emph{local codimension} of $\supp M \subset \spec R$.
Namely, $\dim R_{\mathfrak{p}} - \dim \supp M_{\mathfrak{p}}$ is the local
codimension because $R_{\mathfrak{p}}$ is regular, and consequently $\spec
R_{\mathfrak{p}}$ is biequidimensional (\add{argument}).
The local codimension of any set is always lower semi-continuous
(\add{reference in the section on topological dim}).
As a result, the codepth is upper semi-continuous.

We just need to prove the assertion that
$\mathfrak{p} \mapsto \pr_{R_{\mathfrak{p}}} M_{\mathfrak{p}}$ is upper
semi-continuous. That is, we need to show that if $M_{\mathfrak{p}}$ admits a
projective resolution of length $n$ by finitely generated modules, then there is a projective resolution of
length $n$ of $M_{\mathfrak{q}}$ for $\mathfrak{q}$ in some Zariski
neighborhood. But a projective resolution of $M_{\mathfrak{p}}$ ``descends'' to
a projective (even free) resolution of $M_g$ for some $g \notin \mathfrak{p}$,
which gives the result by localization.

If $R$ is the \emph{quotient} of a regular ring, the same result holds (because
the Cohen-Macaulay locus behaves properly with respect to quotients). In
particular, this result holds for $R$ an affine ring.
\end{example}


\begin{example}
Let $R = \mathbb{C}[x_1, \dots, x_n]/\mathfrak{p}$ for
$\mathfrak{p}$ prime.
Choose an injection $R' \to R$ where $R' = \mathbb{C}[y_1,
\dots, y_m]$ and
$R$ is a finitely generated $R'$-module. This exists by the Noether
normalization lemma.

We wanted to show:

\begin{theorem}
$R$ is Cohen-Macaulay\footnote{That is, its localizations at any
prime---or,
though we haven't proved yet, at any maximal ideal---are.} iff
$R$ is a
projective $R'$-module.
\end{theorem}

We shall use the fact that projectiveness can be tested locally
at every
maximal ideal.

\begin{proof}
Choose a maximal ideal $\mathfrak{m} \subset R'$. We will show
that
$R_{\mathfrak{m}}$ is a free $R'_{\mathfrak{m}}$-module via the
injection of
rings $R'_{\mathfrak{m}} \hookrightarrow R_{\mathfrak{m}}$
(where
$R_{\mathfrak{m}}$ is defined as $R$ localized at the
multiplicative subset
of elements of $R' - \mathfrak{m}$) at each $\mathfrak{m}$ iff
Cohen-Macaulayness holds.

Now $R'_{\mathfrak{m}}$ is a regular local ring, so its depth is
$m$. By the
Auslander-Buchsbaum formula, $R_{\mathfrak{m}}$ is projective as
an
$R'_{\mathfrak{m}}$-module iff
\[ \depth_{R'_{\mathfrak{m}}} R_{\mathfrak{m}} = m.  \]
Now $R$ is a projective module iff the above condition holds for
all maximal
ideals $\mathfrak{m} \subset R'$. The claim is that this is
equivalent to
saying that $\depth R_{\mathfrak{n}} = m = \dim
R_{\mathfrak{n}}$
for every maximal ideal $\mathfrak{n} \subset R$ (depth over
$R$!).

These two statements are almost the same, but one is about the
depth of $R$ as
an $R$-module, and another as an $R'$-module.

\begin{quote}
Issue: There may be several maximal ideals of $R$ lying over the
maximal ideal
$\mathfrak{m} \subset R'$.
\end{quote}

The problem is that $R_{\mathfrak{m}}$ is not generally local,
and not
generally equal to $R_{\mathfrak{n}}$ if $\mathfrak{n}$ lies
over
$\mathfrak{m}$. Fortunately, depth makes sense even over
semi-local rings
(rings with finitely many maximal ideals).

Let us just assume that this does not occur, though. Let us
assume that
$R_{\mathfrak{m}}$ is a local ring for every maximal ideal
$\mathfrak{m}
\subset R$. Then we are reduced to showing that if $S =
R_{\mathfrak{m}}$,
then the depth of $S$ as an $R'_{\mathfrak{m}}$-module is the
same as the
depth as an $R_{\mathfrak{m}}$-module. That is, the depth
doesn't depend too
much on the ring, since $R'_{\mathfrak{m}}, R_{\mathfrak{m}}$
are ``pretty
close.'' If you believe this, then you believe the theorem, by
the first
paragraph.


Let's prove this claim in a more general form:

\begin{proposition}
Let $\phi: S' \to S$ be a local\footnote{I.e. $\phi$ sends
non-units into
non-units.} map of local noetherian rings such that $S$ is a
finitely generated
$S'$-module. Then, for any finitely generated $S$-module $M$,
\[ \depth_S M = \depth_{S'} M.  \]
\end{proposition}
With this, the theorem will be proved.

\begin{remark}
This result generalizes to the semi-local case, which is how
one side-steps
the issue above.
\end{remark}

\begin{proof}
By induction on $\depth_{S'} M$. There are two cases.

Let $\mathfrak{m}', \mathfrak{m}$ be the maximal ideals of $S',
S$.
If $\depth_{S'}(M) >0$, then there is an element $a$ in
$\mathfrak{m}'$ such
that
\[ M \stackrel{\phi(a)}{\to} M \]
is injective. Now $\phi(a) \in \mathfrak{m}$. So $\phi(a)$ is a
nonzerodivisor, and we have an exact sequence
\[ 0 \to M \stackrel{\phi(a)}{\to} M \to M/\phi(a) M \to 0.  \]
Thus we find
\[ \depth_{S} M > 0 . \]
Moreover, we find that $\depth_S M = \depth_S (M/\phi(a) M) +1$
and
$\depth_{S'} M = \depth_{S'}(M/\phi(a) M))+1$. The inductive
hypothesis now
tells us that
\[ \depth_S M = \depth_{S'}M.  \]

The hard case is where $\depth_{S'} M = 0$. We need to show that
this is
equivalent to $\depth_{S} M = 0$. So we know at first that
$\mathfrak{m}' \in
\ass(M)$. That is, there is an element $x \in M$ such that
$\ann_{S'}(x) =
\mathfrak{m}'$.
Now $\ann_S(x) \subsetneq S$ and contains $\mathfrak{m}' S$.

$Sx \subset M$ is a submodule, surjected onto by $S$ by the map
$a \to ax$.
This map actually, as we have seen, factors through
$S/\mathfrak{m}' S$. Here
$S$ is a finite $S'$-module, so $S/\mathfrak{m}'S$ is a finite
$S'/\mathfrak{m}'$-module. In particular, it is a
finite-dimensional vector space
over a field. It is thus a local artinian ring. But $Sx$ is a
module over this
local artinian ring. It must have an associated prime, which is
a maximal
ideal in $S/\mathfrak{m}'S$. The only maximal ideal can be
$\mathfrak{m}/\mathfrak{m}'S$. It follows that $\mathfrak{m}
\in\ass(Sx)
\subset \ass(M)$.

In particular, $\depth_S M = 0$ too, and we are done.
\end{proof}

\end{proof}
\end{example}

\begin{comment}We shall eventually prove:

\begin{proposition}
Let $R = \mathbb{C}[X_1, \dots, X_n]/\mathfrak{p}$ for
$\mathfrak{p}$ prime.
Choose an injective map $\mathbb{C}[y_1, \dots, y_n]
\hookrightarrow R$ making $R$ a
finite module. Then $R$ is Cohen-Macaulay iff $R$ is projective
as a module
over $\mathbb{C}[y_1, \dots, y_n]$.\footnote{In fact, this is
equivalent to
freeness, although we will not prove it. Any projective finite
module over a
polynomial ring over a field is free, though this is a hard
theorem.}
\end{proposition}

The picture is that the inclusion $\mathbb{C}[y_1, \dots, y_m ]
\hookrightarrow
\mathbb{C}[x_1, \dots, x_n]/\mathfrak{p}$ corresponds to a map
\[ X \to \mathbb{C}^m  \]
for $X = V(\mathfrak{p}) \subset \mathbb{C}^n$. This statement
of freeness is a
statement about how the fibers of this finite map stay similar
in some sense.

\end{proof}
\end{comment}

\section{Serre's criterion and its consequences}


 We would like to prove
Serre's
criterion for regularity.

\begin{theorem}
Let $(R, \mathfrak{m})$ be a local noetherian ring. Then $R$ is
regular iff
$R/\mathfrak{m}$ has finite projective dimension. In this case,
$\pr(R/\mathfrak{m}) = \dim R$.
\end{theorem}

\add{proof}


\subsection{First consequences}


\begin{proposition}
Let $(R, \mathfrak{m}) \to (S, \mathfrak{n})$ be a flat, local homomorphism of noetherian local
rings. If $S$ is regular, so is $R$.
\end{proposition}
\begin{proof}
Let $n = \dim S$.
Let $M$ be a finitely generated $R$-module, and consider a resolution
\[ P_n \to P_{n-1} \to \dots \to P_0 \to M \to 0,  \]
where all the $\left\{P_i\right\}$ are finite free $R$-modules. If we can show
that the kernel of $P_n \to P_{n-1}$ is projective, then it will follow that
$M$ has finite projective dimension. Since $M$ was arbitrary, it will follow
that $R$ is regular too, by Serre's criterion.

Let $K$ be the kernel, so there is an exact sequence
\[ 0 \to K \to  P_n \to P_{n-1} \to \dots \to P_0 \to M \to 0, \]
which we can tensor with $S$, by flatness:
\[ 0 \to K \otimes_R S \to  P_n \otimes_R S  \to P_{n-1} \otimes_R S \to \dots
\to P_0 \otimes_R S  \to M \otimes_R S\to 0. \]
Because any finitely generated $S$-module has projective dimension $\leq n$, it
follows that $K \otimes_R S$ is projective, and in particular flat.

But now $S$ is \emph{faithfully flat} over $R$ (see \cref{}), and it follows
that $K $ is $R$-flat. Thus $K$ is projective over $R$, proving the claim.
\end{proof}

\begin{theorem}
The localization of a regular local ring at a prime ideal is regular.
\end{theorem}
Geometrically, this means that  to test whether a nice scheme (e.g. a variety) is regular
(i.e., all the local rings are regular), one only has to test the \emph{closed}
points.
\begin{proof}
Let $(R, \mathfrak{m})$ be a regular local ring. Let $\mathfrak{p} \in \spec R$
be a prime ideal; we wish to show that $R_{\mathfrak{p}}$ is regular.
To do this, let $M$ be a finitely generated $R_{\mathfrak{p}}$-module. Then we
can find a finitely generated $R$-submodule $N \subset M$ such that
the natural map $N_{\mathfrak{p}} \to M$ is an isomorphism.
If we take a finite free resolution of $N$ by $R$-modules and localize at
$\mathfrak{p}$, we get a finite free resolution of $M$ by
$R_{\mathfrak{p}}$-modules.

It now follows that $M$ has finite projective dimension as an
$R_{\mathfrak{p}}$-module. By Serre's criterion, this implies that
$R_{\mathfrak{p}}$ is regular.
\end{proof}

\subsection{Regular local rings are factorial}

We now aim to prove that a regular local ring is factorial.

First, we need:
\begin{definition}
Let $R$ be a noetherian ring and $M$ a f.gen. $R$-module.  Then $M$ is
\textbf{stably free} if $M \oplus R^k$ is free for some $k$.
\end{definition}

Stably free obviously implies ``projective.''
Free implies stably free, clearly---take $k=0$. Over a local ring, a finitely
generated projective module is free, so all three notions are equivalent. Over a
general ring, these notions are generally different.

We will need the following lemma:

\begin{lemma}
Let $M$ be an $R$-module with a finite free resolution. If $M$ is projective,
it is stably free.
\end{lemma}
\begin{proof}
There is an exact sequence
\[ 0 \to F_k \to F_{k-1} \to \dots \to F_1 \to F_0 \to M \to 0  \]
with the $F_i$ free and finitely generated, by assumption.

We induct on the length $k$ of the resolution. We know that if $N$ is the
kernel of $F_0 \to M$, then $N$ is projective (as the sequence $0 \to N \to
F_0 \to M \to 0$ splits) so there is a resolution
\[ 0 \to F_k \to \dots \to F_1 \to N \to 0.  \]
By the inductive hypothesis, $N$ is stably free.
So there is a free module $R^d$ such that $N \oplus R^d$ is free.

We know that $M \oplus N=F_0$ is
free. Thus $M \oplus N \oplus R^d = F_0 \oplus R^d$ is free and $N \oplus R^d$
is free. Thus $M$ is stably free.
\end{proof}


\begin{remark}
Stably freeness does \textbf{not} generally imply freeness, though it does
over a local noetherian ring.
\end{remark}

Nonetheless,

\begin{proposition}
Stably free does imply free for invertible modules.
\end{proposition}
\begin{proof}
Let $I$ be stably free and invertible. We must show that $I \simeq R$.
Without loss of generality, we can assume that $\spec R$ is connected, i.e.
$R$ has no nontrivial idempotents. We will assume this in order to talk about
the \textbf{rank} of a projective module.

We know that $I \oplus R^n \simeq R^m$ for some $m$. We know that $m=n+1$ by
localization. So $I \oplus R^n \simeq R^{n+1}$ for some $n$.
We will now need to construct the \textbf{exterior powers}, for which we
digress:

\begin{definition}
Let $R$ be a commutative ring and $M$ an $R$-module. Then $\wedge M$, the
\textbf{exterior algebra on $M$}, is the free (noncommutative) graded $R$-algebra
generated by $M$ (with product $\wedge$) with just enough relations such that
$\wedge$ is anticommutative (and, \emph{more strongly}, $x \wedge x=0$ for
$x$ degree one).
\end{definition}

Clearly $\wedge M$ is a quotient of the \textbf{tensor algebra} $T(M)$, which is by
definition $R
\oplus M \oplus M \otimes M \oplus \dots \oplus M^{\otimes n} \oplus \dots$.
The tensor algebra is a graded $R$-algebra in an obvious way: $(x_1 \otimes
\dots \otimes x_a) . (y_1 \otimes \dots \otimes y_b) = x_1 \otimes \dots
\otimes x_a \otimes y_1 \otimes \dots \otimes y_b$. This is an associative
$R$-algebra.
Then
\[ \wedge M = T(M)/( x \otimes x, \ x,y \in M).  \]
The grading on $\wedge M$ comes from the grading of $T(M)$.

We are interested in basically one example:
\begin{example}
Say $M = R^m$. Then $\wedge^m M = R$. If $e_1, \dots, e_m \in M$ are
generators, then $e_1 \wedge \dots \wedge e_m$ is a generator. More generally,
$\wedge^k M$ is free on $e_{i_1} \wedge \dots \wedge e_{i_k}$ for $i_1 < \dots <
i_k$.
\end{example}

We now make:

\begin{definition}
If $M$ is a projective $R$-module of rank $n$, then
\[ \det(M) = \wedge^n M.  \]
\end{definition}
If $M$ is free, then $\det(M)$ is free of rank one. So, as we see by
localization, $\det(M)$ is always an
invertible module for $M$ locally free (i.e. projective) and $\wedge^{n+1}M = 0$.

\begin{lemma}
$\det(M \oplus N) = \det M \otimes \det N$.
\end{lemma}
\begin{proof}
This isomorphism is given by wedging $\wedge^{\mathrm{top}} M \otimes
\wedge^{\mathrm{top}} N \to \wedge^{\mathrm{top}}(M \oplus N)$. This is easily
checked for oneself.
\end{proof}

Anyway, let us finally go back to the proof. If $I \oplus R^n = R^{n+1}$, then
taking determinants shows that
\[ \det I \otimes R = R,  \]
so $\det I = R$. But this is $I$ as $I$ is of rank one. So $I$ is free.

\end{proof}

\begin{theorem}
A regular local ring is factorial.
\end{theorem}

Let $R$ be a regular local ring of dimension $n$. We want to show that $R$ is factorial.
Choose a prime ideal $\mathfrak{p}$ of height one.
We'd like to show that $\mathfrak{p}$ is principal.

\begin{proof}
Induction on $n$. If $n=0$, then we are done---we have a field.

If $n=1$, then a height one prime is maximal, hence principal, because
regularity is equivalent to the ring's being a DVR.

Assume $n>1$.  The prime ideal $\mathfrak{p}$ has height one, so it is
contained in  a maximal ideal $\mathfrak{m}$. Note that $\mathfrak{m}^2
\subset \mathfrak{m}$ as well. I claim that there is an element $x$ of
$\mathfrak{m} - \mathfrak{p} - \mathfrak{m}^2$. This follows as an argument
like prime avoidance. To see that $x$ exists, choose $x_1 \in \mathfrak{m} - \mathfrak{p}$ and $x_2
\in \mathfrak{m} - \mathfrak{m}^2$. We are done unless $x_1 \in
\mathfrak{m}^2$ and $x_2 \in \mathfrak{p}$ (or we could take $x$ to be $x_1$
or $x_2$). In this case, we just take $x = x_1 + x_2$.

So choose $x \in \mathfrak{m} - \mathfrak{p} - \mathfrak{m}^2$. Let us examine
the ring $R_{x} = R[1/x]$, which contains an ideal $\mathfrak{p}[x^{-1}]$.
This is a proper ideal as $x \notin \mathfrak{p}$. Now $R[1/x]$ is regular
(i.e. its localizations at primes are regular local). The dimension, however,
is of dimension less than $n$ since by inverting $x$ we have removed
$\mathfrak{m}$. By induction we can assume that $R_x$ is locally factorial.

Now $\mathfrak{p}R_{x}$ is prime and of height one, so it is invertible as
$R_x$ is locally factorial.
In particular it is projective.

But $\mathfrak{p}$ has a finite resolution by $R$-modules (by regularity), so
$\mathfrak{p}R_x$ has a finite free resolution. In particular,
$\mathfrak{p}R_{x}$ is stably free and invertible, hence free.
Thus $\mathfrak{p}R_x$ is \textbf{principal}.

We want to show that $\mathfrak{p}$ is principal, not just after localization.
We know that there is a $y \in \mathfrak{p}$ such that $y$ generates
$\mathfrak{p}R_x$. Choose $y$ such that $(y) \subset \mathfrak{p}$ is as large
as possible. We can do this since $R$ is noetherian. This implies that $x
\nmid y$ because otherwise we could use $y/x$ instead of $y$.

We shall now show that
\[ \mathfrak{p} = (y).  \]
So suppose $z \in \mathfrak{p}$. We know that $y$ generates $\mathfrak{p}$
\textbf{after $x$ is inverted.} In particular, $z \in \mathfrak{p}R_x$. That
is, $zx^a \in (y)$ for $a$ large.  That is, we can write
\[ zx^a = yw, \quad \mathrm{for \ some} \ w \in R . \]
We chose $x$ such that $x \notin \mathfrak{m}^2$. In particular, $R/(x)$ is
regular, hence an integral domain; i.e. $x$ is a prime element. We find that
$x$ must divide one of $y,w$ if $a>0$. But we know that $x \nmid y$, so $x
\mid w$.  Thus $w = w'x$ for some $x$. We find that, cancelling $x$,
\[ zx^{a-1} = yw'  \]
and we can repeat this argument over and over until we find that
\[ z \in (y).  \]
\end{proof}




% ============================ chapters/etale.tex}
\chapter{\'Etale, unramified, and smooth morphisms}


In this chapter, we shall introduce three classes of morphisms of rings
defined by lifting properties and study their properties.
Although in the case of morphisms of finite presentation, the three types of
morphisms (unramified, smooth, and \'etale) can be defined directly (without
lifting properties), in practice, in algebraic geometry, the functorial
criterion given by lifts matter: if one wants to show an algebra is
representable, then one can just study the \emph{corepresentable functor},
which may be more accessible.

\section{Unramified morphisms}
\label{section-formally-unramified}


\subsection{Definition}

Formal \'etaleness, smoothness, and unramifiedness all deal with the existence
or uniqueness of liftings under nilpotent extensions. We start with formal
unramifiedness.

\begin{definition}
\label{definition-formally-unramified}
Let $R \to S$ be a ring map.
We say $S$ is {\bf formally unramified over $R$} if for every
commutative solid diagram
\begin{equation} \label{inflift}
\xymatrix{
S \ar[r] \ar@{-->}[rd] & A/I \\
R \ar[r] \ar[u] & A \ar[u]
}
\end{equation}
where $I \subset A$ is an ideal of square zero, there exists
at most one dotted arrow making the diagram commute.

We say that $S$ is \textbf{unramified over $R$} if $S$ is formally unramified
over $R$ and is a finitely generated $R$-algebra.
\end{definition}

In other words, an $R$-algebra $S$ is formally unramified if and only if
whenever $A$ is an $R$-algebra and $I \subset A$ an ideal of square zero, the
map of sets
\[ \hom_R(S, A) \to \hom_R(S, A/I)  \]
is injective.
Restated again, for such $A, I$, there is \emph{at most one}  lift of a given
$R$-homomorphism $S \to A/I$ to $S \to A$.
This is a statement purely about the associated ``functor of points.''
Namely, let $S$ be an $R$-algebra, and consider the functor $F:
R\text{--}\mathbf{alg}
\to \mathbf{Sets}$ given by $F(X) = \hom_R(S, X)$.
This is the ``functor of points.''
Then $S$ is formally unramified over $R$ if $F(A) \to F(A/I)$ is injective for each
$A, I$ as above.

The intuition is that maps from $S$ into $T$ are like ``tangent vectors,'' and
consequently the condition geometrically means something like that tangent
vectors can be lifted uniquely: that is, the associated map is an immersion.
More formally, if $R\to  S$ is a morphism of algebras of finite type
over $\mathbb{C}$, which corresponds to a map $\spec S \to \spec R$ of
\emph{smooth} varieties (this is a condition on $R, S$!), then $R \to S$ is
unramified if and only if the  associated map of complex manifolds is an
immersion. (We are not proving this, just stating it for intuition.)

Note also that we can replace ``$I$ of square zero'' with the weaker condition
``$I$ nilpotent.'' That is, the map $R \to S$ (if it is formally unramified)
still has the same lifting property. This follows because one can factor $A \to
A/I$ into the \emph{finite} sequence $\dots \to A/I^{n+1} \to A/I^{n} \to \dots
\to A/I$, and each step is a square-zero extension.


We now show that the module of K\"ahler differentials provides a simple
criterion for an extension to be formally unramified.
\begin{proposition} \label{formalunrmeansomegazero}
An $R$-algebra $S$ is formally unramified if and only if $\Omega_{S/R} = 0$.
\end{proposition}

Suppose $R, S$ are both algebras over some smaller ring $k$.
Then there is an exact sequence
\[ \Omega_{R/k}\otimes_R S \to \Omega_{S/k} \to \Omega_{S/R} \to 0,  \]
and consequently, we see that formal unramifiedness corresponds to surjectivity
of the map on ``cotangent spaces'' $\Omega_{R/k} \otimes_R S \to \Omega_{S/k}$.
This is part of the intuition that formally unramified maps are geometrically
like immersions (since surjectivity on the cotangent spaces corresponds to
injectivity on the tangent spaces).

\begin{proof}
Suppose first $\Omega_{S/R}=0$. This is equivalent to the statement that
\emph{any} $R$-derivation of $S$ into an $S$-module is trivial, because
$\Omega_{S/R}$ is the recipient of the ``universal'' $R$-derivation.
If given an $R$-algebra $T$ with an ideal $I \subset T$ of square zero and a
morphism
\[ S \to T/I,  \]
and two liftings $f,g: S \to T$, then we find that $f-g$ maps $S$ into $I$.
Since $T/I$ is naturally an $S$-algebra, it is easy to see (since $I$ has
square zero) that $I$ is naturally an $S$-module and $f-g$ is an
$R$-derivation $S \to I$.
Thus $f-g \equiv 0$ and $f=g$.

Conversely, suppose $S$ has the property that liftings in \eqref{inflift} are
unique.
Consider the $S$-module $T=S \oplus \Omega_{S/R}$ with the multiplicative
structure $(a,a')(b,b') = (ab, ab' + a'b)$ that makes it into an algebra.
(This is a general construction one can do with an $S$-module $M$: $S \oplus
M$ is an algebra where $M$ becomes an ideal of square zero.)

Consider the ideal $\Omega_{S/R} \subset T$, which has
square zero; the quotient is $S$. We will find two liftings of the identity $S
\to S$. For the first, define $S \to T$ sending $s \to (s,0)$. For the second,
define $S \to T$ sending $s \to (s, ds)$; the derivation property of $b$ shows
that this is a morphism of algebras.

By the lifting property, the two morphisms $S \to T$ are equal. In particular,
the map $S \to \Omega_{S/R}$ sending $s \to ds$ is trivial. This implies that
$\Omega_{S/R}=0$.

\end{proof}

Here is the essential point of the above argument. Let $I \subset T$ be an
ideal of square zero in the $R$-algebra $T$.
Suppose given a homomorphism $g: S \to T/I$.
Then the set of lifts $S \to T$ of $g$ (which are $R$-algebra morphisms)
is either empty or a torsor over
$\mathrm{Der}_R(S, I)$ (by adding a derivation to
a homomorphism).
Note that $I$ is naturally a $T/I$-module (because $I^2 = 0$), and hence an
$S$-module by $g$.

This means that if the object $\mathrm{Der}_R(S, I)$ is trivial, then
injectivity of the above map must hold.
Conversely, if injectivity of the above map always holds (i.e. $S$ is formally
unramified),
then we must have $\mathrm{Der}_R(S, I) = 0$ for all such $I \subset T$; since
we can obtain any $S$-module in this manner, it follows that there is no such
thing as  a nontrivial $R$-derivation out of $S$.
%most of the code below was contributed by the Stacks project authors


We next show that formal unramifiedness is a local property.
\begin{lemma}
\label{lemma-formally-unramified-local}
Let $R \to S$ be a ring map.
The following are equivalent:
\begin{enumerate}
\item $R \to S$ is formally unramified,
\item $R \to S_{\mathfrak q}$ is formally unramified for all
primes $\mathfrak q$ of $S$, and
\item $R_{\mathfrak p} \to S_{\mathfrak q}$ is formally unramified
for all primes $\mathfrak q$ of $S$ with $\mathfrak p = R \cap \mathfrak q$.
\end{enumerate}
\end{lemma}

\begin{proof}
We have seen in
\cref{formalunrmeansomegazero}
that (1) is equivalent to
$\Omega_{S/R} = 0$. Similarly, since K\"ahler differentials localize, we see that (2) and (3)
are equivalent to $(\Omega_{S/R})_{\mathfrak q} = 0$ for all
$\mathfrak q$.
As a result, the statement of this lemma is simply the fact that an $S$-module
is zero if and only if all its localizations at prime ideals are zero.
\end{proof}

We shall now give the typical list of properties (``le sorite'') of unramified morphisms.

\begin{proposition} \label{locunramified}
Any map $R \to R_f$ for $f \in  R$ is unramified.
More generally, a map from a ring to any localization is \emph{formally}
unramified, but not necessarily unramified.
\end{proposition}
\begin{proof}
Indeed, we know that $\Omega_{R/R}  = 0$ and $\Omega_{R_f/R } =
(\Omega_{R/R})_f=0$, and the map is clearly of finite type.
\end{proof}

\begin{proposition} \label{epiunr}
A surjection of rings is unramified.
More generally, a categorical epimorphism of rings is formally unramified.
\end{proposition}
\begin{proof}
Obvious from the lifting property: if $R \to S$ is a categorical epimorphism,
then given any $R$-algebra $T$, there can be \emph{at most one} map of
$R$-algebras $S \to T$ (regardless of anything involving square-zero ideals).
\end{proof}

In the proof of \cref{epiunr}, we could have alternatively argued as follows. If $R \to S$ is an epimorphism
in the category of rings, then $S \otimes_R S \to S$ is an isomorphism.
This is a general categorical fact, the dual of which for monomorphisms is
perhaps simpler: if $X \to Y$ is a monomorphism of objects in any category,
then $X \to X \times_Y X$ is an isomorphism. See \cref{}. By the alternate
construction of $\Omega_{S/R}$ (\cref{alternateOmega}), it follows that this must vanish.


\begin{proposition}
\label{sorite1unr}
If $R \to S$ and $S \to T$ are unramified (resp. formally unramified), so is $R \to T$.
\end{proposition}
\begin{proof}
Since morphisms of finite type are preserved under composition, we only need
to prove the result about formally unramified maps. So let $R \to S, S \to T$
be formally unramified. We need to check that
$\Omega_{T/R}  = 0$. However, we have an exact sequence (see
\cref{firstexactseq}):
\[ \Omega_{S/R}\otimes_S T \to \Omega_{T/R} \to \Omega_{T/S} \to 0,  \]
and since $\Omega_{S/R} = 0, \Omega_{T/S} = 0$, we find that $\Omega_{T/R}  =
0$. This shows that $R \to T$ is formally unramified.
\end{proof}
More elegantly, we could have proved this by using the lifting property (and
this is what we will do for formal \'etaleness and smoothness).
Then this is simply a formal argument.

\begin{proposition}  \label{unrbasechange}
If $R \to S$ is unramified (resp. formally unramified), so is $R' \to S' = S \otimes_R R'$ for any $R$-algebra
$R'$.
\end{proposition}
\begin{proof}
This follows from the fact that $\Omega_{S'/R'} = \Omega_{S/R} \otimes_S S'$
(see \cref{basechangediff}).
Alternatively, it can be checked easily using the lifting criterion.
For instance, suppose given an $R'$-algebra $T$ and an ideal $I \subset T$ of
square zero. We want to show that a morphism of $R'$-algebras
$S' \to T/I$ lifts in at most one way to a map $S' \to T$. But if we had two
distinct liftings, then we could restrict to $S$ to get two liftings  of $S \to
S' \to T/I$. These are easily seen to be distinct, a contradiction as $R \to
S$ was assumed formally unramified.
\end{proof}


In fact, the question of what unramified morphisms look like can be reduced to
the case where the ground ring is a \emph{field} in view of the previous and
the following result.
Given $\mathfrak{p} \in \spec R$, we let $k(\mathfrak{p})$ to be the residue
field of $R_{\mathfrak{p}}$.


\begin{proposition} \label{reduceunrtofield}
Let $\phi: R \to S$ be a morphism of finite type. Then $\phi$ is unramified if
and only if for every $\mathfrak{p} \in \spec R$, we have
\( k(\mathfrak{p}) \to S \otimes_R k(\mathfrak{p})  \)
unramified.
\end{proposition}
The classification of unramified extensions of a field is very simple, so this
will be useful.
\begin{proof}
One direction is clear by \cref{unrbasechange}. For the other, suppose
$k(\mathfrak{p}) \to S \otimes_R k(\mathfrak{p})$ unramified for all $\mathfrak{p} \subset R$.
We then know that
\( \Omega_{S/R} \otimes_R k(\mathfrak{p}) = \Omega_{S \otimes_R
k(\mathfrak{p})/k(\mathfrak{p})} = 0  \)
for all $\mathfrak{p}$. By localization, it follows that
\begin{equation} \label{auxdiff} \mathfrak{p}
\Omega_{S_{\mathfrak{q}}/R_{\mathfrak{p}}} =
\Omega_{S_{\mathfrak{q}}/R_{\mathfrak{p}}} = \Omega_{S_{\mathfrak{q}}/R}  \end{equation}
for any $\mathfrak{q} \in \spec S$ lying over $\mathfrak{p}$.

Let $\mathfrak{q} \in \spec S$. We will now show that
$(\Omega_{S/R})_{\mathfrak{q}} = 0$.
Given this, we will find that $\Omega_{S/R} =0$, which will prove the
assertion of the corollary.
Indeed, let $\mathfrak{p} \in \spec R$ be
the image of $\mathfrak{q}$, so that there is a \emph{local} homomorphism
$R_{\mathfrak{p}} \to S_{\mathfrak{q}}$. By \eqref{auxdiff}, we find that
\[ \mathfrak{q} \Omega_{S_{\mathfrak{q}}/R} = \Omega_{S_{\mathfrak{q}}/R}.  \]
and since $\Omega_{S_{\mathfrak{q}}/R}$ is a finite $S_{\mathfrak{q}}$-module
(\cref{finitelygeneratedOmega}),
Nakayama's lemma now implies that $\Omega_{S_{\mathfrak{q}}/R}=0$, proving
what we wanted.
\end{proof}


The following is simply a combination of the various results proved:
\begin{corollary}
\label{lemma-formally-unramified-localize}
Let $A \to B$ be a formally unramified ring map.
\begin{enumerate}
\item For $S \subset A$ a multiplicative subset,
$S^{-1}A \to S^{-1}B$ is formally unramified.
\item For $S \subset B$ a multiplicative subset,
$A \to S^{-1}B$ is formally unramified.
\end{enumerate}
\end{corollary}

\subsection{Unramified extensions of a field}
Motivated by \cref{reduceunrtofield}, we classify unramified morphisms out of a
field; we are going to see that these are just finite products of separable
extensions. Let us first consider the case when the field is \emph{algebraically
closed.}

\begin{proposition} \label{unrextalgclosedfld}
Suppose $k$ is algebraically closed. If $A$ is an unramified $k$-algebra, then
$A$ is a product of copies of $k$.
\end{proposition}
\begin{proof}
Let us
show first that $A$ is necessarily finite-dimensional.
If not,


So let us now assume that $A$ is finite-dimensional over $k$, hence \emph{artinian}.
Then $A$ is a direct product of artinian local $k$-algebras.
Each of these is unramified over $k$. So we need to study what local,
artinian, unramified extensions of $k$ look like; we shall show that any such
is isomorphic to $k$ with:

\begin{lemma}
A finite-dimensional, local $k$-algebra which is unramified over $k$ (for $k$
algebraically closed) is isomorphic to $k$.
\end{lemma}
\begin{proof}
First, if $\mathfrak{m} \subset A$ is the maximal ideal, then $\mathfrak{m}$
is nilpotent, and $A/\mathfrak{m}\simeq k$ by the Hilbert Nullstellensatz. Thus the ideal
$\mathfrak{M}=\mathfrak{m}
\otimes A + A \otimes \mathfrak{m} \subset A \otimes_k A$ is nilpotent and
$(A \otimes_k A)/\mathfrak{M} = k \otimes_k k = k$. In particular, $\mathfrak{M}$ is maximal and
$A \otimes_k A$ is also local.
(We could see this as follows: $A$ is associated to a one-point variety, so the
fibered product $\spec A \times_k \spec A$ is also associated to a one-point
variety. It really does matter that we are working  over an
algebraically closed field here!)

By assumption, $\Omega_{A/k} = 0$. So if $I = \ker(A \otimes_k A \to A)$, then
$I = I^2$.
 But from \cref{idemlemma}, we find that if  we had $I \neq 0$, then $\spec A \otimes_k A$
would be disconnected. This is clearly false (a local ring has no nontrivial
idempotents), so $I  = 0$ and
$A \otimes_k A \simeq A$. Since $A$ is finite-dimensional over $k$,
necessarily $A \simeq k$.
\end{proof}
\end{proof}

Now let us drop the assumption of algebraic closedness to get:

\begin{theorem} \label{unrfield}
An unramified $k$-algebra for $k$ any field is isomorphic to a product $\prod
k_i$ of finite separable extensions $k_i$ of $k$.
\end{theorem}
\begin{proof}
Let $k$ be a field, and $\overline{k}$ its algebraic closure. Let $A$ be an
unramified $k$-algebra. Then $A \otimes_k \overline{k}$ is an unramified
$\overline{k}$-algebra by \cref{unrbasechange}, so is a  finite product of copies of
$\overline{k}$.
It is thus natural that we need to study tensor products of fields to
understand this problem.

\begin{lemma} \label{productoffields}
Let $E/k$ be a finite extension, and $L/k$ any extension.
If $E/k$ is separable, then $L \otimes_k E$ is isomorphic (as a $L$-algebra) to a product of
copies of separable extensions of $L$.
\end{lemma}
\begin{proof}
By the primitive element theorem, we have $E = k(\alpha)$ for some $\alpha \in
E$ satisfying a separable irreducible polynomial $P \in k[X]$.
Thus
\[ E = k[X]/(P),  \]
so
\[ E \otimes_k L = L[X]/(P).  \]
But $P$ splits into several irreducible factors $\left\{P_i\right\}$ in
$L[X]$, no two of which are the same by separability.
Thus by the Chinese remainder theorem,
\[ E \otimes_k L = L(X)/(\prod P_i) = \prod L[X]/(P_i),  \]
and each $L[X]/(P_i)$ is a finite separable extension of $L$.
\end{proof}

As a result of this, we can easily deduce that any $k$-algebra of the form
$A=\prod k_i$ for the $k_i$ separable over $k$ is unramified.
Indeed, we have
\[ \Omega_{A/k}\otimes_k \overline{k} = \Omega_{A \otimes_k
\overline{k}/\overline{k}}, \]
so it suffices to prove that $A \otimes_k \overline{k}$ is unramified over
$\overline{k}$. However, from \cref{productoffields}, $A \otimes_k
\overline{k}$ is isomorphic as a $\overline{k}$-algebra to a product of copies
of $\overline{k}$. Thus $A \otimes_k \overline{k}$ is obviously unramified
over $\overline{k}$.

On the other hand, suppose $A/k$ is unramified. We shall show it is of the
form given as in the theorem. Then $A \otimes_k
\overline{k}$ is unramified over $\overline{k}$, so it follows by
\cref{unrextalgclosedfld} that $A$ is finite-dimensional over $k$. In
particular, $A$ is \emph{artinian}, and thus decomposes as a product of
finite-dimensional unramified $k$-algebras.

We are thus reduced to showing that a local, finite-dimensional $k$-algebra
that is unramified is a separable extension of $k$. Let $A$ be one such. Then
$A$ can have no nilpotents because then $A \otimes_k \overline{k}$ would have
nilpotents, and could not be isomorphic to a product of copies of
$\overline{k}$.
Thus the unique maximal ideal of $A$ is zero, and $A$ is a field.
We need only show that $A$ is separable over $k$. This is accomplished by:

\begin{lemma}
Let $E/k$ be a finite inseparable extension. Then $E \otimes_k \overline{k}$
contains nonzero nilpotents.
\end{lemma}

\begin{proof} There exists an $\alpha \in E$ which is inseparable over $k$,
i.e. whose minimal polynomial has multiple roots.
Let $E' = k(\alpha)$. We will show that $E' \otimes_k \overline{k}$ has
nonzero nilpotents; since the map $E' \otimes_k \overline{k} \to E \otimes_k
\overline{k}$ is an injection, we will be done.
Let $P$ be the minimal polynomial of $\alpha$, so that $E' = k[X]/(P)$.
Let $P = \prod P_i^{e_i}$ be the factorization of $P$ in $\overline{k}$ for
the $P_i \in \overline{k}[X]$ irreducible (i.e. linear). By
assumption, one of the $e_i$ is greater than one.
It follows that
\[ E' \otimes_k \overline{k} = \overline{k}[X]/(P) = \prod
\overline{k}[X]/(P_i^{e_i})  \]
has nilpotents corresponding to the $e_i$'s that are greater than one.
\end{proof}

\end{proof}
\begin{comment}
We now come to the result that explains why the present theory is connected
with Zariski's Main Theorem.
\begin{corollary} \label{unrisqf}
An unramified morphism $A \to B$ is quasi-finite.
\end{corollary}
\begin{proof}
Recall that a morphism of rings is \emph{quasi-finite} if the associated map
on spectra is. Equivalently, the morphism must be of finite type and have
finite fibers. But by assumption $A \to B$ is of finite type. Moreover, if
$\mathfrak{p} \in \spec A$ and $k(\mathfrak{p})$ is the residue field, then
$k(\mathfrak{p}) \to B \otimes_A k(\mathfrak{p})$ is \emph{finite} by the
above results, so the fibers are finite.
\end{proof}


\end{comment}


\subsection{Conormal modules and universal thickenings}
\label{section-conormal}

It turns out that one can define the first infinitesimal neighbourhood
not just for a closed immersion of schemes, but already for any formally
unramified morphism. This is based on the following algebraic fact.

\begin{lemma}
\label{lemma-universal-thickening}
Let $R \to S$ be a formally unramified ring map. There exists a surjection of
$R$-algebras $S' \to S$ whose kernel is an ideal of square zero with the
following universal property: Given any commutative diagram
$$
\xymatrix{
S \ar[r]_{a} & A/I \\
R \ar[r]^b \ar[u] & A \ar[u]
}
$$
where $I \subset A$ is an ideal of square zero, there is a unique $R$-algebra
map $a' : S' \to A$ such that $S' \to A \to A/I$ is equal to $S' \to S \to A$.
\end{lemma}

\begin{proof}
Choose a set of generators $z_i \in S$, $i \in I$ for $S$ as an $R$-algebra.
Let $P = R[\{x_i\_{i \in I}]$ denote the polynomial ring on generators
$x_i$, $i \in I$. Consider the $R$-algebra map $P \to S$ which maps
$x_i$ to $z_i$. Let $J = \text{Ker}(P \to S)$. Consider the map
$$
\text{d} : J/J^2 \longrightarrow \Omega_{P/R} \otimes_P S
$$
see
\rref{lemma-differential-seq}.
This is surjective since $\Omega_{S/R} = 0$ by assumption, see
\rref{lemma-characterize-formally-unramified}.
Note that $\Omega_{P/R}$ is free on $\text{d}x_i$, and hence the module
$\Omega_{P/R} \otimes_P S$ is free over $S$. Thus we may choose a splitting
of the surjection above and write
$$
J/J^2 = K \oplus \Omega_{P/R} \otimes_P S
$$
Let $J^2 \subset J' \subset J$ be the ideal of $P$ such that
$J'/J^2$ is the second summand in the decomposition above.
Set $S' = P/J'$. We obtain a short exact sequence
$$
0 \to J/J' \to S' \to S \to 0
$$
and we see that $J/J' \cong K$ is a square zero ideal in $S'$. Hence
$$
\xymatrix{
S \ar[r]_1 & S \\
R \ar[r] \ar[u] & S' \ar[u]
}
$$
is a diagram as above. In fact we claim that this is an initial object in
the category of diagrams. Namely, let $(I \subset A, a, b)$ be an arbitrary
diagram. We may choose an $R$-algebra map $\beta : P \to A$ such that
$$
\xymatrix{
S \ar[r]_1 & S \ar[r]_a & A/I \\
R \ar[r] \ar@/_/[rr]_b \ar[u] & P \ar[u] \ar[r]^\beta & A \ar[u]
}
$$
is commutative. Now it may not be the case that $\beta(J') = 0$, in other
words it may not be true that $\beta$ factors through $S' = P/J'$.
But what is clear is that $\beta(J') \subset I$ and
since $\beta(J) \subset I$ and $I^2 = 0$ we have $\beta(J^2) = 0$.
Thus the ``obstruction'' to finding a morphism from
$(J/J' \subset S', 1, R \to S')$ to $(I \subset A, a, b)$ is
the corresponding $S$-linear map $\overline{\beta} : J'/J^2 \to I$.
The choice in picking $\beta$ lies in the choice of $\beta(x_i)$.
A different choice of $\beta$, say $\beta'$, is gotten by taking
$\beta'(x_i) = \beta(x_i) + \delta_i$ with $\delta_i \in I$.
In this case, for $g \in J'$, we obtain
$$
\beta'(g) =
\beta(g) + \sum\nolimits_i \delta_i \frac{\partial g}{\partial x_i}.
$$
Since the map $\text{d}|_{J'/J^2} : J'/J^2 \to \Omega_{P/R} \otimes_P S$
given by $g \mapsto \frac{\partial g}{\partial x_i}\text{d}x_i$
is an isomorphism by construction, we see that there is a unique choice
of $\delta_i \in I$ such that $\beta'(g) = 0$ for all $g \in J'$.
(Namely, $\delta_i$ is $-\overline{\beta}(g)$ where $g \in J'/J^2$
is the unique element with $\frac{\partial g}{\partial x_j} = 1$ if
$i = j$ and $0$ else.) The uniqueness of the solution implies the
uniqueness required in the lemma.
\end{proof}

\noindent
In the situation of
\rref{lemma-universal-thickening}
the $R$-algebra map $S' \to S$ is unique up to unique isomorphism.

\begin{definition}
\label{definition-universal-thickening}
Let $R \to S$ be a formally unramified ring map.
\begin{enumerate}
\item The {\it universal first order thickening} of $S$ over $R$ is
the surjection of $R$-algebras $S' \to S$ of
\rref{lemma-universal-thickening}.
\item The {\it conormal module} of $R \to S$ is the kernel $I$ of the
universal first order thickening $S' \to S$, seen as a $S$-module.
\end{enumerate}
We often denote the conormal module {\it $C_{S/R}$} in this situation.
\end{definition}

\begin{lemma}
\label{lemma-universal-thickening-quotient}
Let $I \subset R$ be an ideal of a ring.
The universal first order thickening of $R/I$ over $R$
is the surjection $R/I^2 \to R/I$. The conormal module
of $R/I$ over $R$ is $C_{(R/I)/R} = I/I^2$.
\end{lemma}

\begin{proof}
Omitted.
\end{proof}

\begin{lemma}
\label{lemma-universal-thickening-localize}
Let $A \to B$ be a formally unramified ring map.
Let $\varphi : B' \to B$ be the universal first order thickening of
$B$ over $A$.
\begin{enumerate}
\item Let $S \subset A$ be a multiplicative subset.
Then $S^{-1}B' \to S^{-1}B$ is the universal first order thickening of
$S^{-1}B$ over $S^{-1}A$. In particular $S^{-1}C_{B/A} = C_{S^{-1}B/S^{-1}A}$.
\item Let $S \subset B$ be a multiplicative subset.
Then $S' = \varphi^{-1}(S)$ is a multiplicative subset in $B'$
and $(S')^{-1}B' \to S^{-1}B$ is the universal first order thickening
of $S^{-1}B$ over $A$. In particular $S^{-1}C_{B/A} = C_{S^{-1}B/A}$.
\end{enumerate}
Note that the lemma makes sense by
\rref{lemma-formally-unramified-localize}.
\end{lemma}

\begin{proof}
With notation and assumptions as in (1). Let $(S^{-1}B)' \to S^{-1}B$
be the universal first order thickening of $S^{-1}B$ over $S^{-1}A$.
Note that $S^{-1}B' \to S^{-1}B$ is a surjection of $S^{-1}A$-algebras
whose kernel has square zero. Hence by definition we obtain a map
$(S^{-1}B)' \to S^{-1}B'$ compatible with the maps towards $S^{-1}B$.
Consider any commutative diagram
$$
\xymatrix{
B \ar[r] & S^{-1}B \ar[r] & D/I \\
A \ar[r] \ar[u] & S^{-1}A \ar[r] \ar[u] & D \ar[u]
}
$$
where $I \subset D$ is an ideal of square zero. Since $B'$ is the universal
first order thickening of $B$ over $A$ we obtain an $A$-algebra map
$B' \to D$. But it is clear that the image of $S$ in $D$ is mapped to
invertible elements of $D$, and hence we obtain a compatible map
$S^{-1}B' \to D$. Applying this to $D = (S^{-1}B)'$ we see that we get
a map $S^{-1}B' \to (S^{-1}B)'$. We omit the verification that this map
is inverse to the map described above.

\medskip\noindent
With notation and assumptions as in (2). Let $(S^{-1}B)' \to S^{-1}B$
be the universal first order thickening of $S^{-1}B$ over $A$.
Note that $(S')^{-1}B' \to S^{-1}B$ is a surjection of $A$-algebras
whose kernel has square zero. Hence by definition we obtain a map
$(S^{-1}B)' \to (S')^{-1}B'$ compatible with the maps towards $S^{-1}B$.
Consider any commutative diagram
$$
\xymatrix{
B \ar[r] & S^{-1}B \ar[r] & D/I \\
A \ar[r] \ar[u] & A \ar[r] \ar[u] & D \ar[u]
}
$$
where $I \subset D$ is an ideal of square zero. Since $B'$ is the universal
first order thickening of $B$ over $A$ we obtain an $A$-algebra map
$B' \to D$. But it is clear that the image of $S'$ in $D$ is mapped to
invertible elements of $D$, and hence we obtain a compatible map
$(S')^{-1}B' \to D$. Applying this to $D = (S^{-1}B)'$ we see that we get
a map $(S')^{-1}B' \to (S^{-1}B)'$. We omit the verification that this map
is inverse to the map described above.
\end{proof}

\begin{lemma}
\label{lemma-differentials-universal-thickening}
Let $R \to A  \to B$ be ring maps. Assume $A \to B$ formally unramified.
Let $B' \to B$ be the universal first order thickening of $B$ over $A$.
Then $B'$ is formally unramified over $A$, and the canonical map
$\Omega_{A/R} \otimes_A B \to \Omega_{B'/R} \otimes_{B'} B$ is an
isomorphism.
\end{lemma}

\begin{proof}
We are going to use the construction of $B'$ from the proof of
\rref{lemma-universal-thickening}
allthough in principle it should be possible to deduce these results
formally from the definition. Namely, we choose a presentation
$B = P/J$, where $P = A[x_i]$ is a polynomial ring over $A$.
Next, we choose elements $f_i \in J$ such that
$\text{d}f_i = \text{d}x_i \otimes 1$ in $\Omega_{P/A} \otimes_P B$.
Having made these choices we have
$B' = P/J'$ with $J' = (f_i) + J^2$, see proof of
\rref{lemma-universal-thickening}.

\medskip\noindent
Consider the canonical exact sequence
$$
J'/(J')^2 \to \Omega_{P/A} \otimes_P B' \to \Omega_{B'/A} \to 0
$$
see
\rref{lemma-differential-seq}.
By construction the classes of the $f_i \in J'$ map to elements of
the module $\Omega_{P/A} \otimes_P B'$ which generate it modulo
$J'/J^2$ by construction. Since $J'/J^2$ is a nilpotent ideal, we see
that these elements generate the module alltogether (by
Nakayama's \rref{lemma-NAK}). This proves that $\Omega_{B'/A} = 0$
and hence that $B'$ is formally unramified over $A$, see
\rref{lemma-characterize-formally-unramified}.

\medskip\noindent
Since $P$ is a polynomial ring over $A$ we have
$\Omega_{P/R} = \Omega_{A/R} \otimes_A P \oplus \bigoplus P\text{d}x_i$.
We are going to use this decomposition.
Consider the following exact sequence
$$
J'/(J')^2 \to
\Omega_{P/R} \otimes_P B' \to
\Omega_{B'/R} \to 0
$$
see
\rref{lemma-differential-seq}.
We may tensor this with $B$ and obtain the exact sequence
$$
J'/(J')^2 \otimes_{B'} B \to
\Omega_{P/R} \otimes_P B \to
\Omega_{B'/R} \otimes_{B'} B \to 0
$$
If we remember that $J' = (f_i) + J^2$
then we see that the first arrow annihilates the submodule $J^2/(J')^2$.
In terms of the direct sum decomposition
$\Omega_{P/R} \otimes_P B =
\Omega_{A/R} \otimes_A B \oplus \bigoplus B\text{d}x_i $ given
we see that the submodule $(f_i)/(J')^2 \otimes_{B'} B$ maps
isomorphically onto the summand $\bigoplus B\text{d}x_i$. Hence what is
left of this exact sequence is an isomorphism
$\Omega_{A/R} \otimes_A B \to \Omega_{B'/R} \otimes_{B'} B$
as desired.
\end{proof}


\section{Smooth morphisms}

\subsection{Definition}
The idea of a \emph{smooth} morphism in algebraic geometry is one that is
surjective on the tangent space, at least if one is working with smooth
varieties over an algebraically closed field. So this means that one should be
able to lift tangent vectors, which are given by maps from the ring into
$k[\epsilon]/\epsilon^2$.

This makes the following definition seem more plausible:

\begin{definition}
Let $S$ be an $R$-algebra. Then $S$ is \textbf{formally smooth} over $R$ (or
the map $R \to S$ is formally smooth) if given any
$R$-algebra $A$ and ideal $I \subset A $ of square zero, the map
\[ \hom_R(S, A) \to \hom_R(S, A/I)\]
is a surjection.
We shall say that $S$ is \textbf{smooth} (over $R$) if it is formally smooth and of finite
presentation.
\end{definition}

So this means that in any diagram
$$
\xymatrix{
S \ar[r] \ar@{-->}[rd] & A/I \\
R \ar[r] \ar[u] & A, \ar[u]
}
$$
with $I$ an ideal of square zero in $A$, there exists a dotted arrow making the diagram commute.
As with formal unramifiedness, this is a purely functorial statement: if $F$ is
the corepresentable functor associated to $S$, then we want $F(A) \to F(A/I)$
to be a \emph{surjection} for each $I \subset A$ of square zero and each
$R$-algebra $A$. Also, again we can replace ``$I$ of square zero'' with ``$I$
nilpotent.''


\begin{example}
The basic example of a formally smooth $R$-algebra is the polynomial ring
$R[x_1, \dots, x_n]$. For to give a map $R[x_1, \dots, x_n] \to A/I$ is to give
$n$ elements of $A/I$; each of these elements can clearly be lifted to $A$.
This is analogous to the statement that a free module is projective.

More generally, if $P$ is a projective $R$-module (not necessarily of finite
type), then the symmetric algebra $\Sym P$ is a formally smooth $R$-algebra.
This follows by the same reasoning.
\end{example}

We can state the usual list of properties of formally smooth morphisms:

\begin{proposition}
\label{smoothsorite}
Smooth (resp. formally smooth) morphisms are preserved under base extension and
composition.
If $R$ is a ring, then any localization  is formally smooth over $R$.
\end{proposition}
\begin{proof}  As usual, only the statements about \emph{formal} smoothness are
interesting.
The statements about base extension and composition will be mostly left to the reader:
they are an exercise in diagram-chasing. (Note that we cannot argue as we did
for formally unramified morphisms, where we had a simple criterion in terms of
the module of K\"ahler differentials and various properties of them.)
For example, let $R \to S, S \to T$ be formally smooth.
Given a diagram (with $I \subset A$ an ideal of square zero)
\[ \xymatrix{
T \ar[r]  \ar@{-->}[rdd]  & A/I \\
S  \ar[u] \ar@{-->}[rd] & \\
R \ar[r] \ar[u] & A, \ar[uu]
}\]
we start by finding a dotted arrow $S \to A$ by using formal smoothness of $R
\to S$. Then we find a dotted arrow $T \to A$ making the top quadrilateral
commute. This proves that the composite is formally smooth.
\end{proof}
\subsection{Quotients of formally smooth rings}

Now, ultimately, we want to show that this somewhat abstract definition of
smoothness will give us something nice and geometric. In particular, in this case we want to show
that $B$ is \emph{flat,} and the fibers are smooth varieties (in the old sense).
To do this, we will need to do a bit of work, but we can argue in a fairly
elementary manner. On the one hand, we will first need to give a criterion for when a
quotient of a formally smooth ring is formally smooth.



\begin{theorem}
\label{smoothconormal}
Let $A$ be a ring, $B$ an $A$-algebra. Suppose $B$ is formally smooth over $A$,
and let $I \subset B$ be an ideal.
Then $C = B/I$ is a formally smooth $A$-algebra if and only if the canonical map
\[ I/I^2 \to \Omega_{B/A} \otimes_B C  \]
has a section.
In other words, $C$ is formally smooth precisely when the conormal sequence
\[  I/I^2 \to \Omega_{B/A} \otimes_B C \to \Omega_{C/A} \to 0 \]
is split exact.
\end{theorem}

This result is stated in more generality  for \emph{topological} rings, and uses
some functors on ring extensions, in \cite{EGA}, 0-IV, 22.6.1.

\begin{proof}
Suppose first $C$ is formally smooth over $A$.
Then we have a map
\( B/I^2 \to C  \)
given by the quotient. The claim is that there is a section of this map.
There is a diagram of $A$-algebras
\[ \xymatrix{
B/I & \ar[l] B/I^2 \\
C \ar[u]^{=} \ar@{-->}[ru]
}\]
and the lifting $s: C \to B/I^2$ exists by formal smoothness.
This is a section of the natural projection $B/I^2 \to C = B/I$.


In particular, the combination of the natural inclusion $I/I^2 \to B/I^2$ and
the section $s$ gives an isomorphism  of \emph{rings} (even $A$-algebras)
\( B/I^2 \simeq C \oplus I/I^2 . \)
Here $I/I^2$ squares to zero.

We are interested in showing that $I/I^2 \to \Omega_{B/A} \otimes_B C$ is a
split injection of $C$-modules. To see this, we will show that any map out of the former
extends to a map out of the latter.
Now suppose given a map
of $C$-modules
\[ \phi:  I/I^2 \to M \]
into a $C$-module $M$.
Then we get an $A$-derivation
\[ \delta:  B/I^2 \to M  \]
by using the splitting $B/I^2 = C \oplus I/I^2$.
(Namely, we just extend the map by zero on $C$.)
Since $I/I^2$ is imbedded in $B/I^2$ by the canonical injection, this
derivation restricts on $I/I^2$ to $\phi$. In other words there is a
commutative diagram
\[ \xymatrix{
I/I^2 \ar[d]^{\phi}  \ar[r] &  B/I^2 \ar[ld]^{\delta} \\
M
}.\]
It follows thus that we may define, by pulling back, an $A$-derivation $B \to
M$ that restricts on $I$ to the map $I \to I/I^2 \stackrel{\phi}{\to} M$.
By the universal property of the differentials, this is the same thing as a
homomorphism $\Omega_{B/A} \to M$, or equivalently $\Omega_{B/A} \otimes_B C
\to M$ since $M$ is a $C$-module.
Pulling back this derivation to $I/I^2$ corresponds to pulling back via $I/I^2
\to \Omega_{B/A} \otimes_B C$.

It follows that the map
\[ \hom_C(\Omega_{B/A} \otimes_B C, M) \to \hom_C(I/I^2, M)  \]
is a surjection. This proves one half of the result.

Now for the other.
Suppose that there is a section of the conormal map.
This translates, as above, to saying that
any map $I/I^2 \to M$  (of $C$-modules) for a $C$-module $M$
 can be extended to an $A$-derivation $B \to M$.
We must deduce from this formal smoothness.

Let $E$ be any $A$-algebra, and $J \subset E$
an ideal of square zero.
We suppose given an $A$-homomorphism $C \to E/J$
and would like to lift it to $C \to E$; in other words, we must
find a lift in the diagram
\[ \xymatrix{
& C \ar@{-->}[ld] \ar[d]  \\
E \ar[r] & E/J
}.\]
Let us pull this map back by the surjection
$B \twoheadrightarrow C$; we get a diagram
\[ \xymatrix{
& B \ar@{-->}[ldd]^{\phi}\ar[d] \\
& C \ar@{-->}[ld] \ar[d]  \\
E \ar[r] & E/J
}.\]
In this diagram, we know that a lifting $\phi: B \to E$ does exist because $B$ is
formally smooth over $A$.
So we can find a dotted arrow from $B \to E$ in the diagram.
The problem is that it might not send
$I = \ker(B \to C) $ into zero.
If we can show that there \emph{exists} a lifting that does factor through $C$
(i.e. sends $I$ to zero), then we are done.

In any event, we have a morphism of $A$-modules
$  I \to E$  given by restricting $\phi: B \to E$.
This lands in $J$, so we get a map $I \to J$. Note that $J$ is an $E/J$-module,
hence a $C$-module, because $J$ has square zero. Moreover $I^2$ gets sent to
zero because $J^2 = 0$, and we have a morphism of
$C$-modules $I/I^2 \to J$.
Now by hypothesis, there is an $A$-derivation
$\delta: B \to J$ such that $\delta|_I = \phi$.
Since $J$ has square zero, it follows that
\[ \phi - \delta: B \to E  \]
is an $A$-homomorphism of algebras, and it kills $I$.
Consequently this factors through $C$ and gives the desired lifting $C \to E$.



\end{proof}

\begin{corollary} \label{fsOmegaprojective}
If $A \to B$ is formally smooth, then
$\Omega_{B/A}$ is a projective $B$-module.
\end{corollary}
The intuition is that projective modules correspond to vector bundles
over the $\spec$ (unlike general modules, the rank is locally constant,
which should happen in a vector bundle). But a smooth algebra is like a
manifold, and for a manifold the cotangent bundle is very much a vector
bundle, whose dimension is locally constant.
\begin{proof}
Indeed, we can write $B$ as a quotient of a polynomial ring $D$ over $A$; this
is formally smooth. Suppose $B = D/I$.
Then we know that there is a split exact sequence
\[ 0 \to I/I^2 \to \Omega_{D/A} \otimes_D B \to \Omega_{B/A} \to 0.  \]
But the middle term is free as $D/A$ is a polynomial ring; hence the last term
is projective.
\end{proof}

In particular, we can rewrite the criterion for formal smoothness of $C= B/I$,
if $B$ is formally smooth over $A$:
\begin{enumerate}
\item $\Omega_{C/A} $ is a projective $C$-module.
\item $I/I^2 \to \Omega_{B/A} \otimes_B C$ is a monomorphism.
\end{enumerate}
Indeed, these two are equivalent to the splitting of the conormal sequence
(since the middle term is always projective by \cref{fsOmegaprojective}).

In particular, we can check that smoothness is \emph{local}:
\begin{corollary} \label{fsislocal}
Let $A$ be a ring, $B$ a finitely presented $A$-algebra. Then $B$ is smooth
over $A$ if and only if for each $\mathfrak{q} \in \spec B$ with $\mathfrak{p}
\in \spec A$ the inverse image, the map $A_{\mathfrak{p}} \to B_{\mathfrak{q}}$
is formally smooth.
\end{corollary}
\begin{proof}
Indeed, we see that $B = D/I$ for a polynomial ring $D = A[x_1,\dots, x_n]$ in finitely many
variables, and $I \subset D$ a finitely generated ideal.
We have just seen that we just need to check that the conormal map $I/I^2 \to
\Omega_{D/A} \otimes_D B$ is injective, and that $\Omega_{B/A}$ is a projective
$B$-module, if and only if the analogs hold over the localizations. This
follows by the criterion for formal smoothness just given above.

But both can be checked locally. Namely, the conormal map is an injection if
and only if, for all $\mathfrak{q} \in \spec B$ corresponding to $\mathfrak{Q}
\in \spec D$, the map $(I/I^2)_{\mathfrak{q}} \to
\Omega_{D_{\mathfrak{Q}}/A_{\mathfrak{p}}} \otimes_{D_{\mathfrak{Q}}}
B_{\mathfrak{q}}$ is an injection.
Moreover, we know that for a finitely presented module over a  ring,
like $\Omega_{B/A}$, projectivity is equivalent to projectivity (or freeness) of all the stalks
(\cref{}). So we can check projectivity on the localizations too.
\end{proof}

In fact, the method of proof of \cref{fsislocal} yields the following
observation: \emph{formal} smoothness ``descends'' under faithfully flat base change.
That is:
\begin{corollary}
If $B$ is an $A$-algebra, and $A'$ a faithfully flat algebra, then $B$ is
formally smooth over $A$ if and only if $B \otimes_A A'$ is formally smooth
over $A'$.
\end{corollary}
We shall not give a complete proof, except in the case when $B$ is finitely
presented over $A$ (so that the question is of smoothness).
\begin{proof}
One direction is  just the ``sorite'' (see \cref{}). We want to show that
formal smoothness ``descends.''
The claim is that the two conditions for formal smoothness above (that
$\Omega_{B/A}$ be projective and the conormal map be a monomorphism) descend
under faithfully flat base-change. Namely, the fact about the conormal maps is
clear (by faithful flatness).

Now let $B' = B \otimes_A A'$.
So we need to argue that if $\Omega_{B'/A'} = \Omega_{B/A} \otimes_B
B'$ is projective as a $B'$-module, then so is $\Omega_{B/A}$. Here we use the
famous result of Raynaud-Gruson (see \cite{RG71}), which states that
projectivity descends under faithfully flat extensions, to complete the proof.

If $B$ is finitely presented over $A$, then $\Omega_{B/A}$ is finitely
presented as a $B$-module.
We can run most of the same proof as before, but we want to avoid using the
Raynaud-Gruson theorem: we must give a separate argument that $\Omega_{B/A}$ is
projective if $\Omega_{B'/A'}$ is. However, for a finitely presented module,
projectivity is \emph{equivalent} to flatness, by \cref{fpflatmeansprojective}. Moreover, since $\Omega_{B'/A'}$
is $B'$-flat, faithful flatness enables us to conclude that $\Omega_{B/A}$ is
$B$-flat, and hence projective.
\end{proof}



\subsection{The Jacobian criterion}


Now we want  a characterization of when a morphism is smooth. Let us
motivate this with an analogy from standard differential topology.
Consider real-valued functions $f_1, \dots, f_p \in C^{\infty}(\mathbb{R}^n)$.
Now, if $f_1, f_2, \dots, f_p$ are such that their gradients $\nabla f_i$ form a
matrix of rank $p$, then we can define a manifold near zero
which is the common zero set of all the $f_i$.
We are going to give a relative version of this in the algebraic setting.



Recall that a map of rings $A \to B$ is \emph{essentially of finite
presentation} if $B$ is the localization of a finitely presented $A$-algebra.


\begin{proposition} \label{smoothjac}
Let $(A, \mathfrak{m}) \to (B, \mathfrak{n})$ be a local homomorphism of local
rings such that $B$ is essentially of finite presentation.
Suppose $B = (A[X_1, \dots, X_n])_{\mathfrak{q}}/I$ for some finitely generated
ideal $I \subset A[X_1, \dots, X_n]_{\mathfrak{q}}$, where $\mathfrak{q}$ is a
prime ideal in the polynomial ring.

Then $I/I^2$ is generated as a $B$-module by polynomials
$f_1, \dots, f_k \in I \subset A[X_1, \dots, X_n]$ whose Jacobian matrix has maximal rank
in $C/\mathfrak{q} = B/\mathfrak{n}$ if and only if $B$ is formally smooth over $A$.
In this case, $I/I^2$ is even freely generated by the $f_i$.
\end{proposition}

The Jacobian matrix $\frac{\partial f_i}{\partial X_j}$ is a matrix of
elements of $A[X_1, \dots, X_n]$, and we can take the associated images in
$B/\mathfrak{n}$.

\begin{example}
Suppose $A$ is an algebraically closed field $k$.
Then $I$ corresponds to some ideal in the polynomial ring $k[X_1, \dots,
X_n]$, which cuts out a variety $X$.
Suppose $\mathfrak{q}$ is a maximal ideal in the polynomial ring.

Then $B$ is the  local
ring of the  algebraic variety $X$ at $\mathfrak{q}$.
Then \cref{smoothjac} states that $\mathfrak{q}$ is  a ``smooth point''
of the variety (i.e., the Jacobian matrix has maximal rank) if and only if
$B$ is formally smooth over $k$.
We will expand on this later.
\end{example}


\begin{proof}
Indeed, we know that polynomial rings are formally smooth.
In particular $D = A[X_1, \dots, X_n]_{\mathfrak{q}}$ is formally smooth over
$A$, because localization preserves formal smoothness.  Note also that $\Omega_{D/A}$ is a free $D$-module, because
this is true for a polynomial ring and K\"ahler differentials commute with
localization.

So \cref{smoothconormal} implies that
\[ I/I^2 \to \Omega_{D/A} \otimes_D B  \]
is a split injection precisely when $B$ is formally smooth over $A$. Suppose
that this holds.
Now $I/I^2$ is then a summand of the free module $\Omega_{D/A} \otimes_D B$, so it
is projective, hence free as $B$ is local.
Let $K = B/\mathfrak{n}$. It follows that the map
\[ I/I^2 \otimes_D K \to \Omega_{D/A} \otimes_D  K = K^n \]
is an injection. This map sends a polynomial to its gradient (reduced
modulo $\mathfrak{q}$, or $\mathfrak{n}$). Hence the assertion is
clear: choose polynomials $f_1, \dots, f_k \in I$ that generate
$(I/I^2)_{\mathfrak{q}}$, and their gradients in $B/\mathfrak{n}$ must be
linearly independent.

Conversely, suppose that $I/I^2$ has such generators.
Then the map
\[ I/I^2 \otimes K \to K^n, \quad f\mapsto df  \]
is a split injection.
However, if a map of finitely generated modules over a local ring, with the
target free, is such that tensoring with
the residue field makes it an injection, then it is a split injection. (We
shall prove this below.) Thus $I/I^2 \to \Omega_{D/A} \otimes_D B$ is a split
injection. In view
of the criterion for formal smoothness, we find that $B$ is formally smooth.
\end{proof}

Here is the promised lemma necessary to complete the proof:
\begin{lemma}
\label{splitinjreduce}
If $(A, \mathfrak{m})$ is a local ring with residue field $k$, $M$ a finitely
generated $A$-module, $N$ a finitely
generated projective $A$-module, then a map
\( \phi: M \to N  \)
is a split injection if and only if
\(M \otimes_A k \to N \otimes_A k  \)
is an injection.
\end{lemma}
\begin{proof}
One direction is clear, so it suffices to show that $M \to N$ is a split
injection if the map on fibers is an injection.


Let $L$ be a ``free approximation'' to $M$, that is, a free module $L$ together
with a map $L \to M$ which is an isomorphism modulo $k$. By Nakayama's lemma,
$L \to M$ is surjective.
Then the map
$L \to M \to N$ is such that the $L \otimes k \to N \otimes k$ is injective, so
$L \to N$ is a split injection (by an elementary criterion).
It follows that we can find a splitting $N \to L$, which when composed with $L
\to M$ is a splitting of $M \to N$.
\end{proof}

\subsection{The fiberwise criterion for smoothness}

We shall now prove that a smooth morphism is flat. In fact, we will get
a general ``fiberwise'' criterion for smoothness (i.e., a morphism is smooth
if and only if it is flat and the fibers are smooth), which will enable
us to reduce smoothness questions, in some cases, to the situation where the
base is a field.

We shall need some lemmas on regular sequences.
The first will give a useful criterion for checking $M$-regularity of an
element by checking on the fiber.
For our purposes, it will also give a criterion for when quotienting by a
regular element preserves flatness over a smaller ring.

\begin{lemma}
Let $(A, \mathfrak{m}) \to (B, \mathfrak{n})$ be a local homomorphism
of local noetherian
rings.
Let $M$ be a finitely generated $B$-module, which is flat over $A$.

Let $f \in B$. Then the following are equivalent:
\begin{enumerate}
\item $M/fM$ is flat over $A$ and $f: M \to M$ is injective.
\item $f: M \otimes_A k \to M \otimes_A k$ is injective where $k = A/\mathfrak{m}$.
\end{enumerate}
\end{lemma}

For instance, let us consider the case $M = B$. The lemma states that if
multiplication by $f$ is regular on $B \otimes_A k$, then the hypersurface cut
out by $f$ (i.e., corresponding to the ring $B/fB$) is flat over $A$.

\begin{proof} All $\tor$ functors here will be over $A$.
If $M/fM$ is $A$-flat and $f: M \to M$ is injective, then the sequence
\[ 0 \to M \stackrel{f}{\to} M \to M/fM \to 0 \]
leads to a long exact sequence
\[ \tor_1(k, M/fM) \to M \otimes_A k \stackrel{f}{\to} M \otimes_A k \to (M/fM)
\otimes_A k \to 0. \]
But since $M/fM$ is flat, the first term is zero, and  it follows that $M \otimes k \stackrel{f}{\to} M
\otimes k$ is injective.

The other direction is more subtle. Suppose multiplication by $f$ is a
monomorphism on $M \otimes_A k$. Now write the exact sequence
\[ 0 \to P \to M \stackrel{f}{\to} M \to Q \to 0 \]
where $P, Q$ are the kernel and cokernel. We want to show that $P = 0$
and $Q$ is flat over $A$.

We can also consider the image $I = fM \subset M$, to split this into two
exact sequences
\[ 0 \to P \to M \to I \to 0  \]
and
\[ 0 \to I \to M \to Q \to 0.  \]
Here the map $M \otimes_A k \to I \otimes_A k \to M \otimes_A k$ is given by
multiplication by $f$, so it is injective by hypothesis. This implies
that $M \otimes_A k \to I
\otimes_A k$ is injective. So $M \otimes k \to I \otimes k$ is actually an isomorphism because it
is obviously surjective, and we have just seen it is injective.
Moreover, $I \otimes_A k \to M \otimes_A k$ is isomorphic to the
homothety $f: M \otimes_A k \to M \otimes_A k$, and consequently is
injective.
To summarize:
\begin{enumerate}
\item $M \otimes_A k \to I \otimes_A k$ is an isomorphism.
\item $I \otimes_A k \to M \otimes_A k$ is an injection.
\end{enumerate}

Let us tensor these two exact sequences with $k$. We get
\[ 0 \to  \tor_1(k, I) \to P \otimes_A k \to M  \otimes_A k \to I \otimes_A k \to 0   \]
because $M$ is flat. We also get
\[ 0 \to  \tor_1(k, Q) \to I \otimes_A k \to M  \otimes_A k \to Q \otimes_A k \to 0
.\]
We'll start by using the second sequence. Now $I \otimes_A k \to M
\otimes_A k$
was just said to be injective, so that $\tor_1(k, Q) = 0$. By the local
criterion for flatness, it follows that $Q$ is a flat
$A$-module as well.
But $Q = M/fM$, so this gives one part of what we wanted.

Now, we want to show finally that $P = 0$.
Now, $I$ is flat; indeed, it is the kernel of a surjection of flat maps $M \to
Q$, so the long exact sequence shows that it is flat. So we have a short exact
sequence
\[ 0 \to P \otimes_A k \to M \otimes_A k \to I \otimes_A k \to 0,  \]
which shows now that $P \otimes_A k  = 0$ (as $M \otimes_A k \to I \otimes_A k$ was
just shown to be an isomorphism earlier). By Nakayama $P = 0$.
This implies that $f$ is $M$-regular.
\end{proof}

\begin{corollary} \label{regseqflat} Let $(A, \mathfrak{m}) \to (B, \mathfrak{n})$ be a morphism
of noetherian local rings.
Suppose $M$ is a finitely generated $B$-module, which is flat over $A$.

Let $f_1, \dots, f_k \in \mathfrak{n}$. Suppose that $f_1, \dots, f_k$ is a
regular sequence on $M \otimes_A k$. Then it is a regular sequence on $M$ and,
in fact, $M/(f_1, \dots, f_k ) M$ is flat over $A$.
\end{corollary}
\begin{proof}
This is now clear by induction.
\end{proof}


\begin{theorem}\label{smoothflat1} Let $(A, \mathfrak{m}) \to (B, \mathfrak{n})$ be
a morphism of local  rings such that $B$ is the localization of
a finitely presented $A$-algebra at a prime
ideal, $B = (A[X_1, \dots, X_n])_{\mathfrak{q}}/I$. Then if $A \to B$ is formally smooth, $B$ is a flat $A$-algebra.
\end{theorem}

The strategy is that $B$ is going to be written as the quotient of a
localization of a  polynomial
ring by a sequence $\left\{f_i\right\}$
whose gradients are independent (modulo the maximal ideal), i.e. modulo
$B/\mathfrak{n}$.
If we were working modulo a field, then we could use arguments about regular
local rings to argue that the $\left\{f_i\right\}$ formed a regular
sequence. We will use \cref{regseqflat} to bootstrap from this case to the
general situation.

\begin{proof}
Let us first assume that $A$ is \emph{noetherian.}

Let $C = (A[X_1, \dots, X_n])_{\mathfrak{q}}$. Then $C$ is a local ring,
smooth over $A$, and we have morphisms of local rings
\[ (A, \mathfrak{m}) \to (C, \mathfrak{q}) \twoheadrightarrow (B,
\mathfrak{n}).  \]
Moroever, $C$ is a \emph{flat} $A$-module, and we are going to apply the
fiberwise criterion for regularity to $C$ and a suitable sequence.

Now we know that $I/I^2$ is a $B$-module generated by polynomials $f_1,
\dots, f_m
\in A[X_1, \dots, X_n]$
whose Jacobian matrix has maximal rank in $B/\mathfrak{n}$ (by the Jacobian
criterion, \cref{smoothjac}).
The claim is that the $f_i$ are linearly independent in
$\mathfrak{q}/\mathfrak{q}^2$. This will be the first key step in the proof.
In other words, if $\left\{u_i\right\}$ is a family of elements of $C$, not all
non-units, we do not have
\[ \sum u_i f_i \in \mathfrak{q}^2.  \]
For if we did, then we could take derivatives
and find
\[ \sum u_i \partial_j f_i \in \mathfrak{q}  \]
for each $j$. This contradicts the gradients of the $f_i$ being linearly
independent in $B/\mathfrak{n} = C/\mathfrak{q}$.

Now we want to show that the $\left\{f_i\right\}$ form a regular sequence in
$C$. To do this, we shall reduce to the case where $A$ is a field. Indeed, let
us make the base-change $A \to k = A/\mathfrak{m}, B \to \overline{B} = B
\otimes_A k, C \to \overline{C}=C \otimes_A k$ where $k  =
A/\mathfrak{m}$ is the residue field.
Then $\overline{B},\overline{C}$ are  formally smooth local rings over a
field $k$. We also know that $\overline{C}$ is a \emph{regular} local ring,
since it is a localization of a polynomial ring over a field.


Let us denote the maximal ideal of
$\overline{C}$ by
$\overline{\mathfrak{q}}$; this is just the image of $\mathfrak{q}$.


Now the $\left\{f_i\right\}$ have images in $\overline{C}$ that are linearly
independent
in $\overline{\mathfrak{q}}/\overline{\mathfrak{q}}^2 =
\mathfrak{q}/\mathfrak{q}^2$. It follows that the $\left\{f_i\right\}$ form a
regular sequence in $\overline{C}$, by general facts about regular local
rings (see, e.g. \cref{quotientreg44}); indeed, each of the successive quotients $\overline{C}/(f_1, \dots,
f_i)$ will then be regular.
It follows from the fiberwise criterion ($C$ being flat) that the
$\left\{f_i\right\}$ form a regular sequence in $C$ itself, and that the
quotient $C/(f_i) = B$ is $A$-flat.
\end{proof}

The proof in fact showed a bit more: we expressed $B$ as the quotient of a
localized
polynomial ring by a regular sequence.
In other words:

\begin{corollary}[Smooth maps are local complete intersections]
Let $(A, \mathfrak{m}) \to (B, \mathfrak{n})$ be an essentially of
finite presentation, formally smooth map. Then there exists a localization
of a polynomial ring, $C$, such that $B$ can be expressed as
$C/(f_1, \dots, f_n)$ for the $\left\{f_i\right\}$ forming  a regular
sequence in the maximal ideal of $C$.
\end{corollary}

We also get the promised result:
\begin{theorem} \label{smoothflat}
Let $A \to B$ be a smooth morphism of rings. Then $B$ is flat over $A$.
\end{theorem}
\begin{proof}
Indeed, we immediately reduce to \cref{smoothflat1} by checking locally at each
prime (which gives formally smooth maps).
\end{proof}

In fact, we can get a general criterion now:

\begin{theorem} \label{fiberwisesmooth}
Let $(A, \mathfrak{m}) \to (B, \mathfrak{n})$ be a (local) morphism of local
noetherian rings such that $B$ is the localization of a finitely presented $A$-algebra at a prime
ideal, $B = (A[X_1, \dots, X_n])_{\mathfrak{q}}/I$. Then $B$ is formally
smooth over $A$ if $B$ is $A$-flat and $B/\mathfrak{m}B$ is formally smooth
over $A/\mathfrak{m}$.
\end{theorem}

\begin{proof}
One direction is immediate from what we have already shown. Now we need to
show that if $B$ is $A$-flat, and $B/\mathfrak{m}B$ is formally smooth over
$A/\mathfrak{m}$, then $B$ is itself formally smooth over $A$.
This will be comparatively easy, with all the machinery developed.
This will be comparatively easy, with all the machinery developed.

As before, write the sequence
\[ (A, \mathfrak{m}) \to (C, \mathfrak{q}) \twoheadrightarrow
(B,\mathfrak{n}),
\]
where $C$ is a localization of a polynomial ring at a prime ideal, and in
particular is formally smooth over $A$.
We know that $B = C/I$, where $I \subset \mathfrak{q}$.

To check that $B$ is formally smooth over $A$, we need to show ($C$ being
formally smooth) that the conormal sequence
\begin{equation} \label{thisexact1} I/I^2 \to  \Omega_{C/A} \otimes_C B \to
\Omega_{C/B} \to 0. \end{equation}
is split exact.

Let $\overline{A}, \overline{C}, \overline{B}$ be the base changes of $A, B,
C$ to $k = A/\mathfrak{m}$; let $\overline{I}$ be the kernel of $\overline{C}
\twoheadrightarrow \overline{B}$.
Note that $\overline{I} = I/\mathfrak{m}I$ by flatness of $B$.
Then we know that the sequence
\begin{equation} \label{thisexact2} \overline{I}/\overline{I}^2 \to  \Omega_{\overline{C}/k} / \overline{I}
\Omega_{\overline{C}/k} \to \Omega_{\overline{C}/\overline{B}} \to
0\end{equation}
is split exact, because $\overline{C}$ is a formally smooth $k$-algebra (in
view of \cref{smoothconormal}).

But \eqref{thisexact2} is the reduction of \eqref{thisexact1}. Since the middle
term of \eqref{thisexact1} is finitely generated and projective over $B$, we can check
splitting modulo the maximal ideal (see \cref{splitinjreduce}).
\end{proof}

In particular, we get the global version of the fiberwise criterion:

\begin{theorem}
Let $A \to B$ be a finitely presented morphism of rings. Then $B$ is a smooth
$A$-algebra if and only if $B$ is a flat $A$-algebra and, for each
$\mathfrak{p} \in \spec A$, the morphism $k(\mathfrak{p}) \to B \otimes_A
k(\mathfrak{p})$ is  smooth.
\end{theorem}
Here $k(\mathfrak{p})$ denotes the residue field of $A_{\mathfrak{p}}$, as
usual.
\begin{proof}
One direction is clear. For the other, we recall
that smoothness is \emph{local}: $A \to B$ is smooth if and only if, for each
$\mathfrak{q} \in \spec B$ with image $\mathfrak{p} \in \spec A$, we have $A_{\mathfrak{p}} \to B_{\mathfrak{q}}$
formally smooth (see \cref{fsislocal}).
But, by \cref{fiberwisesmooth}, this is the case if and only if, for each such
pair $(\mathfrak{p}, \mathfrak{q})$, the morphism $k(\mathfrak{p}) \to
B_{\mathfrak{q}} \otimes_{A_{\mathfrak{p}}} k(\mathfrak{p})$ is formally smooth.
Now if $k(\mathfrak{p}) \to B \otimes_A k(\mathfrak{p})$ is smooth for each
$\mathfrak{p}$, then this condition is clearly satisfied.
\end{proof}

\subsection{Formal smoothness and regularity}

We now want to explore the connection between formal smoothness and regularity.
In general, the intuition is that a variety over an algebraically closed field
is \emph{smooth} if and only if the local rings at closed points (and thus at
all points by \cref{locofregularloc}) are regular local rings.
Over a non-algebraically closed field, only one direction is still true: we
want the local rings to be \emph{geometrically regular.}
So far we will just prove one direction, though.

\begin{theorem}
Let $(A, \mathfrak{m})$ be a noetherian local ring containing a copy of its
residue field $A/\mathfrak{m}= k$. Then if $A$ is formally smooth over $k$, $A$
is regular.
\end{theorem}
\begin{proof}
We are going to compare the quotients $A/\mathfrak{m}^m$ to the quotients of
$R= k[x_1, \dots, x_n]$ where  $n$ is the \emph{embedding dimension} of
$A$.
Let $\mathfrak{n} \subset k[x_1, \dots, x_n]$ be the ideal $(x_1, \dots, x_n)$.
We are going to give surjections
\[ A/\mathfrak{m}^m \twoheadrightarrow R/\mathfrak{n}^m  \]
for each $m \geq 2$.

Let $t_1, \dots, t_n \in \mathfrak{m}$ be a $k$-basis for
$\mathfrak{m}/\mathfrak{m}^2$.
Consider the map $A \twoheadrightarrow R/\mathfrak{n}^2 $ that goes
$A  \twoheadrightarrow A/\mathfrak{m}^2 \simeq  k \oplus
\mathfrak{m}/\mathfrak{m}^2 \simeq R/\mathfrak{n}^2$, where $t_i$ is sent to
$x_i$. This is well-defined, and gives a surjection $A \twoheadrightarrow
R/\mathfrak{n}^2$.
Using the infinitesimal lifting property, we can lift this map to
$k$-algebra maps
\[ A \to R/\mathfrak{n}^m  \]
for each $k$, which necessarily factor through $A/\mathfrak{m}^m$ (as they send
$\mathfrak{m}$ into $\mathfrak{n}$). They are surjective by Nakayama's lemma.
It follows that
\[ \dim_k A/\mathfrak{m}^m \geq \dim_k R/\mathfrak{n}^m,  \]
and since $R_{\mathfrak{n}}$ is a regular local ring, the last term grows
asymptotically like $m^n$. It follows that $\dim R \geq n$, and since $\dim R$
is always at most the embedding dimension, we are done.
\end{proof}


\subsection{A counterexample}

It is in fact true that a formally smooth morphism between \emph{arbitrary} noetherian rings is
flat, although we have only proved this in the case of a morphism of finite
type.
This is false if we do not assume noetherian hypotheses.
A formally smooth morphism need not be flat.

\begin{example} \label{fsisn'tflat}
Consider a field $k$, and consider $R = k[T^{x}]_{x \in \mathbb{Q}_{>0}}$.
This is the filtered colimit of the polynomial rings $k[T^{1/n}]$ over all $n$. There is a
natural map $R \to k$ sending each power of $T$ to zero.
The claim is that $R \to k$ is a formally smooth morphism which is not flat.
It is a \emph{surjection}, so it is a lot different from the intuitive idea of
a smooth map.

Yet it turns out to be \emph{formally} smooth. To see this, consider an $R$-algebra $S$ and an ideal $I \subset S$ such that $S^2 =
0$. The claim is that an $R$-homomorphism $k \to S/I$ lifts to $k \to S$.
Consider the diagram
\[ \xymatrix{ \\
& & S \ar[d]  \\
R  \ar[rru] \ar[r] & k \ar@{-->}[ru] \ar[r] & S/I,
}\]
in which we have to show that a dotted arrow exists.

However, there can be at most one $R$-homomorphism $k \to S/I$, since $k$ is a
quotient of $R$. It follows that each $T^{x}, x \in \mathbb{Q}_{>0}$ is mapped
to zero in $S/I$.
So each $T^x, x \in I$ maps to elements of $I$ (by the map $R \to S$ assumed to
exist). It follows that $T^x = (T^{x/2})^2$ maps to zero in $S$, as $I^2 =0$.
Thus the map $R \to S$ annihilates each $T^x$, which means that there is a
(unique) dotted arrow.

Note that $R \to k$ is not flat. Indeed, multiplication by $T$ is injective on
$R$, but it acts by zero on $k$.
\end{example}

This example was described by Anton Geraschenko on MathOverflow; see
\cite{MO200}.
The same reasoning shows more generally:

\begin{proposition}
Let $R$ be a ring, $I \subset R$ an ideal such that $I = I^2$. Then the
projection $R \to R/I$ is formally \'etale.
\end{proposition}

For a noetherian ring, if $I = I^2$, then we know that $I$ is generated by an
idempotent in $R$ (see \cref{idempotentideal}), and the projection $R \to R/I$ is projection on the
corresponding direct factor (actually, the complementary one).
In this case, the projection is flat, and this is to be expected: as stated
earlier, formally \'etale implies flat for noetherian rings.
But in the non-noetherian case, we can get interesting examples.

\begin{example} We shall now give an example showing that formally \'etale
morphisms do not necessarily preserve reducedness. We shall later see that this
is true in the \emph{\'etale} case (see \cref{reducedetale}).

Let $k$ be a field of characteristic $\neq 2$.
Consider the ring $R = k[T^x]_{x \in \mathbb{Q}_{>0}}$ as before.
Take $S = R[X]/(X^2 - T)$, and consider the ideal $I$ generated by all the positive
powers $T^x, x > 0$. As before, clearly $I=I^2$, and thus $S \to S/I$ is
formally \'etale.
The claim is that $S$ is reduced; clearly $S/I = k[X]/(X^2)$ is not.
Indeed, an element of $S$ can be  uniquely described by $\alpha = P(T) + Q(T)X$ where $P, Q$ are
``polynomials'' in $T$---in actuality, they are allowed to have terms $T^x, x
\in \mathbb{Q}_{>0}$.
Then $\alpha^2 = P(T)^2 + Q(T)^2 T + 2 P(T) Q(T) X$. It is thus easy to see
that if $\alpha^2 = 0$, then $\alpha = 0$.
\end{example}


\section{\'Etale morphisms}
\label{section-formally-etale}

\subsection{Definition}
The definition is just another nilpotent lifting property:
\begin{definition}
\label{definition-formally-etale}
Let $S$ be an $R$-algebra. Then $S$ is \textbf{formally \'etale} over $R$ (or
the map $R \to S$ is formally \'etale) if given any
$R$-algebra $A$ and ideal $I \subset A $ of square zero, the map
\[ \hom_R(S, A) \to \hom_R(S, A/I)\]
is a bijection.
A ring homomorphism is \textbf{\'etale} if and only if it is formally \'etale
and of finite presentation.
\end{definition}

So $S$ is {\it formally \'etale over $R$} if for every
commutative solid diagram
$$
\xymatrix{
S \ar[r] \ar@{-->}[rd] & A/I \\
R \ar[r] \ar[u] & A \ar[u]
}
$$
where $I \subset A$ is an ideal of square zero, there exists
a unique dotted arrow making the diagram commute. As before, the functor
of points can be used to test formal \'etaleness.
Moreover, clearly a ring map is formally \'etale if and only if
it is both formally smooth and formally unramified.

We have the usual:
\begin{proposition}
\'Etale (resp. formally \'etale) morphisms are closed under composition
and base change.
\end{proposition}
\begin{proof}
Either a combination of the corresponding results for formal
smoothness and formal unramifiedness (i.e.  \cref{sorite1unr},
\cref{unrbasechange}, and  \cref{smoothsorite}), or easy to verify
directly.
\end{proof}

Filtered colimits preserve formal \'etaleness:
\begin{lemma}
\label{lemma-colimit-formally-etale}
Let $R$ be a ring. Let $I$ be a directed partially ordered set.
Let $(S_i, \varphi_{ii'})$ be a system of $R$-algebras
over $I$. If each $R \to S_i$ is formally \'etale, then
$S = \text{colim}_{i \in I}\ S_i$ is formally \'etale over $R$
\end{lemma}
The idea is that we can make the lifts on each piece, and glue them
automatically.
\begin{proof}
Consider a diagram as in \rref{definition-formally-etale}.
By assumption we get unique $R$-algebra maps $S_i \to A$ lifting
the compositions $S_i \to S \to A/I$. Hence these are compatible
with the transition maps $\varphi_{ii'}$ and define a lift
$S \to A$. This proves existence.
The uniqueness is clear by restricting to each $S_i$.
\end{proof}

\begin{lemma}
\label{lemma-localization-formally-etale}
Let $R$ be a ring. Let $S \subset R$ be any multiplicative subset.
Then the ring map $R \to S^{-1}R$ is formally \'etale.
\end{lemma}

\begin{proof}
Let $I \subset A$ be an ideal of square zero. What we are saying
here is that given a ring map $\varphi : R \to A$ such that
$\varphi(f) \mod I$ is invertible for all $f \in S$ we have also that
$\varphi(f)$ is invertible in $A$ for all $f \in S$. This is true because
$A^*$ is the inverse image of $(A/I)^*$ under the canonical map
$A \to A/I$.
\end{proof}


We now want to give the standard example of an \'etale morphism;
geometrically, this corresponds to a hypersurface in affine 1-space given by
a nonsingular equation. We will eventually show that any \'etale
morphism looks like this, locally.


\begin{example}
Let $R$ be a ring, $P \in R[X]$ a polynomial. Suppose $Q \in R[X]/P$ is such that in the
localization $(R[X]/P)_Q$, the image of the derivative $P' \in R[X]$ is a unit. Then the map
\[ R \to (R[X]/P)_Q  \]
is called a \textbf{standard \'etale morphism.}
\end{example}



The name is justified by:
\begin{proposition}
A standard \'etale morphism is \'etale.
\end{proposition}
\begin{proof}
It is sufficient to check the condition on the K\"ahler differentials, since a
standard \'etale morphism is evidently flat and of finite presentation.
Indeed, we have that
\[ \Omega_{(R[X]/P)_Q/R} = Q^{-1} \Omega_{(R[X]/P)/R} = Q^{-1}
\frac{R[X]}{(P'(X), P(X)) R[X]}  \]
by basic properties of K\"ahler differentials. Since $P'$ is a unit after
localization at $Q$, this last object is clearly zero.
\end{proof}

\begin{example} \label{etalefield}
A separable algebraic extension of a field  $k$ is formally \'etale.
Indeed, we just need to check this
for a finite separable extension $L/k$, in view of \cref{lemma-colimit-formally-etale}, and then we can write $L = k[X]/(P(X))$
for $P$ a separable polynomial. But it is easy to see that this is a special
case of a standard \'etale morphism.
In particular, any unramified extension of a field is \'etale, in view of the
structure theory for unramified extensions of fields (\cref{unrfield}).
\end{example}


\begin{example}
The example of \cref{fsisn'tflat} is a formally \'etale morphism, because we
showed the map was formally smooth and it was clearly surjective.
It follows that a formally \'etale morphism is not necessarily flat!
\end{example}


We also want a slightly different characterization of an \'etale morphism. This
criterion will be of extreme importance for us in the sequel.
\begin{theorem}
An $R$-algebra $S$ of finite presentation is \'etale if and only if
it is flat and unramified.
\end{theorem}
This is in fact how \'etale morphisms are defined in \cite{SGA1} and in
\cite{Ha77}.
\begin{proof}
An \'etale morphism is smooth, hence flat (\cref{smoothflat}). Conversely,
suppose $S$ is flat and unramified over $R$. We just need to show that $S$ is
smooth over $R$. But this follows by the fiberwise criterion for smoothness,
\cref{fiberwisesmooth}, and the fact that an unramified extension of a
field is automatically \'etale, by \cref{etalefield}.
\end{proof}


Finally, we would like a criterion for when a morphism of \emph{smooth}
algebras is \'etale.
We state it in the local case first.
\begin{proposition} \label{etalecotangent}
Let $B, C$ be local, formally smooth, essentially of finite presentation
$A$-algebras and let $f: B \to C$ be a local $A$-morphism.
Then $f$ is formally \'etale if and only if and only if the map $\Omega_{B/A}\otimes_B C \to \Omega_{C/A}$ is an isomorphism.
\end{proposition}
The intuition is that $f$ induces an isomorphism on the cotangent spaces; this
is analogous to the definition of an \emph{\'etale} morphism of smooth
manifolds (i.e. one that induces an isomorphism on each tangent space, so is a
local isomorphism at each point).
\begin{proof}
We prove this for $A$ noetherian.

We just need to check that $f$ is flat if the map on differentials is an
isomorphism.
Since $B, C$ are flat $A$-algebras, it suffices (by the general criterion,
\cref{fiberwiseflat}), to show that $B
\otimes_A k \to C \otimes_A k$ is flat for $k$ the residue field of $A$.
We will also be done if we show that $B \otimes_A \overline{k} \to C \otimes_A
\overline{k}$ is flat. Note that the same hypotheses (that

So we have reduced to a question about rings essentially of finite type over a
\emph{field}. Namely, we have local rings $\overline{B}, \overline{C}$ which
are both formally smooth, essentially of finite-type $k$-algebras, and a map $\overline{B} \to \overline{C}$ that
induces an isomorphism on the K\"ahler differentials as above.

The claim is that $\overline{B} \to \overline{C}$ is flat (even local-\'etale).
Note that both $\overline{B}, \overline{C}$ are \emph{regular} local rings, and
the condition about K\"ahler differentials implies that they of the same
dimension. Consequently, $\overline{B} \to \overline{C}$ is \emph{injective}:
if it were not injective, then the dimension of $\im(\overline{B} \to
\overline{C})$ would be \emph{less} than $\dim \overline{B} = \dim \overline{C}$.
But since $\overline{C}$ is unramified over $\im(\overline{B} \to
\overline{C})$, the dimension can only drop: $\dim \overline{C} \leq \dim
\im(\overline{B} \to \overline{C})$.\footnote{This follows by the surjection of
modules of K\"ahler differentials, in view of \cref{}.}
This contradicts $\dim \overline{B} = \dim\overline{C}$. It follows that
$\overline{B} \to \overline{C}$ is injective, and hence flat by \cref{} below
(one can check that there is no circularity).


\end{proof}

\subsection{The local structure theory}
We know two easy ways of getting an unramified morphism out of a ring $R$.
First, we can take a standard \'etale morphism, which is necessarily
unramified; next we can take a quotient of that. The local structure theory
states that this is all we can have, locally.

\textbf{Warning: this section will use Zariski's Main Theorem, which is not in
this book yet.}


For this we introduce a definition.

\begin{definition}
Let $R$ be a commutative ring, $S$ an $R$-algebra of finite type. Let $\mathfrak{q} \in \spec
S$ and $\mathfrak{p} \in \spec R$ be the image. Then $S$ is called
\textbf{unramified at $\mathfrak{q}$} (resp. \textbf{\'etale at
$\mathfrak{p}$}) if $\Omega_{S_{\mathfrak{q}}/R_{\mathfrak{p}}} = 0$ (resp.
that and $S_{\mathfrak{q}}$ is $R_{\mathfrak{p}}$-flat).
\end{definition}

Now when works with finitely generated algebras, the module of K\"ahler
differentials is always finitely generated over the top ring.
In particular, if
$\Omega_{S_{\mathfrak{q}}/R_{\mathfrak{p}}} = (\Omega_{S/R} )_{\mathfrak{q}} =
0$, then there is $f \in S - \mathfrak{q}$ with $\Omega_{S_f/R} = 0$.
So being unramified at $\mathfrak{q}$ is equivalent to the existence of $f \in
S-\mathfrak{q}$ such that $S_f$ is unramified over $R$.
Clearly if $S$ is unramified over $R$, then it is unramified at all primes,
and conversely.


\begin{theorem}
Let $\phi: R \to S$ be  morphism of finite type, and $\mathfrak{q} \subset S$ prime
with $\mathfrak{p} = \phi^{-1}(\mathfrak{q})$. Suppose $\phi$ is unramified at
$\mathfrak{q}$.
Then there is $f \in R- \mathfrak{p}$ and $g \in S - \mathfrak{q}$ (divisible
by $\phi(f)$) such that
the morphism
\[ R_f \to S_g  \]
factors as a composite
\[ R_f \to (R_f[x]/P)_{h} \twoheadrightarrow S_g  \]
where the first is a standard \'etale morphism and the second is a
surjection. Moreover, we can arrange things such that the fibers above
$\mathfrak{p}$ are isomorphic.
\end{theorem}


\begin{proof}We shall assume that $R$ is \emph{local} with maximal ideal
$\mathfrak{p}$. Then the question reduces to finding
$g \in S$ such that $S_g$ is a quotient of an algebra standard \'etale over $R$.
This reduction is justified by the following argument: if $R$ is
not necessarily local, then the morphism $R_{\mathfrak{p}} \to
S_{\mathfrak{p}}$ is still unramified. If we can show that there is $g \in
S_{\mathfrak{p}} - \mathfrak{q}S_{\mathfrak{p}}$ such
that $(S_{\mathfrak{p}})_g$ is a quotient of a standard \'etale
$R_{\mathfrak{p}}$-algebra, it
will follow that there is $f \notin \mathfrak{p}$ such that the same works
with $R_f \to S_{gf}$.

\emph{We shall now reduce to the case where $S$ is a finite $R$-algebra.}
Let $R$ be local, and let $R \to S$ be unramified at $\mathfrak{q}$. By assumption, $S$ is finitely generated over $R$.
We have seen by \cref{unrisqf} that $S$ is quasi-finite over $R$ at
$\mathfrak{q}$.
By Zariski's Main Theorem (\cref{zmtCA}), there is a finite
$R$-algebra $S'$ and $\mathfrak{q} ' \in \spec S'$ such that $S$ near
$\mathfrak{q}$ and $S'$ near $\mathfrak{q}'$ are isomorphic (in
the sense that there are $g \in S-\mathfrak{q}$, $h \in S' -
\mathfrak{q}'$ with $S_g \simeq S'_h$).
Since $S'$ must be unramified at $\mathfrak{q}'$, we can assume at
the outset, by
replacing $S$ by $S'$, that $R
\to S$ is finite and unramified at $\mathfrak{q}$.


\emph{We shall now reduce to the case where $S$ is generated by one element as
$R$-algebra}. This will occupy us for a few paragraphs.

We have assumed that $R$ is a local ring with maximal ideal $\mathfrak{p} \subset R$; the
maximal ideals of $S$ are finite, say, $\mathfrak{q},\mathfrak{q}_1, \dots,
\mathfrak{q}_r$ because $S$ is finite over $R$; these all contain $\mathfrak{p}$ by Nakayama.
These are no inclusion relations among $\mathfrak{q}$ and the $\mathfrak{q}_i$
as $S/\mathfrak{p}S$ is an artinian ring.

Now $S/\mathfrak{q}$ is a finite separable field extension of
$R/\mathfrak{p}$ by \cref{unrfield}; indeed, the morphism $R/\mathfrak{p}
\to S/\mathfrak{p}S \to S/\mathfrak{q}$ is a composite of
unramified extensions and is thus unramified. In particular, by the primitive element theorem, there is $x \in S$ such that $x$ is a
generator of the field extension $R/\mathfrak{p} \to S/\mathfrak{q}$.
We can also choose $x$ to lie in the other $\mathfrak{q}_i$ by the Chinese
remainder theorem.
Consider the subring $C=R[x] \subset S$.
It has a maximal ideal $\mathfrak{s}$ which is the intersection of
$\mathfrak{q}$ with $C$.
We are going to show that locally, $C$ and $S$ look the same.

\begin{lemma}[Reduction to the monogenic case]
Let $(R, \mathfrak{p})$ be a local ring and $S$ a finite $R$-algebra. Let
$\mathfrak{q}, \mathfrak{q}_1, \dots, \mathfrak{q}_r \in \spec S$ be the prime ideals
lying above $\mathfrak{p}$. Suppose $S$ is unramified at $\mathfrak{q}$.

Then there is $x \in S$ such that the rings $R[x] \subset S$ and $S$ are
isomorphic near $\mathfrak{q}$: more precisely, there is $g \in R[x] -
\mathfrak{q}$ with $R[x]_g = S_g$.
\end{lemma}
\begin{proof} Choose $x$ as in the paragraph preceding the statement of
the lemma.
Define $\mathfrak{s}$ in the same way.
We have  morphisms
\[ R \to C_{\mathfrak{s}} \to S_{\mathfrak{s}}  \]
where $S_{\mathfrak{s}}$ denotes $S$ localized at $C-\mathfrak{s}$, as usual.
The second morphism here is finite.
However, we claim that $S_{\mathfrak{s}}$ is in fact a local ring with maximal
ideal $\mathfrak{q} S_{\mathfrak{s}}$; in particular, $S_{\mathfrak{s}} =
S_{\mathfrak{q}}$.
Indeed, $S$ can have no maximal ideals other than
$\mathfrak{q}$ lying above $\mathfrak{s}$; for,
if $\mathfrak{q}_i$ lay over $\mathfrak{s}$ for some $i$, then $x \in
\mathfrak{q}_i \cap C = \mathfrak{s}$. But $x \notin\mathfrak{s}$ because $x$
is not zero in $S/\mathfrak{q}$.


It thus follows that $S_{\mathfrak{s}}$ is a local ring with maximal ideal
$\mathfrak{q}S_{\mathfrak{s}}$. In particular, it is
equal to $S_{\mathfrak{q}}$, which is a localization of
$S_{\mathfrak{s}}$ at the maximal ideal.
In particular, the morphism
\[ C_{\mathfrak{s}} \to S_{\mathfrak{s}} = S_{\mathfrak{q}}  \]
is finite. Moreover, we have $\mathfrak{s} S_{\mathfrak{q}} =
\mathfrak{q}S_{\mathfrak{q}}$ by unramifiedness of $R \to S$.
So since the residue fields are the same by choice of $x$, we have
$\mathfrak{s}S_{\mathfrak{q}} + C_{\mathfrak{s}} = S_{\mathfrak{q}}$.
Thus by Nakyama's lemma, we find that $S_{\mathfrak{s}} = S_{\mathfrak{q}} = C_{\mathfrak{s}}$.


There is thus an element $g \in C - \mathfrak{r}$ such that $S_g = C_g$.
In particular, $S$ and $C$ are isomorphic near $\mathfrak{q}$.
\end{proof}

We can thus replace $S$ by $C$ and assume that $C$ has one generator.

\emph{With this reduction now made, we proceed.} We are now considering the
case where $S$ is generated by one element, so a quotient $S = R[X]$ for
some monic polynomial $P$.
Now $\overline{S} = S/\mathfrak{p}S$ is thus a quotient of $k[X]$, where $k =
R/\mathfrak{p}$ is the residue field.
It thus follows that
\[ \overline{S} = k[X]/(\overline{P})  \]
for $\overline{P}$ a monic polynomial, as $\overline{S}$ is a finite
$k$-vector space.

Suppose $\overline{P}$ has degree $n$.
Let $x \in S$ be a generator of $S/R$.
We know that $1, x, \dots, x^{n-1}$ has reductions that form a $k$-basis for
$S \otimes_R k$, so by Nakayama they generate $S$ as an $R$-module.
In particular, we can find a monic polynomial $P$ of degree $n$ such that
$P(x) = 0$.
It follows that the reduction of $P$ is necessarily $\overline{P}$.
So we have a surjection
\[ R[X]/(P) \twoheadrightarrow S  \]
which induces an isomorphism modulo $\mathfrak{p}$ (i.e. on the fiber).

Finally, we claim that we can modify $R[X]/P$ to make a standard \'etale
algebra. Now,
if we let $\mathfrak{q}'$ be the preimage of $\mathfrak{q}$ in
$R[X]/P$, then we have morphisms of local rings
\[ R \to (R[X]/P)_{\mathfrak{q}'} \to S_{\mathfrak{q}}. \]
The claim is that $R[X]/(P)$ is unramified
over $R$ at $\mathfrak{q}'$.


To see this, let $T = (R[X]/P)_{\mathfrak{q}'}$. Then, since the fibers of $T$ and $S_{\mathfrak{q}}$ are the same at
$\mathfrak{p}$,  we have that
\[ \Omega_{T/R} \otimes_R k(\mathfrak{p}) = \Omega_{T \otimes_R
k(\mathfrak{p})/k(\mathfrak{p})} =
\Omega_{(S_{\mathfrak{q}}/\mathfrak{p}S_{\mathfrak{q}})/k(\mathfrak{p})} = 0   \]
as $S$ is $R$-unramified at $\mathfrak{q}$.
It follows that $\Omega_{T/R} = \mathfrak{p} \Omega_{T/R}$, so a fortiori
$\Omega_{T/R} = \mathfrak{q} \Omega_{T/R}$; since this is a finitely generated
$T$-module, Nakayama's lemma implies that is zero.
 We conclude
that $R[X]/P$ is unramified at $\mathfrak{q}'$; in particular, by the
K\"ahler differential criterion, the image of the derivative $P'$ is not in
$\mathfrak{q}'$. If we localize at the image of $P'$, we then get what we
wanted in the theorem.
\end{proof}

We now want to deduce a corresponding (stronger) result for \emph{\'etale}
morphisms. Indeed, we prove:

\begin{theorem}
If $R \to S$ is \'etale at $\mathfrak{q} \in \spec S$ (lying over
$\mathfrak{p} \in \spec R$), then there are $f \in R-\mathfrak{p}, g \in S -
\mathfrak{q}$ such that the morphism $R_f \to S_g$ is a standard \'etale
morphism.
\end{theorem}
\begin{proof}
By localizing suitably, we can assume that   $(R, \mathfrak{p})$ is local,
and  (in view of \cref{}),
$R \to S$ is a quotient of a standard \'etale morphism
\[ (R[X]/P)_h \twoheadrightarrow S  \]
with the kernel some ideal $I$. We may assume that the surjection is an
isomorphism modulo $\mathfrak{p}$, moreover.
By localizing $S$ enough\footnote{We are not assuming $S$ finite over $R$ here,}
we may suppose that $S$ is a \emph{flat} $R$-module as well.

Consider the exact sequence of $(R[X]/P)_h$-modules
\[ 0 \to I \to  (R[X]/P)_h/I \to S \to 0. \]

Let $\mathfrak{q}'$ be the image of $\mathfrak{q}$ in $\spec (R[X]/P)_h$.
We are going to show that the first term vanishes upon localization at
$\mathfrak{q}'$.
Since everything here is finitely generated,
it will follow that after further localization by some element in
$(R[X]/P)_h - \mathfrak{q}'$, the first term will vanish. In particular, we
will then be done.

Everything here is a module over $(R[X]/P)_h$, and certainly a module over
$R$. Let us tensor everything over $R$ with
$R/\mathfrak{p}$; we find an exact sequence
\[  I \to  S/\mathfrak{p}S \to S/\mathfrak{p}S \to 0 ;\]
we have used the fact that the morphism $(R[X]/P)_h \to S$ was assumed to
induce an isomorphism modulo $\mathfrak{p}$.

However, by \'etaleness we assumed that $S$ was \emph{$R$-flat}, so we find that exactness holds at the left too.
It follows that
\[ I  = \mathfrak{p}I,  \]
so a fortiori
\[ I = \mathfrak{q}'I,  \]
which implies by Nakayama that $I_{\mathfrak{q}'} = 0$. Localizing at a
further element of $(R[X]/P)_h - \mathfrak{q}'$, we can assume that $I=0$;
after this localization, we find that $S$ looks \emph{precisely} a standard
\'etale algebra.
\end{proof}

\subsection{Permanence properties of \'etale morphisms}
We shall now return to (more elementary) commutative algebra, and discuss the
properties that an \'etale extension $A \to B$ has. An \'etale extension is
not supposed to make $B$ differ too much from $A$, so we might expect some of
the same properties to be satisfied.

We might not necessarily expect global properties to be preserved
(geometrically, an open imbedding of schemes is \'etale, and that does
not necessarily preserve global properties), but local ones should be.

Thus the right definition for us will be the following:
\begin{definition}
A morphism of local rings $(A, \mathfrak{m}_A) \to (B, \mathfrak{m}_B)$ is \textbf{local-unramified}
$\mathfrak{m}_A B$ is the maximal ideal of $B$ and $B/\mathfrak{m}_B$ is a
finite separable extension of $A/\mathfrak{m}_A$.

A morphism of local rings $A \to B$ is \textbf{local-\'etale} if it is flat
and local-unramified.
\end{definition}



\begin{proposition}  \label{dimpreserved}
Let $(R, \mathfrak{m}) \to (S, \mathfrak{n})$ be a local-\'etale morphism of noetherian local
rings. Then $\dim R = \dim S$.
\end{proposition}
\begin{proof}
Indeed, we know that $\mathfrak{m}S = \mathfrak{n}$ because $R \to S$ is
local-unramified.
Also $R/\mathfrak{m}\to S/\mathfrak{n}$ is a finite separable extension.
We have a natural morphism
\[ \mathfrak{m} \otimes_R S \to \mathfrak{n}  \]
which is injective (as the map $\mathfrak{m} \otimes_R S \to S$ is injective by
flatness) and consequently is an isomorphism.
More generally, $\mathfrak{m}^n \otimes_R S \simeq \mathfrak{n}^n$ for each $n$.
By flatness again, it follows that
\begin{equation} \label{thisiso} \mathfrak{m}^n/\mathfrak{m}^{n+1} \otimes_{R/\mathfrak{m}}
(S/\mathfrak{n}) =  \mathfrak{m}^n/\mathfrak{m}^{n+1} \otimes_R S \simeq
\mathfrak{n}^n/\mathfrak{n}^{n+1}. \end{equation}
Now if we take the dimensions of these vector spaces, we get polynomials in
$n$; these polynomials are the dimensions of $R, S$, respectively. It follows
that $\dim R = \dim S$.
\end{proof}



\begin{proposition} \label{depthpreserved}
Let $(R, \mathfrak{m}) \to (S, \mathfrak{n})$ be a local-\'etale morphism of noetherian local
rings.
Then $\depth R = \depth S$.
\end{proposition}
\begin{proof}
We know that a nonzerodivisor in $R$ maps to a nonzerodivisor in $S$. Thus by
an easy induction we reduce to the case where $\depth R = 0$.
This means that $\mathfrak{m}$ is an associated prime of $R$; there is thus
some $x \in R$, nonzero (and necessarily a non-unit) such that the annihilator
of $x$ is all of $\mathfrak{m}$. Now $x$ is a nonzero element of $S$, too, as
the map $R \to S$ is an inclusion by flatness.
It is then clear that $\mathfrak{n} = \mathfrak{m}S$ is the annilhilator of
$x$ in $S$, so $\mathfrak{n}$ is an associated prime of $S$ too.
\end{proof}

\begin{corollary}
Let $(R, \mathfrak{m}) \to (S, \mathfrak{n})$ be a local-\'etale morphism of noetherian local
rings.
Then $R$ is regular (resp. Cohen-Macaulay) if and only if $S$ is.
\end{corollary}
\begin{proof}
The  results \cref{depthpreserved} and \cref{dimpreserved} immediately give
the result about Cohen-Macaulayness.
For regularity, we use \eqref{thisiso} with $n=1$ to see at once that the
embedding dimensions of $R$ and $S$ are the same.
\end{proof}

Recall, however, that regularity of $S$ implies that of $R$ if we just assume
that $R \to S$ is \emph{flat} (by Serre's characterization of regular
local rings as those having finite global dimension).


We shall next show that reducedness is preserved
under \'etale extensions.
We shall need another hypothesis, though, that the map of local rings
be essentially of finite type.
This will always be the case in situations of interest, when we are looking at
the map on local rings induced by a morphism of rings of finite type.

\begin{proposition}
\label{reducedetale}
Let $(R, \mathfrak{m}) \to (S, \mathfrak{n})$ be a local-\'etale morphism of noetherian local
rings.
Suppose $S$ is essentially of finite type over $R$.
Then $S$ is reduced if and only if $R$ is reduced.
\end{proposition}
\begin{proof}
As $R \to S$ is injective by (faithful) flatness, it suffices to show that if
$R$ is reduced, so is $S$.
Now there is an imbedding $R \to \prod_{\mathfrak{p} \ \mathrm{minimal}}
R/\mathfrak{p}$ of $R$ into a product of local domains. We get an imbedding of
$S$ into a product of local rings $\prod S/\mathfrak{p}S$.
Each $S/\mathfrak{p}S$ is essentially of finite type over $R/\mathfrak{p}$,
and local-\'etale over it too.

We are reduced to showing that each $S/\mathfrak{p}S$ is reduced. So we need
only show that a local-\'etale, essentially of finite type local ring over a
local noetherian domain is reduced.

So suppose $A$ is a local noetherian domain, $B$ a
local-\'etale, essentially of finite type local $A$-algebra.
We want to show that $B$ is reduced, and then we will be done. Now $A$ imbeds into its field of
fractions $K$; thus $B$ imbeds into $B \otimes_A K$.
Then $B \otimes_A K$ is formally unramified over $K$ and is essentially of
finite type over $K$. This means that $B \otimes_A K$ is a product of fields
by the usual classification, and is in particular reduced. Thus $B$ was itself
reduced.
\end{proof}


To motivate the proof that normality is preserved, though, we indicate another
proof of this fact, which does not even use the essentially of finite type
hypothesis.
Recall that a noetherian ring $A$ is reduced if and only if
for every prime $\mathfrak{p} \in \spec A$ of height zero,
$A_{\mathfrak{p}}$ is regular (i.e., a field), and for every
prime $\mathfrak{p}$ of height $>0$, $R_{\mathfrak{p}}$ has depth
at least one. See \cref{reducedserrecrit}.

So suppose $R \to S$ is a local-\'etale and suppose $R$ is reduced.
We are going to apply the above criterion, together with the results already
proved, to show that $S$ is reduced.

Let $\mathfrak{q} \in \spec S$ be a minimal prime, whose image in
$\spec R$ is $\mathfrak{p}$.
Then we have a morphism
\[ R_{\mathfrak{p}} \to S_{\mathfrak{q}}  \]
which is locally of finite type, flat, and indeed local-\'etale, as it is
formally unramified (as $R \to S$ was).
We know that $\dim R_{\mathfrak{p}}  = \dim S_{\mathfrak{q}}$
by \cref{dimpreserved}, and consequently
since $R_{\mathfrak{p}}$ is regular, so is $S_{\mathfrak{q}}$.
Thus the localization of $S$ at any minimal prime is regular.

Next, if $\mathfrak{q} \in \spec S$ is such that $S_{\mathfrak{q}}$ has height
has positive dimension, then $R_{\mathfrak{p}} \to S_{\mathfrak{q}}$ (where
$\mathfrak{p}$ is as above) is local-\'etale and consequently $\dim
R_{\mathfrak{q}} = \dim S_{\mathfrak{q}} > 0$.
Thus,
$\depth R_{\mathfrak{p}} = \depth S_{\mathfrak{q}} >0$ because $R$ was reduced.
It follows that the above criterion is valid for $S$.


Recall that a noetherian ring is a \emph{normal} domain if it is integrally closed
in its quotient field, and simply \emph{normal} if all its localizations are
normal domains; this equates to the ring being a product of normal domains.
We want to show that this is preserved under \'etaleness.
To do this, we shall use a criterion similar to that used at the end of the
last section.
We have the following important criterion for normality.

\begin{theorem*}[Serre] Let $A$ be a noetherian ring. Then $A$ is normal if
and only if for all $\mathfrak{p} \in \spec R$:
\begin{enumerate}
\item  If $\dim A_{\mathfrak{p}} \leq 1$, then $A_{\mathfrak{p}}$ is regular.
\item If $\dim A_{\mathfrak{p}} \geq 2$, then $\depth A_{\mathfrak{p}} \geq 2$.
\end{enumerate}
\end{theorem*}
This is discussed in \cref{realserrecrit}.

From this, we will be able to prove without difficulty the next result.
\begin{proposition} \label{normalitypreserved}
Let $(R, \mathfrak{m}) \to (S, \mathfrak{n})$ be a local-\'etale morphism of noetherian local
rings.
Suppose $S$ is essentially of finite type over $R$.
Then $S$ is normal if and only if $R$ is normal.
\end{proposition}
\begin{proof}
This is proved in the same manner as the result for reducedness was proved at
the end of the previous subsection.
For instance, suppose $R$ normal. Let $\mathfrak{q} \in \spec S$ be arbitrary,
contracting to $\mathfrak{p} \in \spec R$. If $\dim S_{\mathfrak{q}} \leq 1$,
then $\dim R_{\mathfrak{p}} \leq 1$ so that $R_{\mathfrak{p}}$, hence
$S_{\mathfrak{q}}$ is regular. If $\dim S_{\mathfrak{q}} \geq 2$, then $\dim
R_{\mathfrak{p}} \geq 2$, so
$\depth S_{\mathfrak{q}} = \depth R_{\mathfrak{p}} \geq 2$.
\end{proof}

We mention a harder result:

\begin{theorem}
\label{injunrflat}
If $f:(R, \mathfrak{m}) \to (S, \mathfrak{n})$ is local-unramified, injective,
and essentially of finite type, with $R$ normal and noetherian, then $R \to S$ is
local-\'etale.
Thus, an injective unramified morphism of finite type between noetherian rings,
whose source is a normal domain, is \'etale.
\end{theorem}

A priori, it is not obvious at all that $R \to S$ should be flat. In fact,
proving flatness directly seems to be difficult, and we will have to use the
local structure theory for \emph{unramified} morphisms together with nontrivial
facts about \'etale morphisms to establish this result.
\begin{proof}
We essentially follow \cite{Mi67} in the proof.
Clearly, only the local statement needs to be proved.

We shall use the (non-elementary, relying on ZMT) structure theory of unramified morphisms,
which implies that there is a factorization of $R \to S$ via
\[ (R, \mathfrak{m}) \stackrel{g}{\to} (T, \mathfrak{q}) \stackrel{h}{\to} (S, \mathfrak{n}),  \]
where all morphisms are local homomorphisms of local rings, $g: R \to T$ is
local-\'etale and essentially of finite type, and $h:T \to S$ is surjective.
This was established in \cref{}.

We are going to show that $h$ is an isomorphism, which will complete the proof.
Let $K$ be the quotient field of $R$.
Consider the diagram
\[ \xymatrix{
R \ar[d] \ar[r]^g &  T \ar[r]^h \ar[d]  &  S \ar[d] \\
K \ar[r]^{g \otimes 1} & T \otimes_R K \ar[r]^{h \otimes 1}&   S
\otimes_R K.
}\]
Now the strategy is to show that $h$ is injective.
We will prove this by chasing around the diagram.

Here $R \to S$ is formally unramified and essentially of finite type, so $K \to S
\otimes_R K$ is too, and $S \otimes_R K$ is in particular a finite product of
separable extensions of $K$. The claim is that it is nonzero; this follows
because $f: R \to S$ is injective, and $S \to S \otimes_R K$ is injective
because localization is exact. Consequently $R \to S \otimes_R K$ is injective,
and the target must be nonzero.

As a result, the surjective map $h \otimes 1: T \otimes_R K \to S \otimes_R K$
is nonzero. Now we claim that  $T \otimes_R K$ is a field. Indeed, it is an \'etale extension
of $K$ (by base-change), so it is a product of fields.  Moreover, $T$ is a
normal domain since $R$ is (by \cref{normalitypreserved}) and $R \to T$ is injective by flatness,
so the localization $T \otimes_R K$ is a domain as well.
Thus it must be a field. In particular, the map $h \otimes 1: T \otimes_R K \to
S \otimes_R K$ is a surjection from a field to a product of fields. It is thus
an \emph{isomorphism.}

Finally, we can show that $h$ is injective. Indeed, it suffices to show that
the composite $T \to T \otimes_R K \to S \otimes_R K$ is injective. But the
first map is injective as it is a map from a domain to a localization, and the
second is an isomorphism (as we have just seen). So $h$ is injective, hence an
isomorphism. Thus $T \simeq S$, and we are done.
\end{proof}

Note that this \emph{fails} if the source is not normal.
\begin{example}
Consider a nodal cubic $C$ given by $y^2 = x^2 (x-1)$ in $\mathbb{A}^2_k$ over an
algebraically closed field $k$. As is well-known, this curve is smooth except
at the origin. There is a map $\overline{C} \to C$ where $\overline{C}$ is
the normalization; this is a finite map, and a local isomorphism outside of
the origin.

The claim is that $\overline{C} \to C$ is unramified but not \'etale. If it
were \'etale, then $C$ would be smooth since $\overline{C}$ is. So it is not
\'etale. We just need to see that it is unramified, and for this we need only
see that the map is unramified at the origin.

We may compute: the normalization of $C$ is given by $\overline{C} =
\mathbb{A}^1_k$, with the map
\[ t \mapsto (t^2+1, t (t^2 + 1)).  \]
Now the two points $\pm 1$ are both mapped to $0$.
We will show that
\[ \mathcal{O}_{C, 0} \to \mathcal{O}_{\mathbb{A}^1_k, 1}  \]
is local-unramified; the other case is similar.
Indeed, any line through the origin which is not a tangent direction will be
something in $\mathfrak{m}_{C, 0}$ that is mapped to a uniformizer in $
\mathcal{O}_{\mathbb{A}^1_k, 1}$.
For instance, the local function $x \in \mathcal{O}_{C,0}$ is mapped to
the function $t \mapsto t^2 + 1$ on $\mathbb{A}^1_k$, which has a simple zero
at $1$ (or $-1$).
It follows that the maximal ideal $\mathfrak{m}_{C,0}$ generates the maximal
ideal of $\mathcal{O}_{\mathbb{A}^1_k, 1}$ (and similarly for $-1$).
\end{example}

\subsection{Application to smooth morphisms}

We now want to show that the class of \'etale morphisms essentially determines
the class of smooth morphisms. Namely, we are going to show that
smooth morphisms are those that look \'etale-locally like \'etale morphisms
followed by projection from affine space. (Here ``projection from affine
space'' is the geometric picture: in terms of commutative rings, this is the
embedding $A \hookrightarrow A[x_1, \dots, x_n]$.)

Here is the first goal:
\begin{theorem}
Let $f: (A, \mathfrak{m}) \to (B, \mathfrak{n})$ be an essentially of finite
presentation, local morphism of local rings.
Then $f$ is formally smooth
if and only if there exists a factorization
\[ A \to C \to B  \]
where $(C, \mathfrak{q})$ is a localization of the polynomial ring $A[X_1,
\dots, X_n]$ at a prime ideal with $A \to C$ the natural embedding, and $C \to
B$ a formally \'etale morphism.
\end{theorem}

For convenience, we have stated this result for local rings, but we can get a
more general criterion as well (see below). This states that smooth
morphisms, \'etale locally, look like the imbedding of a ring into a
polynomial ring.
In \cite{SGA1}, this is in fact how smooth morphisms are \emph{defined.}

\begin{proof} First assume $f$ smooth.
We know then that $\Omega_{B/A}$ is a finitely generated projective $B$-module,
hence free, say of rank $n$.
There are $t_1, \dots, t_n \in B$ such that $\left\{dt_i\right\}$ forms a basis
for $\Omega_{B/A}$: namely, just choose a set of such elements that forms a
basis for $\Omega_{B/A} \otimes_B B/\mathfrak{n}$ (since these elements
generate $\Omega_{B/A}$).

Now these elements $\left\{t_i\right\}$ give a map of rings $A[X_1, \dots, X_n]
\to B$. We let $\mathfrak{q}$ be the pre-image of $\mathfrak{n}$ (so
$\mathfrak{n}$ contains the image of $\mathfrak{m} \subset A$), and take $C =
C = A[X_1,\dots, X_n]_{\mathfrak{q}}$. This gives local homomorphisms $A \to C,
C \to B$. We only need to check that $C \to B$ is \'etale.
But the map
\[ \Omega_{C/A} \otimes_C B \to \Omega_{B/A}  \]
is an isomorphism, by construction. Since $C, B$ are both formally smooth over
$A$, we find that $C \to B$ is \'etale by the characterization of \'etaleness
via cotangent vectors
(\cref{etalecotangent}).

The other direction, that $f$ is formally smooth if it admits such a
factorization, is clear because the localization of a polynomial algebra is
formally smooth, and a formally \'etale map is clearly formally smooth.
\end{proof}

\begin{corollary}
Let $(R, \mathfrak{m}) \to (S, \mathfrak{n})$ be a formally smooth, essentially
of finite type morphism of noetherian rings. Then if $R$ is normal, so is $S$.
Ditto for reduced.
\end{corollary}
\begin{proof}

\end{proof}

\subsection{Lifting under nilpotent extensions}

In this subsection, we consider the following question. Let $A$ be a ring, $I
\subset A$ an ideal of square zero, and let $A_0 = A/I$. Suppose $B_0$ is a
flat $A_0$-algebra (possibly satisfying other conditions).
Then, we ask if there exists a flat $A$-algebra $B$ such that $B_0 \simeq B
\otimes_A A_0 = B/IB$.
If there is, we say that $B$ can be \emph{lifted} along the nilpotent
thickening from $B_0$ to $B$---we think of $B$ as the mostly the same as $B_0$,
but with some additional ``fuzz'' (given by the additional nilpotents).

We are going to show that this can \emph{always} be done for \'etale
algebras, and that this always can be done \emph{locally} for smooth
algebras. As a result, we will get a very simple characterization of what
finite\'etale algebras over a complete (and later, henselian) local ring look like:
they are the same as \'etale extensions of the residue field (which we have
classified completely).

In algebraic geometry, one spectacular application of these ideas is
Grothendieck's proof in \cite{SGA1} that a smooth projective curve over a field
of characteristic $p$ can be ``lifted'' to characteristic zero. The idea is to
lift it successively along nilpotent thickenings of the base field, bit by bit
(for instance, $\mathbb{Z}/p^n \mathbb{Z}$ of $\mathbb{Z}/p\mathbb{Z}$),
by using the techniques of this subsection; then, he uses hard existence
results in formal geometry to show that this compatible system of nilpotent
thickenings comes from a curve over a DVR (e.g. the $p$-adic numbers). The
application in mind is the (partial) computation of the \'etale fundamental
group of a smooth projective curve over a field of positive characteristic.
We will only develop some of the more basic ideas in commutative algebra.

Namely, here is the main result.
For a ring $A$, let $\et(A)$ denote the category of \'etale $A$-algebras (and
$A$-morphisms). Given $A \to A'$, there is  a natural functor $\et(A) \to
\et(A')$  given by base-change.
\begin{theorem}
Let $A \to A_0$ be a surjective morphism whose kernel is nilpotent. Then
$\et(A) \to \et(A_0)$ is an equivalence of categories.
\end{theorem}

$\spec A$ and $\spec A_0$ are identical topologically, so this result is
sometimes called the topological invariance of the \'etale site.
Let us sketch the idea before giving the proof. Full faithfulness is the easy
part, and is essentially a restatement of the nilpotent lifting property.
The essential surjectivity is the non-elementary part, and relies on the local
structure theory. Namely, we will show that a standard \'etale morphism can be
lifted (this is essentially trivial). Since an \'etale morphism is locally
standard \'etale, we can \emph{locally} lift an \'etale $A_0$-algebra to an
\'etale $A$-algebra.
We next ``glue'' the local liftings using the full faithfulness.
\begin{proof} Without loss of generality, we can assume that the ideal defining
$A_0$ has square zero.
Let $B, B'$ be \'etale $A$-algebras. We need to show that
\[ \hom_A(B, B') = \hom_{A_0}(B_0, B_0'),  \]
where $B_0, B_0'$ denote the reductions to $A_0$ (i.e. the base change).
But $\hom_{A_0}(B_0, B_0') = \hom_{A}(B, B_0')$, and this is clearly the same
as $\hom_A(B, B')$ by the definition of an \'etale morphism. So full
faithfulness is automatic.

The trickier part is to show that any \'etale $A_0$-algebra can be lifted
to an \'etale $A$-algebra.
First, note that  a standard \'etale $A_0$-algebra of the form
$(A_0[X]/(P(X))_{Q}$ can be lifted to $A$---just lift $P$ and $Q$. The condition
that it be standard \'etale is invertibility of $P'$, which is unaffected by
nilpotents.

Now the strategy is to glue these appropriately.
The details should be added at some point, but they are not. \add{details}
\end{proof}




% ============================ chapters/completelocal.tex}

% ============================ chapters/homotopical.tex}
\chapter{Homotopical algebra}

In this chapter, we shall introduce the formalism of \emph{model categories}.
Model categories provide an abstract setting for homotopy theory: in
particular, we shall see that topological spaces form a model category. In a
model category, it is possible to talk about notions such as ``homotopy,'' and
thus to pass to the homotopy category.

But many algebraic categories form model categories as well. The category of
chain complexes over a ring forms one. It turns out that this observation
essentially encodes classical homological algebra. We shall see, in
particular, how the notion of \emph{derived functor} can be interpreted in a
model category, via this model structure on chain complexes.

Our ultimate goal in developing this theory, however, is to study the
\emph{non-abelian} case. We are interested in developing the theory of the
\emph{cotangent complex}, which is loosely speaking the derived functor of the
K\"ahler differentials $\Omega_{S/R}$ on the category of $R$-algebras. This is
not a functor on an additive category; however, we shall see that the
non-abelian version of derived functors (in the category of \emph{simplicial}
$R$-algebras) allows one to construct the cotangent complex in an elegant way.

\section{Model categories}



\subsection{Definition}

We need to begin with the notion of a \emph{retract} of a map.

\begin{definition}
Let $\mathcal{C}$ be a category. Then we can form a new category
$\mathrm{Map}\mathcal{C}$ of
\emph{maps} of $\mathcal{C}$. The objects of this category are the morphisms
$A \to B$ of $\mathcal{C}$, and a morphism between $A \to B$ and $C \to D$ is
given by a commutative square
\[ \xymatrix{
A \ar[d] \ar[r] &  C \ar[d] \\
B \ar[r] &  D
}.\]

A map in $\mathcal{C}$ is a \textbf{retract} of another map in $\mathcal{C}$
if it is a retract as an object of $\mathrm{Map}\mathcal{C}$.
This means that there is a diagram:
\begin{xyxy}{
A \ar[r]\ar@/^1pc/[rr]^{Id}\ar[d]^{f} & B\ar[d]^{g} \ar[r] & A\ar[d]^{f}
\\ X \ar[r]\ar@/_2pc/[rr]^{Id}  & Y \ar[r] & X
}\end{xyxy}
\end{definition}

For instance, one can prove:
\begin{proposition}
In any category, isomorphisms are closed under retracts.
\end{proposition}
We leave the proof as an exercise.

\begin{definition}
A \textbf{model category} is a category $\mathcal{C}$ equipped with three classes of maps called \emph{cofibrations}, \emph{fibrations}, and \emph{weak equivalences}. They have to satisfy five axioms $M1 - M5$.

Denote cofibrations as $\hookrightarrow$, fibrations as $\twoheadrightarrow$, and weak equivalences as $\to{\sim}$.
\begin{itemize}
\item [(M1)] $\mathcal{C}$ is closed under all  limits and colimits.\footnote{Many of our arguments
will involve infinite colimits. The original formulation in
\cite{Qui67} required only finite
such, but most people assume infinite.}
\item [(M2)] Each of the three classes of cofibrations, fibrations, and weak
equivalences is \emph{closed under retracts}.\footnote{Quillen initially
called model categories satisfying this axiom \emph{closed} model categories.
All the model categories we consider will be closed, and we have, following
\cite{Ho07}, omitted this axiom.}
\item [(M3)] If \emph{two of three} in a composition are weak equivalences, so is the third.
\begin{xyxy}{
\ar[r]^{f}\ar[d]_h & \ar[dl]^g
\\&
}\end{xyxy}
\item [(M4)] (\emph{Lifts}) Suppose we have  a diagram
\begin{xyxy}{
A\ar[r]\ar@{^(->}[d]^{i}&  X\ar@{->>}[d]^{p}
\\B\ar[r]\ar@{-->}[ru] &  Y
}\end{xyxy}
Here $i: A \to B$ is a cofibration and $p: X \to Y$ is a fibration.
Then a lift exists if $i$ or $p$ is a weak equivalence.
\item [(M5)] (\emph{Factorization}) Every map can be factored in two ways:
\begin{xyxy}{
&.\ar@{->>}[dr]^{\sim} &
\\.\ar@{^(->}[ru]\ar@{_(->}[dr]_{\sim}\ar[rr]^{f} & &.
\\&.\ar@{->>}[ru]&
}\end{xyxy}
In words, it can be factored as a composite of a cofibration followed by a
fibration which is a weak equivalence, or as a cofibration which is a weak
equivalence followed by a fibration.
\end{itemize}
\end{definition}

A map which is a weak equivalence and a fibration will be called an
\textbf{acyclic fibration}. Denote this by $\twoheadrightarrow{\sim}$. A map
which is both a weak equivalence and a cofibration will be called an
\textbf{acyclic cofibration}, denoted $\hookrightarrow{\sim}$.
(The word ``acyclic'' means for a chain complex that the homology is trivial;
we shall see that this etymology is accurate when we construct a model
structure on the category of chain complexes.)

\begin{remark}
If $C$ is a model category, then $\mathcal{C}^{op}$ is a model category, with the notions of fibrations and cofibrations reversed. So if we prove something about fibrations, we automatically know something about cofibrations.
\end{remark}

We begin by listing a few elementary examples of model categories:

\begin{example}
\begin{enumerate}
\item Given a complete and cocomplete category $\mathcal{C} $, then we can
give a model structure to $\mathcal{C}$ by taking the weak equivalences to be
the isomorphisms and the cofibrations and fibrations to be all maps.
\item If $R$ is a \emph{Frobenius ring}, or the classes of projective and
injective $R$-modules coincide, then the category of modules over $R$ is a
model category. The cofibrations are the injections, the fibrations are the
surjections, and the weak equivalences are the \emph{stable equivalences} (a
term which we do not define). See \cite{Ho07}.
\item The category of topological spaces admits a model structure where the
fibrations are the \emph{Serre fibrations} and the weak equivalences are the
\emph{weak homotopy equivalences.} The cofibrations are, as we shall see,
determined from this, though they can be described explicitly.
\end{enumerate}
\end{example}


\begin{exercise}
Show that there exists a model structure on the category of sets where the injections are
the cofibrations, the surjections are fibrations, and all maps are weak
equivalences.
\end{exercise}


\subsection{The retract argument}

The axioms for a model category are somewhat complicated.
We are now going to see that they are actually redundant. That is, any two of
the classes of cofibrations, fibrations, and weak equivalences determine the
third. We shall thus introduce a useful trick that we shall have occasion to
use many times further when developing the foundations.


\begin{definition}
Let $\mathcal{C}$ be any category.
Suppose that $P$ is a class of maps of $\mathcal{C}$. A map $f: A \to B$ has
the \textbf{left lifting property} with respect to $P$ iff: for all $p: C \to D$ in $ P$ and all diagrams
\begin{xyxy}{
A\ar[r]\ar[d]_{f} &  C\ar[d]^{p}
\\B\ar@{-->}[ru]^{\exists }\ar[r] & D
}\end{xyxy}
a lift represented by the dotted arrow exists, making the diagram commute. We
abbreviate this property to \textbf{LLP}. There is also a notion of a
\textbf{right lifting property}, abbreviated \textbf{RLP}, where $f$ is on the right.
\end{definition}

\begin{proposition}
Let $P$ be a class of maps of $\mathcal{C}$. Then the set of maps $f: A \to B $
that have the LLP (resp. RLP) with respect to $P$ is closed under retracts and
composition.
\end{proposition}
\begin{proof}
This will be a diagram chase. Suppose $f: A \to B$ and $g: B \to C$ have the
LLP with respect to maps in $P$. Suppose given a diagram
\[ \xymatrix{
A \ar[d]^{ g \circ f}  \ar[r] &  X \ar[d]  \\
C \ar[r] &  Y
}\]
with $X \to Y$ in $P$. We have to show that there exists a lift $C \to X$. We can split this into a commutative diagram:
\[ \xymatrix{
A \ar[d]^{ f }  \ar[r] &  X \ar[dd]  \\
B  \ar@{-->}[ru] \ar[rd] \ar[d]^g &  \\
C \ar[r] &  Y
}\]
The lifting property provides a map $\phi: B \to X$ as in the dotted line in the
diagram. This gives a diagram
\[   \xymatrix{
B \ar[d]^{ g }  \ar[r]^{\phi} &  X \ar[d]  \\
C \ar[r] \ar@{-->}[ru] &  Y
}\]
and in here we can find a lift because $g$ has the LLP with respect to $p$. It
is easy to check that this lift is what we wanted.

\end{proof}

The axioms of a model category imply that cofibrations have the LLP with
respect to trivial fibrations, and acyclic cofibrations have the LLP with
respect to fibrations. There are dual statements for fibrations. It turns out
that these properties \emph{characterize} cofibrations and fibrations (and
acyclic ones).


\begin{theorem}
Suppose $C$ is a model category. Then:
\begin{itemize}
\item [(1)] A map $f$ is a cofibration iff it has the left lifting property with respect to the class of acyclic fibrations.
\item [(2)] A map is a fibration iff it has the right lifting property w.r.t. the class of acyclic cofibrations.
\end{itemize}
\end{theorem}
\begin{proof}
Suppose you have a map $f$, that has LLP w.r.t. all acyclic fibrations and you want it to be a cofibration. (The other direction is an axiom.) Somehow we're going to have to get it to be a retract of a cofibration. Somehow you have to use factorization. Factor $f$:
\begin{xyxy}{
A\ar[d]^{f}\ar@{^(->}[rd] &
\\ X  & X'\ar@{->>}[l]^{\sim}
}\end{xyxy}
We had assumed that $f$ has LLP. There is a lift:
\begin{xyxy}{
A \ar@{^(->}[r]^i\ar[d]^{f} & X'\ar@{->>}[d]^{\sim}
\\X \ar[r]^{Id}\ar@{-->}[ru] & X
}\end{xyxy}
This implies that $f$ is a retract of $i$.
\begin{xyxy}{
A\ar[r]\ar[d]^f & A\ar@{^(->}[d]^{i}\ar[r] & A\ar[d]^{f}
\\X \ar@{..>}[r]^{\exists} & X' \ar[r] & X
}\end{xyxy}
\end{proof}
\begin{theorem}
\begin{itemize}
\item [(1)] A map $p$ is an acyclic fibration iff it has RLP w.r.t. cofibrations
\item [(2)] A map is an acyclic cofibration iff it has LLP w.r.t. all fibrations.
\end{itemize}
\end{theorem}
Suppose we know the cofibrations. Then we don't know the weak equivalences, or the fibrations, but we know the maps that are both. If we know the fibrations, we know the maps that are both weak equivalences and cofibrations. This is basically the same argument. One direction is easy: if a map is an acyclic fibration, it has the lifting property by the definitions. Conversely, suppose $f$ has RLP w.r.t. cofibrations. Factor this as a cofibration followed by an acyclic fibration.
\begin{xyxy}{
X\ar[r]^{Id}\ar@{^(->}[d] & X\ar[d]^f
\\Y'\ar@{->>}[r]^p_\sim \ar@{-->}[ru]& Y
}\end{xyxy}
$f$ is a retract of $p$; it is a weak equivalence because $p$ is a weak equivalence. It is a fibration by the previous theorem.
\begin{corollary}
A map is a weak equivalence iff it can be written as the product of an acyclic fibration and an acyclic cofibration.
\end{corollary}
We can always write
\begin{xyxy}{
&.\ar@{->>}[dr]^p &
\\.\ar[rr]^f\ar@{^(->}[ur]^\sim && .
}\end{xyxy}
By two out of three $f$ is a weak equivalence iff $p$ is. The class of weak equivalences is determined by the fibrations and cofibrations.
\begin{example} [Topological spaces]
The construction here is called the Serre model structure (although it was defined by Quillen). We have to define some maps.
\begin{itemize}
\item [(1)] The fibrations will be Serre fibrations.
\item [(2)] The weak equivalences will be weak homotopy equivalences
\item [(3)] The cofibrations are determined by the above classes of maps.
\end{itemize}
\end{example}
\begin{theorem}
A space equipped with these classes of maps is a model category.
\end{theorem}
\begin{proof}
More work than you realize. M1 is not a problem. The retract axiom is also obvious. (Any class that has the lifting property also has retracts.) The third property is also obvious: \emph{something is a weak equivalence iff when you apply some functor (homotopy), it becomes an isomorphism}. (This is important.) So we need lifting and factorization. One of the lifting axioms is also automatic, by the definition of a cofibration.
%\begin{xyxy}{
%	\ar[d]^{\sim} \ar[r] & .\ar@{->>}[d]^{\sim}
%	\\ .\ar[r]\ar@{-->}[ru] & .
%}\end{xyxy}
Let's start with the factorizations. Introduce two classes of maps:
$$ A = \{D^n \times \{0\} \to D^n \times [0,1] \st n \geq 0\} $$
$$ B = A \cup \{S^{n-1} \to D^n \st n \geq 0, S^{-1} = \emptyset\} $$
These are compact, in a category-theory sense. By definition of Serre fibrations, a map is a fibration iff it has the right lifting property with respect to $A$. A map is an acyclic fibration iff it has the RLP w.r.t. B. (This was on the homework.) I need another general fact:
\begin{proposition}
The class of maps having the left lifting property w.r.t. a class $P$ is closed under arbitrary coproducts, co-base change, and countable (or even transfinite) composition. By countable composition
$$ A_0 \hookrightarrow A_1 \to A_2 \to \cdots $$
we mean the map $A \to colim_n \ss A_n$.
\end{proposition}
Suppose I have a map $f_0: X_0 \to Y_0$. We want to produce a diagram:
\begin{xyxy}{
X_0\ar[r]\ar[dr]_{f_0}  &  X_1\ar[d]^{f_1}
\\&Y
}\end{xyxy}
We have $ \sqcup V \to \sqcup D$
where the disjoint union is taken over commutative diagrams
\begin{xyxy}{
V\ar[d]\ar[r]  &  X\ar[d]
\\ D \ar[r]  &  Y
}\end{xyxy}
where $V \to D$ is in $A$. Sometimes we call these lifting problems. For every lifting problem, we formally create a solution.
This gives a diagram:
\begin{xyxy}{
\sqcup V \ar[r]\ar[d] &  \sqcup D\ar[d]\ar[ddr] &
\\ X\ar[rrd]\ar[r]& X_1\ar[dr]^<<<<*--{f_1} &
\\ && Y
}\end{xyxy}
where we have subsequently made the pushout to $Y$. By construction, every lifting problem in $X_0$ can be solved in $X_1$.
\begin{xyxy}{
V \ar[r]\ar[d] &  X_0\ar[d]\ar@{^(->}[r]^k & X_1\ar[d]
\\D\ar[r]\ar@{-->}[ru]\ar@{..>}[rru]  & Y\ar[r] & Y
}\end{xyxy}
We know that every map in $A$ is a cofibration. Also, $\sqcup V \to \sqcup D$ is a homotopy equivalence. $k$ is an acylic cofibration because it is a weak equivalence (recall that it is a homotopy equivalence) and a cofibration.

Now we make a cone of $X_0 \to X_1 \to \cdots X_\infty$ into $Y$. The claim is that $f$ is a fibration:
\begin{xyxy}{
X\ar@{^(->}[r]^\sim \ar[dr]  &  X_\infty\ar[d]^f
\\ &Y
}\end{xyxy}
by which we mean
\begin{xyxy}{
V\ar[r]\ar[d]_{\ell}  &  X_n\ar[d]\ar[r]  &  X_{n+1}\ar[d]\ar[r] & X_\infty\ar[d]
\\D \ar@{-->}[ru]\ar[r] & Y \ar[r] & Y \ar[r] & Y
}\end{xyxy}
where $\ell \in A$. $V$ is compact Hausdorff. $X_\infty$ was a colimit along closed inclusions.

\end{proof}
So I owe you one lifting property, and the other factorization.

% ============================ chapters/license.tex}
\chapter{GNU Free Documentation License}

\phantomsection
\label{section-phantom}

\begin{center}

      Version 1.2, November 2002


Copyright \copyright 2000, 2001, 2002  Free Software Foundation, Inc.

\bigskip

    51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA

\bigskip

Everyone is permitted to copy and distribute verbatim copies
of this license document, but changing it is not allowed.
\end{center}


\begin{center}
{\bf\large Preamble}
\end{center}

The purpose of this License is to make a manual, textbook, or other
functional and useful document "free" in the sense of freedom: to
assure everyone the effective freedom to copy and redistribute it,
with or without modifying it, either commercially or noncommercially.
Secondarily, this License preserves for the author and publisher a way
to get credit for their work, while not being considered responsible
for modifications made by others.

This License is a kind of "copyleft", which means that derivative
works of the document must themselves be free in the same sense.  It
complements the GNU General Public License, which is a copyleft
license designed for free software.

We have designed this License in order to use it for manuals for free
software, because free software needs free documentation: a free
program should come with manuals providing the same freedoms that the
software does.  But this License is not limited to software manuals;
it can be used for any textual work, regardless of subject matter or
whether it is published as a printed book.  We recommend this License
principally for works whose purpose is instruction or reference.


\section{APPLICABILITY AND DEFINITIONS}
\label{section-applicability-and-definitions}

This License applies to any manual or other work, in any medium, that
contains a notice placed by the copyright holder saying it can be
distributed under the terms of this License.  Such a notice grants a
world-wide, royalty-free license, unlimited in duration, to use that
work under the conditions stated herein.  The \textbf{"Document"}, below,
refers to any such manual or work.  Any member of the public is a
licensee, and is addressed as \textbf{"you"}.  You accept the license if you
copy, modify or distribute the work in a way requiring permission
under copyright law.

A \textbf{"Modified Version"} of the Document means any work containing the
Document or a portion of it, either copied verbatim, or with
modifications and/or translated into another language.

A \textbf{"Secondary Section"} is a named appendix or a front-matter section of
the Document that deals exclusively with the relationship of the
publishers or authors of the Document to the Document's overall subject
(or to related matters) and contains nothing that could fall directly
within that overall subject.  (Thus, if the Document is in part a
textbook of mathematics, a Secondary Section may not explain any
mathematics.)  The relationship could be a matter of historical
connection with the subject or with related matters, or of legal,
commercial, philosophical, ethical or political position regarding
them.

The \textbf{"Invariant Sections"} are certain Secondary Sections whose titles
are designated, as being those of Invariant Sections, in the notice
that says that the Document is released under this License.  If a
section does not fit the above definition of Secondary then it is not
allowed to be designated as Invariant.  The Document may contain zero
Invariant Sections.  If the Document does not identify any Invariant
Sections then there are none.

The \textbf{"Cover Texts"} are certain short passages of text that are listed,
as Front-Cover Texts or Back-Cover Texts, in the notice that says that
the Document is released under this License.  A Front-Cover Text may
be at most 5 words, and a Back-Cover Text may be at most 25 words.

A \textbf{"Transparent"} copy of the Document means a machine-readable copy,
represented in a format whose specification is available to the
general public, that is suitable for revising the document
straightforwardly with generic text editors or (for images composed of
pixels) generic paint programs or (for drawings) some widely available
drawing editor, and that is suitable for input to text formatters or
for automatic translation to a variety of formats suitable for input
to text formatters.  A copy made in an otherwise Transparent file
format whose markup, or absence of markup, has been arranged to thwart
or discourage subsequent modification by readers is not Transparent.
An image format is not Transparent if used for any substantial amount
of text.  A copy that is not "Transparent" is called \textbf{"Opaque"}.

Examples of suitable formats for Transparent copies include plain
ASCII without markup, Texinfo input format, LaTeX input format, SGML
or XML using a publicly available DTD, and standard-conforming simple
HTML, PostScript or PDF designed for human modification.  Examples of
transparent image formats include PNG, XCF and JPG.  Opaque formats
include proprietary formats that can be read and edited only by
proprietary word processors, SGML or XML for which the DTD and/or
processing tools are not generally available, and the
machine-generated HTML, PostScript or PDF produced by some word
processors for output purposes only.

The \textbf{"Title Page"} means, for a printed book, the title page itself,
plus such following pages as are needed to hold, legibly, the material
this License requires to appear in the title page.  For works in
formats which do not have any title page as such, "Title Page" means
the text near the most prominent appearance of the work's title,
preceding the beginning of the body of the text.

A section \textbf{"Entitled XYZ"} means a named subunit of the Document whose
title either is precisely XYZ or contains XYZ in parentheses following
text that translates XYZ in another language.  (Here XYZ stands for a
specific section name mentioned below, such as \textbf{"Acknowledgements"},
\textbf{"Dedications"}, \textbf{"Endorsements"}, or \textbf{"History"}.)
To \textbf{"Preserve the Title"}
of such a section when you modify the Document means that it remains a
section "Entitled XYZ" according to this definition.

The Document may include Warranty Disclaimers next to the notice which
states that this License applies to the Document.  These Warranty
Disclaimers are considered to be included by reference in this
License, but only as regards disclaiming warranties: any other
implication that these Warranty Disclaimers may have is void and has
no effect on the meaning of this License.


\section{VERBATIM COPYING}
\label{section-verbatim-copying}

You may copy and distribute the Document in any medium, either
commercially or noncommercially, provided that this License, the
copyright notices, and the license notice saying this License applies
to the Document are reproduced in all copies, and that you add no other
conditions whatsoever to those of this License.  You may not use
technical measures to obstruct or control the reading or further
copying of the copies you make or distribute.  However, you may accept
compensation in exchange for copies.  If you distribute a large enough
number of copies you must also follow the conditions in section 3.

You may also lend copies, under the same conditions stated above, and
you may publicly display copies.


\section{COPYING IN QUANTITY}
\label{section-copying-in-quantity}


If you publish printed copies (or copies in media that commonly have
printed covers) of the Document, numbering more than 100, and the
Document's license notice requires Cover Texts, you must enclose the
copies in covers that carry, clearly and legibly, all these Cover
Texts: Front-Cover Texts on the front cover, and Back-Cover Texts on
the back cover.  Both covers must also clearly and legibly identify
you as the publisher of these copies.  The front cover must present
the full title with all words of the title equally prominent and
visible.  You may add other material on the covers in addition.
Copying with changes limited to the covers, as long as they preserve
the title of the Document and satisfy these conditions, can be treated
as verbatim copying in other respects.

If the required texts for either cover are too voluminous to fit
legibly, you should put the first ones listed (as many as fit
reasonably) on the actual cover, and continue the rest onto adjacent
pages.

If you publish or distribute Opaque copies of the Document numbering
more than 100, you must either include a machine-readable Transparent
copy along with each Opaque copy, or state in or with each Opaque copy
a computer-network location from which the general network-using
public has access to download using public-standard network protocols
a complete Transparent copy of the Document, free of added material.
If you use the latter option, you must take reasonably prudent steps,
when you begin distribution of Opaque copies in quantity, to ensure
that this Transparent copy will remain thus accessible at the stated
location until at least one year after the last time you distribute an
Opaque copy (directly or through your agents or retailers) of that
edition to the public.

It is requested, but not required, that you contact the authors of the
Document well before redistributing any large number of copies, to give
them a chance to provide you with an updated version of the Document.


\section{MODIFICATIONS}
\label{section-modifications}

You may copy and distribute a Modified Version of the Document under
the conditions of sections 2 and 3 above, provided that you release
the Modified Version under precisely this License, with the Modified
Version filling the role of the Document, thus licensing distribution
and modification of the Modified Version to whoever possesses a copy
of it.  In addition, you must do these things in the Modified Version:

\begin{itemize}
\item[A.]
   Use in the Title Page (and on the covers, if any) a title distinct
   from that of the Document, and from those of previous versions
   (which should, if there were any, be listed in the History section
   of the Document).  You may use the same title as a previous version
   if the original publisher of that version gives permission.

\item[B.]
   List on the Title Page, as authors, one or more persons or entities
   responsible for authorship of the modifications in the Modified
   Version, together with at least five of the principal authors of the
   Document (all of its principal authors, if it has fewer than five),
   unless they release you from this requirement.

\item[C.]
   State on the Title page the name of the publisher of the
   Modified Version, as the publisher.

\item[D.]
   Preserve all the copyright notices of the Document.

\item[E.]
   Add an appropriate copyright notice for your modifications
   adjacent to the other copyright notices.

\item[F.]
   Include, immediately after the copyright notices, a license notice
   giving the public permission to use the Modified Version under the
   terms of this License, in the form shown in the Addendum below.

\item[G.]
   Preserve in that license notice the full lists of Invariant Sections
   and required Cover Texts given in the Document's license notice.

\item[H.]
   Include an unaltered copy of this License.

\item[I.]
   Preserve the section Entitled "History", Preserve its Title, and add
   to it an item stating at least the title, year, new authors, and
   publisher of the Modified Version as given on the Title Page.  If
   there is no section Entitled "History" in the Document, create one
   stating the title, year, authors, and publisher of the Document as
   given on its Title Page, then add an item describing the Modified
   Version as stated in the previous sentence.

\item[J.]
   Preserve the network location, if any, given in the Document for
   public access to a Transparent copy of the Document, and likewise
   the network locations given in the Document for previous versions
   it was based on.  These may be placed in the "History" section.
   You may omit a network location for a work that was published at
   least four years before the Document itself, or if the original
   publisher of the version it refers to gives permission.

\item[K.]
   For any section Entitled "Acknowledgements" or "Dedications",
   Preserve the Title of the section, and preserve in the section all
   the substance and tone of each of the contributor acknowledgements
   and/or dedications given therein.

\item[L.]
   Preserve all the Invariant Sections of the Document,
   unaltered in their text and in their titles.  Section numbers
   or the equivalent are not considered part of the section titles.

\item[M.]
   Delete any section Entitled "Endorsements".  Such a section
   may not be included in the Modified Version.

\item[N.]
   Do not retitle any existing section to be Entitled "Endorsements"
   or to conflict in title with any Invariant Section.

\item[O.]
   Preserve any Warranty Disclaimers.
\end{itemize}

If the Modified Version includes new front-matter sections or
appendices that qualify as Secondary Sections and contain no material
copied from the Document, you may at your option designate some or all
of these sections as invariant.  To do this, add their titles to the
list of Invariant Sections in the Modified Version's license notice.
These titles must be distinct from any other section titles.

You may add a section Entitled "Endorsements", provided it contains
nothing but endorsements of your Modified Version by various
parties--for example, statements of peer review or that the text has
been approved by an organization as the authoritative definition of a
standard.

You may add a passage of up to five words as a Front-Cover Text, and a
passage of up to 25 words as a Back-Cover Text, to the end of the list
of Cover Texts in the Modified Version.  Only one passage of
Front-Cover Text and one of Back-Cover Text may be added by (or
through arrangements made by) any one entity.  If the Document already
includes a cover text for the same cover, previously added by you or
by arrangement made by the same entity you are acting on behalf of,
you may not add another; but you may replace the old one, on explicit
permission from the previous publisher that added the old one.

The author(s) and publisher(s) of the Document do not by this License
give permission to use their names for publicity for or to assert or
imply endorsement of any Modified Version.


\section{COMBINING DOCUMENTS}
\label{section-combining-documents}


You may combine the Document with other documents released under this
License, under the terms defined in section 4 above for modified
versions, provided that you include in the combination all of the
Invariant Sections of all of the original documents, unmodified, and
list them all as Invariant Sections of your combined work in its
license notice, and that you preserve all their Warranty Disclaimers.

The combined work need only contain one copy of this License, and
multiple identical Invariant Sections may be replaced with a single
copy.  If there are multiple Invariant Sections with the same name but
different contents, make the title of each such section unique by
adding at the end of it, in parentheses, the name of the original
author or publisher of that section if known, or else a unique number.
Make the same adjustment to the section titles in the list of
Invariant Sections in the license notice of the combined work.

In the combination, you must combine any sections Entitled "History"
in the various original documents, forming one section Entitled
"History"; likewise combine any sections Entitled "Acknowledgements",
and any sections Entitled "Dedications".  You must delete all sections
Entitled "Endorsements".

\section{COLLECTIONS OF DOCUMENTS}
\label{section-collections-of-documents}

You may make a collection consisting of the Document and other documents
released under this License, and replace the individual copies of this
License in the various documents with a single copy that is included in
the collection, provided that you follow the rules of this License for
verbatim copying of each of the documents in all other respects.

You may extract a single document from such a collection, and distribute
it individually under this License, provided you insert a copy of this
License into the extracted document, and follow this License in all
other respects regarding verbatim copying of that document.


\section{AGGREGATION WITH INDEPENDENT WORKS}
\label{section-aggregation-with-independent-works}


A compilation of the Document or its derivatives with other separate
and independent documents or works, in or on a volume of a storage or
distribution medium, is called an "aggregate" if the copyright
resulting from the compilation is not used to limit the legal rights
of the compilation's users beyond what the individual works permit.
When the Document is included in an aggregate, this License does not
apply to the other works in the aggregate which are not themselves
derivative works of the Document.

If the Cover Text requirement of section 3 is applicable to these
copies of the Document, then if the Document is less than one half of
the entire aggregate, the Document's Cover Texts may be placed on
covers that bracket the Document within the aggregate, or the
electronic equivalent of covers if the Document is in electronic form.
Otherwise they must appear on printed covers that bracket the whole
aggregate.


\section{TRANSLATION}
\label{section-translation}


Translation is considered a kind of modification, so you may
distribute translations of the Document under the terms of section 4.
Replacing Invariant Sections with translations requires special
permission from their copyright holders, but you may include
translations of some or all Invariant Sections in addition to the
original versions of these Invariant Sections.  You may include a
translation of this License, and all the license notices in the
Document, and any Warranty Disclaimers, provided that you also include
the original English version of this License and the original versions
of those notices and disclaimers.  In case of a disagreement between
the translation and the original version of this License or a notice
or disclaimer, the original version will prevail.

If a section in the Document is Entitled "Acknowledgements",
"Dedications", or "History", the requirement (section 4) to Preserve
its Title (section 1) will typically require changing the actual
title.


\section{TERMINATION}
\label{section-termination}


You may not copy, modify, sublicense, or distribute the Document except
as expressly provided for under this License.  Any other attempt to
copy, modify, sublicense or distribute the Document is void, and will
automatically terminate your rights under this License.  However,
parties who have received copies, or rights, from you under this
License will not have their licenses terminated so long as such
parties remain in full compliance.


\section{FUTURE REVISIONS OF THIS LICENSE}
\label{section-future-revisions-of-this-license}


The Free Software Foundation may publish new, revised versions
of the GNU Free Documentation License from time to time.  Such new
versions will be similar in spirit to the present version, but may
differ in detail to address new problems or concerns.  See
http://www.gnu.org/copyleft/.

Each version of the License is given a distinguishing version number.
If the Document specifies that a particular numbered version of this
License "or any later version" applies to it, you have the option of
following the terms and conditions either of that specified version or
of any later version that has been published (not as a draft) by the
Free Software Foundation.  If the Document does not specify a version
number of this License, you may choose any version ever published (not
as a draft) by the Free Software Foundation.


\section{ADDENDUM: How to use this License for your documents}
\label{section-addendum-how-to-use-this-license-for-your-doucments}

To use this License in a document you have written, include a copy of
the License in the document and put the following copyright and
license notices just after the title page:

\bigskip
\begin{quote}
    Copyright \copyright  YEAR  YOUR NAME.
    Permission is granted to copy, distribute and/or modify this document
    under the terms of the GNU Free Documentation License, Version 1.2
    or any later version published by the Free Software Foundation;
    with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts.
    A copy of the license is included in the section entitled "GNU
    Free Documentation License".
\end{quote}
\bigskip

If you have Invariant Sections, Front-Cover Texts and Back-Cover Texts,
replace the "with...Texts." line with this:

\bigskip
\begin{quote}
    with the Invariant Sections being LIST THEIR TITLES, with the
    Front-Cover Texts being LIST, and with the Back-Cover Texts being LIST.
\end{quote}
\bigskip

If you have Invariant Sections without Cover Texts, or some other
combination of the three, merge those two alternatives to suit the
situation.

If your document contains nontrivial examples of program code, we
recommend releasing these examples in parallel under your choice of
free software license, such as the GNU General Public License,
to permit their use in free software.

%---------------------------------------------------------------------



% ============================ other/biblio.tex}
\bibliographystyle{alpha}
\bibliography{other/references}


\end{document}
